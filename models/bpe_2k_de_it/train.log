2025-05-27 18:45:17,122 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_de_it
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                     cfg.data.train : data/bpe_2k/train.bpe
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                       cfg.data.dev : data/bpe_2k/dev.bpe
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                      cfg.data.test : data/bpe_2k/test.bpe
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : None
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : bpe
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : None
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : bpe
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-27 18:45:17,123 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_de_it
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-27 18:45:17,124 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-27 18:45:17,265 - INFO - joeynmt.data - Building tokenizer...
2025-05-27 18:49:27,775 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-27 18:49:27,776 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_de_it
2025-05-27 18:49:27,776 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-27 18:49:27,776 - INFO - joeynmt.helpers -                     cfg.data.train : data/bpe_2k/train.bpe
2025-05-27 18:49:27,776 - INFO - joeynmt.helpers -                       cfg.data.dev : data/bpe_2k/dev.bpe
2025-05-27 18:49:27,776 - INFO - joeynmt.helpers -                      cfg.data.test : data/bpe_2k/test.bpe
2025-05-27 18:49:27,776 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : None
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : None
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_de_it
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-27 18:49:27,777 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-27 18:49:27,778 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-27 18:49:27,915 - INFO - joeynmt.data - Building tokenizer...
2025-05-27 18:49:27,924 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 18:49:27,925 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 18:49:27,925 - INFO - joeynmt.data - Loading train set...
2025-05-27 18:49:28,108 - INFO - joeynmt.data - Building vocabulary...
2025-05-27 18:52:43,175 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_de_it
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -                     cfg.data.train : data/bpe_2k/train.bpe
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -                       cfg.data.dev : data/bpe_2k/dev.bpe
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -                      cfg.data.test : data/bpe_2k/test.bpe
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-27 18:52:43,176 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : None
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_de_it
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-27 18:52:43,177 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-27 18:52:43,178 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-27 18:52:43,315 - INFO - joeynmt.data - Building tokenizer...
2025-05-27 18:52:43,325 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 18:52:43,325 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 18:52:43,325 - INFO - joeynmt.data - Loading train set...
2025-05-27 18:52:43,513 - INFO - joeynmt.data - Building vocabulary...
2025-05-27 18:54:30,168 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-27 18:54:30,168 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_de_it
2025-05-27 18:54:30,168 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-27 18:54:30,168 - INFO - joeynmt.helpers -                     cfg.data.train : data/bpe_2k/train.bpe
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -                       cfg.data.dev : data/bpe_2k/dev.bpe
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -                      cfg.data.test : data/bpe_2k/test.bpe
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_de_it
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-27 18:54:30,169 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-27 18:54:30,170 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-27 18:54:30,309 - INFO - joeynmt.data - Building tokenizer...
2025-05-27 18:54:30,319 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 18:54:30,319 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 18:54:30,319 - INFO - joeynmt.data - Loading train set...
2025-05-27 18:54:30,502 - INFO - joeynmt.data - Building vocabulary...
2025-05-27 18:54:30,535 - INFO - joeynmt.data - Loading dev set...
2025-05-27 18:54:30,539 - INFO - joeynmt.data - Loading test set...
2025-05-27 18:54:30,543 - INFO - joeynmt.data - Data loaded.
2025-05-27 18:54:30,544 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 18:54:30,544 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=923, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 18:54:30,544 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1567, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 18:54:30,544 - INFO - joeynmt.data - First training example:
	[SRC] J@@ @@@ @ etzt er@@ @@@ @ inn@@ @@@ @ ern Sie sich , wir unter@@ @@@ @ su@@ @@@ @ chen G@@ @@@ @ ene .
	[TRG] R@@ @@@ @ ic@@ @@@ @ ord@@ @@@ @ ate che noi an@@ @@@ @ al@@ @@@ @ i@@ @@@ @ z@@ @@@ @ zi@@ @@@ @ amo i gen@@ @@@ @ i .
2025-05-27 18:54:30,544 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ! (5) # (6) $ (7) % (8) &#9@@ (9) &@@
2025-05-27 18:54:30,544 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ! (5) # (6) $ (7) % (8) &#9@@ (9) &@@
2025-05-27 18:54:30,544 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2000
2025-05-27 18:54:30,544 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2000
2025-05-27 18:54:30,551 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-27 18:54:30,691 - INFO - joeynmt.model - Enc-dec model built.
2025-05-27 18:54:30,701 - INFO - joeynmt.model - Total params: 3411200
2025-05-27 18:54:30,701 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2025-05-27 18:54:30,702 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-27 18:54:34,588 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-27 19:02:17,084 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_de_it
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                     cfg.data.train : data/bpe_2k/train.bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                       cfg.data.dev : data/bpe_2k/dev.bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                      cfg.data.test : data/bpe_2k/test.bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_de_it
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-27 19:02:17,087 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-27 19:02:17,087 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-27 19:02:17,087 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-27 19:02:17,087 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-27 19:02:17,225 - INFO - joeynmt.data - Building tokenizer...
2025-05-27 19:02:17,236 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 19:02:17,236 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 19:02:17,236 - INFO - joeynmt.data - Loading train set...
2025-05-27 19:02:17,426 - INFO - joeynmt.data - Building vocabulary...
2025-05-27 19:02:17,459 - INFO - joeynmt.data - Loading dev set...
2025-05-27 19:02:17,464 - INFO - joeynmt.data - Loading test set...
2025-05-27 19:02:17,470 - INFO - joeynmt.data - Data loaded.
2025-05-27 19:02:17,470 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 19:02:17,470 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=923, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 19:02:17,470 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1567, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 19:02:17,471 - INFO - joeynmt.data - First training example:
	[SRC] J@@ @@@ @ etzt er@@ @@@ @ inn@@ @@@ @ ern Sie sich , wir unter@@ @@@ @ su@@ @@@ @ chen G@@ @@@ @ ene .
	[TRG] R@@ @@@ @ ic@@ @@@ @ ord@@ @@@ @ ate che noi an@@ @@@ @ al@@ @@@ @ i@@ @@@ @ z@@ @@@ @ zi@@ @@@ @ amo i gen@@ @@@ @ i .
2025-05-27 19:02:17,471 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ! (5) # (6) $ (7) % (8) &#9@@ (9) &@@
2025-05-27 19:02:17,471 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ! (5) # (6) $ (7) % (8) &#9@@ (9) &@@
2025-05-27 19:02:17,471 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2000
2025-05-27 19:02:17,471 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2000
2025-05-27 19:02:17,478 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-27 19:02:17,547 - INFO - joeynmt.model - Enc-dec model built.
2025-05-27 19:02:17,555 - INFO - joeynmt.model - Total params: 3411200
2025-05-27 19:02:17,555 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2025-05-27 19:02:17,556 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-27 19:02:19,714 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-27 19:02:19,715 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-27 19:02:19,716 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-27 19:02:19,716 - INFO - joeynmt.training - EPOCH 1
2025-05-27 19:02:24,072 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     2.375705, Batch Acc: 0.431204, Tokens per Sec:    18396, Lr: 0.000300
2025-05-27 19:02:27,460 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.060086, Batch Acc: 0.479482, Tokens per Sec:    23769, Lr: 0.000300
2025-05-27 19:02:30,860 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.021719, Batch Acc: 0.493525, Tokens per Sec:    23355, Lr: 0.000300
2025-05-27 19:02:34,250 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.171319, Batch Acc: 0.495307, Tokens per Sec:    22977, Lr: 0.000300
2025-05-27 19:02:37,673 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.043835, Batch Acc: 0.498460, Tokens per Sec:    23345, Lr: 0.000300
2025-05-27 19:02:37,674 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:02:37,675 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:03:01,651 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.30, acc:   0.50, generation: 23.9608[sec], evaluation: 0.0000[sec]
2025-05-27 19:03:01,652 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:03:02,128 - INFO - joeynmt.training - Example #0
2025-05-27 19:03:02,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:03:02,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:03:02,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'e', '.', '</s>']
2025-05-27 19:03:02,130 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:03:02,130 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:03:02,130 - INFO - joeynmt.training - 	Hypothesis: E   la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la e .
2025-05-27 19:03:02,130 - INFO - joeynmt.training - Example #1
2025-05-27 19:03:02,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:03:02,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:03:02,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'e', '.', '</s>']
2025-05-27 19:03:02,131 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:03:02,131 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:03:02,132 - INFO - joeynmt.training - 	Hypothesis: E      la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la e .
2025-05-27 19:03:02,132 - INFO - joeynmt.training - Example #2
2025-05-27 19:03:02,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:03:02,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:03:02,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', '.', '</s>']
2025-05-27 19:03:02,133 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:03:02,133 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:03:02,133 - INFO - joeynmt.training - 	Hypothesis: E                            la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la .
2025-05-27 19:03:02,133 - INFO - joeynmt.training - Example #3
2025-05-27 19:03:02,133 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:03:02,133 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:03:02,133 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'e', '.', '</s>']
2025-05-27 19:03:02,133 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:03:02,134 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:03:02,134 - INFO - joeynmt.training - 	Hypothesis: E                                            la la la la la la la la la la e .
2025-05-27 19:03:02,134 - INFO - joeynmt.training - Example #4
2025-05-27 19:03:02,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:03:02,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:03:02,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', '.', '</s>']
2025-05-27 19:03:02,134 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:03:02,135 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:03:02,135 - INFO - joeynmt.training - 	Hypothesis: E                            la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la .
2025-05-27 19:03:05,652 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.020925, Batch Acc: 0.498667, Tokens per Sec:    20252, Lr: 0.000300
2025-05-27 19:03:09,207 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     1.892585, Batch Acc: 0.500728, Tokens per Sec:    22214, Lr: 0.000300
2025-05-27 19:03:12,700 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     1.863940, Batch Acc: 0.498636, Tokens per Sec:    22887, Lr: 0.000300
2025-05-27 19:03:16,146 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     1.925505, Batch Acc: 0.497653, Tokens per Sec:    23062, Lr: 0.000300
2025-05-27 19:03:19,568 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     1.982655, Batch Acc: 0.501826, Tokens per Sec:    22809, Lr: 0.000300
2025-05-27 19:03:19,569 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:03:19,569 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:03:40,158 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.04, acc:   0.50, generation: 20.5790[sec], evaluation: 0.0000[sec]
2025-05-27 19:03:40,159 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:03:40,643 - INFO - joeynmt.training - Example #0
2025-05-27 19:03:40,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:03:40,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:03:40,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'la', 'la', 'm@@', '<unk>', '@', 'o', ',', ',', ',', ',', ',', ',', ',', ',', 'la', 's@@', '<unk>', '@', 'o', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 's@@', '<unk>', '@', 'o', ',', ',', ',', ',', ',', ',', ',', 'la', 'la', '.', '</s>']
2025-05-27 19:03:40,644 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:03:40,644 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:03:40,644 - INFO - joeynmt.training - 	Hypothesis: E                             la la m<unk> @ o , , , , , , , , la s<unk> @ o , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , la la la la la la la la la la la la la la la la la la la la la la la la la la la s<unk> @ o , , , , , , , la la .
2025-05-27 19:03:40,644 - INFO - joeynmt.training - Example #1
2025-05-27 19:03:40,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:03:40,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:03:40,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'la', 'la', 'la', 'm@@', '<unk>', '@', 'o', ',', 'la', 's@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:03:40,645 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:03:40,645 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:03:40,645 - INFO - joeynmt.training - 	Hypothesis: E                            la la la m<unk> @ o , la s<unk> @ o .
2025-05-27 19:03:40,646 - INFO - joeynmt.training - Example #2
2025-05-27 19:03:40,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:03:40,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:03:40,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'la', 'm@@', '<unk>', '@', 'a', ',', ',', ',', ',', 'la', 'la', 'la', 'm@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:03:40,646 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:03:40,647 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:03:40,647 - INFO - joeynmt.training - 	Hypothesis: E                  la m<unk> @ a , , , , la la la m<unk> @ a .
2025-05-27 19:03:40,647 - INFO - joeynmt.training - Example #3
2025-05-27 19:03:40,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:03:40,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:03:40,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'm@@', '<unk>', '@', 'o', ',', 'la', 'm@@', '<unk>', '@', 'o', ',', 'la', 'm@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:03:40,647 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:03:40,647 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:03:40,648 - INFO - joeynmt.training - 	Hypothesis: E la m<unk> @ o , la m<unk> @ o , la m<unk> @ o .
2025-05-27 19:03:40,648 - INFO - joeynmt.training - Example #4
2025-05-27 19:03:40,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:03:40,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:03:40,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ',', ',', ',', ',', ',', ',', ',', ',', ',', 'la', '.', '</s>']
2025-05-27 19:03:40,648 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:03:40,649 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:03:40,649 - INFO - joeynmt.training - 	Hypothesis: E                                               , , , , , , , , , la .
2025-05-27 19:03:43,974 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     1.986058, Batch Acc: 0.504054, Tokens per Sec:    20755, Lr: 0.000300
2025-05-27 19:03:47,299 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     1.910730, Batch Acc: 0.501730, Tokens per Sec:    23653, Lr: 0.000300
2025-05-27 19:03:50,554 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     1.947831, Batch Acc: 0.505690, Tokens per Sec:    24389, Lr: 0.000300
2025-05-27 19:03:53,785 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     1.876700, Batch Acc: 0.502200, Tokens per Sec:    25053, Lr: 0.000300
2025-05-27 19:03:57,035 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     1.945475, Batch Acc: 0.503745, Tokens per Sec:    25022, Lr: 0.000300
2025-05-27 19:03:57,035 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:03:57,035 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:04:15,214 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.92, acc:   0.51, generation: 18.1670[sec], evaluation: 0.0000[sec]
2025-05-27 19:04:15,215 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:04:15,736 - INFO - joeynmt.training - Example #0
2025-05-27 19:04:15,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:04:15,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:04:15,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', 'che', '', 'che', '', 'che', '', '', '', '', ',', 'che', '', ',', 'la', 'mondo', ',', 'che', 'la', 'mondo', ',', 'che', 'la', 'mondo', ',', 'che', 'la', 'mondo', ',', 'che', '', ',', 'che', 'la', 'mondo', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'e', ',', 'la', 'mondo', '.', '</s>']
2025-05-27 19:04:15,738 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:04:15,738 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:04:15,738 - INFO - joeynmt.training - 	Hypothesis: E       che  che  che     , che  , la mondo , che la mondo , che la mondo , che la mondo , che  , che la mondo , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , la mondo .
2025-05-27 19:04:15,738 - INFO - joeynmt.training - Example #1
2025-05-27 19:04:15,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:04:15,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:04:15,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-27 19:04:15,739 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:04:15,739 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:04:15,739 - INFO - joeynmt.training - 	Hypothesis: E non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-27 19:04:15,739 - INFO - joeynmt.training - Example #2
2025-05-27 19:04:15,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:04:15,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:04:15,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mondo', ',', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ',', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '.', '</s>']
2025-05-27 19:04:15,740 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:04:15,740 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:04:15,740 - INFO - joeynmt.training - 	Hypothesis: Il mondo ,               ,                                              .
2025-05-27 19:04:15,740 - INFO - joeynmt.training - Example #3
2025-05-27 19:04:15,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:04:15,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:04:15,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', '<unk>', '@', 'a', ',', 'e', 'la', 'mondo', ',', 'e', 'la', 'mondo', ',', 'e', 'la', 'mondo', ',', 'e', 'la', 'mondo', '.', '</s>']
2025-05-27 19:04:15,741 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:04:15,741 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:04:15,741 - INFO - joeynmt.training - 	Hypothesis: C<unk> @ a , e la mondo , e la mondo , e la mondo , e la mondo .
2025-05-27 19:04:15,741 - INFO - joeynmt.training - Example #4
2025-05-27 19:04:15,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:04:15,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:04:15,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '.', '</s>']
2025-05-27 19:04:15,742 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:04:15,742 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:04:15,742 - INFO - joeynmt.training - 	Hypothesis: E                                                                       .
2025-05-27 19:04:19,202 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     1.902544, Batch Acc: 0.505508, Tokens per Sec:    20085, Lr: 0.000300
2025-05-27 19:04:22,616 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     1.960353, Batch Acc: 0.508130, Tokens per Sec:    23664, Lr: 0.000300
2025-05-27 19:04:26,012 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     1.942113, Batch Acc: 0.504558, Tokens per Sec:    23427, Lr: 0.000300
2025-05-27 19:04:29,391 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     1.928912, Batch Acc: 0.507378, Tokens per Sec:    22848, Lr: 0.000300
2025-05-27 19:04:32,778 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     1.947224, Batch Acc: 0.508230, Tokens per Sec:    23594, Lr: 0.000300
2025-05-27 19:04:32,779 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:04:32,779 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:04:54,429 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.75, acc:   0.51, generation: 21.6406[sec], evaluation: 0.0000[sec]
2025-05-27 19:04:54,430 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:04:54,921 - INFO - joeynmt.training - Example #0
2025-05-27 19:04:54,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:04:54,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:04:54,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'ho', 'ho', 'ho', 'ho', 'ho', 'un', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mondo', ',', 'e', 'la', 'm@@', '<unk>', '@', 'o', ',', 'e', 'il', 'mondo', ',', 'e', 'la', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', ',', 'e', 'il', 'mondo', '.', '</s>']
2025-05-27 19:04:54,923 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:04:54,923 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:04:54,923 - INFO - joeynmt.training - 	Hypothesis: E ho ho ho ho ho ho un mio mio mio mio mio mio mio mio mio mio mio mondo , e la m<unk> @ o , e il mondo , e la mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo .
2025-05-27 19:04:54,923 - INFO - joeynmt.training - Example #1
2025-05-27 19:04:54,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:04:54,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:04:54,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'la', 'mondo', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:04:54,924 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:04:54,924 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:04:54,924 - INFO - joeynmt.training - 	Hypothesis: Ma non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non la mondo <unk> @ o .
2025-05-27 19:04:54,924 - INFO - joeynmt.training - Example #2
2025-05-27 19:04:54,924 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:04:54,924 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:04:54,924 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', 'un', 'p@@', '<unk>', '@', 'o', ',', '', 'un', 'p@@', '<unk>', '@', 'o', ',', '', 'un', 'p@@', '<unk>', '@', 'o', ',', '', 'un', 'p@@', '<unk>', '@', 'o', ',', '', 'un', 'p@@', '<unk>', '@', 'o', ',', '', 'un', 'p@@', '<unk>', '@', 'o', ',', '', 'un', 'p@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:04:54,925 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:04:54,925 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:04:54,925 - INFO - joeynmt.training - 	Hypothesis: E  un p<unk> @ o ,  un p<unk> @ o ,  un p<unk> @ o ,  un p<unk> @ o ,  un p<unk> @ o ,  un p<unk> @ o ,  un p<unk> @ o .
2025-05-27 19:04:54,925 - INFO - joeynmt.training - Example #3
2025-05-27 19:04:54,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:04:54,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:04:54,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', '<unk>', '@', 'e', 'la', 's@@', '<unk>', '@', 'o', ',', 'e', 'il', 'mio', 'mio', 'mio', 'mio', 'mio', 'm@@', '<unk>', '@', 'o', ',', 'e', 'il', 'mio', 'm@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:04:54,926 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:04:54,926 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:04:54,926 - INFO - joeynmt.training - 	Hypothesis: C<unk> @ e la s<unk> @ o , e il mio mio mio mio mio m<unk> @ o , e il mio m<unk> @ o .
2025-05-27 19:04:54,926 - INFO - joeynmt.training - Example #4
2025-05-27 19:04:54,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:04:54,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:04:54,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'ho', 'ho', 'ho', 'ho', 'ho', 'un', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'm@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:04:54,927 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:04:54,927 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:04:54,927 - INFO - joeynmt.training - 	Hypothesis: E ho ho ho ho ho ho un mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio m<unk> @ o .
2025-05-27 19:04:58,297 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     1.972605, Batch Acc: 0.510490, Tokens per Sec:    20709, Lr: 0.000300
2025-05-27 19:05:01,669 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     1.915320, Batch Acc: 0.509307, Tokens per Sec:    22818, Lr: 0.000300
2025-05-27 19:05:05,047 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     1.915236, Batch Acc: 0.510479, Tokens per Sec:    23274, Lr: 0.000300
2025-05-27 19:05:08,446 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     1.875664, Batch Acc: 0.510589, Tokens per Sec:    23552, Lr: 0.000300
2025-05-27 19:05:11,819 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     1.883425, Batch Acc: 0.510943, Tokens per Sec:    22910, Lr: 0.000300
2025-05-27 19:05:11,820 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:05:11,820 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:05:31,303 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.63, acc:   0.51, generation: 19.4690[sec], evaluation: 0.0000[sec]
2025-05-27 19:05:31,304 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:05:31,842 - INFO - joeynmt.training - Example #0
2025-05-27 19:05:31,843 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:05:31,843 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:05:31,843 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', ',', 'se', ',', 'se', ',', 'se', 'se', ',', 'se', ',', 'se', 'se', 'se', 'se', ',', 'se', 'se', 'se', 'se', 'se', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'che', 'la', ',', 'che', 'la', ',', 'che', 'la', ',', 'che', 'la', ',', 'che', 'la', ',', 'che', 'la', ',', 'che', 'la', ',', 'che', 'la', ',', 'che', 'la', ',', 'che', 'la', '.', '</s>']
2025-05-27 19:05:31,844 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:05:31,844 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:05:31,844 - INFO - joeynmt.training - 	Hypothesis: E questo , se , se , se se , se , se se se se , se se se se se , ma , ma , ma , ma , ma , ma , che la , che la , che la , che la , che la , che la , che la , che la , che la , che la .
2025-05-27 19:05:31,844 - INFO - joeynmt.training - Example #1
2025-05-27 19:05:31,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:05:31,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:05:31,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', '', 'una', '.', '</s>']
2025-05-27 19:05:31,845 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:05:31,845 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:05:31,845 - INFO - joeynmt.training - 	Hypothesis: Ma non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non  una .
2025-05-27 19:05:31,845 - INFO - joeynmt.training - Example #2
2025-05-27 19:05:31,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:05:31,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:05:31,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['', 'un', 'p@@', '<unk>', '@', 'a', ',', '', 'un', 'p@@', '<unk>', '@', 'a', ',', '', 'una', 'p@@', '<unk>', '@', 'o', ',', 'la', 'sua', 'p@@', '<unk>', '@', 'a', ',', 'la', 'sua', 'p@@', '<unk>', '@', 'a', ',', 'la', 'sua', 'p@@', '<unk>', '@', 'a', ',', 'la', '.', '</s>']
2025-05-27 19:05:31,846 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:05:31,846 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:05:31,847 - INFO - joeynmt.training - 	Hypothesis:  un p<unk> @ a ,  un p<unk> @ a ,  una p<unk> @ o , la sua p<unk> @ a , la sua p<unk> @ a , la sua p<unk> @ a , la .
2025-05-27 19:05:31,847 - INFO - joeynmt.training - Example #3
2025-05-27 19:05:31,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:05:31,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:05:31,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Non', 'sono', 'sono', 'sono', 'sono', 'un', 'p@@', '<unk>', '@', 'a', ',', 'e', 'i', 'e', 'i', 'm@@', '<unk>', '@', 'o', ',', 'e', 'e', 'e', 'e', ',', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', '.', '</s>']
2025-05-27 19:05:31,847 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:05:31,847 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:05:31,847 - INFO - joeynmt.training - 	Hypothesis: Non sono sono sono sono un p<unk> @ a , e i e i m<unk> @ o , e e e e , e e e e e e e e e e e e e e e e .
2025-05-27 19:05:31,848 - INFO - joeynmt.training - Example #4
2025-05-27 19:05:31,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:05:31,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:05:31,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '', 'un', 'mio', 'cosa', '', 'un', 'altro', ',', '', 'un', 'po', '&apos;', 'cosa', '', 'un', 'po', '&apos;', 'un', 'po', '&apos;', 'un', 'po', '&apos;', 'un', 'po', '&apos;', 'un', 'altro', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', ',', 'ma', '.', '</s>']
2025-05-27 19:05:31,848 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:05:31,848 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:05:31,848 - INFO - joeynmt.training - 	Hypothesis: E  un mio cosa  un altro ,  un po &apos; cosa  un po &apos; un po &apos; un po &apos; un po &apos; un altro , ma , ma , ma , ma , ma , ma , ma , ma , ma , ma , ma .
2025-05-27 19:05:35,255 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     1.863181, Batch Acc: 0.511785, Tokens per Sec:    20048, Lr: 0.000300
2025-05-27 19:05:38,647 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     1.853239, Batch Acc: 0.515497, Tokens per Sec:    23459, Lr: 0.000300
2025-05-27 19:05:42,051 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     1.879747, Batch Acc: 0.515161, Tokens per Sec:    24180, Lr: 0.000300
2025-05-27 19:05:45,424 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     1.856018, Batch Acc: 0.515862, Tokens per Sec:    24220, Lr: 0.000300
2025-05-27 19:05:48,809 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     1.795134, Batch Acc: 0.520147, Tokens per Sec:    23341, Lr: 0.000300
2025-05-27 19:05:48,809 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:05:48,809 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:06:14,774 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.26, acc:   0.52, generation: 25.9496[sec], evaluation: 0.0000[sec]
2025-05-27 19:06:14,775 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:06:15,245 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/500.ckpt
2025-05-27 19:06:15,268 - INFO - joeynmt.training - Example #0
2025-05-27 19:06:15,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:06:15,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:06:15,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', '', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'av@@', '<unk>', '@', 'rebbe', 'che', 'la', 'mia', 'f@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ato', 'che', 'che', 'che', 'la', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', ',', 'che', 'la', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'f@@', '<unk>', '@', 'i@@', '<unk>', '@', 'i@@', '<unk>', '@', 'i', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'persone', 'che', 'la', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'c@@', '<unk>', '@', 'are', '.', '</s>']
2025-05-27 19:06:15,269 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:06:15,269 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:06:15,269 - INFO - joeynmt.training - 	Hypothesis: E questo  che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che av<unk> @ rebbe che la mia f<unk> @ or<unk> @ i<unk> @ ato che che che la sua sua sua sua sua sua sua sua sua sua sua sua sua , che la sua sua sua sua sua sua sua f<unk> @ i<unk> @ i<unk> @ i di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di persone che la sua sua sua sua sua sua sua c<unk> @ are .
2025-05-27 19:06:15,269 - INFO - joeynmt.training - Example #1
2025-05-27 19:06:15,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:06:15,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:06:15,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'una', 'cosa', 'non', '', 'una', 'cosa', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', '', 'una', 'cosa', 'non', '', 'una', 'cosa', 'non', '', 'una', 'cosa', 'non', '', 'una', 'cosa', 'non', '', 'una', 'cosa', 'che', 'non', '', 'una', 'cosa', 'non', 'non', 'non', 'non', 'non', 'non', 'non', '', 'un', 'po', 'a', 'un', 'po', 'i@@', '<unk>', '@', 'are', '.', '</s>']
2025-05-27 19:06:15,270 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:06:15,270 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:06:15,270 - INFO - joeynmt.training - 	Hypothesis: Ma non  una cosa non  una cosa non non non non non non non non non non non non non non non non non non non non non non non non non  una cosa non  una cosa non  una cosa non  una cosa non  una cosa che non  una cosa non non non non non non non  un po a un po i<unk> @ are .
2025-05-27 19:06:15,270 - INFO - joeynmt.training - Example #2
2025-05-27 19:06:15,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:06:15,271 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:06:15,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', '', 'una', 'b@@', '<unk>', '@', 'i@@', '<unk>', '@', 'a', '', 'una', 'b@@', '<unk>', '@', 'i@@', '<unk>', '@', 'a', ',', 'la', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', '.', '</s>']
2025-05-27 19:06:15,271 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:06:15,271 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:06:15,271 - INFO - joeynmt.training - 	Hypothesis: La sua sua sua sua sua sua sua  una b<unk> @ i<unk> @ a  una b<unk> @ i<unk> @ a , la sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua .
2025-05-27 19:06:15,271 - INFO - joeynmt.training - Example #3
2025-05-27 19:06:15,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:06:15,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:06:15,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'se', 'av@@', '<unk>', '@', 'ete', 'un', 'p@@', '<unk>', '@', 'o@@', '<unk>', '@', 'o@@', '<unk>', '@', 'o@@', '<unk>', '@', 'o@@', '<unk>', '@', 'i@@', '<unk>', '@', 'o', 'e', '.', '</s>']
2025-05-27 19:06:15,272 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:06:15,272 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:06:15,272 - INFO - joeynmt.training - 	Hypothesis: E se av<unk> @ ete un p<unk> @ o<unk> @ o<unk> @ o<unk> @ o<unk> @ i<unk> @ o e .
2025-05-27 19:06:15,272 - INFO - joeynmt.training - Example #4
2025-05-27 19:06:15,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:06:15,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:06:15,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'cosa', 'che', '', 'una', 'cosa', 'che', 'la', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'f@@', '<unk>', '@', 'at@@', '<unk>', '@', 'at@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ato', '.', '</s>']
2025-05-27 19:06:15,273 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:06:15,273 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:06:15,273 - INFO - joeynmt.training - 	Hypothesis: La mia mia mia mia mia mia mia mia mia mia mia mia mia mia cosa che  una cosa che la mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia f<unk> @ at<unk> @ at<unk> @ i<unk> @ ato .
2025-05-27 19:06:18,694 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     1.818535, Batch Acc: 0.520575, Tokens per Sec:    20446, Lr: 0.000300
2025-05-27 19:06:22,111 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     1.876826, Batch Acc: 0.522271, Tokens per Sec:    23532, Lr: 0.000300
2025-05-27 19:06:25,495 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     1.760885, Batch Acc: 0.525896, Tokens per Sec:    23075, Lr: 0.000300
2025-05-27 19:06:28,891 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     1.814273, Batch Acc: 0.530121, Tokens per Sec:    23221, Lr: 0.000300
2025-05-27 19:06:32,291 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     1.756444, Batch Acc: 0.531600, Tokens per Sec:    23160, Lr: 0.000300
2025-05-27 19:06:32,292 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:06:32,292 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:06:45,205 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.54, generation: 12.9012[sec], evaluation: 0.0000[sec]
2025-05-27 19:06:45,205 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:06:45,801 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/1000.ckpt
2025-05-27 19:06:45,816 - INFO - joeynmt.training - Example #0
2025-05-27 19:06:45,817 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:06:45,817 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:06:45,817 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'av@@', '<unk>', '@', 'ete', ',', 'sono', 'le', 'persone', 'che', 'ha', 'detto', 'che', 'av@@', '<unk>', '@', 'ete', ',', 'che', 'i', 'm@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i@@', '<unk>', '@', 'enti', 'che', 'si', 'si', 'av@@', '<unk>', '@', 'ete', ',', 'che', 'i', 'sono', 'sono', '1@@', '<unk>', '@', '0', ',', 'sono', 'sono', 'sono', '1@@', '<unk>', '@', '0', 'anni', ',', 'e', 'i', 'sono', 'sono', 'sono', '1@@', '<unk>', '@', '0', ',', 'per', '1@@', '<unk>', '@', '00', 'anni', ',', 'sono', '1@@', '<unk>', '@', '0', ',', 'sono', '1@@', '<unk>', '@', '00', 'anni', '.', '</s>']
2025-05-27 19:06:45,818 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:06:45,818 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:06:45,818 - INFO - joeynmt.training - 	Hypothesis: E ho detto che ho detto che ho detto che ho detto che ho detto che ho detto che ho detto che av<unk> @ ete , sono le persone che ha detto che av<unk> @ ete , che i m<unk> @ ec<unk> @ i<unk> @ enti che si si av<unk> @ ete , che i sono sono 1<unk> @ 0 , sono sono sono 1<unk> @ 0 anni , e i sono sono sono 1<unk> @ 0 , per 1<unk> @ 00 anni , sono 1<unk> @ 0 , sono 1<unk> @ 00 anni .
2025-05-27 19:06:45,818 - INFO - joeynmt.training - Example #1
2025-05-27 19:06:45,818 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:06:45,818 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:06:45,818 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 's@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ale', ',', 'non', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 's@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ale', ',', 'non', 'si', 'si', 'si', 'si', 'si', '.', '</s>']
2025-05-27 19:06:45,819 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:06:45,819 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:06:45,819 - INFO - joeynmt.training - 	Hypothesis: Ma non si si si si si si si si si si si si s<unk> @ ent<unk> @ ale , non si si si si si si si si si si si si si si si s<unk> @ ent<unk> @ ale , non si si si si si .
2025-05-27 19:06:45,819 - INFO - joeynmt.training - Example #2
2025-05-27 19:06:45,819 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:06:45,819 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:06:45,819 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'parte', 'di', 'questo', '', 'il', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'pa@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ica', ',', '', 'il', 'mondo', '.', '</s>']
2025-05-27 19:06:45,819 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Hypothesis: La parte di questo  il nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro pa<unk> @ ic<unk> @ ica ,  il mondo .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - Example #3
2025-05-27 19:06:45,820 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:06:45,820 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:06:45,820 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'i', ',', 'e', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 's@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ato', '.', '</s>']
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ i , e si si si si si si si si s<unk> @ ent<unk> @ ato .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - Example #4
2025-05-27 19:06:45,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:06:45,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:06:45,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', ',', 'se', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'ho', 'detto', 'che', 'la', 'mia', 'mia', 'mia', 'mia', 'parte', 'di', 'un', 'po', '&apos;', '', 'che', 'si', 'si', 'si', 'si', 'si', 'si', 'av@@', '<unk>', '@', 'ete', '.', '</s>']
2025-05-27 19:06:45,821 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:06:45,821 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:06:45,821 - INFO - joeynmt.training - 	Hypothesis: La prima , se ho detto che ho detto che ho detto che ho detto che la mia mia mia mia parte di un po &apos;  che si si si si si si av<unk> @ ete .
2025-05-27 19:06:49,183 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     1.725436, Batch Acc: 0.537382, Tokens per Sec:    20325, Lr: 0.000300
2025-05-27 19:06:52,611 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     1.689029, Batch Acc: 0.542396, Tokens per Sec:    23321, Lr: 0.000300
2025-05-27 19:06:56,034 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     1.685906, Batch Acc: 0.546390, Tokens per Sec:    23076, Lr: 0.000300
2025-05-27 19:06:59,450 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     1.645360, Batch Acc: 0.549287, Tokens per Sec:    22848, Lr: 0.000300
2025-05-27 19:07:02,894 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     1.601819, Batch Acc: 0.551824, Tokens per Sec:    23033, Lr: 0.000300
2025-05-27 19:07:02,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:07:02,895 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:07:20,778 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.56, generation: 17.8701[sec], evaluation: 0.0000[sec]
2025-05-27 19:07:20,779 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:07:21,472 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/1500.ckpt
2025-05-27 19:07:21,496 - INFO - joeynmt.training - Example #0
2025-05-27 19:07:21,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:07:21,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:07:21,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'detto', 'che', 'ho', 'detto', ',', 'ho', 'detto', 'che', 'ho', 'detto', ',', 'mi', 'sono', 'stato', 'stato', 'stato', 'stato', 'di', 'c@@', '<unk>', '@', 'ento', 'di', 'ri@@', '<unk>', '@', 'vol@@', '<unk>', '@', 'ere', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'i', ',', 'che', 'la', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'che', 'la', 'nostra', 'nostra', 's@@', '<unk>', '@', 'ett@@', '<unk>', '@', 'azione', 'di', 'persone', 'che', 'hanno', 'ri@@', '<unk>', '@', 'vol@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ppo', 'di', 'di', 'di', 'persone', 'che', 'la', 'nostra', 's@@', '<unk>', '@', 'es@@', '<unk>', '@', 'peri@@', '<unk>', '@', 'enza', 'di', '1@@', '<unk>', '@', '0@@', '<unk>', '@', '0@@', '<unk>', '@', '0', '.', '</s>']
2025-05-27 19:07:21,497 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:07:21,498 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:07:21,498 - INFO - joeynmt.training - 	Hypothesis: E ho detto che ho detto , ho detto che ho detto , mi sono stato stato stato stato di c<unk> @ ento di ri<unk> @ vol<unk> @ ere la c<unk> @ ur<unk> @ i , che la nostra nostra nostra nostra nostra c<unk> @ ult<unk> @ ura che la nostra nostra s<unk> @ ett<unk> @ azione di persone che hanno ri<unk> @ vol<unk> @ u<unk> @ ppo di di di persone che la nostra s<unk> @ es<unk> @ peri<unk> @ enza di 1<unk> @ 0<unk> @ 0<unk> @ 0 .
2025-05-27 19:07:21,498 - INFO - joeynmt.training - Example #1
2025-05-27 19:07:21,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:07:21,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:07:21,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'la', 'nostra', 'vita', ',', 'non', 'non', 'non', '', 'la', 'nostra', 'vita', ',', 'non', '', 'la', 'nostra', 'cosa', 'che', 'la', 'nostra', 'nostra', 'vita', ',', 'non', '', 'la', 'nostra', 'vita', ',', 'non', '', 'la', 'nostra', 'cosa', 'non', '', 'la', 'nostra', 'vita', '.', '</s>']
2025-05-27 19:07:21,499 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:07:21,499 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:07:21,499 - INFO - joeynmt.training - 	Hypothesis: Ma non  la nostra vita , non non non  la nostra vita , non  la nostra cosa che la nostra nostra vita , non  la nostra vita , non  la nostra cosa non  la nostra vita .
2025-05-27 19:07:21,499 - INFO - joeynmt.training - Example #2
2025-05-27 19:07:21,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:07:21,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:07:21,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostra', 'nostra', 'nostra', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ale', ',', '', 'la', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'i', ',', 'la', 'nostra', 'nostra', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ale', ',', 'la', 'la', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'm@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 19:07:21,500 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:07:21,500 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:07:21,500 - INFO - joeynmt.training - 	Hypothesis: E la nostra nostra nostra c<unk> @ ur<unk> @ ale ,  la la c<unk> @ ur<unk> @ i , la nostra nostra c<unk> @ ur<unk> @ ale , la la con<unk> @ si<unk> @ m<unk> @ esso .
2025-05-27 19:07:21,500 - INFO - joeynmt.training - Example #3
2025-05-27 19:07:21,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:07:21,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:07:21,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'i', 'miei', 'miei', 'miei', 'miei', 'miei', 'miei', 'miei', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ist@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:07:21,501 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:07:21,501 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:07:21,501 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ i miei miei miei miei miei miei miei p<unk> @ es<unk> @ ist<unk> @ a .
2025-05-27 19:07:21,501 - INFO - joeynmt.training - Example #4
2025-05-27 19:07:21,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:07:21,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:07:21,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'che', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'mi', 'sono', 'sono', 'un', 'po', '&apos;', 'di', 'un', 'po', '&apos;', 'di', 'c@@', '<unk>', '@', 'ento', 'di', 's@@', '<unk>', '@', 'etti@@', '<unk>', '@', 'vo', '.', '</s>']
2025-05-27 19:07:21,502 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:07:21,502 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:07:21,502 - INFO - joeynmt.training - 	Hypothesis: La cosa che mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi sono sono un po &apos; di un po &apos; di c<unk> @ ento di s<unk> @ etti<unk> @ vo .
2025-05-27 19:07:24,942 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     1.634318, Batch Acc: 0.552202, Tokens per Sec:    18982, Lr: 0.000300
2025-05-27 19:07:28,369 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     1.645152, Batch Acc: 0.556187, Tokens per Sec:    23316, Lr: 0.000300
2025-05-27 19:07:31,768 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     1.622139, Batch Acc: 0.558895, Tokens per Sec:    23667, Lr: 0.000300
2025-05-27 19:07:35,164 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     1.614781, Batch Acc: 0.560197, Tokens per Sec:    22735, Lr: 0.000300
2025-05-27 19:07:38,566 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     1.600858, Batch Acc: 0.561609, Tokens per Sec:    23440, Lr: 0.000300
2025-05-27 19:07:38,567 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:07:38,567 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:07:56,686 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.74, acc:   0.56, generation: 18.1104[sec], evaluation: 0.0000[sec]
2025-05-27 19:07:56,687 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:07:57,131 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/2000.ckpt
2025-05-27 19:07:57,154 - INFO - joeynmt.training - Example #0
2025-05-27 19:07:57,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:07:57,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:07:57,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'fatto', 'il', 'mio', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', ',', 'che', 'le', 'nostr@@', '<unk>', '@', 'e', 's@@', '<unk>', '@', 'etti@@', '<unk>', '@', 'man@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'ento', 'di', '1@@', '<unk>', '@', '00', '%', 'di', 'persone', 'che', 'hanno', 'fatto', 'che', 'hanno', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'te', 'le', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ppo', 'di', 'persone', 'che', 'hanno', 'fatto', 'di', '1@@', '<unk>', '@', '00', '%', 'di', 'doll@@', '<unk>', '@', 'ari', '.', '</s>']
2025-05-27 19:07:57,156 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:07:57,156 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:07:57,156 - INFO - joeynmt.training - 	Hypothesis: E ho fatto che ho fatto che ho fatto che ho fatto che ho fatto fatto il mio p<unk> @ op<unk> @ ol<unk> @ i , che le nostr<unk> @ e s<unk> @ etti<unk> @ man<unk> @ a di c<unk> @ ento di 1<unk> @ 00 % di persone che hanno fatto che hanno sc<unk> @ u<unk> @ te le persone che hanno sc<unk> @ u<unk> @ ppo di persone che hanno fatto di 1<unk> @ 00 % di doll<unk> @ ari .
2025-05-27 19:07:57,156 - INFO - joeynmt.training - Example #1
2025-05-27 19:07:57,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:07:57,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:07:57,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'il', 'mio', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'po', 'non', '', 'il', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'po', ',', 'che', 'non', 'si', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'da', 'un', 'po', '&apos;', 'di', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', ',', 'non', '', 'che', 'non', 'si', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'da', 'un', 'po', '&apos;', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:07:57,157 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:07:57,157 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:07:57,157 - INFO - joeynmt.training - 	Hypothesis: Ma non  il mio p<unk> @ op<unk> @ po non  il p<unk> @ op<unk> @ po , che non si ri<unk> @ guar<unk> @ da un po &apos; di c<unk> @ ult<unk> @ ura , non  che non si ri<unk> @ guar<unk> @ da un po &apos; di c<unk> @ aus<unk> @ a .
2025-05-27 19:07:57,157 - INFO - joeynmt.training - Example #2
2025-05-27 19:07:57,157 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:07:57,157 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:07:57,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'nostro', 'nostro', 'nostro', 'nostro', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', '', 'il', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ale', '', 'il', 'nostro', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'di', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ale', ',', 'che', 'si', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'da', 'un', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'po', '.', '</s>']
2025-05-27 19:07:57,158 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:07:57,158 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:07:57,158 - INFO - joeynmt.training - 	Hypothesis: Il nostro nostro nostro nostro c<unk> @ ult<unk> @ ura  il c<unk> @ ur<unk> @ ale  il nostro c<unk> @ ult<unk> @ ura di c<unk> @ ur<unk> @ ale , che si ri<unk> @ guar<unk> @ da un p<unk> @ op<unk> @ po .
2025-05-27 19:07:57,158 - INFO - joeynmt.training - Example #3
2025-05-27 19:07:57,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:07:57,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:07:57,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'i', 'i', 'm@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'o', ',', 'e', 'la', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ i i m<unk> @ eg<unk> @ gi<unk> @ o , e la m<unk> @ ezz<unk> @ o .
2025-05-27 19:07:57,159 - INFO - joeynmt.training - Example #4
2025-05-27 19:07:57,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:07:57,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:07:57,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'un', 'po', '&apos;', 'di', 'anni', 'fa', ',', '', 'un', 'po', '&apos;', 'di', 'anni', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', '&apos;', 'anni', '.', '</s>']
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:07:57,160 - INFO - joeynmt.training - 	Hypothesis: La prima volta che ho fatto che ho fatto che ho fatto che ho fatto un po &apos; di anni fa ,  un po &apos; di anni &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; anni .
2025-05-27 19:08:00,457 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:     1.587359, Batch Acc: 0.564328, Tokens per Sec:    21004, Lr: 0.000300
2025-05-27 19:08:03,876 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:     1.644898, Batch Acc: 0.563259, Tokens per Sec:    23845, Lr: 0.000300
2025-05-27 19:08:07,253 - INFO - joeynmt.training - Epoch   1, Step:     4800, Batch Loss:     1.577929, Batch Acc: 0.564450, Tokens per Sec:    23436, Lr: 0.000300
2025-05-27 19:08:10,657 - INFO - joeynmt.training - Epoch   1, Step:     4900, Batch Loss:     1.524483, Batch Acc: 0.565920, Tokens per Sec:    23798, Lr: 0.000300
2025-05-27 19:08:14,013 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:     1.512671, Batch Acc: 0.568500, Tokens per Sec:    23260, Lr: 0.000300
2025-05-27 19:08:14,014 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:08:14,014 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:08:29,827 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.55, acc:   0.57, generation: 15.8006[sec], evaluation: 0.0000[sec]
2025-05-27 19:08:29,828 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:08:30,353 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/2500.ckpt
2025-05-27 19:08:30,372 - INFO - joeynmt.training - Example #0
2025-05-27 19:08:30,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:08:30,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:08:30,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Per', 'cui', 'ho', 'inizi@@', '<unk>', '@', 'ato', 'a', 'fare', 'un', 'po', '&apos;', 'di', 'anni', ',', 'ho', 'inizi@@', '<unk>', '@', 'ato', 'a', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', ',', 'le', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', 'che', 'che', 'che', 'la', 'nostra', 's@@', '<unk>', '@', 'an@@', '<unk>', '@', 'ze', 'che', 'che', 'che', 'la', 'nostra', 's@@', '<unk>', '@', 'per@@', '<unk>', '@', 'f@@', '<unk>', '@', 'anno', ',', 'le', 'nostr@@', '<unk>', '@', 'e', 'i', 'nostri', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'anni', ',', 'per', 'le', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', 'di', 'anni', '.', '</s>']
2025-05-27 19:08:30,374 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:08:30,374 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:08:30,374 - INFO - joeynmt.training - 	Hypothesis: Per cui ho inizi<unk> @ ato a fare un po &apos; di anni , ho inizi<unk> @ ato a sc<unk> @ u<unk> @ ola , le persone che hanno sc<unk> @ u<unk> @ ola che che che la nostra s<unk> @ an<unk> @ ze che che che la nostra s<unk> @ per<unk> @ f<unk> @ anno , le nostr<unk> @ e i nostri mili<unk> @ ar<unk> @ di di di anni , per le persone che hanno sc<unk> @ u<unk> @ ola di anni .
2025-05-27 19:08:30,374 - INFO - joeynmt.training - Example #1
2025-05-27 19:08:30,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:08:30,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:08:30,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'che', 'non', '', 'che', 'non', '', 'che', 'non', '', 'che', 'non', '', 'che', 'non', '', 'che', 'la', 'nostra', 'cosa', 'che', 'la', 'nostra', 'cosa', 'che', 'non', '', 'che', 'non', '', 'che', 'non', 'si', 'pu', 'essere', 'essere', 'in@@', '<unk>', '@', 'forma@@', '<unk>', '@', 'zione', 'di', 'cui', 'non', 'si', 'pu', 'essere', 'essere', 'in@@', '<unk>', '@', 'forma@@', '<unk>', '@', 'zione', '.', '</s>']
2025-05-27 19:08:30,375 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:08:30,375 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:08:30,375 - INFO - joeynmt.training - 	Hypothesis: Ma non  che non  che non  che non  che non  che non  che la nostra cosa che la nostra cosa che non  che non  che non si pu essere essere in<unk> @ forma<unk> @ zione di cui non si pu essere essere in<unk> @ forma<unk> @ zione .
2025-05-27 19:08:30,375 - INFO - joeynmt.training - Example #2
2025-05-27 19:08:30,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:08:30,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:08:30,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', '<unk>', '@', 'el', 'prim@@', '<unk>', '@', 'o', '', 'che', '', 'il', 'nostro', 'problema', '', '', 'il', 'nostro', 'modo', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'n', '', 'il', 'mondo', '.', '</s>']
2025-05-27 19:08:30,376 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:08:30,376 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:08:30,376 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el prim<unk> @ o  che  il nostro problema   il nostro modo di in<unk> @ f<unk> @ ig<unk> @ n  il mondo .
2025-05-27 19:08:30,376 - INFO - joeynmt.training - Example #3
2025-05-27 19:08:30,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:08:30,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:08:30,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'ogli@@', '<unk>', '@', 'o', 'che', 'si', 'pu', 'essere', 'un', 'po', '&apos;', 'di', 's@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'olo', '.', '</s>']
2025-05-27 19:08:30,377 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:08:30,377 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:08:30,377 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ ogli<unk> @ o che si pu essere un po &apos; di s<unk> @ ec<unk> @ olo .
2025-05-27 19:08:30,377 - INFO - joeynmt.training - Example #4
2025-05-27 19:08:30,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:08:30,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:08:30,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Per', 'cui', 'ho', 'fatto', 'un', 'po', '&apos;', 'di', 'un', 'po', '&apos;', 'di', 'anni', ',', '', 'che', 'ho', 'fatto', 'un', 'po', '&apos;', 'anni', 'fa', ',', '', 'che', '', 'che', '', 'che', 'la', 'mia', 'anni', '.', '</s>']
2025-05-27 19:08:30,378 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:08:30,378 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:08:30,378 - INFO - joeynmt.training - 	Hypothesis: Per cui ho fatto un po &apos; di un po &apos; di anni ,  che ho fatto un po &apos; anni fa ,  che  che  che la mia anni .
2025-05-27 19:08:33,788 - INFO - joeynmt.training - Epoch   1, Step:     5100, Batch Loss:     1.489514, Batch Acc: 0.570389, Tokens per Sec:    20015, Lr: 0.000300
2025-05-27 19:08:37,161 - INFO - joeynmt.training - Epoch   1, Step:     5200, Batch Loss:     1.489687, Batch Acc: 0.569565, Tokens per Sec:    23715, Lr: 0.000300
2025-05-27 19:08:40,543 - INFO - joeynmt.training - Epoch   1, Step:     5300, Batch Loss:     1.433503, Batch Acc: 0.574029, Tokens per Sec:    23623, Lr: 0.000300
2025-05-27 19:08:43,893 - INFO - joeynmt.training - Epoch   1, Step:     5400, Batch Loss:     1.506775, Batch Acc: 0.574157, Tokens per Sec:    23204, Lr: 0.000300
2025-05-27 19:08:47,249 - INFO - joeynmt.training - Epoch   1, Step:     5500, Batch Loss:     1.494792, Batch Acc: 0.575532, Tokens per Sec:    22934, Lr: 0.000300
2025-05-27 19:08:47,249 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:08:47,249 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:09:02,277 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.41, acc:   0.58, generation: 15.0193[sec], evaluation: 0.0000[sec]
2025-05-27 19:09:02,278 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:09:02,786 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/3000.ckpt
2025-05-27 19:09:02,808 - INFO - joeynmt.training - Example #0
2025-05-27 19:09:02,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:09:02,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:09:02,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Per', 'cui', 'ho', 'inizi@@', '<unk>', '@', 'ato', 'a', 'fare', 'questo', '', 'il', 'mio', 'prim@@', '<unk>', '@', 'o', 'di', 'cui', 'ho', 'sc@@', '<unk>', '@', 'rit@@', '<unk>', '@', 'to', 'che', 'si', 'ri@@', '<unk>', '@', 'vol@@', '<unk>', '@', 'are', 'il', 'mondo', ',', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'no', ',', 'che', 'si', 'ri@@', '<unk>', '@', 'vol@@', '<unk>', '@', 'o', '2@@', '<unk>', '@', '5', 'anni', ',', 'e', 'abbiamo', 'bisogno', 'di', 'un', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'doll@@', '<unk>', '@', 'ari', ',', 'e', 'ho', 'fatto', 'il', 'mondo', ',', 'per', 'il', '19@@', '<unk>', '@', '1@@', '<unk>', '@', '00', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', '.', '</s>']
2025-05-27 19:09:02,809 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:09:02,809 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:09:02,809 - INFO - joeynmt.training - 	Hypothesis: Per cui ho inizi<unk> @ ato a fare questo  il mio prim<unk> @ o di cui ho sc<unk> @ rit<unk> @ to che si ri<unk> @ vol<unk> @ are il mondo , la c<unk> @ ult<unk> @ ur<unk> @ g<unk> @ over<unk> @ no , che si ri<unk> @ vol<unk> @ o 2<unk> @ 5 anni , e abbiamo bisogno di un mili<unk> @ ar<unk> @ di di doll<unk> @ ari , e ho fatto il mondo , per il 19<unk> @ 1<unk> @ 00 milioni di doll<unk> @ ari .
2025-05-27 19:09:02,809 - INFO - joeynmt.training - Example #1
2025-05-27 19:09:02,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:09:02,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:09:02,810 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'la', 'cosa', 'non', '', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'della', 'nostra', 'vita', ',', 'la', 'cosa', 'non', '', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'della', 'nostra', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', ',', 'non', '', 'la', 'nostra', 'cosa', 'che', 'non', '', 'la', 'nostra', 'cosa', 'non', 'non', '', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'della', 'vita', '.', '</s>']
2025-05-27 19:09:02,810 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:09:02,810 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:09:02,810 - INFO - joeynmt.training - 	Hypothesis: Ma non  la cosa non  la maggi<unk> @ or parte della nostra vita , la cosa non  la maggi<unk> @ or parte della nostra c<unk> @ ult<unk> @ ura , non  la nostra cosa che non  la nostra cosa non non  la maggi<unk> @ or parte della vita .
2025-05-27 19:09:02,810 - INFO - joeynmt.training - Example #2
2025-05-27 19:09:02,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:09:02,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:09:02,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mio', 'prim@@', '<unk>', '@', 'o', '', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', '', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', '', 'la', 'c@@', '<unk>', '@', 'ura', 'della', 'nostra', 'c@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 19:09:02,811 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:09:02,811 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:09:02,811 - INFO - joeynmt.training - 	Hypothesis: Il mio prim<unk> @ o  la c<unk> @ ult<unk> @ ura  la c<unk> @ ult<unk> @ ura  la c<unk> @ ura della nostra c<unk> @ ura .
2025-05-27 19:09:02,811 - INFO - joeynmt.training - Example #3
2025-05-27 19:09:02,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:09:02,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:09:02,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'poi', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'e', 'la', 'b@@', '<unk>', '@', 'att@@', '<unk>', '@', 'a', 'e', 'la', 'f@@', '<unk>', '@', 'att@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:09:02,812 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:09:02,812 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:09:02,812 - INFO - joeynmt.training - 	Hypothesis: E poi si tr<unk> @ at<unk> @ ta e la b<unk> @ att<unk> @ a e la f<unk> @ att<unk> @ a .
2025-05-27 19:09:02,812 - INFO - joeynmt.training - Example #4
2025-05-27 19:09:02,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:09:02,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:09:02,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'ho', 'fatto', 'il', 'mio', 'prim@@', '<unk>', '@', 'o', '', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'una', 'cosa', '', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'un', 'po', '&apos;', '8@@', '<unk>', '@', '0', 'anni', '.', '</s>']
2025-05-27 19:09:02,813 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:09:02,813 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:09:02,813 - INFO - joeynmt.training - 	Hypothesis: La prima volta che ho fatto il mio prim<unk> @ o  una cosa che  una cosa che  una cosa che  una cosa  una cosa che  una cosa che  una cosa che  una cosa che  una cosa che  una cosa che  un po &apos; 8<unk> @ 0 anni .
2025-05-27 19:09:06,136 - INFO - joeynmt.training - Epoch   1, Step:     5600, Batch Loss:     1.487764, Batch Acc: 0.577287, Tokens per Sec:    20049, Lr: 0.000300
2025-05-27 19:09:09,533 - INFO - joeynmt.training - Epoch   1, Step:     5700, Batch Loss:     1.430234, Batch Acc: 0.580687, Tokens per Sec:    22876, Lr: 0.000300
2025-05-27 19:09:12,909 - INFO - joeynmt.training - Epoch   1, Step:     5800, Batch Loss:     1.507910, Batch Acc: 0.581922, Tokens per Sec:    23185, Lr: 0.000300
2025-05-27 19:09:16,297 - INFO - joeynmt.training - Epoch   1, Step:     5900, Batch Loss:     1.493704, Batch Acc: 0.581970, Tokens per Sec:    24002, Lr: 0.000300
2025-05-27 19:09:19,669 - INFO - joeynmt.training - Epoch   1, Step:     6000, Batch Loss:     1.352775, Batch Acc: 0.583851, Tokens per Sec:    24345, Lr: 0.000300
2025-05-27 19:09:19,670 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:09:19,670 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:09:34,543 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.27, acc:   0.59, generation: 14.8648[sec], evaluation: 0.0000[sec]
2025-05-27 19:09:34,544 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:09:35,019 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/3500.ckpt
2025-05-27 19:09:35,044 - INFO - joeynmt.training - Example #0
2025-05-27 19:09:35,044 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:09:35,045 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:09:35,045 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'fatto', 'che', 'ho', 'fatto', ',', 'ho', 'fatto', 'che', 'ho', 'fatto', ',', 'ho', 'fatto', 'che', 'ho', 'fatto', 'il', 'prim@@', '<unk>', '@', 'o', 'di', 'cui', 'ho', 'fatto', 'che', 'av@@', '<unk>', '@', 'uto', 'il', 'm@@', '<unk>', '@', 'ett@@', '<unk>', '@', 'ore', ',', 'che', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'cui', 'i', 'nostri', 'milioni', 'di', 'anni', ',', 'che', 'i', 'nostri', 'milioni', 'di', 'anni', ',', 'che', 'av@@', '<unk>', '@', 'evano', '1@@', '<unk>', '@', '00', 'milioni', 'di', 'anni', ',', 'che', 'hanno', 'fatto', 'che', 'av@@', '<unk>', '@', 'uto', 'il', '1@@', '<unk>', '@', '00', 'milioni', 'di', 'anni', ',', 'che', 'av@@', '<unk>', '@', 'evano', '1@@', '<unk>', '@', '00', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 19:09:35,045 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:09:35,045 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:09:35,046 - INFO - joeynmt.training - 	Hypothesis: E ho fatto che ho fatto , ho fatto che ho fatto , ho fatto che ho fatto il prim<unk> @ o di cui ho fatto che av<unk> @ uto il m<unk> @ ett<unk> @ ore , che la s<unk> @ itu<unk> @ azione di cui i nostri milioni di anni , che i nostri milioni di anni , che av<unk> @ evano 1<unk> @ 00 milioni di anni , che hanno fatto che av<unk> @ uto il 1<unk> @ 00 milioni di anni , che av<unk> @ evano 1<unk> @ 00 milioni di anni .
2025-05-27 19:09:35,046 - INFO - joeynmt.training - Example #1
2025-05-27 19:09:35,046 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:09:35,046 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:09:35,046 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'la', 'cosa', 'non', '', 'che', 'non', '', 'la', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'che', 'la', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'di', 'questo', 'modo', 'di', 'questo', 'modo', 'di', 'questo', 'modo', 'di', 'questo', 'modo', 'di', 'questo', 'modo', 'di', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'do', 'di', 'questo', 'modo', 'di', 'pi', 'pi', 'di', 'pi', 'di', 'cui', 'non', '', 'la', 'nostra', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '.', '</s>']
2025-05-27 19:09:35,047 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:09:35,047 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:09:35,047 - INFO - joeynmt.training - 	Hypothesis: Ma non  la cosa non  che non  la ris<unk> @ ult<unk> @ ura che la ris<unk> @ ult<unk> @ ura di questo modo di questo modo di questo modo di questo modo di questo modo di ri<unk> @ guar<unk> @ do di questo modo di pi pi di pi di cui non  la nostra s<unk> @ itu<unk> @ azione .
2025-05-27 19:09:35,047 - INFO - joeynmt.training - Example #2
2025-05-27 19:09:35,047 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:09:35,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:09:35,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', '<unk>', '@', 'el', 'c@@', '<unk>', '@', 'entr@@', '<unk>', '@', 'o', '', 'il', 'fatto', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', '', 'il', 'nostro', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', ',', 'il', 'nostro', 'cervello', 'di', 'c@@', '<unk>', '@', 'entr@@', '<unk>', '@', 'o', 'di', 'c@@', '<unk>', '@', 'entr@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:09:35,048 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:09:35,048 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:09:35,048 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el c<unk> @ entr<unk> @ o  il fatto  il ris<unk> @ ult<unk> @ ato  il nostro in<unk> @ f<unk> @ ico , il nostro cervello di c<unk> @ entr<unk> @ o di c<unk> @ entr<unk> @ o .
2025-05-27 19:09:35,048 - INFO - joeynmt.training - Example #3
2025-05-27 19:09:35,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:09:35,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:09:35,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'e', 'si', 'trov@@', '<unk>', '@', 'a', 'a', 'a', 'a', ',', 'e', 'poi', 'si', 'trov@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:09:35,048 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:09:35,049 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:09:35,049 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , e si trov<unk> @ a a a a , e poi si trov<unk> @ a .
2025-05-27 19:09:35,049 - INFO - joeynmt.training - Example #4
2025-05-27 19:09:35,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:09:35,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:09:35,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'che', 'ho', 'fatto', ',', 'il', 'mio', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', ',', '', 'che', 'ho', 'fatto', 'che', '', 'una', 'cosa', 'che', '', 'che', '', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'che', '', 'stato', 'stato', 'il', 'prim@@', '<unk>', '@', 'o', 'di', 'anni', '.', '</s>']
2025-05-27 19:09:35,049 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:09:35,049 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:09:35,050 - INFO - joeynmt.training - 	Hypothesis: La cosa che ho fatto , il mio p<unk> @ ezz<unk> @ o ,  che ho fatto che  una cosa che  che  una cosa che  una cosa che  che  stato stato il prim<unk> @ o di anni .
2025-05-27 19:09:38,471 - INFO - joeynmt.training - Epoch   1, Step:     6100, Batch Loss:     1.509397, Batch Acc: 0.586169, Tokens per Sec:    20109, Lr: 0.000300
2025-05-27 19:09:41,874 - INFO - joeynmt.training - Epoch   1, Step:     6200, Batch Loss:     1.477101, Batch Acc: 0.586691, Tokens per Sec:    23683, Lr: 0.000300
2025-05-27 19:09:45,263 - INFO - joeynmt.training - Epoch   1, Step:     6300, Batch Loss:     1.387346, Batch Acc: 0.587745, Tokens per Sec:    23525, Lr: 0.000300
2025-05-27 19:09:48,643 - INFO - joeynmt.training - Epoch   1, Step:     6400, Batch Loss:     1.500510, Batch Acc: 0.586706, Tokens per Sec:    23642, Lr: 0.000300
2025-05-27 19:09:52,040 - INFO - joeynmt.training - Epoch   1, Step:     6500, Batch Loss:     1.375237, Batch Acc: 0.588201, Tokens per Sec:    23624, Lr: 0.000300
2025-05-27 19:09:52,040 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:09:52,040 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:10:07,298 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.15, acc:   0.59, generation: 15.2492[sec], evaluation: 0.0000[sec]
2025-05-27 19:10:07,299 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:10:07,776 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/4000.ckpt
2025-05-27 19:10:07,794 - INFO - joeynmt.training - Example #0
2025-05-27 19:10:07,794 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:10:07,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:10:07,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'ho', 'fatto', 'che', 'ho', 'fatto', ',', 'ho', 'fatto', ',', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'il', 'm@@', '<unk>', '@', 'esso', 'di', 'fare', 'il', 'm@@', '<unk>', '@', 'esso', 'di', '1@@', '<unk>', '@', '5', 'anni', ',', 'il', 'mondo', ',', 'il', 'modo', 'che', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'di', 'anni', ',', 'che', 'il', 'giorno', ',', 'il', 'giorno', ',', 'il', 'giorno', ',', 'per', '1@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:10:07,795 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:10:07,795 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:10:07,795 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , ho fatto che ho fatto , ho fatto , ho fatto che ho fatto che ho fatto che il m<unk> @ esso di fare il m<unk> @ esso di 1<unk> @ 5 anni , il mondo , il modo che la maggi<unk> @ or parte di anni , che il giorno , il giorno , il giorno , per 1<unk> @ 5 anni .
2025-05-27 19:10:07,795 - INFO - joeynmt.training - Example #1
2025-05-27 19:10:07,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:10:07,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:10:07,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', '', 'la', 'cosa', 'non', '', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'di', 'questo', 'non', '', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'del', 'nostro', 'modo', 'di', 'questa', 'tecnologia', ',', 'il', 'problema', 'di', 'questa', '', 'la', 'gente', 'non', '', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'di', 'cui', 'non', '', 'la', 'gente', 'non', '', 'il', 'problema', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:10:07,796 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:10:07,796 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:10:07,796 - INFO - joeynmt.training - 	Hypothesis: Ma questo  la cosa non  la maggi<unk> @ or parte di questo non  la maggi<unk> @ or parte del nostro modo di questa tecnologia , il problema di questa  la gente non  la maggi<unk> @ or parte di cui non  la gente non  il problema di questo problema .
2025-05-27 19:10:07,796 - INFO - joeynmt.training - Example #2
2025-05-27 19:10:07,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:10:07,797 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:10:07,797 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'di', 'questa', '', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ezza', 'di', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'i@@', '<unk>', '@', 'os@@', '<unk>', '@', 'a', ',', 'la', 'nostra', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 19:10:07,797 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:10:07,797 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:10:07,797 - INFO - joeynmt.training - 	Hypothesis: In realt , la maggi<unk> @ or parte di questa  la c<unk> @ ur<unk> @ ezza di c<unk> @ ur<unk> @ i<unk> @ os<unk> @ a , la nostra c<unk> @ ult<unk> @ ura .
2025-05-27 19:10:07,797 - INFO - joeynmt.training - Example #3
2025-05-27 19:10:07,797 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:10:07,797 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:10:07,797 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'e', 'la', 'b@@', '<unk>', '@', 'an@@', '<unk>', '@', 'ta', 'e', 'e', 'la', 'b@@', '<unk>', '@', 'an@@', '<unk>', '@', 'ta', '.', '</s>']
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta e la b<unk> @ an<unk> @ ta e e la b<unk> @ an<unk> @ ta .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - Example #4
2025-05-27 19:10:07,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:10:07,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:10:07,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', '<unk>', '@', 'o', '', 'stato', 'un', 'po', '&apos;', 'di', 'cui', 'ho', 'fatto', 'che', 'ho', 'fatto', 'una', 'cosa', 'che', '', 'che', '', 'stata', 'una', 'cosa', 'che', '', 'stata', 'una', 'cosa', 'che', '', 'che', '', 'stata', 'una', 'cosa', 'che', '', 'stata', 'stata', 'una', 'cosa', 'che', '', 'stata', 'pi', 'pi', 'anni', '.', '</s>']
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o  stato un po &apos; di cui ho fatto che ho fatto una cosa che  che  stata una cosa che  stata una cosa che  che  stata una cosa che  stata stata una cosa che  stata pi pi anni .
2025-05-27 19:10:11,158 - INFO - joeynmt.training - Epoch   1, Step:     6600, Batch Loss:     1.378398, Batch Acc: 0.589312, Tokens per Sec:    20684, Lr: 0.000300
2025-05-27 19:10:14,554 - INFO - joeynmt.training - Epoch   1, Step:     6700, Batch Loss:     1.457967, Batch Acc: 0.590939, Tokens per Sec:    23483, Lr: 0.000300
2025-05-27 19:10:17,970 - INFO - joeynmt.training - Epoch   1, Step:     6800, Batch Loss:     1.477306, Batch Acc: 0.591351, Tokens per Sec:    23387, Lr: 0.000300
2025-05-27 19:10:21,360 - INFO - joeynmt.training - Epoch   1, Step:     6900, Batch Loss:     1.499579, Batch Acc: 0.594163, Tokens per Sec:    23174, Lr: 0.000300
2025-05-27 19:10:24,740 - INFO - joeynmt.training - Epoch   1, Step:     7000, Batch Loss:     1.277357, Batch Acc: 0.593569, Tokens per Sec:    23395, Lr: 0.000300
2025-05-27 19:10:24,740 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:10:24,741 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:10:42,696 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.40, ppl:   4.07, acc:   0.60, generation: 17.9460[sec], evaluation: 0.0000[sec]
2025-05-27 19:10:42,696 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:10:43,179 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/4500.ckpt
2025-05-27 19:10:43,202 - INFO - joeynmt.training - Example #0
2025-05-27 19:10:43,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:10:43,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:10:43,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'visto', 'che', 'ho', 'visto', 'che', 'ho', 'visto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'il', 'mondo', ',', 'che', 'ho', 'fatto', 'che', 'la', 'prima', 'volta', ',', 'che', 'la', 'gente', 'si', 'ha', 'fatto', 'che', 'la', 'gente', 'si', 'ha', 'fatto', 'che', 'la', 'gente', 'che', 'la', 'gente', 'che', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'di', '1@@', '<unk>', '@', '00', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', ',', 'che', 'hanno', '1@@', '<unk>', '@', '00', 'anni', ',', 'e', 'il', '1@@', '<unk>', '@', '5', 'anni', ',', 'che', 'hanno', '1@@', '<unk>', '@', '00', 'anni', ',', 'che', 'ha', '1@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:10:43,203 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:10:43,203 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:10:43,203 - INFO - joeynmt.training - 	Hypothesis: E ho visto che ho visto che ho visto che ho fatto che ho fatto il mondo , che ho fatto che la prima volta , che la gente si ha fatto che la gente si ha fatto che la gente che la gente che la c<unk> @ ult<unk> @ ura di 1<unk> @ 00 milioni di doll<unk> @ ari , che hanno 1<unk> @ 00 anni , e il 1<unk> @ 5 anni , che hanno 1<unk> @ 00 anni , che ha 1<unk> @ 5 anni .
2025-05-27 19:10:43,203 - INFO - joeynmt.training - Example #1
2025-05-27 19:10:43,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:10:43,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:10:43,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'punto', ',', 'non', '', 'che', 'non', '', 'la', 'gente', 'non', '', 'la', 'prima', 'volta', 'che', 'non', '', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'di', 'questa', 'tecnologia', ',', 'che', 'non', '', 'la', 'gente', 'non', '', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'di', 'questa', 'tecnologia', '.', '</s>']
2025-05-27 19:10:43,204 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:10:43,204 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:10:43,204 - INFO - joeynmt.training - 	Hypothesis: Ma questo punto , non  che non  la gente non  la prima volta che non  la c<unk> @ ult<unk> @ ura di questa tecnologia , che non  la gente non  la c<unk> @ ult<unk> @ ura di questa tecnologia .
2025-05-27 19:10:43,204 - INFO - joeynmt.training - Example #2
2025-05-27 19:10:43,205 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:10:43,205 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:10:43,205 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', '<unk>', '@', 'el', 'modo', 'di', 'cui', 'la', 'tecnologia', '', 'la', 'nostra', 'sp@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ie', '', 'il', 'nostro', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', ',', 'la', 'nostra', 'soci@@', '<unk>', '@', 'et', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', '.', '</s>']
2025-05-27 19:10:43,205 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:10:43,205 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:10:43,205 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el modo di cui la tecnologia  la nostra sp<unk> @ ec<unk> @ ie  il nostro in<unk> @ f<unk> @ ico , la nostra soci<unk> @ et di in<unk> @ f<unk> @ am<unk> @ ig<unk> @ lia .
2025-05-27 19:10:43,205 - INFO - joeynmt.training - Example #3
2025-05-27 19:10:43,206 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:10:43,206 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:10:43,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'po', '&apos;', 'di', 'l@@', '<unk>', '@', '', ',', 'e', 'poi', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', '.', '</s>']
2025-05-27 19:10:43,206 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:10:43,206 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:10:43,206 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un po &apos; di l<unk> @  , e poi si tr<unk> @ at<unk> @ ta .
2025-05-27 19:10:43,206 - INFO - joeynmt.training - Example #4
2025-05-27 19:10:43,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:10:43,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:10:43,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'a', 'una', 'cosa', 'che', 'ha', 'un', 'anno', 'anno', 'di', '1@@', '<unk>', '@', '00', 'anni', '.', '</s>']
2025-05-27 19:10:43,207 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:10:43,207 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:10:43,207 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o che vi mostr<unk> @ er<unk> @  che vi mostr<unk> @ a che vi mostr<unk> @ a a una cosa che ha un anno anno di 1<unk> @ 00 anni .
2025-05-27 19:10:46,523 - INFO - joeynmt.training - Epoch   1, Step:     7100, Batch Loss:     1.472641, Batch Acc: 0.592737, Tokens per Sec:    20730, Lr: 0.000300
2025-05-27 19:10:49,847 - INFO - joeynmt.training - Epoch   1, Step:     7200, Batch Loss:     1.423405, Batch Acc: 0.596922, Tokens per Sec:    24645, Lr: 0.000300
2025-05-27 19:10:53,163 - INFO - joeynmt.training - Epoch   1, Step:     7300, Batch Loss:     1.456144, Batch Acc: 0.593800, Tokens per Sec:    24285, Lr: 0.000300
2025-05-27 19:10:56,447 - INFO - joeynmt.training - Epoch   1, Step:     7400, Batch Loss:     1.442577, Batch Acc: 0.596320, Tokens per Sec:    24105, Lr: 0.000300
2025-05-27 19:10:59,760 - INFO - joeynmt.training - Epoch   1, Step:     7500, Batch Loss:     1.375107, Batch Acc: 0.601157, Tokens per Sec:    23701, Lr: 0.000300
2025-05-27 19:10:59,761 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:10:59,761 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:11:12,652 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.01, acc:   0.60, generation: 12.8832[sec], evaluation: 0.0000[sec]
2025-05-27 19:11:12,653 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:11:13,118 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/5000.ckpt
2025-05-27 19:11:13,141 - INFO - joeynmt.training - Example #0
2025-05-27 19:11:13,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:11:13,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:11:13,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'la', 'prima', 'volta', 'che', 'ho', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'questo', ',', 'ho', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'che', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'cui', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', ',', 'che', 'la', 'sci@@', '<unk>', '@', 'enza', 'di', 'persone', 'che', 'i', 'bambini', 'sono', '1@@', '<unk>', '@', '00', 'milioni', 'di', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'il', '1@@', '<unk>', '@', '8@@', '<unk>', '@', '0', 'anni', ',', 'che', 'ho', 'av@@', '<unk>', '@', 'uto', 'il', '19@@', '<unk>', '@', '8@@', '<unk>', '@', '0', 'anni', ',', 'che', 'ho', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', '.', '</s>']
2025-05-27 19:11:13,142 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:11:13,142 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:11:13,142 - INFO - joeynmt.training - 	Hypothesis: E &apos; la prima volta che ho sc<unk> @ oper<unk> @ to questo , ho sc<unk> @ oper<unk> @ to che la s<unk> @ itu<unk> @ azione di cui la s<unk> @ itu<unk> @ azione , che la sci<unk> @ enza di persone che i bambini sono 1<unk> @ 00 milioni di persone che hanno sc<unk> @ oper<unk> @ to il 1<unk> @ 8<unk> @ 0 anni , che ho av<unk> @ uto il 19<unk> @ 8<unk> @ 0 anni , che ho sc<unk> @ oper<unk> @ to .
2025-05-27 19:11:13,143 - INFO - joeynmt.training - Example #1
2025-05-27 19:11:13,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:11:13,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:11:13,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', '', 'il', 'problema', 'non', '', 'la', 'cosa', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'cui', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:11:13,143 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:11:13,144 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:11:13,144 - INFO - joeynmt.training - 	Hypothesis: Ma questo  il problema non  la cosa non  la s<unk> @ itu<unk> @ azione di cui non  la s<unk> @ itu<unk> @ azione di questo problema .
2025-05-27 19:11:13,144 - INFO - joeynmt.training - Example #2
2025-05-27 19:11:13,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:11:13,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:11:13,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 'parte', '', 'la', 'parte', '', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', '', 'la', 'tecnologia', 'del', 'mondo', '', 'la', 'nostra', 'soci@@', '<unk>', '@', 'et', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ar', '.', '</s>']
2025-05-27 19:11:13,144 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Hypothesis: In realt , la parte  la parte  la c<unk> @ ult<unk> @ ura  la tecnologia del mondo  la nostra soci<unk> @ et di in<unk> @ f<unk> @ ar .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - Example #3
2025-05-27 19:11:13,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:11:13,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:11:13,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', '<unk>', '@', '&apos;', '', 'la', 'cosa', '', 'stato', 'stato', 'stato', 'stato', 'il', 'suo', 'f@@', '<unk>', '@', 'ut@@', '<unk>', '@', 'uro', 'e', 'la', 'di@@', '<unk>', '@', 'sp@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ie', '.', '</s>']
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Hypothesis: C<unk> @ &apos;  la cosa  stato stato stato stato il suo f<unk> @ ut<unk> @ uro e la di<unk> @ sp<unk> @ ec<unk> @ ie .
2025-05-27 19:11:13,146 - INFO - joeynmt.training - Example #4
2025-05-27 19:11:13,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:11:13,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:11:13,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'ho', 'fatto', 'che', 'la', 'prima', 'volta', '', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'che', 'una', 'volta', '', 'una', 'volta', 'che', '', 'stato', 'di', 'anni', 'fa', '.', '</s>']
2025-05-27 19:11:13,146 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:11:13,146 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:11:13,146 - INFO - joeynmt.training - 	Hypothesis: La prima volta che ho fatto che la prima volta  una cosa che vi mostr<unk> @ a che vi mostr<unk> @ a che una volta  una volta che  stato di anni fa .
2025-05-27 19:11:16,453 - INFO - joeynmt.training - Epoch   1, Step:     7600, Batch Loss:     1.305449, Batch Acc: 0.601382, Tokens per Sec:    20870, Lr: 0.000300
2025-05-27 19:11:19,718 - INFO - joeynmt.training - Epoch   1, Step:     7700, Batch Loss:     1.453135, Batch Acc: 0.598884, Tokens per Sec:    23018, Lr: 0.000300
2025-05-27 19:11:23,080 - INFO - joeynmt.training - Epoch   1, Step:     7800, Batch Loss:     1.317912, Batch Acc: 0.599982, Tokens per Sec:    23596, Lr: 0.000300
2025-05-27 19:11:25,389 - INFO - joeynmt.training - Epoch   1: total training loss 13370.39
2025-05-27 19:11:25,390 - INFO - joeynmt.training - EPOCH 2
2025-05-27 19:11:26,376 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     1.373097, Batch Acc: 0.598649, Tokens per Sec:    24358, Lr: 0.000300
2025-05-27 19:11:29,666 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     1.339123, Batch Acc: 0.602712, Tokens per Sec:    24280, Lr: 0.000300
2025-05-27 19:11:29,666 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:11:29,666 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:11:46,001 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.96, acc:   0.60, generation: 16.3238[sec], evaluation: 0.0000[sec]
2025-05-27 19:11:46,001 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:11:46,604 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/5500.ckpt
2025-05-27 19:11:46,626 - INFO - joeynmt.training - Example #0
2025-05-27 19:11:46,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:11:46,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:11:46,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'fatto', ',', 'ho', 'fatto', ',', 'ho', 'fatto', ',', 'ho', 'fatto', ',', 'che', 'ho', 'fatto', ',', 'che', 'la', 'c@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'u@@', '<unk>', '@', 'zione', ',', 'che', 'la', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'na', 'che', 'la', 'c@@', '<unk>', '@', 'a@@', '<unk>', '@', 'ia', 'di', 'anni', ',', 'che', 'la', 'c@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'u@@', '<unk>', '@', 'zione', ',', 'che', 'ha', 'fatto', 'di', '1@@', '<unk>', '@', '5', 'anni', ',', 'che', 'hanno', '1@@', '<unk>', '@', '5', 'anni', ',', 'che', 'ha', 'fatto', 'di', '1@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:11:46,628 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:11:46,628 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:11:46,628 - INFO - joeynmt.training - 	Hypothesis: E ho fatto , ho fatto , ho fatto , ho fatto , che ho fatto , che la c<unk> @ ent<unk> @ u<unk> @ zione , che la con<unk> @ si<unk> @ der<unk> @ na che la c<unk> @ a<unk> @ ia di anni , che la c<unk> @ ent<unk> @ u<unk> @ zione , che ha fatto di 1<unk> @ 5 anni , che hanno 1<unk> @ 5 anni , che ha fatto di 1<unk> @ 5 anni .
2025-05-27 19:11:46,628 - INFO - joeynmt.training - Example #1
2025-05-27 19:11:46,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:11:46,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:11:46,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'la', 'cosa', 'che', 'non', '', 'il', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'peri@@', '<unk>', '@', 'enza', ',', 'non', '', 'il', 'des@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'n', 'di', 'questo', ',', 'che', 'non', '', 'il', 'problema', 'di', 'questo', 'tipo', 'di', 'di', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'questo', 'non', '', 'il', 'problema', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'un', 'problema', '.', '</s>']
2025-05-27 19:11:46,629 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:11:46,629 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:11:46,629 - INFO - joeynmt.training - 	Hypothesis: Ma non  la cosa che non  il p<unk> @ es<unk> @ peri<unk> @ enza , non  il des<unk> @ ig<unk> @ n di questo , che non  il problema di questo tipo di di di c<unk> @ aus<unk> @ a di questo non  il problema di c<unk> @ aus<unk> @ a di un problema .
2025-05-27 19:11:46,629 - INFO - joeynmt.training - Example #2
2025-05-27 19:11:46,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:11:46,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:11:46,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', '', 'il', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ist@@', '<unk>', '@', 'a', '', 'il', 'nostro', 's@@', '<unk>', '@', 'an@@', '<unk>', '@', 'co', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:11:46,630 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:11:46,630 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:11:46,630 - INFO - joeynmt.training - 	Hypothesis: In realt ,  il p<unk> @ es<unk> @ ist<unk> @ a  il nostro s<unk> @ an<unk> @ co di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a .
2025-05-27 19:11:46,630 - INFO - joeynmt.training - Example #3
2025-05-27 19:11:46,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:11:46,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:11:46,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'e@@', '<unk>', '@', 'dete', 'il', 'suo', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lio', '.', '</s>']
2025-05-27 19:11:46,631 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:11:46,631 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:11:46,631 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ e<unk> @ dete il suo f<unk> @ ig<unk> @ lio .
2025-05-27 19:11:46,631 - INFO - joeynmt.training - Example #4
2025-05-27 19:11:46,632 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:11:46,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:11:46,632 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', '<unk>', '@', 'o', 'anno', ',', 'ho', 'fatto', 'che', 'ho', 'fatto', ',', '', 'un', 'po', '&apos;', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'anni', 'fa', ',', '', 'un', 'anno', 'di', 'anni', 'fa', '.', '</s>']
2025-05-27 19:11:46,632 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:11:46,632 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:11:46,632 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o anno , ho fatto che ho fatto ,  un po &apos; di c<unk> @ aus<unk> @ a di anni fa ,  un anno di anni fa .
2025-05-27 19:11:49,964 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     1.401587, Batch Acc: 0.604006, Tokens per Sec:    20096, Lr: 0.000300
2025-05-27 19:11:53,295 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     1.330742, Batch Acc: 0.603558, Tokens per Sec:    23212, Lr: 0.000300
2025-05-27 19:11:56,565 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     1.358879, Batch Acc: 0.605823, Tokens per Sec:    23195, Lr: 0.000300
2025-05-27 19:11:59,868 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     1.373996, Batch Acc: 0.609356, Tokens per Sec:    23893, Lr: 0.000300
2025-05-27 19:12:03,178 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     1.267296, Batch Acc: 0.610134, Tokens per Sec:    24660, Lr: 0.000300
2025-05-27 19:12:03,178 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:12:03,178 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:12:15,171 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.90, acc:   0.61, generation: 11.9842[sec], evaluation: 0.0000[sec]
2025-05-27 19:12:15,171 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:12:15,661 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/6000.ckpt
2025-05-27 19:12:15,684 - INFO - joeynmt.training - Example #0
2025-05-27 19:12:15,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:12:15,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:12:15,685 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'fatto', 'che', 'ho', 'fatto', 'questi', 'due', 'due', 'anni', ',', 'ho', 'fatto', 'questi', 'due', 'due', 'anni', ',', 'ho', 'inizi@@', '<unk>', '@', 'ato', 'a', 'lavor@@', '<unk>', '@', 'are', 'per', 'creare', 'un', 'anno', 'di', '1@@', '<unk>', '@', '00', 'milioni', 'di', 'anni', ',', 'che', 'si', '', 'stato', 'stato', 'il', 'mondo', ',', 'che', 'il', '1@@', '<unk>', '@', '00', 'milioni', 'di', 'anni', ',', 'che', 'si', '', 'stato', 'stato', 'il', '1@@', '<unk>', '@', '8@@', '<unk>', '@', '0', ',', 'che', 'hanno', 'inizi@@', '<unk>', '@', 'ato', 'a', '1@@', '<unk>', '@', '8@@', '<unk>', '@', '0', ',', 'che', 'ho', 'inizi@@', '<unk>', '@', 'ato', 'a', '1@@', '<unk>', '@', '8@@', '<unk>', '@', '0', '.', '</s>']
2025-05-27 19:12:15,685 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:12:15,685 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:12:15,685 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho fatto che ho fatto questi due due anni , ho fatto questi due due anni , ho inizi<unk> @ ato a lavor<unk> @ are per creare un anno di 1<unk> @ 00 milioni di anni , che si  stato stato il mondo , che il 1<unk> @ 00 milioni di anni , che si  stato stato il 1<unk> @ 8<unk> @ 0 , che hanno inizi<unk> @ ato a 1<unk> @ 8<unk> @ 0 , che ho inizi<unk> @ ato a 1<unk> @ 8<unk> @ 0 .
2025-05-27 19:12:15,685 - INFO - joeynmt.training - Example #1
2025-05-27 19:12:15,686 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:12:15,686 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:12:15,686 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'la', 'cosa', 'non', '', 'il', 'punto', 'di', 'vi@@', '<unk>', '@', 'sta', ',', 'non', '', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'del', 'mondo', 'non', '', 'la', 'm@@', '<unk>', '@', 'ess@@', '<unk>', '@', 'a', 'di', 'questo', 'tipo', 'di', 'lavoro', '.', '</s>']
2025-05-27 19:12:15,686 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:12:15,686 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:12:15,686 - INFO - joeynmt.training - 	Hypothesis: Ma non  la cosa non  il punto di vi<unk> @ sta , non  la maggi<unk> @ or parte del mondo non  la m<unk> @ ess<unk> @ a di questo tipo di lavoro .
2025-05-27 19:12:15,686 - INFO - joeynmt.training - Example #2
2025-05-27 19:12:15,687 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:12:15,687 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:12:15,687 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', '<unk>', '@', 'etti', ',', 'il', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', '', 'il', 'fatto', 'di', 'un', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ut@@', '<unk>', '@', 'uro', '', 'il', 'nostro', 'modo', 'di', 'cui', 'il', 'nostro', 'cor@@', '<unk>', '@', 'so', 'del', 'nostro', 'cor@@', '<unk>', '@', 'so', '.', '</s>']
2025-05-27 19:12:15,687 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:12:15,687 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:12:15,687 - INFO - joeynmt.training - 	Hypothesis: In eff<unk> @ etti , il m<unk> @ ezz<unk> @ o  il fatto di un in<unk> @ f<unk> @ ut<unk> @ uro  il nostro modo di cui il nostro cor<unk> @ so del nostro cor<unk> @ so .
2025-05-27 19:12:15,687 - INFO - joeynmt.training - Example #3
2025-05-27 19:12:15,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:12:15,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:12:15,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'ri@@', '<unk>', '@', 'vol@@', '<unk>', '@', 'are', 'e', 'poi', 'il', 'suo', 'f@@', '<unk>', '@', 'ut@@', '<unk>', '@', 'uro', '.', '</s>']
2025-05-27 19:12:15,688 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:12:15,688 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:12:15,688 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di ri<unk> @ vol<unk> @ are e poi il suo f<unk> @ ut<unk> @ uro .
2025-05-27 19:12:15,688 - INFO - joeynmt.training - Example #4
2025-05-27 19:12:15,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:12:15,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:12:15,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', '<unk>', '@', 'o', '', 'stato', 'il', 'prim@@', '<unk>', '@', 'o', 'di', 'voi', ',', 'vi', 'mostr@@', '<unk>', '@', 'o', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'che', '', 'stato', 'stato', 'un', 'ulti@@', '<unk>', '@', 'mo', 'di', 'anni', 'fa', '.', '</s>']
2025-05-27 19:12:15,689 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:12:15,689 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:12:15,689 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o  stato il prim<unk> @ o di voi , vi mostr<unk> @ o una cosa che vi mostr<unk> @ a che  stato stato un ulti<unk> @ mo di anni fa .
2025-05-27 19:12:19,004 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     1.287003, Batch Acc: 0.609028, Tokens per Sec:    20939, Lr: 0.000300
2025-05-27 19:12:22,302 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     1.340498, Batch Acc: 0.610428, Tokens per Sec:    24716, Lr: 0.000300
2025-05-27 19:12:25,629 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     1.419819, Batch Acc: 0.608334, Tokens per Sec:    23879, Lr: 0.000300
2025-05-27 19:12:28,943 - INFO - joeynmt.training - Epoch   2, Step:     8900, Batch Loss:     1.523959, Batch Acc: 0.610898, Tokens per Sec:    25195, Lr: 0.000300
2025-05-27 19:12:32,219 - INFO - joeynmt.training - Epoch   2, Step:     9000, Batch Loss:     1.357627, Batch Acc: 0.610646, Tokens per Sec:    23665, Lr: 0.000300
2025-05-27 19:12:32,219 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:12:32,220 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:12:45,638 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.35, ppl:   3.84, acc:   0.61, generation: 13.4040[sec], evaluation: 0.0000[sec]
2025-05-27 19:12:45,639 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:12:46,194 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/6500.ckpt
2025-05-27 19:12:46,219 - INFO - joeynmt.training - Example #0
2025-05-27 19:12:46,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:12:46,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:12:46,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'fatto', 'che', 'ho', 'fatto', ',', 'ho', 'fatto', ',', 'ho', 'fatto', 'che', 'ho', 'fatto', ',', 'per', 'la', 'prima', 'volta', ',', 'per', 'la', 'prima', 'volta', ',', 'per', 'la', 'prima', 'volta', ',', 'per', 'la', 'prima', 'volta', 'che', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', ',', 'che', 'la', 'con@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'enza', ',', 'che', 'l&apos;', 'anno', ',', 'che', 'l&apos;', 'anno', ',', 'che', 'ho', 'inizi@@', '<unk>', '@', 'ato', 'a', '1@@', '<unk>', '@', '6', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', ',', 'che', 'ho', 'inizi@@', '<unk>', '@', 'ato', 'a', '1@@', '<unk>', '@', '6', 'milioni', 'di', 'anni', ',', 'che', 'ho', 'fatto', 'il', '9@@', '<unk>', '@', '0', '.', '</s>']
2025-05-27 19:12:46,221 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:12:46,221 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:12:46,221 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho fatto che ho fatto , ho fatto , ho fatto che ho fatto , per la prima volta , per la prima volta , per la prima volta , per la prima volta che la c<unk> @ ult<unk> @ ura , che la con<unk> @ fer<unk> @ enza , che l&apos; anno , che l&apos; anno , che ho inizi<unk> @ ato a 1<unk> @ 6 milioni di doll<unk> @ ari , che ho inizi<unk> @ ato a 1<unk> @ 6 milioni di anni , che ho fatto il 9<unk> @ 0 .
2025-05-27 19:12:46,221 - INFO - joeynmt.training - Example #1
2025-05-27 19:12:46,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:12:46,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:12:46,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'il', 'modo', 'di', 'cui', 'non', '', 'il', 'cambi@@', '<unk>', '@', 'amento', 'non', '', 'il', 'cambi@@', '<unk>', '@', 'amento', 'non', '', 'il', 'cambi@@', '<unk>', '@', 'amento', 'della', 'nostra', 'soci@@', '<unk>', '@', 'et', 'non', '', 'il', 'cambi@@', '<unk>', '@', 'amento', 'della', 'soci@@', '<unk>', '@', 'et', '.', '</s>']
2025-05-27 19:12:46,222 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:12:46,222 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:12:46,222 - INFO - joeynmt.training - 	Hypothesis: Ma non  il modo di cui non  il cambi<unk> @ amento non  il cambi<unk> @ amento non  il cambi<unk> @ amento della nostra soci<unk> @ et non  il cambi<unk> @ amento della soci<unk> @ et .
2025-05-27 19:12:46,222 - INFO - joeynmt.training - Example #2
2025-05-27 19:12:46,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:12:46,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:12:46,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', '<unk>', '@', 'el', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', '', 'il', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', '', 'che', 'la', 'nostra', 'soci@@', '<unk>', '@', 'et', '', 'la', 'nostra', 'soci@@', '<unk>', '@', 'et', 'della', 'nostra', 'soci@@', '<unk>', '@', 'et', '.', '</s>']
2025-05-27 19:12:46,223 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:12:46,223 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:12:46,223 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el m<unk> @ oti<unk> @ vo  il m<unk> @ oti<unk> @ vo  che la nostra soci<unk> @ et  la nostra soci<unk> @ et della nostra soci<unk> @ et .
2025-05-27 19:12:46,223 - INFO - joeynmt.training - Example #3
2025-05-27 19:12:46,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:12:46,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:12:46,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', '<unk>', '@', 'a', 's@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ito', ',', 'e', 'il', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'o', ',', 'e', 'si', '', 'stato', 's@@', '<unk>', '@', 'otto', '.', '</s>']
2025-05-27 19:12:46,224 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:12:46,224 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:12:46,224 - INFO - joeynmt.training - 	Hypothesis: H<unk> @ a s<unk> @ ent<unk> @ ito , e il p<unk> @ es<unk> @ o , e si  stato s<unk> @ otto .
2025-05-27 19:12:46,224 - INFO - joeynmt.training - Example #4
2025-05-27 19:12:46,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:12:46,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:12:46,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'la', 'prima', 'cosa', 'che', 'ho', 'fatto', ',', '', 'un', 'po', '&apos;', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', 'che', '', 'una', 'cosa', 'che', '', 'stata', 'una', 'cosa', 'che', '', 'stata', 'stata', 'una', 'cosa', 'che', '', 'stata', 'stata', 'stata', 'una', 'cosa', 'che', '', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'il', 'prim@@', '<unk>', '@', 'o', 'ulti@@', '<unk>', '@', 'mo', '.', '</s>']
2025-05-27 19:12:46,225 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:12:46,225 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:12:46,225 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che la prima cosa che ho fatto ,  un po &apos; di m<unk> @ oti<unk> @ vo che  una cosa che  stata una cosa che  stata stata una cosa che  stata stata stata una cosa che  stato stato stato stato stato stato il prim<unk> @ o ulti<unk> @ mo .
2025-05-27 19:12:49,646 - INFO - joeynmt.training - Epoch   2, Step:     9100, Batch Loss:     1.278527, Batch Acc: 0.610051, Tokens per Sec:    19362, Lr: 0.000300
2025-05-27 19:12:53,024 - INFO - joeynmt.training - Epoch   2, Step:     9200, Batch Loss:     1.314478, Batch Acc: 0.613638, Tokens per Sec:    23504, Lr: 0.000300
2025-05-27 19:12:56,387 - INFO - joeynmt.training - Epoch   2, Step:     9300, Batch Loss:     1.304136, Batch Acc: 0.612477, Tokens per Sec:    22975, Lr: 0.000300
2025-05-27 19:12:59,763 - INFO - joeynmt.training - Epoch   2, Step:     9400, Batch Loss:     1.483722, Batch Acc: 0.610910, Tokens per Sec:    23398, Lr: 0.000300
2025-05-27 19:13:03,161 - INFO - joeynmt.training - Epoch   2, Step:     9500, Batch Loss:     1.311440, Batch Acc: 0.614737, Tokens per Sec:    23622, Lr: 0.000300
2025-05-27 19:13:03,162 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:13:03,162 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:13:16,901 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.34, ppl:   3.80, acc:   0.61, generation: 13.7312[sec], evaluation: 0.0000[sec]
2025-05-27 19:13:16,902 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:13:17,394 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/7000.ckpt
2025-05-27 19:13:17,410 - INFO - joeynmt.training - Example #0
2025-05-27 19:13:17,410 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:13:17,410 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:13:17,411 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', ',', 'ho', 'fatto', ',', 'questa', '', 'la', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', ',', 'per', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'fare', 'il', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', 'che', 'la', 'c@@', '<unk>', '@', 'av@@', '<unk>', '@', 'e', 'per', 'tre', 'anni', ',', 'che', 'hanno', 'inizi@@', '<unk>', '@', 'ato', 'a', '1@@', '<unk>', '@', '8', 'anni', ',', 'e', 'il', '1@@', '<unk>', '@', '8', 'anni', ',', 'e', 'il', '1@@', '<unk>', '@', '8', 'anni', ',', 'per', 'tre', 'anni', ',', 'per', 'tre', 'anni', ',', 'il', '1@@', '<unk>', '@', '8', ',', 'il', '1@@', '<unk>', '@', '8', 'anni', '.', '</s>']
2025-05-27 19:13:17,411 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:13:17,411 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:13:17,411 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho sc<unk> @ oper<unk> @ to , ho fatto , questa  la sc<unk> @ u<unk> @ ola , per c<unk> @ aus<unk> @ a di fare il m<unk> @ oti<unk> @ vo che la c<unk> @ av<unk> @ e per tre anni , che hanno inizi<unk> @ ato a 1<unk> @ 8 anni , e il 1<unk> @ 8 anni , e il 1<unk> @ 8 anni , per tre anni , per tre anni , il 1<unk> @ 8 , il 1<unk> @ 8 anni .
2025-05-27 19:13:17,411 - INFO - joeynmt.training - Example #1
2025-05-27 19:13:17,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:13:17,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:13:17,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'non', '', 'la', 'la', 'ri@@', '<unk>', '@', 'vol@@', '<unk>', '@', 'u@@', '<unk>', '@', 'zione', 'di', 'questo', ',', 'la', 'nostra', 'sp@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ie', ',', 'non', '', 'la', 'la', 'nostra', 'sp@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'os@@', '<unk>', '@', 'it', '.', '</s>']
2025-05-27 19:13:17,412 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:13:17,412 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:13:17,412 - INFO - joeynmt.training - 	Hypothesis: Ma non non  la s<unk> @ itu<unk> @ azione di non  la la ri<unk> @ vol<unk> @ u<unk> @ zione di questo , la nostra sp<unk> @ ec<unk> @ ie , non  la la nostra sp<unk> @ ec<unk> @ os<unk> @ it .
2025-05-27 19:13:17,412 - INFO - joeynmt.training - Example #2
2025-05-27 19:13:17,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:13:17,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:13:17,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ric@@', '<unk>', '@', 'e', 'di', 'la', 'nostra', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', ',', 'la', 'nostra', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 19:13:17,413 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:13:17,413 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:13:17,413 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ itu<unk> @ azione  la c<unk> @ at<unk> @ ric<unk> @ e di la nostra c<unk> @ ult<unk> @ ura , la nostra c<unk> @ ult<unk> @ ura .
2025-05-27 19:13:17,413 - INFO - joeynmt.training - Example #3
2025-05-27 19:13:17,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:13:17,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:13:17,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ma', ',', 'e', 'la', 'm@@', '<unk>', '@', 'app@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ ma , e la m<unk> @ app<unk> @ a .
2025-05-27 19:13:17,414 - INFO - joeynmt.training - Example #4
2025-05-27 19:13:17,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:13:17,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:13:17,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', '<unk>', '@', 'o', 'succ@@', '<unk>', '@', 'esso', ',', 'la', 'mia', 'pers@@', '<unk>', '@', 'ona', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'cosa', 'che', '', 'che', '', 'stato', 'un', 'pa@@', '<unk>', '@', 'ese', 'di', 'anni', '.', '</s>']
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:13:17,415 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o succ<unk> @ esso , la mia pers<unk> @ ona che vi mostr<unk> @ a una cosa che vi mostr<unk> @ a una cosa che  che  stato un pa<unk> @ ese di anni .
2025-05-27 19:13:20,774 - INFO - joeynmt.training - Epoch   2, Step:     9600, Batch Loss:     1.246672, Batch Acc: 0.614132, Tokens per Sec:    20868, Lr: 0.000300
2025-05-27 19:13:24,159 - INFO - joeynmt.training - Epoch   2, Step:     9700, Batch Loss:     1.382323, Batch Acc: 0.616143, Tokens per Sec:    23479, Lr: 0.000300
2025-05-27 19:13:27,534 - INFO - joeynmt.training - Epoch   2, Step:     9800, Batch Loss:     1.409018, Batch Acc: 0.617104, Tokens per Sec:    22402, Lr: 0.000300
2025-05-27 19:13:30,951 - INFO - joeynmt.training - Epoch   2, Step:     9900, Batch Loss:     1.277229, Batch Acc: 0.619159, Tokens per Sec:    23579, Lr: 0.000300
2025-05-27 19:13:34,356 - INFO - joeynmt.training - Epoch   2, Step:    10000, Batch Loss:     1.264566, Batch Acc: 0.619506, Tokens per Sec:    23632, Lr: 0.000300
2025-05-27 19:13:34,357 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:13:34,357 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:13:49,507 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.32, ppl:   3.75, acc:   0.62, generation: 15.1385[sec], evaluation: 0.0000[sec]
2025-05-27 19:13:49,507 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:13:50,169 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/7500.ckpt
2025-05-27 19:13:50,191 - INFO - joeynmt.training - Example #0
2025-05-27 19:13:50,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:13:50,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:13:50,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'prima', 'volta', ',', 'ho', 'fatto', ',', 'ho', 'fatto', ',', 'ho', 'fatto', ',', 'questi', 'due', 'anni', ',', 'ho', 'fatto', ',', 'l&apos;', 'ho', 'fatto', 'che', 'la', 'prima', 'volta', ',', 'la', 'prima', 'volta', 'che', 'la', 'c@@', '<unk>', '@', 'r@@', '<unk>', '@', 'os@@', '<unk>', '@', 'sa', 'che', 'la', 'c@@', '<unk>', '@', 'r@@', '<unk>', '@', 'os@@', '<unk>', '@', 'sa', 'che', 'la', 'c@@', '<unk>', '@', 'r@@', '<unk>', '@', 'os@@', '<unk>', '@', 'a', ',', 'la', 'c@@', '<unk>', '@', 'r@@', '<unk>', '@', 'os@@', '<unk>', '@', 'a', ',', 'il', '1@@', '<unk>', '@', '8', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', '.', '</s>']
2025-05-27 19:13:50,192 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:13:50,192 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:13:50,192 - INFO - joeynmt.training - 	Hypothesis: E la prima volta , ho fatto , ho fatto , ho fatto , questi due anni , ho fatto , l&apos; ho fatto che la prima volta , la prima volta che la c<unk> @ r<unk> @ os<unk> @ sa che la c<unk> @ r<unk> @ os<unk> @ sa che la c<unk> @ r<unk> @ os<unk> @ a , la c<unk> @ r<unk> @ os<unk> @ a , il 1<unk> @ 8 milioni di doll<unk> @ ari .
2025-05-27 19:13:50,192 - INFO - joeynmt.training - Example #1
2025-05-27 19:13:50,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:13:50,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:13:50,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'la', 'cosa', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'questo', ',', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'questo', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '.', '</s>']
2025-05-27 19:13:50,193 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:13:50,193 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:13:50,193 - INFO - joeynmt.training - 	Hypothesis: Ma non  la cosa non  la s<unk> @ itu<unk> @ azione di non  la s<unk> @ itu<unk> @ azione di questo , non  la s<unk> @ itu<unk> @ azione di questo non  la s<unk> @ itu<unk> @ azione .
2025-05-27 19:13:50,193 - INFO - joeynmt.training - Example #2
2025-05-27 19:13:50,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:13:50,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:13:50,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ura', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'enti', ',', 'la', 'nostra', 'soci@@', '<unk>', '@', 'et', 'della', 'nostra', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 19:13:50,194 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:13:50,194 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:13:50,194 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ itu<unk> @ azione  la c<unk> @ at<unk> @ ura di in<unk> @ f<unk> @ am<unk> @ enti , la nostra soci<unk> @ et della nostra c<unk> @ ult<unk> @ ura .
2025-05-27 19:13:50,194 - INFO - joeynmt.training - Example #3
2025-05-27 19:13:50,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:13:50,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:13:50,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'tutto', ',', 'e', 'la', 's@@', '<unk>', '@', 'etti@@', '<unk>', '@', 'man@@', '<unk>', '@', 'a', 'e', 'e', 'la', 'tu@@', '<unk>', '@', 'a', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:13:50,195 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:13:50,195 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:13:50,195 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di tutto , e la s<unk> @ etti<unk> @ man<unk> @ a e e la tu<unk> @ a f<unk> @ am<unk> @ a .
2025-05-27 19:13:50,195 - INFO - joeynmt.training - Example #4
2025-05-27 19:13:50,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:13:50,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:13:50,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', '<unk>', '@', 'o', '', 'la', 'prima', 'volta', 'che', 'vi', 'ho', 'fatto', ',', 'vi', 'ho', 'fatto', 'una', 'cosa', 'che', 'ho', 'fatto', ',', 'una', 'cosa', 'che', 'ho', 'fatto', '', 'stato', 'un', 'po', '&apos;', 'di', '1@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:13:50,196 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:13:50,196 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:13:50,196 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o  la prima volta che vi ho fatto , vi ho fatto una cosa che ho fatto , una cosa che ho fatto  stato un po &apos; di 1<unk> @ 5 anni .
2025-05-27 19:13:53,662 - INFO - joeynmt.training - Epoch   2, Step:    10100, Batch Loss:     1.313063, Batch Acc: 0.619812, Tokens per Sec:    18959, Lr: 0.000300
2025-05-27 19:13:57,128 - INFO - joeynmt.training - Epoch   2, Step:    10200, Batch Loss:     1.358874, Batch Acc: 0.619283, Tokens per Sec:    22247, Lr: 0.000300
2025-05-27 19:14:00,620 - INFO - joeynmt.training - Epoch   2, Step:    10300, Batch Loss:     1.271849, Batch Acc: 0.619530, Tokens per Sec:    22594, Lr: 0.000300
2025-05-27 19:14:04,097 - INFO - joeynmt.training - Epoch   2, Step:    10400, Batch Loss:     1.389257, Batch Acc: 0.619495, Tokens per Sec:    22746, Lr: 0.000300
2025-05-27 19:14:07,602 - INFO - joeynmt.training - Epoch   2, Step:    10500, Batch Loss:     1.324364, Batch Acc: 0.622815, Tokens per Sec:    23055, Lr: 0.000300
2025-05-27 19:14:07,602 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:14:07,603 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:14:22,940 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.31, ppl:   3.71, acc:   0.62, generation: 15.3282[sec], evaluation: 0.0000[sec]
2025-05-27 19:14:22,941 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:14:23,569 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/8000.ckpt
2025-05-27 19:14:23,593 - INFO - joeynmt.training - Example #0
2025-05-27 19:14:23,594 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:14:23,594 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:14:23,594 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', '<unk>', '@', 'o', 'anno', ',', 'ho', 'fatto', 'questa', '', 'la', 'prima', 'volta', 'che', 'ho', 'fatto', 'questa', 'in@@', '<unk>', '@', 'du@@', '<unk>', '@', 'stri@@', '<unk>', '@', 'a', 'che', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'delle', 'persone', 'che', 'i', 'dati', ',', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'di', 'cui', 'i', 'dati', ',', 'la', 'ri@@', '<unk>', '@', 'es@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ita', ',', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'di', 'tre', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', ',', 'il', '19@@', '<unk>', '@', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 19:14:23,595 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:14:23,595 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:14:23,595 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o anno , ho fatto questa  la prima volta che ho fatto questa in<unk> @ du<unk> @ stri<unk> @ a che la maggi<unk> @ or parte delle persone che i dati , la maggi<unk> @ or parte di cui i dati , la ri<unk> @ es<unk> @ c<unk> @ ita , la maggi<unk> @ or parte di tre tre milioni di persone che hanno sc<unk> @ oper<unk> @ to , il 19<unk> @ 4<unk> @ 8 milioni di anni .
2025-05-27 19:14:23,595 - INFO - joeynmt.training - Example #1
2025-05-27 19:14:23,595 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:14:23,595 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:14:23,595 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'il', 'problema', 'di', 'questo', 'non', '', 'il', 'problema', 'di', 'cui', 'non', '', 'il', 'problema', 'di', 'questo', 'che', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'i@@', '<unk>', '@', 'den@@', '<unk>', '@', 'za', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'problema', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'problema', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:14:23,596 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:14:23,596 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:14:23,596 - INFO - joeynmt.training - 	Hypothesis: Ma non  il problema di questo non  il problema di cui non  il problema di questo che la c<unk> @ ur<unk> @ i<unk> @ den<unk> @ za di questo problema , non  il problema di questo problema , non  il problema di questo problema .
2025-05-27 19:14:23,596 - INFO - joeynmt.training - Example #2
2025-05-27 19:14:23,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:14:23,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:14:23,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', '', 'la', 'ver@@', '<unk>', '@', 'it', 'di', 'questo', '', 'il', 'sistema', 'di', 'c@@', '<unk>', '@', 'arb@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'o', ',', 'la', 'nostra', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ale', 'del', 'nostro', 'sistema', 'sistema', 'di', 'c@@', '<unk>', '@', 'entr@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:14:23,597 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:14:23,597 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:14:23,597 - INFO - joeynmt.training - 	Hypothesis: In realt  la ver<unk> @ it di questo  il sistema di c<unk> @ arb<unk> @ ar<unk> @ o , la nostra c<unk> @ ur<unk> @ ale del nostro sistema sistema di c<unk> @ entr<unk> @ ale .
2025-05-27 19:14:23,597 - INFO - joeynmt.training - Example #3
2025-05-27 19:14:23,597 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:14:23,597 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:14:23,597 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'stato', 'il', 'tr@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ito', 'e', 'la', 'b@@', '<unk>', '@', 'ella', 'di', 'p@@', '<unk>', '@', 'oco', 'e', 'e', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'b@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:14:23,598 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:14:23,598 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:14:23,598 - INFO - joeynmt.training - 	Hypothesis: E &apos; stato il tr<unk> @ att<unk> @ ito e la b<unk> @ ella di p<unk> @ oco e e la c<unk> @ ur<unk> @ b<unk> @ a .
2025-05-27 19:14:23,598 - INFO - joeynmt.training - Example #4
2025-05-27 19:14:23,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:14:23,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:14:23,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'ho', 'fatto', '', 'il', 'prim@@', '<unk>', '@', 'o', 'di', 'voi', ',', 'vi', 'vi', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'un', 'pa@@', '<unk>', '@', 'io', 'di', 'anni', 'fa', '.', '</s>']
2025-05-27 19:14:23,599 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:14:23,599 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:14:23,599 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che ho fatto  il prim<unk> @ o di voi , vi vi vi mostr<unk> @ er<unk> @  un pa<unk> @ io di anni fa .
2025-05-27 19:14:26,975 - INFO - joeynmt.training - Epoch   2, Step:    10600, Batch Loss:     1.374650, Batch Acc: 0.620803, Tokens per Sec:    19860, Lr: 0.000300
2025-05-27 19:14:30,406 - INFO - joeynmt.training - Epoch   2, Step:    10700, Batch Loss:     1.422705, Batch Acc: 0.619582, Tokens per Sec:    22628, Lr: 0.000300
2025-05-27 19:14:33,837 - INFO - joeynmt.training - Epoch   2, Step:    10800, Batch Loss:     1.282665, Batch Acc: 0.620323, Tokens per Sec:    22876, Lr: 0.000300
2025-05-27 19:14:37,249 - INFO - joeynmt.training - Epoch   2, Step:    10900, Batch Loss:     1.277033, Batch Acc: 0.621964, Tokens per Sec:    22516, Lr: 0.000300
2025-05-27 19:14:40,686 - INFO - joeynmt.training - Epoch   2, Step:    11000, Batch Loss:     1.345781, Batch Acc: 0.623581, Tokens per Sec:    22770, Lr: 0.000300
2025-05-27 19:14:40,686 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:14:40,687 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:14:57,209 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.30, ppl:   3.68, acc:   0.62, generation: 16.5136[sec], evaluation: 0.0000[sec]
2025-05-27 19:14:57,210 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:14:57,840 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/8500.ckpt
2025-05-27 19:14:57,856 - INFO - joeynmt.training - Example #0
2025-05-27 19:14:57,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:14:57,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:14:57,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'fatto', 'questa', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'a', 'questa', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'a', ',', 'ho', 'fatto', 'questa', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', ',', 'che', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', ',', 'che', 'la', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'azione', ',', 'che', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', ',', 'che', 'i', 'dati', ',', 'i', 'dati', 'che', 'hanno', 'fatto', 'i', 'm@@', '<unk>', '@', 'esso', ',', 'per', 'tre', 'tre', 'anni', ',', 'che', 'ho', 'fatto', ',', 'per', '1@@', '<unk>', '@', '5', 'anni', ',', 'che', 'ho', 'fatto', ',', 'ho', 'fatto', 'fatto', 'il', '7@@', '<unk>', '@', '0', 'anni', '.', '</s>']
2025-05-27 19:14:57,857 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Hypothesis: E ho fatto questa sc<unk> @ oper<unk> @ a questa sc<unk> @ oper<unk> @ a , ho fatto questa s<unk> @ itu<unk> @ azione , che la s<unk> @ itu<unk> @ azione , che la con<unk> @ si<unk> @ der<unk> @ azione , che la s<unk> @ itu<unk> @ azione , che i dati , i dati che hanno fatto i m<unk> @ esso , per tre tre anni , che ho fatto , per 1<unk> @ 5 anni , che ho fatto , ho fatto fatto il 7<unk> @ 0 anni .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - Example #1
2025-05-27 19:14:57,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:14:57,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:14:57,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'questo', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'questo', 'prog@@', '<unk>', '@', 'etto', ',', 'questa', '', 'questo', 'problema', 'di', 'questo', 'problema', ',', 'non', '', 'la', 'maggi@@', '<unk>', '@', 'ore', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  la s<unk> @ itu<unk> @ azione di questo non  la s<unk> @ itu<unk> @ azione di questo prog<unk> @ etto , questa  questo problema di questo problema , non  la maggi<unk> @ ore di questo problema .
2025-05-27 19:14:57,859 - INFO - joeynmt.training - Example #2
2025-05-27 19:14:57,859 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:14:57,859 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:14:57,859 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'zione', 'di', 'essere', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'og@@', '<unk>', '@', 'en@@', '<unk>', '@', 'o', ',', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'della', 'nostra', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 19:14:57,859 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:14:57,859 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:14:57,859 - INFO - joeynmt.training - 	Hypothesis: In realt  la s<unk> @ itu<unk> @ zione di essere in<unk> @ f<unk> @ lu<unk> @ og<unk> @ en<unk> @ o , la c<unk> @ ult<unk> @ ura della nostra c<unk> @ ult<unk> @ ura .
2025-05-27 19:14:57,860 - INFO - joeynmt.training - Example #3
2025-05-27 19:14:57,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:14:57,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:14:57,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'e', 'poi', 'si', 'chiam@@', '<unk>', '@', 'a', 'S@@', '<unk>', '@', 'c@@', '<unk>', '@', 'r@@', '<unk>', '@', 'om@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:14:57,860 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:14:57,860 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:14:57,860 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , e poi si chiam<unk> @ a S<unk> @ c<unk> @ r<unk> @ om<unk> @ a .
2025-05-27 19:14:57,860 - INFO - joeynmt.training - Example #4
2025-05-27 19:14:57,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:14:57,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:14:57,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', '<unk>', '@', 'o', 'che', 'ho', 'fatto', '', 'stato', 'stato', 'un', 'gr@@', '<unk>', '@', 'an', 's@@', '<unk>', '@', 'otto', 'di', 'voi', ',', '', 'una', 'cosa', 'che', '', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'in', 'ulti@@', '<unk>', '@', 'ma', 'anni', 'fa', '.', '</s>']
2025-05-27 19:14:57,861 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:14:57,861 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:14:57,861 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o che ho fatto  stato stato un gr<unk> @ an s<unk> @ otto di voi ,  una cosa che  stato stato stato stato stato stato sc<unk> @ oper<unk> @ to in ulti<unk> @ ma anni fa .
2025-05-27 19:15:01,276 - INFO - joeynmt.training - Epoch   2, Step:    11100, Batch Loss:     1.288755, Batch Acc: 0.625534, Tokens per Sec:    19119, Lr: 0.000300
2025-05-27 19:15:04,735 - INFO - joeynmt.training - Epoch   2, Step:    11200, Batch Loss:     1.280525, Batch Acc: 0.623022, Tokens per Sec:    23102, Lr: 0.000300
2025-05-27 19:15:08,173 - INFO - joeynmt.training - Epoch   2, Step:    11300, Batch Loss:     1.252034, Batch Acc: 0.624469, Tokens per Sec:    22730, Lr: 0.000300
2025-05-27 19:15:11,600 - INFO - joeynmt.training - Epoch   2, Step:    11400, Batch Loss:     1.246595, Batch Acc: 0.625609, Tokens per Sec:    22817, Lr: 0.000300
2025-05-27 19:15:14,968 - INFO - joeynmt.training - Epoch   2, Step:    11500, Batch Loss:     1.240937, Batch Acc: 0.626193, Tokens per Sec:    23623, Lr: 0.000300
2025-05-27 19:15:14,969 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:15:14,969 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:15:30,342 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.29, ppl:   3.62, acc:   0.63, generation: 15.3600[sec], evaluation: 0.0000[sec]
2025-05-27 19:15:30,343 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:15:30,864 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/9000.ckpt
2025-05-27 19:15:30,887 - INFO - joeynmt.training - Example #0
2025-05-27 19:15:30,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:15:30,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:15:30,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'm@@', '<unk>', '@', 'app@@', '<unk>', '@', 'a', 'di', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'fatto', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ezza', ',', 'che', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'i@@', '<unk>', '@', 'va', ',', 'che', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ezza', ',', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'azione', ',', 'il', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', ',', 'il', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', 'per', 'tre', 'anni', ',', 'il', '4@@', '<unk>', '@', '4@@', '<unk>', '@', '0', 'e', 'i', '4@@', '<unk>', '@', '0', 'e', 'i', '4@@', '<unk>', '@', '0', 'anni', '.', '</s>']
2025-05-27 19:15:30,888 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:15:30,888 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:15:30,888 - INFO - joeynmt.training - 	Hypothesis: La m<unk> @ app<unk> @ a di questa fot<unk> @ o , ho fatto questa fot<unk> @ o , per la c<unk> @ ur<unk> @ ezza , che la c<unk> @ ur<unk> @ i<unk> @ va , che la c<unk> @ ur<unk> @ ezza , la c<unk> @ ur<unk> @ azione , il m<unk> @ oti<unk> @ vo , il m<unk> @ oti<unk> @ vo per tre anni , il 4<unk> @ 4<unk> @ 0 e i 4<unk> @ 0 e i 4<unk> @ 0 anni .
2025-05-27 19:15:30,889 - INFO - joeynmt.training - Example #1
2025-05-27 19:15:30,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:15:30,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:15:30,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', ',', 'non', '', 'un', 'problema', 'di', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ente', ',', 'il', 'ris@@', '<unk>', '@', 'chio', 'di', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bil@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'problema', 'di', 'non', '', 'il', 'problema', 'di', 'cui', 'non', '', 'il', 'fatto', 'di', 'un', 'problema', '.', '</s>']
2025-05-27 19:15:30,889 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:15:30,890 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:15:30,890 - INFO - joeynmt.training - 	Hypothesis: Ma questo , non  un problema di c<unk> @ ur<unk> @ i<unk> @ ente , il ris<unk> @ chio di in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ it di questo problema , non  il problema di non  il problema di cui non  il fatto di un problema .
2025-05-27 19:15:30,890 - INFO - joeynmt.training - Example #2
2025-05-27 19:15:30,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:15:30,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:15:30,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', '<unk>', '@', 'etti', ',', 'la', 'c@@', '<unk>', '@', 'a@@', '<unk>', '@', 'zza', '', 'la', 'c@@', '<unk>', '@', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', 'il', 'modo', 'di', 'essere', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'to', 'di', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Hypothesis: In eff<unk> @ etti , la c<unk> @ a<unk> @ zza  la c<unk> @ ris<unk> @ ol<unk> @ vere il modo di essere in<unk> @ cre<unk> @ di<unk> @ to di una c<unk> @ ura di c<unk> @ li<unk> @ ma di c<unk> @ li<unk> @ ma .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - Example #3
2025-05-27 19:15:30,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:15:30,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:15:30,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 's@@', '<unk>', '@', 'etti@@', '<unk>', '@', 'man@@', '<unk>', '@', 'e', 'e', 'di', 'l@@', '<unk>', '@', 'ei', 'si', 'chiam@@', '<unk>', '@', 'a', '&quot;', '.', '</s>']
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di s<unk> @ etti<unk> @ man<unk> @ e e di l<unk> @ ei si chiam<unk> @ a &quot; .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - Example #4
2025-05-27 19:15:30,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:15:30,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:15:30,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'la', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', '', 'che', '', 'stato', 'un', 'gr@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ppo', 'di', 'anni', '.', '</s>']
2025-05-27 19:15:30,892 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:15:30,892 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:15:30,892 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ a la prima cosa che vi mostr<unk> @ a una cosa che vi mostr<unk> @ a una cosa che  una cosa che  che  stato un gr<unk> @ u<unk> @ ppo di anni .
2025-05-27 19:15:34,330 - INFO - joeynmt.training - Epoch   2, Step:    11600, Batch Loss:     1.318744, Batch Acc: 0.628237, Tokens per Sec:    20348, Lr: 0.000300
2025-05-27 19:15:37,755 - INFO - joeynmt.training - Epoch   2, Step:    11700, Batch Loss:     1.315692, Batch Acc: 0.623407, Tokens per Sec:    23674, Lr: 0.000300
2025-05-27 19:15:41,165 - INFO - joeynmt.training - Epoch   2, Step:    11800, Batch Loss:     1.257781, Batch Acc: 0.628644, Tokens per Sec:    23221, Lr: 0.000300
2025-05-27 19:15:44,572 - INFO - joeynmt.training - Epoch   2, Step:    11900, Batch Loss:     1.322094, Batch Acc: 0.629743, Tokens per Sec:    23623, Lr: 0.000300
2025-05-27 19:15:47,978 - INFO - joeynmt.training - Epoch   2, Step:    12000, Batch Loss:     1.352537, Batch Acc: 0.632918, Tokens per Sec:    23837, Lr: 0.000300
2025-05-27 19:15:47,978 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:15:47,978 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:16:02,097 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.28, ppl:   3.58, acc:   0.63, generation: 14.1092[sec], evaluation: 0.0000[sec]
2025-05-27 19:16:02,097 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:16:02,702 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/9500.ckpt
2025-05-27 19:16:02,725 - INFO - joeynmt.training - Example #0
2025-05-27 19:16:02,725 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:16:02,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:16:02,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'questo', 'anno', ',', 'ho', 'visto', 'questa', '', 'la', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', ',', 'che', 'la', 'p@@', '<unk>', '@', 'an@@', '<unk>', '@', 'ca', 'che', '', 'che', 'il', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'un', 'anno', ',', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'il', '4@@', '<unk>', '@', '4@@', '<unk>', '@', '4@@', '<unk>', '@', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', '.', '</s>']
2025-05-27 19:16:02,726 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:16:02,726 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:16:02,726 - INFO - joeynmt.training - 	Hypothesis: E in questo anno , ho visto questa  la sc<unk> @ or<unk> @ sa , che la p<unk> @ an<unk> @ ca che  che il m<unk> @ ezz<unk> @ o di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di un anno , tre milioni di persone che hanno sc<unk> @ oper<unk> @ to che hanno sc<unk> @ oper<unk> @ to il 4<unk> @ 4<unk> @ 4<unk> @ 4<unk> @ 8 milioni di doll<unk> @ ari .
2025-05-27 19:16:02,726 - INFO - joeynmt.training - Example #1
2025-05-27 19:16:02,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:16:02,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:16:02,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'la', 'cosa', 'che', '', 'che', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', ',', 'che', 'non', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'questo', '.', '</s>']
2025-05-27 19:16:02,727 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:16:02,727 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:16:02,727 - INFO - joeynmt.training - 	Hypothesis: Ma non  la cosa che  che non  la s<unk> @ itu<unk> @ azione , che non  la s<unk> @ itu<unk> @ azione di questo .
2025-05-27 19:16:02,727 - INFO - joeynmt.training - Example #2
2025-05-27 19:16:02,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:16:02,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:16:02,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', '', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'c@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 19:16:02,728 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:16:02,728 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:16:02,728 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt  la s<unk> @ fi<unk> @ da  la c<unk> @ aus<unk> @ a di una c<unk> @ aus<unk> @ a della c<unk> @ at<unk> @ ura .
2025-05-27 19:16:02,728 - INFO - joeynmt.training - Example #3
2025-05-27 19:16:02,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:16:02,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:16:02,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', '<unk>', '@', 'e@@', '<unk>', '@', 'dete', ',', 'e', 'la', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'e', 'la', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', '.', '</s>']
2025-05-27 19:16:02,729 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:16:02,729 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:16:02,729 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ e<unk> @ dete , e la sc<unk> @ or<unk> @ sa e la sc<unk> @ or<unk> @ sa .
2025-05-27 19:16:02,729 - INFO - joeynmt.training - Example #4
2025-05-27 19:16:02,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:16:02,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:16:02,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', '', 'succ@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 19:16:02,730 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:16:02,730 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:16:02,730 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ er<unk> @  la prima volta che vi mostr<unk> @ er<unk> @  una cosa che  succ<unk> @ esso in cui  succ<unk> @ esso .
2025-05-27 19:16:06,128 - INFO - joeynmt.training - Epoch   2, Step:    12100, Batch Loss:     1.270924, Batch Acc: 0.626987, Tokens per Sec:    20025, Lr: 0.000300
2025-05-27 19:16:09,534 - INFO - joeynmt.training - Epoch   2, Step:    12200, Batch Loss:     1.330685, Batch Acc: 0.629300, Tokens per Sec:    22922, Lr: 0.000300
2025-05-27 19:16:12,852 - INFO - joeynmt.training - Epoch   2, Step:    12300, Batch Loss:     1.254413, Batch Acc: 0.635443, Tokens per Sec:    23225, Lr: 0.000300
2025-05-27 19:16:16,171 - INFO - joeynmt.training - Epoch   2, Step:    12400, Batch Loss:     1.175360, Batch Acc: 0.630482, Tokens per Sec:    24182, Lr: 0.000300
2025-05-27 19:16:19,508 - INFO - joeynmt.training - Epoch   2, Step:    12500, Batch Loss:     1.258564, Batch Acc: 0.635196, Tokens per Sec:    24393, Lr: 0.000300
2025-05-27 19:16:19,509 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:16:19,509 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:16:31,105 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.27, ppl:   3.55, acc:   0.63, generation: 11.5872[sec], evaluation: 0.0000[sec]
2025-05-27 19:16:31,105 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:16:31,593 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/10000.ckpt
2025-05-27 19:16:31,610 - INFO - joeynmt.training - Example #0
2025-05-27 19:16:31,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:16:31,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:16:31,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'fatto', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'fatto', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'fatto', 'questa', 'fot@@', '<unk>', '@', 'o', 'che', 'la', 'c@@', '<unk>', '@', 'av@@', '<unk>', '@', 'e', 'la', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', 'che', 'ha', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'do', 'che', 'la', 'c@@', '<unk>', '@', 'av@@', '<unk>', '@', 'e', 'per', 'le', 'persone', 'che', 'hanno', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ett@@', '<unk>', '@', 'amente', 'c@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'in@@', '<unk>', '@', 'a@@', '<unk>', '@', 'io', ',', 'per', 'tre', 'anni', ',', 'per', 'la', 'citt', 'di', '1@@', '<unk>', '@', '8', 'anni', '.', '</s>']
2025-05-27 19:16:31,612 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:16:31,612 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:16:31,612 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho fatto questa fot<unk> @ o , ho fatto questa fot<unk> @ o , ho fatto questa fot<unk> @ o che la c<unk> @ av<unk> @ e la sc<unk> @ u<unk> @ ola che ha ri<unk> @ guar<unk> @ do che la c<unk> @ av<unk> @ e per le persone che hanno ri<unk> @ m<unk> @ ett<unk> @ amente c<unk> @ ent<unk> @ in<unk> @ a<unk> @ io , per tre anni , per la citt di 1<unk> @ 8 anni .
2025-05-27 19:16:31,612 - INFO - joeynmt.training - Example #1
2025-05-27 19:16:31,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:16:31,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:16:31,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'modo', 'di', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bile', 'che', 'non', '', 'la', 'con@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'enza', 'di', 'questa', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'enza', 'non', '', 'il', 'fatto', 'che', 'non', '', 'il', 'problema', 'di', 'questo', 'che', 'non', '', 'il', 'fatto', 'che', 'non', '', 'il', 'problema', '.', '</s>']
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il modo di in<unk> @ cre<unk> @ di<unk> @ bile che non  la con<unk> @ fer<unk> @ enza di questa in<unk> @ f<unk> @ lu<unk> @ enza non  il fatto che non  il problema di questo che non  il fatto che non  il problema .
2025-05-27 19:16:31,613 - INFO - joeynmt.training - Example #2
2025-05-27 19:16:31,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:16:31,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:16:31,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', '', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'di', 'un', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 'in@@', '<unk>', '@', 'tel@@', '<unk>', '@', 'li@@', '<unk>', '@', 'gen@@', '<unk>', '@', 'za', ',', 'il', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '.', '</s>']
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt  la maggi<unk> @ or parte di un s<unk> @ ac<unk> @ co di in<unk> @ tel<unk> @ li<unk> @ gen<unk> @ za , il sistema di c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - Example #3
2025-05-27 19:16:31,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:16:31,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:16:31,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'stato', 'in', 'realt', ',', 'e', 'la', 's@@', '<unk>', '@', 'etti@@', '<unk>', '@', 'man@@', '<unk>', '@', 'a', 'e', 'la', 'b@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:16:31,614 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - 	Hypothesis: E &apos; stato in realt , e la s<unk> @ etti<unk> @ man<unk> @ a e la b<unk> @ om<unk> @ ma .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - Example #4
2025-05-27 19:16:31,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:16:31,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:16:31,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'i', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'la', 'prima', 'volta', 'che', 'ha', 'fatto', '.', '</s>']
2025-05-27 19:16:31,615 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:16:31,615 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:16:31,615 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ o la prima volta che vi mostr<unk> @ i la prima volta che vi mostr<unk> @ a la prima volta che ha fatto .
2025-05-27 19:16:34,920 - INFO - joeynmt.training - Epoch   2, Step:    12600, Batch Loss:     1.276156, Batch Acc: 0.633897, Tokens per Sec:    20594, Lr: 0.000300
2025-05-27 19:16:38,231 - INFO - joeynmt.training - Epoch   2, Step:    12700, Batch Loss:     1.247316, Batch Acc: 0.635895, Tokens per Sec:    23852, Lr: 0.000300
2025-05-27 19:16:41,574 - INFO - joeynmt.training - Epoch   2, Step:    12800, Batch Loss:     1.289197, Batch Acc: 0.634785, Tokens per Sec:    24327, Lr: 0.000300
2025-05-27 19:16:44,879 - INFO - joeynmt.training - Epoch   2, Step:    12900, Batch Loss:     1.282854, Batch Acc: 0.632701, Tokens per Sec:    23924, Lr: 0.000300
2025-05-27 19:16:48,186 - INFO - joeynmt.training - Epoch   2, Step:    13000, Batch Loss:     1.281909, Batch Acc: 0.633186, Tokens per Sec:    23579, Lr: 0.000300
2025-05-27 19:16:48,187 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:16:48,187 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:17:00,752 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.26, ppl:   3.53, acc:   0.64, generation: 12.5565[sec], evaluation: 0.0000[sec]
2025-05-27 19:17:00,752 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:17:01,412 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/10500.ckpt
2025-05-27 19:17:01,436 - INFO - joeynmt.training - Example #0
2025-05-27 19:17:01,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:17:01,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:17:01,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'in@@', '<unk>', '@', 'fine', ',', 'ho', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'questo', ',', 'ho', 'fatto', 'che', 'la', 'm@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'un', 'ar@@', '<unk>', '@', 'g@@', '<unk>', '@', 'omento', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'in@@', '<unk>', '@', 'azione', ',', 'per', 'tre', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'tre', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'la', 'citt', 'di', 'circa', '4@@', '<unk>', '@', '0', ',', 'il', '1@@', '<unk>', '@', '8', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', '.', '</s>']
2025-05-27 19:17:01,438 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:17:01,438 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:17:01,438 - INFO - joeynmt.training - 	Hypothesis: E &apos; in<unk> @ fine , ho sc<unk> @ oper<unk> @ to questo , ho fatto che la m<unk> @ em<unk> @ br<unk> @ a che la c<unk> @ aus<unk> @ a di un ar<unk> @ g<unk> @ omento di c<unk> @ aus<unk> @ a di c<unk> @ ent<unk> @ in<unk> @ azione , per tre tre milioni di anni , per tre tre milioni di anni , per la citt di circa 4<unk> @ 0 , il 1<unk> @ 8 milioni di doll<unk> @ ari .
2025-05-27 19:17:01,438 - INFO - joeynmt.training - Example #1
2025-05-27 19:17:01,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:17:01,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:17:01,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'problema', 'di', 'non', '', 'che', 'non', '', 'la', 'la', 'prima', 'cosa', 'che', 'la', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', 'il', 'problema', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:17:01,439 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:17:01,439 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:17:01,439 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il problema di non  che non  la la prima cosa che la ris<unk> @ ol<unk> @ vere il problema di questo problema .
2025-05-27 19:17:01,439 - INFO - joeynmt.training - Example #2
2025-05-27 19:17:01,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:17:01,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:17:01,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 'realt', '', 'la', 'n@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ess@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ura', 'del', 'nostro', 'sistema', 'sistema', 'sistema', 'sistema', 'di', 'di@@', '<unk>', '@', 'ag@@', '<unk>', '@', 'n@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:17:01,440 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:17:01,440 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:17:01,440 - INFO - joeynmt.training - 	Hypothesis: In realt , la realt  la n<unk> @ ec<unk> @ ess<unk> @ a  la c<unk> @ at<unk> @ ura del nostro sistema sistema sistema sistema di di<unk> @ ag<unk> @ n<unk> @ et<unk> @ ico .
2025-05-27 19:17:01,440 - INFO - joeynmt.training - Example #3
2025-05-27 19:17:01,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:17:01,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:17:01,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'in@@', '<unk>', '@', 'tr@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'e', 'il', 'p@@', '<unk>', '@', 'om@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:17:01,441 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:17:01,441 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:17:01,441 - INFO - joeynmt.training - 	Hypothesis: E &apos; in<unk> @ tr<unk> @ ac<unk> @ ci<unk> @ ano e il p<unk> @ om<unk> @ e .
2025-05-27 19:17:01,441 - INFO - joeynmt.training - Example #4
2025-05-27 19:17:01,441 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:17:01,441 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:17:01,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'i', 'una', 'di', 'una', 'c@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ale', 'che', '', 'stata', 'la', 'prima', 'volta', 'che', '', 'stata', 'la', 'prima', 'prima', 'volta', '.', '</s>']
2025-05-27 19:17:01,441 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:17:01,442 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:17:01,442 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma che vi mostr<unk> @ o la prima volta che vi mostr<unk> @ i una di una c<unk> @ ent<unk> @ u<unk> @ ale che  stata la prima volta che  stata la prima prima volta .
2025-05-27 19:17:04,865 - INFO - joeynmt.training - Epoch   2, Step:    13100, Batch Loss:     1.233199, Batch Acc: 0.637396, Tokens per Sec:    19290, Lr: 0.000300
2025-05-27 19:17:08,201 - INFO - joeynmt.training - Epoch   2, Step:    13200, Batch Loss:     1.162460, Batch Acc: 0.637399, Tokens per Sec:    23379, Lr: 0.000300
2025-05-27 19:17:11,590 - INFO - joeynmt.training - Epoch   2, Step:    13300, Batch Loss:     1.349093, Batch Acc: 0.637342, Tokens per Sec:    23965, Lr: 0.000300
2025-05-27 19:17:14,998 - INFO - joeynmt.training - Epoch   2, Step:    13400, Batch Loss:     1.283956, Batch Acc: 0.638644, Tokens per Sec:    23864, Lr: 0.000300
2025-05-27 19:17:18,418 - INFO - joeynmt.training - Epoch   2, Step:    13500, Batch Loss:     1.285493, Batch Acc: 0.638752, Tokens per Sec:    23547, Lr: 0.000300
2025-05-27 19:17:18,418 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:17:18,418 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:17:33,974 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.25, ppl:   3.49, acc:   0.64, generation: 15.5428[sec], evaluation: 0.0000[sec]
2025-05-27 19:17:33,975 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:17:34,547 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/11000.ckpt
2025-05-27 19:17:34,569 - INFO - joeynmt.training - Example #0
2025-05-27 19:17:34,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:17:34,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:17:34,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'fatto', 'che', 'ho', 'fatto', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'fatto', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'che', 'la', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'sione', 'di', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ente', ',', 'che', 'la', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'sione', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'la', 'qu@@', '<unk>', '@', 'ale', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', 'tre', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 19:17:34,571 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:17:34,571 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:17:34,571 - INFO - joeynmt.training - 	Hypothesis: E ho fatto che ho fatto questa fot<unk> @ o , ho fatto questa fot<unk> @ o , che la p<unk> @ es<unk> @ sione di p<unk> @ es<unk> @ c<unk> @ ente , che la p<unk> @ es<unk> @ sione di tre milioni di anni , che la qu<unk> @ ale di tre milioni di anni , per tre milioni di anni , per tre milioni di anni , per tre milioni di anni , per c<unk> @ ento di anni , per c<unk> @ ento , per tre milioni di anni .
2025-05-27 19:17:34,571 - INFO - joeynmt.training - Example #1
2025-05-27 19:17:34,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:17:34,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:17:34,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'una', 'cosa', 'che', 'non', '', 'il', 'problema', 'di', 'cui', 'non', '', 'la', 'n@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ess@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:17:34,572 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:17:34,572 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:17:34,572 - INFO - joeynmt.training - 	Hypothesis: Ma non  una cosa che non  il problema di cui non  la n<unk> @ ec<unk> @ ess<unk> @ it di questo problema .
2025-05-27 19:17:34,572 - INFO - joeynmt.training - Example #2
2025-05-27 19:17:34,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:17:34,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:17:34,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', '', 'il', 'sistema', '', 'il', 'sistema', 'di', 's@@', '<unk>', '@', 'es@@', '<unk>', '@', 'im@@', '<unk>', '@', 'o', '', 'il', 'sistema', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:17:34,573 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:17:34,573 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:17:34,573 - INFO - joeynmt.training - 	Hypothesis: In realt ,  il sistema  il sistema di s<unk> @ es<unk> @ im<unk> @ o  il sistema di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:17:34,573 - INFO - joeynmt.training - Example #3
2025-05-27 19:17:34,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:17:34,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:17:34,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'in', 'l@@', '<unk>', '@', 'ei', 's@@', '<unk>', '@', 'otto', ',', 'e', 'in', 'gi@@', '<unk>', '@', 'ro', '.', '</s>']
2025-05-27 19:17:34,574 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:17:34,574 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:17:34,574 - INFO - joeynmt.training - 	Hypothesis: E &apos; in l<unk> @ ei s<unk> @ otto , e in gi<unk> @ ro .
2025-05-27 19:17:34,574 - INFO - joeynmt.training - Example #4
2025-05-27 19:17:34,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:17:34,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:17:34,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'cosa', 'che', 'ho', 'fatto', 'una', 'cosa', 'che', '', 'una', 'cosa', 'che', 'ha', 'fatto', '.', '</s>']
2025-05-27 19:17:34,575 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:17:34,575 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:17:34,575 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ er<unk> @  una cosa che vi mostr<unk> @ a una cosa che ho fatto una cosa che  una cosa che ha fatto .
2025-05-27 19:17:38,009 - INFO - joeynmt.training - Epoch   2, Step:    13600, Batch Loss:     1.268145, Batch Acc: 0.640567, Tokens per Sec:    19682, Lr: 0.000300
2025-05-27 19:17:41,448 - INFO - joeynmt.training - Epoch   2, Step:    13700, Batch Loss:     1.313471, Batch Acc: 0.639062, Tokens per Sec:    23129, Lr: 0.000300
2025-05-27 19:17:44,854 - INFO - joeynmt.training - Epoch   2, Step:    13800, Batch Loss:     1.204301, Batch Acc: 0.639151, Tokens per Sec:    23067, Lr: 0.000300
2025-05-27 19:17:48,287 - INFO - joeynmt.training - Epoch   2, Step:    13900, Batch Loss:     1.198202, Batch Acc: 0.639215, Tokens per Sec:    23524, Lr: 0.000300
2025-05-27 19:17:51,705 - INFO - joeynmt.training - Epoch   2, Step:    14000, Batch Loss:     1.249046, Batch Acc: 0.639392, Tokens per Sec:    23392, Lr: 0.000300
2025-05-27 19:17:51,705 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:17:51,705 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:18:07,113 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.24, ppl:   3.46, acc:   0.64, generation: 15.3995[sec], evaluation: 0.0000[sec]
2025-05-27 19:18:07,114 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:18:07,602 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/11500.ckpt
2025-05-27 19:18:07,626 - INFO - joeynmt.training - Example #0
2025-05-27 19:18:07,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:18:07,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:18:07,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'fine', ',', 'ho', 'fatto', 'questa', '', 'la', 'mia', 'f@@', '<unk>', '@', 'est@@', '<unk>', '@', 'a', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'che', 'la', 'f@@', '<unk>', '@', 'ant@@', '<unk>', '@', 'as@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ita', ',', 'che', 'la', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'n@@', '<unk>', '@', 'on@@', '<unk>', '@', 'al@@', '<unk>', '@', 'ia', 'di', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', ',', 'che', 'i', 'dati', 'per', 'i', '1@@', '<unk>', '@', '8', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', ',', 'che', 'hanno', 'av@@', '<unk>', '@', 'uto', 'per', 'i', 'dati', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', '1@@', '<unk>', '@', '8', 'milioni', 'di', 'doll@@', '<unk>', '@', 'ari', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:18:07,627 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:18:07,627 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:18:07,627 - INFO - joeynmt.training - 	Hypothesis: E la fine , ho fatto questa  la mia f<unk> @ est<unk> @ a , ho mostr<unk> @ ato che la f<unk> @ ant<unk> @ as<unk> @ c<unk> @ ita , che la g<unk> @ over<unk> @ n<unk> @ on<unk> @ al<unk> @ ia di milioni di doll<unk> @ ari , che i dati per i 1<unk> @ 8 milioni di doll<unk> @ ari , che hanno av<unk> @ uto per i dati , per c<unk> @ ento di 1<unk> @ 8 milioni di doll<unk> @ ari , per c<unk> @ ento , il 4<unk> @ 0 % .
2025-05-27 19:18:07,627 - INFO - joeynmt.training - Example #1
2025-05-27 19:18:07,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:18:07,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:18:07,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'fatto', 'che', 'non', '', 'il', 'fatto', 'di', 'questo', 'non', '', 'il', 'ris@@', '<unk>', '@', 'chio', 'di', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', 'questo', 'problema', 'di', 'queste', 'cose', 'che', 'non', '', 'il', 'problema', 'di', 'questo', 'non', '', 'il', 'problema', 'di', 'questo', 'che', 'non', '', 'il', 'problema', 'di', 'questo', 'non', '', 'il', 'mondo', '.', '</s>']
2025-05-27 19:18:07,628 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:18:07,628 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:18:07,628 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il fatto che non  il fatto di questo non  il ris<unk> @ chio di ris<unk> @ ol<unk> @ vere questo problema di queste cose che non  il problema di questo non  il problema di questo che non  il problema di questo non  il mondo .
2025-05-27 19:18:07,628 - INFO - joeynmt.training - Example #2
2025-05-27 19:18:07,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:18:07,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:18:07,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'il', 'sistema', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'og@@', '<unk>', '@', 'o', 'del', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:18:07,629 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:18:07,629 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:18:07,629 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ fi<unk> @ da  la s<unk> @ fi<unk> @ da  il sistema di in<unk> @ f<unk> @ lu<unk> @ og<unk> @ o del sistema di c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:18:07,629 - INFO - joeynmt.training - Example #3
2025-05-27 19:18:07,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:18:07,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:18:07,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', '', 'in', 'un', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 's@@', '<unk>', '@', '', '.', '</s>']
2025-05-27 19:18:07,630 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:18:07,630 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:18:07,630 - INFO - joeynmt.training - 	Hypothesis: E si  in un s<unk> @ ac<unk> @ co di s<unk> @  .
2025-05-27 19:18:07,630 - INFO - joeynmt.training - Example #4
2025-05-27 19:18:07,631 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:18:07,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:18:07,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'questa', '', 'una', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'essi@@', '<unk>', '@', 'va', 'in', 'cin@@', '<unk>', '@', 'que', 'anni', '.', '</s>']
2025-05-27 19:18:07,631 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:18:07,631 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:18:07,631 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostr<unk> @ er<unk> @  che vi mostr<unk> @ er<unk> @   una c<unk> @ aus<unk> @ a di questa  una cosa che  succ<unk> @ essi<unk> @ va in cin<unk> @ que anni .
2025-05-27 19:18:11,036 - INFO - joeynmt.training - Epoch   2, Step:    14100, Batch Loss:     1.259939, Batch Acc: 0.641321, Tokens per Sec:    20386, Lr: 0.000300
2025-05-27 19:18:14,430 - INFO - joeynmt.training - Epoch   2, Step:    14200, Batch Loss:     1.233723, Batch Acc: 0.643578, Tokens per Sec:    22989, Lr: 0.000300
2025-05-27 19:18:17,816 - INFO - joeynmt.training - Epoch   2, Step:    14300, Batch Loss:     1.247798, Batch Acc: 0.645113, Tokens per Sec:    23875, Lr: 0.000300
2025-05-27 19:18:21,194 - INFO - joeynmt.training - Epoch   2, Step:    14400, Batch Loss:     1.268963, Batch Acc: 0.643792, Tokens per Sec:    23719, Lr: 0.000300
2025-05-27 19:18:24,600 - INFO - joeynmt.training - Epoch   2, Step:    14500, Batch Loss:     1.158336, Batch Acc: 0.644444, Tokens per Sec:    23586, Lr: 0.000300
2025-05-27 19:18:24,600 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:18:24,601 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:18:40,325 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.23, ppl:   3.42, acc:   0.65, generation: 15.7110[sec], evaluation: 0.0000[sec]
2025-05-27 19:18:40,325 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:18:40,997 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/12000.ckpt
2025-05-27 19:18:41,023 - INFO - joeynmt.training - Example #0
2025-05-27 19:18:41,024 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:18:41,024 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:18:41,024 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'fatto', 'questa', 'parte', 'di', 'questi', 'due', 'anni', ',', 'ho', 'fatto', ',', 'ho', 'fatto', 'questa', '', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'azione', 'per', 'la', 'prima', 'volta', 'che', 'i', 'dati', 'i', 'dati', 'i', 'dati', 'in', 'gra@@', '<unk>', '@', 'do', 'di', 'f@@', '<unk>', '@', 'ar', 's@@', '<unk>', '@', '', 'che', 'i', 'dati', 'sono', 'tre', 'gior@@', '<unk>', '@', 'n@@', '<unk>', '@', 'ali', 'per', 'i', 'tre', 'anni', ',', 'per', 'i', 'dati', ',', 'tre', 'tre', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'i', 'dati', ',', 'tre', 'anni', ',', 'per', 'i', 'dati', ',', 'per', 'i', 'dati', ',', 'per', 'i', 'dati', ',', 'per', 'i', 'dati', ',', 'per', 'i', 'dati', '.', '</s>']
2025-05-27 19:18:41,024 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:18:41,024 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:18:41,025 - INFO - joeynmt.training - 	Hypothesis: E ho fatto questa parte di questi due anni , ho fatto , ho fatto questa  la p<unk> @ op<unk> @ ol<unk> @ azione per la prima volta che i dati i dati i dati in gra<unk> @ do di f<unk> @ ar s<unk> @  che i dati sono tre gior<unk> @ n<unk> @ ali per i tre anni , per i dati , tre tre m<unk> @ oti<unk> @ vi per i dati , tre anni , per i dati , per i dati , per i dati , per i dati , per i dati .
2025-05-27 19:18:41,025 - INFO - joeynmt.training - Example #1
2025-05-27 19:18:41,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:18:41,025 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:18:41,025 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'la', 'cosa', 'che', 'non', '', 'che', '', 'il', 'fatto', 'di', 'questo', 'che', 'non', '', 'il', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'ato', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'problema', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:18:41,026 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:18:41,026 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:18:41,026 - INFO - joeynmt.training - 	Hypothesis: Ma non  la cosa che non  che  il fatto di questo che non  il con<unk> @ si<unk> @ der<unk> @ ato di questo problema , non  il problema di questo problema .
2025-05-27 19:18:41,026 - INFO - joeynmt.training - Example #2
2025-05-27 19:18:41,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:18:41,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:18:41,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'che', '', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 's@@', '<unk>', '@', 'in@@', '<unk>', '@', 'azione', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'vello', 'glob@@', '<unk>', '@', 'ale', 'del', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', ',', 'il', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:18:41,027 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:18:41,027 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:18:41,027 - INFO - joeynmt.training - 	Hypothesis: In realt , che  la s<unk> @ fi<unk> @ da  la s<unk> @ in<unk> @ azione di c<unk> @ li<unk> @ vello glob<unk> @ ale del sistema glob<unk> @ ale glob<unk> @ ale , il sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:18:41,027 - INFO - joeynmt.training - Example #3
2025-05-27 19:18:41,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:18:41,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:18:41,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'in', 'realt', ',', 'e', 'in', 's@@', '<unk>', '@', 'etti@@', '<unk>', '@', 'man@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:18:41,027 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e in realt , e in s<unk> @ etti<unk> @ man<unk> @ a .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - Example #4
2025-05-27 19:18:41,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:18:41,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:18:41,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'un', 'pa@@', '<unk>', '@', 'io', 'di', 'anni', 'fa', '.', '</s>']
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @  un pa<unk> @ io di anni fa .
2025-05-27 19:18:44,438 - INFO - joeynmt.training - Epoch   2, Step:    14600, Batch Loss:     1.406981, Batch Acc: 0.643522, Tokens per Sec:    19286, Lr: 0.000300
2025-05-27 19:18:47,853 - INFO - joeynmt.training - Epoch   2, Step:    14700, Batch Loss:     1.265407, Batch Acc: 0.644272, Tokens per Sec:    24064, Lr: 0.000300
2025-05-27 19:18:51,234 - INFO - joeynmt.training - Epoch   2, Step:    14800, Batch Loss:     1.291039, Batch Acc: 0.642656, Tokens per Sec:    23050, Lr: 0.000300
2025-05-27 19:18:54,637 - INFO - joeynmt.training - Epoch   2, Step:    14900, Batch Loss:     1.365782, Batch Acc: 0.646855, Tokens per Sec:    23338, Lr: 0.000300
2025-05-27 19:18:58,031 - INFO - joeynmt.training - Epoch   2, Step:    15000, Batch Loss:     1.359763, Batch Acc: 0.643470, Tokens per Sec:    23562, Lr: 0.000300
2025-05-27 19:18:58,031 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:18:58,031 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:19:15,082 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.22, ppl:   3.39, acc:   0.65, generation: 17.0377[sec], evaluation: 0.0000[sec]
2025-05-27 19:19:15,083 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:19:15,676 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/12500.ckpt
2025-05-27 19:19:15,696 - INFO - joeynmt.training - Example #0
2025-05-27 19:19:15,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:19:15,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:19:15,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', 'pa@@', '<unk>', '@', 'io', 'ho', 'fatto', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'fatto', 'questa', 'fot@@', '<unk>', '@', 'o', 'per', 'mostr@@', '<unk>', '@', 'are', 'che', 'la', 'm@@', '<unk>', '@', 'app@@', '<unk>', '@', 'a', 'per', 'i', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'enti', 'che', 'i', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'enti', 'per', 'i', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'persone', 'per', 'tre', 'anni', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'tre', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'anni', ',', 'per', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:19:15,698 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:19:15,698 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:19:15,698 - INFO - joeynmt.training - 	Hypothesis: E questo pa<unk> @ io ho fatto questa fot<unk> @ o , ho fatto questa fot<unk> @ o per mostr<unk> @ are che la m<unk> @ app<unk> @ a per i g<unk> @ am<unk> @ enti che i g<unk> @ am<unk> @ enti per i tre mili<unk> @ ar<unk> @ di di di persone per tre anni , per tre milioni di anni , per tre tre mili<unk> @ ar<unk> @ di di di anni , per per c<unk> @ ento , per tre mili<unk> @ ar<unk> @ di di di anni , per c<unk> @ ento .
2025-05-27 19:19:15,698 - INFO - joeynmt.training - Example #1
2025-05-27 19:19:15,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:19:15,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:19:15,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'questo', 'non', '', 'il', 'fatto', 'di', 'questo', 'non', '', 'il', 'fatto', 'di', 'questo', 'che', 'la', 'con@@', '<unk>', '@', 'n@@', '<unk>', '@', 'as@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ita', 'di', 'queste', 'cell@@', '<unk>', '@', 'ule', 'che', 'non', '', 'il', 'problema', 'di', 'queste', 'cell@@', '<unk>', '@', 'ule', 'che', 'non', '', 'il', 'li@@', '<unk>', '@', 'vello', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'enza', '.', '</s>']
2025-05-27 19:19:15,699 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:19:15,699 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:19:15,699 - INFO - joeynmt.training - 	Hypothesis: Ma non questo non  il fatto di questo non  il fatto di questo che la con<unk> @ n<unk> @ as<unk> @ c<unk> @ ita di queste cell<unk> @ ule che non  il problema di queste cell<unk> @ ule che non  il li<unk> @ vello di in<unk> @ f<unk> @ lu<unk> @ enza .
2025-05-27 19:19:15,699 - INFO - joeynmt.training - Example #2
2025-05-27 19:19:15,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:19:15,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:19:15,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 'nostra', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'di', 'sistema', 'soci@@', '<unk>', '@', 'ale', ',', 'il', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:19:15,700 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:19:15,700 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:19:15,700 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la s<unk> @ fi<unk> @ da  la nostra in<unk> @ f<unk> @ am<unk> @ ig<unk> @ lia di sistema soci<unk> @ ale , il sistema di c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:19:15,700 - INFO - joeynmt.training - Example #3
2025-05-27 19:19:15,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:19:15,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:19:15,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'il', 's@@', '<unk>', '@', 'ito', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'e', ',', 'e', 'in', 'gra@@', '<unk>', '@', 'do', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:19:15,701 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:19:15,701 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:19:15,701 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e il s<unk> @ ito di s<unk> @ om<unk> @ e , e in gra<unk> @ do di s<unk> @ om<unk> @ e .
2025-05-27 19:19:15,701 - INFO - joeynmt.training - Example #4
2025-05-27 19:19:15,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:19:15,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:19:15,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'una', 'delle', 'due', 'anni', 'fa', ',', '', 'una', 'cosa', 'che', 'succ@@', '<unk>', '@', 'ede', 'in', 'cui', 'la', 'prima', 'volta', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', '2@@', '<unk>', '@', '5', 'anni', 'fa', '.', '</s>']
2025-05-27 19:19:15,702 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:19:15,702 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:19:15,702 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o la prima volta che vi mostr<unk> @ o una delle due anni fa ,  una cosa che succ<unk> @ ede in cui la prima volta , che  succ<unk> @ esso in 2<unk> @ 5 anni fa .
2025-05-27 19:19:19,104 - INFO - joeynmt.training - Epoch   2, Step:    15100, Batch Loss:     1.179104, Batch Acc: 0.653630, Tokens per Sec:    19793, Lr: 0.000300
2025-05-27 19:19:22,498 - INFO - joeynmt.training - Epoch   2, Step:    15200, Batch Loss:     1.147978, Batch Acc: 0.647779, Tokens per Sec:    23468, Lr: 0.000300
2025-05-27 19:19:25,859 - INFO - joeynmt.training - Epoch   2, Step:    15300, Batch Loss:     1.260328, Batch Acc: 0.646384, Tokens per Sec:    23284, Lr: 0.000300
2025-05-27 19:19:29,256 - INFO - joeynmt.training - Epoch   2, Step:    15400, Batch Loss:     1.164020, Batch Acc: 0.649811, Tokens per Sec:    23582, Lr: 0.000300
2025-05-27 19:19:32,645 - INFO - joeynmt.training - Epoch   2, Step:    15500, Batch Loss:     1.152776, Batch Acc: 0.651024, Tokens per Sec:    22822, Lr: 0.000300
2025-05-27 19:19:32,645 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:19:32,645 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:19:48,345 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.22, ppl:   3.37, acc:   0.65, generation: 15.6910[sec], evaluation: 0.0000[sec]
2025-05-27 19:19:48,345 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:19:48,825 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/13000.ckpt
2025-05-27 19:19:48,849 - INFO - joeynmt.training - Example #0
2025-05-27 19:19:48,850 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:19:48,850 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:19:48,850 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'di', 'questi', 'due', 'anni', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'ogra@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ia', 'per', 'la', 'sc@@', '<unk>', '@', 'al@@', '<unk>', '@', 'a', 'per', 'la', 'com@@', '<unk>', '@', 'pren@@', '<unk>', '@', 'sione', ',', 'che', 'la', 'c@@', '<unk>', '@', 'r@@', '<unk>', '@', 'oc@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ina', ',', 'che', 'la', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', ',', 'per', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'di', 'doll@@', '<unk>', '@', 'ari', 'che', 'av@@', '<unk>', '@', 'evano', 'un', 'gr@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ppo', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:19:48,850 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:19:48,851 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:19:48,851 - INFO - joeynmt.training - 	Hypothesis: La sc<unk> @ or<unk> @ sa di questi due anni , ho mostr<unk> @ ato questa fot<unk> @ ogra<unk> @ f<unk> @ ia per la sc<unk> @ al<unk> @ a per la com<unk> @ pren<unk> @ sione , che la c<unk> @ r<unk> @ oc<unk> @ c<unk> @ ina , che la c<unk> @ las<unk> @ se , per tre mili<unk> @ ar<unk> @ di di di di doll<unk> @ ari che av<unk> @ evano un gr<unk> @ u<unk> @ ppo di persone che av<unk> @ evano il 4<unk> @ 0 % .
2025-05-27 19:19:48,851 - INFO - joeynmt.training - Example #1
2025-05-27 19:19:48,851 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:19:48,851 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:19:48,851 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'modo', 'di', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'do', ',', 'la', 'prima', 'volta', 'che', '', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'problema', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:19:48,851 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:19:48,852 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:19:48,852 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il modo di ri<unk> @ guar<unk> @ do , la prima volta che  la ris<unk> @ post<unk> @ a di questo problema , non  il problema di questo problema .
2025-05-27 19:19:48,852 - INFO - joeynmt.training - Example #2
2025-05-27 19:19:48,852 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:19:48,852 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:19:48,852 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', '', 'una', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'una', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', ',', 'la', 'c@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ura', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:19:48,852 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:19:48,853 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:19:48,853 - INFO - joeynmt.training - 	Hypothesis: In realt ,  una s<unk> @ itu<unk> @ azione di una s<unk> @ fi<unk> @ da , la c<unk> @ ult<unk> @ ura del nostro sistema glob<unk> @ ale .
2025-05-27 19:19:48,853 - INFO - joeynmt.training - Example #3
2025-05-27 19:19:48,853 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:19:48,853 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:19:48,853 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'in', 'realt', ',', 'e', 'in', 'realt', ',', 'e', 'in', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'b@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:19:48,853 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:19:48,853 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:19:48,854 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e in realt , e in realt , e in s<unk> @ om<unk> @ b<unk> @ a .
2025-05-27 19:19:48,854 - INFO - joeynmt.training - Example #4
2025-05-27 19:19:48,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:19:48,854 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:19:48,854 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'delle', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ole', 'che', '', 'una', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', 'di', 'quello', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'circa', '1@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:19:48,854 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:19:48,854 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:19:48,855 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostr<unk> @ o  una cosa che vi mostr<unk> @ a una delle sc<unk> @ u<unk> @ ole che  una sc<unk> @ u<unk> @ ola di quello che  succ<unk> @ esso in circa 1<unk> @ 5 anni .
2025-05-27 19:19:52,237 - INFO - joeynmt.training - Epoch   2, Step:    15600, Batch Loss:     1.133865, Batch Acc: 0.650231, Tokens per Sec:    20804, Lr: 0.000300
2025-05-27 19:19:55,651 - INFO - joeynmt.training - Epoch   2, Step:    15700, Batch Loss:     1.312570, Batch Acc: 0.648119, Tokens per Sec:    23194, Lr: 0.000300
2025-05-27 19:19:57,169 - INFO - joeynmt.training - Epoch   2: total training loss 10139.88
2025-05-27 19:19:57,170 - INFO - joeynmt.training - EPOCH 3
2025-05-27 19:19:59,032 - INFO - joeynmt.training - Epoch   3, Step:    15800, Batch Loss:     1.239009, Batch Acc: 0.655112, Tokens per Sec:    23377, Lr: 0.000300
2025-05-27 19:20:02,405 - INFO - joeynmt.training - Epoch   3, Step:    15900, Batch Loss:     1.144844, Batch Acc: 0.657273, Tokens per Sec:    23690, Lr: 0.000300
2025-05-27 19:20:05,774 - INFO - joeynmt.training - Epoch   3, Step:    16000, Batch Loss:     1.093356, Batch Acc: 0.658668, Tokens per Sec:    23409, Lr: 0.000300
2025-05-27 19:20:05,774 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:20:05,774 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:20:24,229 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.20, ppl:   3.31, acc:   0.66, generation: 18.4397[sec], evaluation: 0.0000[sec]
2025-05-27 19:20:24,230 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:20:24,782 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/13500.ckpt
2025-05-27 19:20:24,808 - INFO - joeynmt.training - Example #0
2025-05-27 19:20:24,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:20:24,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:20:24,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'questi', 'due', 'anni', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'che', 'i', 'due', 'anni', 'fa', ',', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ali', 'che', 'i', 'i', 'i', 'i', 'dati', 'i', 'mo@@', '<unk>', '@', 'di', 'che', 'i', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'i', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'i', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'i', 'anni', ',', 'che', 'i', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'la', 'citt', '.', '</s>']
2025-05-27 19:20:24,810 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:20:24,810 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:20:24,810 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so che ho mostr<unk> @ ato a questi due anni , ho mostr<unk> @ ato che i due anni fa , i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ali che i i i i dati i mo<unk> @ di che i m<unk> @ oti<unk> @ vi per i m<unk> @ oti<unk> @ vi per i m<unk> @ oti<unk> @ vi per i anni , che i m<unk> @ oti<unk> @ vi per la citt .
2025-05-27 19:20:24,810 - INFO - joeynmt.training - Example #1
2025-05-27 19:20:24,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:20:24,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:20:24,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'ris@@', '<unk>', '@', 'chio', 'di', 'non', '', 'la', 'ris@@', '<unk>', '@', 'p@@', '<unk>', '@', 'etto', 'a', 'questo', 'problema', ',', 'che', 'non', '', 'il', 'problema', 'di', 'questo', 'che', 'non', '', 'il', 'problema', '.', '</s>']
2025-05-27 19:20:24,811 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:20:24,811 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:20:24,811 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il ris<unk> @ chio di non  la ris<unk> @ p<unk> @ etto a questo problema , che non  il problema di questo che non  il problema .
2025-05-27 19:20:24,811 - INFO - joeynmt.training - Example #2
2025-05-27 19:20:24,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:20:24,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:20:24,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 'str@@', '<unk>', '@', 'utt@@', '<unk>', '@', 'ura', 'del', 'nostro', 'cor@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'del', 'nostro', 'sistema', 'soci@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:20:24,812 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:20:24,812 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:20:24,812 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ fi<unk> @ da  la str<unk> @ utt<unk> @ ura del nostro cor<unk> @ so  la c<unk> @ li<unk> @ ma del nostro sistema soci<unk> @ ale .
2025-05-27 19:20:24,812 - INFO - joeynmt.training - Example #3
2025-05-27 19:20:24,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:20:24,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:20:24,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'un', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', 'e', 'in', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:20:24,813 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:20:24,813 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:20:24,813 - INFO - joeynmt.training - 	Hypothesis: E &apos; un s<unk> @ ac<unk> @ co di s<unk> @ om<unk> @ b<unk> @ o e in un p<unk> @ ezz<unk> @ o .
2025-05-27 19:20:24,813 - INFO - joeynmt.training - Example #4
2025-05-27 19:20:24,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:20:24,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:20:24,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'i', 'che', 'vi', '', 'un', 'po', '&apos;', 'di', 'qu@@', '<unk>', '@', 'ale', '', 'un', 'po', '&apos;', 'di', 'qu@@', '<unk>', '@', 'ale', '', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'due', 'anni', '.', '</s>']
2025-05-27 19:20:24,814 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:20:24,814 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:20:24,814 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo  che vi mostr<unk> @ i che vi  un po &apos; di qu<unk> @ ale  un po &apos; di qu<unk> @ ale  che  succ<unk> @ esso in due anni .
2025-05-27 19:20:28,213 - INFO - joeynmt.training - Epoch   3, Step:    16100, Batch Loss:     1.159508, Batch Acc: 0.656295, Tokens per Sec:    20032, Lr: 0.000300
2025-05-27 19:20:31,601 - INFO - joeynmt.training - Epoch   3, Step:    16200, Batch Loss:     1.163716, Batch Acc: 0.657870, Tokens per Sec:    23294, Lr: 0.000300
2025-05-27 19:20:34,982 - INFO - joeynmt.training - Epoch   3, Step:    16300, Batch Loss:     1.201549, Batch Acc: 0.658831, Tokens per Sec:    23456, Lr: 0.000300
2025-05-27 19:20:38,330 - INFO - joeynmt.training - Epoch   3, Step:    16400, Batch Loss:     1.117826, Batch Acc: 0.658425, Tokens per Sec:    23941, Lr: 0.000300
2025-05-27 19:20:41,689 - INFO - joeynmt.training - Epoch   3, Step:    16500, Batch Loss:     1.368971, Batch Acc: 0.659029, Tokens per Sec:    23543, Lr: 0.000300
2025-05-27 19:20:41,689 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:20:41,689 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:20:57,282 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.19, ppl:   3.29, acc:   0.66, generation: 15.5799[sec], evaluation: 0.0000[sec]
2025-05-27 19:20:57,282 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:20:58,007 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/14000.ckpt
2025-05-27 19:20:58,034 - INFO - joeynmt.training - Example #0
2025-05-27 19:20:58,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:20:58,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:20:58,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'questi', 'due', 'milioni', 'di', 'anni', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'questi', 'due', 'milioni', 'di', 'anni', ',', 'per', 'cerc@@', '<unk>', '@', 'are', 'di', 'fare', 'per', 'ri@@', '<unk>', '@', 'fl@@', '<unk>', '@', 'et@@', '<unk>', '@', 'tere', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ate', 'che', 'il', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 19:20:58,035 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:20:58,036 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:20:58,036 - INFO - joeynmt.training - 	Hypothesis: E ho mostr<unk> @ ato a questi due milioni di anni , ho mostr<unk> @ ato a questi due milioni di anni , per cerc<unk> @ are di fare per ri<unk> @ fl<unk> @ et<unk> @ tere che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ate che il 4<unk> @ 0 milioni di anni .
2025-05-27 19:20:58,036 - INFO - joeynmt.training - Example #1
2025-05-27 19:20:58,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:20:58,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:20:58,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'n@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ess@@', '<unk>', '@', 'it', 'di', 'questo', 'non', '', 'il', 'modo', 'di', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bile', ',', 'non', '', 'il', 'fatto', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:20:58,037 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:20:58,037 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:20:58,037 - INFO - joeynmt.training - 	Hypothesis: Ma non  n<unk> @ ec<unk> @ ess<unk> @ it di questo non  il modo di in<unk> @ cre<unk> @ di<unk> @ bile , non  il fatto di questo problema .
2025-05-27 19:20:58,037 - INFO - joeynmt.training - Example #2
2025-05-27 19:20:58,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:20:58,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:20:58,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', '', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 'str@@', '<unk>', '@', 'utt@@', '<unk>', '@', 'ura', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'nostro', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ente', '.', '</s>']
2025-05-27 19:20:58,038 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:20:58,038 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:20:58,038 - INFO - joeynmt.training - 	Hypothesis: In realt ,  la s<unk> @ fi<unk> @ da  la str<unk> @ utt<unk> @ ura di g<unk> @ hi<unk> @ ac<unk> @ cio , il nostro sistema di c<unk> @ li<unk> @ ente .
2025-05-27 19:20:58,038 - INFO - joeynmt.training - Example #3
2025-05-27 19:20:58,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:20:58,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:20:58,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'succ@@', '<unk>', '@', 'ede', 'in', 'gra@@', '<unk>', '@', 'do', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'era', 'e', 's@@', '<unk>', '@', 'otto', '.', '</s>']
2025-05-27 19:20:58,039 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:20:58,039 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:20:58,039 - INFO - joeynmt.training - 	Hypothesis: E &apos; succ<unk> @ ede in gra<unk> @ do di in<unk> @ f<unk> @ era e s<unk> @ otto .
2025-05-27 19:20:58,039 - INFO - joeynmt.training - Example #4
2025-05-27 19:20:58,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:20:58,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:20:58,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'delle', 'cose', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'delle', 'sc@@', '<unk>', '@', 'el@@', '<unk>', '@', 'ta', 'di', 'una', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '.', '</s>']
2025-05-27 19:20:58,040 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:20:58,040 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:20:58,040 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma  che vi mostr<unk> @ er<unk> @  una delle cose che vi mostr<unk> @ er<unk> @  una delle sc<unk> @ el<unk> @ ta di una s<unk> @ itu<unk> @ azione .
2025-05-27 19:21:01,445 - INFO - joeynmt.training - Epoch   3, Step:    16600, Batch Loss:     1.208213, Batch Acc: 0.658889, Tokens per Sec:    19088, Lr: 0.000300
2025-05-27 19:21:04,811 - INFO - joeynmt.training - Epoch   3, Step:    16700, Batch Loss:     1.146444, Batch Acc: 0.660464, Tokens per Sec:    23415, Lr: 0.000300
2025-05-27 19:21:08,172 - INFO - joeynmt.training - Epoch   3, Step:    16800, Batch Loss:     1.167095, Batch Acc: 0.660528, Tokens per Sec:    23172, Lr: 0.000300
2025-05-27 19:21:11,556 - INFO - joeynmt.training - Epoch   3, Step:    16900, Batch Loss:     1.198058, Batch Acc: 0.663488, Tokens per Sec:    23282, Lr: 0.000300
2025-05-27 19:21:14,927 - INFO - joeynmt.training - Epoch   3, Step:    17000, Batch Loss:     1.265898, Batch Acc: 0.658818, Tokens per Sec:    23528, Lr: 0.000300
2025-05-27 19:21:14,927 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:21:14,927 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:21:26,324 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.19, ppl:   3.27, acc:   0.66, generation: 11.3884[sec], evaluation: 0.0000[sec]
2025-05-27 19:21:26,324 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:21:26,817 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/14500.ckpt
2025-05-27 19:21:26,834 - INFO - joeynmt.training - Example #0
2025-05-27 19:21:26,835 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:21:26,835 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:21:26,835 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'l&apos;', 'anno', 'anno', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'che', 'la', 'f@@', '<unk>', '@', 'anno', ',', 'per', 'la', 'f@@', '<unk>', '@', 'ar', 's@@', '<unk>', '@', '', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'un', 'gr@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ppo', 'di', 'persone', 'che', 'non', 'av@@', '<unk>', '@', 'evano', 'visto', 'per', 'i', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 19:21:26,836 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:21:26,836 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:21:26,836 - INFO - joeynmt.training - 	Hypothesis: E l&apos; anno anno ho mostr<unk> @ ato a questa fot<unk> @ o , ho mostr<unk> @ ato che la f<unk> @ anno , per la f<unk> @ ar s<unk> @  che la c<unk> @ aus<unk> @ a di un gr<unk> @ u<unk> @ ppo di persone che non av<unk> @ evano visto per i tre mili<unk> @ ar<unk> @ di di di persone che hanno sc<unk> @ oper<unk> @ to per i 4<unk> @ 8 milioni di anni .
2025-05-27 19:21:26,836 - INFO - joeynmt.training - Example #1
2025-05-27 19:21:26,836 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:21:26,836 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:21:26,836 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'lo', 've@@', '<unk>', '@', 'dete', ',', 'non', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'che', 'non', '', 'il', 'loro', 'ris@@', '<unk>', '@', 'p@@', '<unk>', '@', 'etto', 'a', 'questo', 'problema', '.', '</s>']
2025-05-27 19:21:26,837 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:21:26,837 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:21:26,837 - INFO - joeynmt.training - 	Hypothesis: Ma non lo ve<unk> @ dete , non  il ris<unk> @ ult<unk> @ ato che non  il loro ris<unk> @ p<unk> @ etto a questo problema .
2025-05-27 19:21:26,837 - INFO - joeynmt.training - Example #2
2025-05-27 19:21:26,837 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:21:26,837 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:21:26,837 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 'la', 'stessa', 'cosa', 'che', 'la', 'cap@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'it', 'di', 'c@@', '<unk>', '@', 'at@@', '<unk>', '@', 'tere', 'il', 'nostro', 'cor@@', '<unk>', '@', 'po', '.', '</s>']
2025-05-27 19:21:26,838 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:21:26,838 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:21:26,838 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la s<unk> @ fi<unk> @ da  la la stessa cosa che la cap<unk> @ ac<unk> @ it di c<unk> @ at<unk> @ tere il nostro cor<unk> @ po .
2025-05-27 19:21:26,838 - INFO - joeynmt.training - Example #3
2025-05-27 19:21:26,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:21:26,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:21:26,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', '', 'in', 'tutto', ',', 'e', 'la', 'm@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ma', 'e', 'in', 'tutto', 'il', 'm@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:21:26,839 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:21:26,839 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:21:26,839 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @  in tutto , e la m<unk> @ am<unk> @ ma e in tutto il m<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:21:26,839 - INFO - joeynmt.training - Example #4
2025-05-27 19:21:26,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:21:26,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:21:26,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'la', 'cosa', 'che', 'vi', '', 'stato', 'un', 'po', '&apos;', 'di', 'qu@@', '<unk>', '@', 'ale', '', 'stato', 'un', 'po', '&apos;', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'essi@@', '<unk>', '@', 'vo', '.', '</s>']
2025-05-27 19:21:26,840 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:21:26,840 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:21:26,840 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo m<unk> @ ezz<unk> @ o che vi mostr<unk> @ a la cosa che vi  stato un po &apos; di qu<unk> @ ale  stato un po &apos; di quello che succ<unk> @ essi<unk> @ vo .
2025-05-27 19:21:30,204 - INFO - joeynmt.training - Epoch   3, Step:    17100, Batch Loss:     1.150646, Batch Acc: 0.658185, Tokens per Sec:    20171, Lr: 0.000300
2025-05-27 19:21:33,609 - INFO - joeynmt.training - Epoch   3, Step:    17200, Batch Loss:     1.318043, Batch Acc: 0.661177, Tokens per Sec:    24237, Lr: 0.000300
2025-05-27 19:21:36,988 - INFO - joeynmt.training - Epoch   3, Step:    17300, Batch Loss:     1.193127, Batch Acc: 0.661338, Tokens per Sec:    23426, Lr: 0.000300
2025-05-27 19:21:40,488 - INFO - joeynmt.training - Epoch   3, Step:    17400, Batch Loss:     1.152196, Batch Acc: 0.662607, Tokens per Sec:    23256, Lr: 0.000300
2025-05-27 19:21:43,893 - INFO - joeynmt.training - Epoch   3, Step:    17500, Batch Loss:     1.421140, Batch Acc: 0.658683, Tokens per Sec:    24250, Lr: 0.000300
2025-05-27 19:21:43,893 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:21:43,893 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:22:00,741 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.17, ppl:   3.24, acc:   0.66, generation: 16.8356[sec], evaluation: 0.0000[sec]
2025-05-27 19:22:00,742 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:22:01,298 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/15000.ckpt
2025-05-27 19:22:01,321 - INFO - joeynmt.training - Example #0
2025-05-27 19:22:01,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:22:01,322 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:22:01,322 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'questi', 'due', 'anni', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'questo', 'p@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'no', 'per', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'do', 'di', 'per', 'la', 'prima', 'volta', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'la', 'prima', 'volta', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'anni', ',', 'per', 'la', 'prima', 'volta', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'sono', 'stati', 'stati', 'stati', 'stati', 'stati', 'stati', 'stati', 'stati', 'stati', 'stati', 'stati', 's@@', '<unk>', '@', 'iti', 'a', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:22:01,322 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:22:01,322 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:22:01,322 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato a questi due anni , ho mostr<unk> @ ato a questo p<unk> @ eg<unk> @ no per ri<unk> @ guar<unk> @ do di per la prima volta che la c<unk> @ aus<unk> @ a di tre milioni di anni , per la prima volta che la c<unk> @ aus<unk> @ a di tre mili<unk> @ ar<unk> @ di di anni , per la prima volta , per tre milioni di anni , sono stati stati stati stati stati stati stati stati stati stati stati s<unk> @ iti a 4<unk> @ 0 % .
2025-05-27 19:22:01,322 - INFO - joeynmt.training - Example #1
2025-05-27 19:22:01,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:22:01,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:22:01,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'n@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ess@@', '<unk>', '@', 'ario', 'la', 'di@@', '<unk>', '@', 'men@@', '<unk>', '@', 'sione', 'di', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', 'probl@@', '<unk>', '@', 'emi', 'di', 'questo', 'probl@@', '<unk>', '@', 'emi', 'di', 'questo', 'probl@@', '<unk>', '@', 'emi', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'a@@', '<unk>', '@', 'io', 'che', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'a@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'd@@', '<unk>', '@', 'ente', '.', '</s>']
2025-05-27 19:22:01,323 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:22:01,323 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:22:01,324 - INFO - joeynmt.training - 	Hypothesis: Ma non  n<unk> @ ec<unk> @ ess<unk> @ ario la di<unk> @ men<unk> @ sione di ris<unk> @ ol<unk> @ vere probl<unk> @ emi di questo probl<unk> @ emi di questo probl<unk> @ emi , non  il d<unk> @ ic<unk> @ a<unk> @ io che non  il D<unk> @ ic<unk> @ a<unk> @ ci<unk> @ d<unk> @ ente .
2025-05-27 19:22:01,324 - INFO - joeynmt.training - Example #2
2025-05-27 19:22:01,324 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:22:01,324 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:22:01,324 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', ',', 'il', 'nostro', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:22:01,324 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:22:01,324 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la s<unk> @ fi<unk> @ da  la s<unk> @ fi<unk> @ da , il nostro sistema di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - Example #3
2025-05-27 19:22:01,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:22:01,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:22:01,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', 'e', 'la', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:22:01,325 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - 	Hypothesis: E si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ p<unk> @ a e la s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - Example #4
2025-05-27 19:22:01,326 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:22:01,326 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:22:01,326 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'una', 'cosa', 'che', '', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', 'si', '', 'trov@@', '<unk>', '@', 'ato', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:22:01,326 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:22:01,326 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:22:01,326 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o , ho mostr<unk> @ ato a una cosa che  che  succ<unk> @ esso in cui si  trov<unk> @ ato in 2<unk> @ 5 anni .
2025-05-27 19:22:04,712 - INFO - joeynmt.training - Epoch   3, Step:    17600, Batch Loss:     1.208378, Batch Acc: 0.665078, Tokens per Sec:    19552, Lr: 0.000300
2025-05-27 19:22:08,123 - INFO - joeynmt.training - Epoch   3, Step:    17700, Batch Loss:     1.269725, Batch Acc: 0.661711, Tokens per Sec:    23612, Lr: 0.000300
2025-05-27 19:22:11,509 - INFO - joeynmt.training - Epoch   3, Step:    17800, Batch Loss:     1.157221, Batch Acc: 0.661276, Tokens per Sec:    23891, Lr: 0.000300
2025-05-27 19:22:14,875 - INFO - joeynmt.training - Epoch   3, Step:    17900, Batch Loss:     1.080647, Batch Acc: 0.662928, Tokens per Sec:    23449, Lr: 0.000300
2025-05-27 19:22:18,227 - INFO - joeynmt.training - Epoch   3, Step:    18000, Batch Loss:     0.998702, Batch Acc: 0.663932, Tokens per Sec:    23420, Lr: 0.000300
2025-05-27 19:22:18,227 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:22:18,228 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:22:34,164 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.17, ppl:   3.22, acc:   0.66, generation: 15.9244[sec], evaluation: 0.0000[sec]
2025-05-27 19:22:34,165 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:22:34,685 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/15500.ckpt
2025-05-27 19:22:34,705 - INFO - joeynmt.training - Example #0
2025-05-27 19:22:34,705 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:22:34,705 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:22:34,706 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'abbiamo', 'fatto', 'questa', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', ',', 'questi', 'due', 'anni', ',', 'ho', 'fatto', 'questa', '', 'la', 'f@@', '<unk>', '@', 'ant@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'ica', 'per', 'la', 'c@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'azione', 'per', 'le', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'fatto', 'che', 'la', 'c@@', '<unk>', '@', 'at@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'per', 'tre', 'tre', 'anni', ',', 'per', 'la', 'citt', 'per', 'la', 'prima', 'volta', 'che', 'av@@', '<unk>', '@', 'evo', 'tre', 'tre', 'tre', 'anni', '.', '</s>']
2025-05-27 19:22:34,706 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:22:34,706 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:22:34,706 - INFO - joeynmt.training - 	Hypothesis: E abbiamo fatto questa sc<unk> @ or<unk> @ sa , questi due anni , ho fatto questa  la f<unk> @ ant<unk> @ ast<unk> @ ica per la c<unk> @ op<unk> @ ol<unk> @ azione per le persone che av<unk> @ evano fatto che la c<unk> @ at<unk> @ en<unk> @ a per tre tre anni , per la citt per la prima volta che av<unk> @ evo tre tre tre anni .
2025-05-27 19:22:34,706 - INFO - joeynmt.training - Example #1
2025-05-27 19:22:34,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:22:34,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:22:34,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'stato', 'un', 'problema', ',', 'non', '', 'molto', 'diff@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ile', 'di', 'questa', 'con@@', '<unk>', '@', 'n@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ica', ',', 'non', '', 'la', 'gente', 'che', 'non', '', 'il', 'fatto', '.', '</s>']
2025-05-27 19:22:34,707 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:22:34,707 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:22:34,707 - INFO - joeynmt.training - 	Hypothesis: Ma non  stato un problema , non  molto diff<unk> @ ic<unk> @ ile di questa con<unk> @ n<unk> @ et<unk> @ ica , non  la gente che non  il fatto .
2025-05-27 19:22:34,707 - INFO - joeynmt.training - Example #2
2025-05-27 19:22:34,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:22:34,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:22:34,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', '', 'la', 's@@', '<unk>', '@', 'edi@@', '<unk>', '@', 'zione', '', 'la', 'nostra', 'c@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'azione', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '.', '</s>']
2025-05-27 19:22:34,708 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:22:34,708 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:22:34,708 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt ,  la s<unk> @ edi<unk> @ zione  la nostra c<unk> @ op<unk> @ ol<unk> @ azione di c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:22:34,708 - INFO - joeynmt.training - Example #3
2025-05-27 19:22:34,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:22:34,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:22:34,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ete', ',', 'in', 's@@', '<unk>', '@', '', 'e', 'in', 's@@', '<unk>', '@', '', 'e', 'in', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', 'e', '.', '</s>']
2025-05-27 19:22:34,709 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:22:34,709 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:22:34,709 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ ete , in s<unk> @  e in s<unk> @  e in s<unk> @ om<unk> @ p<unk> @ a e .
2025-05-27 19:22:34,709 - INFO - joeynmt.training - Example #4
2025-05-27 19:22:34,710 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:22:34,710 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:22:34,710 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'una', 'delle', 'cose', 'che', '', 'una', 'delle', 'cose', 'che', '', 'stata', 'una', 'delle', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'me', ',', 'e', '&apos;', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:22:34,710 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:22:34,710 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:22:34,710 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo pros<unk> @ si<unk> @ mo che vi mostr<unk> @ o una delle cose che  una delle cose che  stata una delle sc<unk> @ or<unk> @ me , e &apos; 2<unk> @ 5 anni .
2025-05-27 19:22:38,108 - INFO - joeynmt.training - Epoch   3, Step:    18100, Batch Loss:     1.129996, Batch Acc: 0.664604, Tokens per Sec:    19545, Lr: 0.000300
2025-05-27 19:22:41,496 - INFO - joeynmt.training - Epoch   3, Step:    18200, Batch Loss:     1.257040, Batch Acc: 0.664668, Tokens per Sec:    23188, Lr: 0.000300
2025-05-27 19:22:44,877 - INFO - joeynmt.training - Epoch   3, Step:    18300, Batch Loss:     1.154723, Batch Acc: 0.667427, Tokens per Sec:    23852, Lr: 0.000300
2025-05-27 19:22:48,213 - INFO - joeynmt.training - Epoch   3, Step:    18400, Batch Loss:     1.192705, Batch Acc: 0.665634, Tokens per Sec:    23321, Lr: 0.000300
2025-05-27 19:22:51,608 - INFO - joeynmt.training - Epoch   3, Step:    18500, Batch Loss:     1.253750, Batch Acc: 0.664483, Tokens per Sec:    23568, Lr: 0.000300
2025-05-27 19:22:51,608 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:22:51,608 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:23:08,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.16, ppl:   3.20, acc:   0.66, generation: 17.0995[sec], evaluation: 0.0000[sec]
2025-05-27 19:23:08,717 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:23:09,288 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/16000.ckpt
2025-05-27 19:23:09,312 - INFO - joeynmt.training - Example #0
2025-05-27 19:23:09,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:23:09,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:23:09,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'costru@@', '<unk>', '@', 'ire', 'che', 'i', 'comp@@', '<unk>', '@', 'ag@@', '<unk>', '@', 'iti', ',', 'che', 'i', 'f@@', '<unk>', '@', 'anno', 'che', 'il', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', 'per', 'cui', 'i', 'dati', ',', 'per', 'la', 'gr@@', '<unk>', '@', 'av@@', '<unk>', '@', 'e', 'per', 'la', 'prima', 'volta', 'che', 'av@@', '<unk>', '@', 'evano', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', '4@@', '<unk>', '@', '0', '%', 'della', 'citt', '.', '</s>']
2025-05-27 19:23:09,313 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o , per costru<unk> @ ire che i comp<unk> @ ag<unk> @ iti , che i f<unk> @ anno che il m<unk> @ oti<unk> @ vo per cui i dati , per la gr<unk> @ av<unk> @ e per la prima volta che av<unk> @ evano 4<unk> @ 0 milioni di persone che av<unk> @ evano 4<unk> @ 0 % della citt .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - Example #1
2025-05-27 19:23:09,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:23:09,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:23:09,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'si', '', 'in@@', '<unk>', '@', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'con@@', '<unk>', '@', 'n@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ta', 'di', 'questa', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'era', 'di', 'questa', 'in@@', '<unk>', '@', 'forma@@', '<unk>', '@', 'zione', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Hypothesis: Ma non si  in<unk> @ tr<unk> @ at<unk> @ ta di una con<unk> @ n<unk> @ et<unk> @ ta di questa in<unk> @ f<unk> @ era di questa in<unk> @ forma<unk> @ zione di questo problema .
2025-05-27 19:23:09,315 - INFO - joeynmt.training - Example #2
2025-05-27 19:23:09,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:23:09,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:23:09,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'nostra', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '.', '</s>']
2025-05-27 19:23:09,315 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:23:09,315 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:23:09,315 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la s<unk> @ itu<unk> @ azione  la c<unk> @ aus<unk> @ a della nostra c<unk> @ aus<unk> @ a della nostra c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:23:09,315 - INFO - joeynmt.training - Example #3
2025-05-27 19:23:09,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:23:09,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:23:09,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'olo', ',', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', 'e', 'in', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:23:09,316 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:23:09,316 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:23:09,316 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ olo , si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ p<unk> @ a e in s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:23:09,316 - INFO - joeynmt.training - Example #4
2025-05-27 19:23:09,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:23:09,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:23:09,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'la', 'cosa', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'una', 'delle', 'cose', 'che', '', 'che', '', 'una', 'delle', 'sc@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'quello', 'che', 'sta', 'succ@@', '<unk>', '@', 'e@@', '<unk>', '@', 'dendo', 'in', 'ulti@@', '<unk>', '@', 'ma', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:23:09,317 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:23:09,317 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:23:09,317 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o la cosa che ho mostr<unk> @ ato una delle cose che  che  una delle sc<unk> @ en<unk> @ a di quello che sta succ<unk> @ e<unk> @ dendo in ulti<unk> @ ma 2<unk> @ 5 anni .
2025-05-27 19:23:12,648 - INFO - joeynmt.training - Epoch   3, Step:    18600, Batch Loss:     1.135028, Batch Acc: 0.663487, Tokens per Sec:    20212, Lr: 0.000300
2025-05-27 19:23:15,996 - INFO - joeynmt.training - Epoch   3, Step:    18700, Batch Loss:     1.164630, Batch Acc: 0.666127, Tokens per Sec:    23445, Lr: 0.000300
2025-05-27 19:23:19,363 - INFO - joeynmt.training - Epoch   3, Step:    18800, Batch Loss:     1.134684, Batch Acc: 0.665665, Tokens per Sec:    24135, Lr: 0.000300
2025-05-27 19:23:22,710 - INFO - joeynmt.training - Epoch   3, Step:    18900, Batch Loss:     1.270692, Batch Acc: 0.663689, Tokens per Sec:    23552, Lr: 0.000300
2025-05-27 19:23:26,066 - INFO - joeynmt.training - Epoch   3, Step:    19000, Batch Loss:     1.190498, Batch Acc: 0.670388, Tokens per Sec:    23842, Lr: 0.000300
2025-05-27 19:23:26,066 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:23:26,066 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:23:40,013 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.16, ppl:   3.19, acc:   0.67, generation: 13.9342[sec], evaluation: 0.0000[sec]
2025-05-27 19:23:40,014 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:23:40,612 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/16500.ckpt
2025-05-27 19:23:40,637 - INFO - joeynmt.training - Example #0
2025-05-27 19:23:40,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:23:40,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:23:40,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', 'di', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'ta', 'per', 'creare', 'il', 'can@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ro', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'i', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', '4@@', '<unk>', '@', '0', '%', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:23:40,638 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:23:40,638 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:23:40,638 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o di sc<unk> @ oper<unk> @ ta per creare il can<unk> @ c<unk> @ ro di g<unk> @ hi<unk> @ ac<unk> @ cio per i tre mili<unk> @ ar<unk> @ di di di persone che av<unk> @ evano tre mili<unk> @ ar<unk> @ di di di di anni , il 4<unk> @ 0 , 4<unk> @ 0 % di persone che av<unk> @ evano 4<unk> @ 0 % .
2025-05-27 19:23:40,638 - INFO - joeynmt.training - Example #1
2025-05-27 19:23:40,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:23:40,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:23:40,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'questo', 'non', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questi', 'probl@@', '<unk>', '@', 'emi', 'di', 'questi', 'probl@@', '<unk>', '@', 'emi', 'di', 'questi', 'probl@@', '<unk>', '@', 'emi', 'di', 'questi', 'probl@@', '<unk>', '@', 'emi', '.', '</s>']
2025-05-27 19:23:40,639 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:23:40,640 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:23:40,640 - INFO - joeynmt.training - 	Hypothesis: Ma questo non questo non  il ris<unk> @ ult<unk> @ ato di ris<unk> @ ol<unk> @ vere il ris<unk> @ ult<unk> @ ato di questi probl<unk> @ emi di questi probl<unk> @ emi di questi probl<unk> @ emi di questi probl<unk> @ emi .
2025-05-27 19:23:40,640 - INFO - joeynmt.training - Example #2
2025-05-27 19:23:40,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:23:40,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:23:40,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', '<unk>', '@', 'ella', 's@@', '<unk>', '@', 'ov@@', '<unk>', '@', 'it', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'em@@', '<unk>', '@', 'issi@@', '<unk>', '@', 'oni', ',', 'il', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '.', '</s>']
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ ella s<unk> @ ov<unk> @ it  la s<unk> @ itu<unk> @ azione di em<unk> @ issi<unk> @ oni , il sistema di c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:23:40,641 - INFO - joeynmt.training - Example #3
2025-05-27 19:23:40,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:23:40,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:23:40,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'olo', ',', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', 'e', 'in', 's@@', '<unk>', '@', '', '.', '</s>']
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:23:40,642 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ olo , si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ p<unk> @ a e in s<unk> @  .
2025-05-27 19:23:40,642 - INFO - joeynmt.training - Example #4
2025-05-27 19:23:40,642 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:23:40,642 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:23:40,642 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', '', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'che', '', 'una', 'cosa', 'che', '', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', '', 'succ@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 19:23:40,642 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:23:40,642 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:23:40,642 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma  una cosa che vi mostr<unk> @ a che  una cosa che  che  succ<unk> @ esso in cui  succ<unk> @ esso in cui  succ<unk> @ esso in cui  succ<unk> @ esso .
2025-05-27 19:23:44,003 - INFO - joeynmt.training - Epoch   3, Step:    19100, Batch Loss:     1.155507, Batch Acc: 0.666815, Tokens per Sec:    19716, Lr: 0.000300
2025-05-27 19:23:47,329 - INFO - joeynmt.training - Epoch   3, Step:    19200, Batch Loss:     1.204934, Batch Acc: 0.665535, Tokens per Sec:    23920, Lr: 0.000300
2025-05-27 19:23:50,654 - INFO - joeynmt.training - Epoch   3, Step:    19300, Batch Loss:     1.016007, Batch Acc: 0.670112, Tokens per Sec:    24219, Lr: 0.000300
2025-05-27 19:23:54,017 - INFO - joeynmt.training - Epoch   3, Step:    19400, Batch Loss:     1.216370, Batch Acc: 0.668333, Tokens per Sec:    23920, Lr: 0.000300
2025-05-27 19:23:57,398 - INFO - joeynmt.training - Epoch   3, Step:    19500, Batch Loss:     1.282668, Batch Acc: 0.671632, Tokens per Sec:    23950, Lr: 0.000300
2025-05-27 19:23:57,399 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:23:57,399 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:24:13,186 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.15, ppl:   3.16, acc:   0.67, generation: 15.7750[sec], evaluation: 0.0000[sec]
2025-05-27 19:24:13,187 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:24:13,713 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/17000.ckpt
2025-05-27 19:24:13,737 - INFO - joeynmt.training - Example #0
2025-05-27 19:24:13,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:24:13,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:24:13,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'fine', 'di', 'cui', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'don@@', '<unk>', '@', 'na', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'che', 'la', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ca', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'ar@@', '<unk>', '@', 're', 'il', 'g@@', '<unk>', '@', 'atto', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'anni', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'av@@', '<unk>', '@', 'evo', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'anni', ',', 'che', 'av@@', '<unk>', '@', 'evo', '4@@', '<unk>', '@', '0', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:24:13,738 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:24:13,738 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:24:13,738 - INFO - joeynmt.training - 	Hypothesis: E la fine di cui ho mostr<unk> @ ato questa don<unk> @ na , ho mostr<unk> @ ato che la p<unk> @ es<unk> @ ca di c<unk> @ aus<unk> @ a di g<unk> @ ar<unk> @ re il g<unk> @ atto di c<unk> @ aus<unk> @ a di tre milioni di anni , che aveva tre mili<unk> @ ar<unk> @ di di di anni , per tre milioni di anni , che av<unk> @ evo 4<unk> @ 0 milioni di anni , che av<unk> @ evo 4<unk> @ 0 anni , il 4<unk> @ 0 anni , il 4<unk> @ 0 % .
2025-05-27 19:24:13,738 - INFO - joeynmt.training - Example #1
2025-05-27 19:24:13,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:24:13,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:24:13,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'il', 'fatto', 'di', 'un', 'problema', 'di', 'cui', 'non', '', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'che', 'non', '', 'il', 'fatto', 'di', 'questo', 'problema', 'di', 'questo', 'problema', ',', 'e', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:24:13,739 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:24:13,739 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:24:13,739 - INFO - joeynmt.training - 	Hypothesis: Ma non  il fatto di un problema di cui non  la ris<unk> @ post<unk> @ a di questo problema , che non  il fatto di questo problema di questo problema , e non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:24:13,739 - INFO - joeynmt.training - Example #2
2025-05-27 19:24:13,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:24:13,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:24:13,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', '', 'il', 'sistema', 'di', 's@@', '<unk>', '@', '', 'che', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:24:13,740 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:24:13,740 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:24:13,740 - INFO - joeynmt.training - 	Hypothesis: In realt ,  il sistema di s<unk> @  che  la c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a del nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:24:13,741 - INFO - joeynmt.training - Example #3
2025-05-27 19:24:13,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:24:13,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:24:13,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'il', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:24:13,741 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:24:13,741 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:24:13,741 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e il s<unk> @ ac<unk> @ co di s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:24:13,741 - INFO - joeynmt.training - Example #4
2025-05-27 19:24:13,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:24:13,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:24:13,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', 'l&apos;', 'ulti@@', '<unk>', '@', 'mo', 'anni', '.', '</s>']
2025-05-27 19:24:13,742 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:24:13,742 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:24:13,742 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @  una cosa che vi mostr<unk> @ a una cosa che  succ<unk> @ esso in cui l&apos; ulti<unk> @ mo anni .
2025-05-27 19:24:17,118 - INFO - joeynmt.training - Epoch   3, Step:    19600, Batch Loss:     1.135661, Batch Acc: 0.667354, Tokens per Sec:    20223, Lr: 0.000300
2025-05-27 19:24:20,485 - INFO - joeynmt.training - Epoch   3, Step:    19700, Batch Loss:     1.130685, Batch Acc: 0.669139, Tokens per Sec:    24155, Lr: 0.000300
2025-05-27 19:24:23,840 - INFO - joeynmt.training - Epoch   3, Step:    19800, Batch Loss:     1.155150, Batch Acc: 0.670867, Tokens per Sec:    23680, Lr: 0.000300
2025-05-27 19:24:27,193 - INFO - joeynmt.training - Epoch   3, Step:    19900, Batch Loss:     1.073417, Batch Acc: 0.670823, Tokens per Sec:    23209, Lr: 0.000300
2025-05-27 19:24:30,580 - INFO - joeynmt.training - Epoch   3, Step:    20000, Batch Loss:     1.070847, Batch Acc: 0.670837, Tokens per Sec:    23701, Lr: 0.000300
2025-05-27 19:24:30,580 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:24:30,581 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:24:45,810 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.14, ppl:   3.14, acc:   0.67, generation: 15.2170[sec], evaluation: 0.0000[sec]
2025-05-27 19:24:45,811 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:24:46,405 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/17500.ckpt
2025-05-27 19:24:46,433 - INFO - joeynmt.training - Example #0
2025-05-27 19:24:46,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:24:46,434 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:24:46,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'che', 'la', 'f@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'ia', 'per', 'la', 'f@@', '<unk>', '@', 'av@@', '<unk>', '@', 'e', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 19:24:46,434 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:24:46,434 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:24:46,434 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato a questa fot<unk> @ o , ho mostr<unk> @ ato che la f<unk> @ ol<unk> @ ia per la f<unk> @ av<unk> @ e per i tre milioni di anni , che la c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di tre milioni di anni , per i tre milioni di anni , per i tre milioni di anni , per c<unk> @ ento , 4<unk> @ 0 milioni di anni .
2025-05-27 19:24:46,434 - INFO - joeynmt.training - Example #1
2025-05-27 19:24:46,435 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:24:46,435 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:24:46,435 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'fatto', 'che', 'non', '', 'stato', 'mostr@@', '<unk>', '@', 'ato', 'a', 'una', 'cosa', 'che', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questa', 'con@@', '<unk>', '@', 'n@@', '<unk>', '@', 'es@@', '<unk>', '@', 'sione', ',', 'non', '', 'il', 'problema', 'della', 'de@@', '<unk>', '@', 'fin@@', '<unk>', '@', 'i@@', '<unk>', '@', 'zione', '.', '</s>']
2025-05-27 19:24:46,435 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:24:46,435 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:24:46,436 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il fatto che non  stato mostr<unk> @ ato a una cosa che  il ris<unk> @ ult<unk> @ ato di questa con<unk> @ n<unk> @ es<unk> @ sione , non  il problema della de<unk> @ fin<unk> @ i<unk> @ zione .
2025-05-27 19:24:46,436 - INFO - joeynmt.training - Example #2
2025-05-27 19:24:46,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:24:46,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:24:46,436 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'f@@', '<unk>', '@', 're@@', '<unk>', '@', 'zione', '', 'la', 'nostra', 'in@@', '<unk>', '@', 't@@', '<unk>', '@', 'ura', ',', 'la', 'nostra', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '.', '</s>']
2025-05-27 19:24:46,436 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:24:46,437 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:24:46,437 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ f<unk> @ re<unk> @ zione  la nostra in<unk> @ t<unk> @ ura , la nostra c<unk> @ aus<unk> @ a della nostra c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:24:46,437 - INFO - joeynmt.training - Example #3
2025-05-27 19:24:46,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:24:46,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:24:46,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'si', 'trov@@', '<unk>', '@', 'a', 'in', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'b@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:24:46,437 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:24:46,437 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:24:46,438 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e si trov<unk> @ a in s<unk> @ om<unk> @ b<unk> @ a .
2025-05-27 19:24:46,438 - INFO - joeynmt.training - Example #4
2025-05-27 19:24:46,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:24:46,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:24:46,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'la', 'mia', 'm@@', '<unk>', '@', 'em@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ia', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:24:46,438 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:24:46,438 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:24:46,439 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ er<unk> @  la mia m<unk> @ em<unk> @ or<unk> @ ia  una c<unk> @ aus<unk> @ a di 2<unk> @ 5 anni .
2025-05-27 19:24:49,846 - INFO - joeynmt.training - Epoch   3, Step:    20100, Batch Loss:     1.146412, Batch Acc: 0.671980, Tokens per Sec:    20245, Lr: 0.000300
2025-05-27 19:24:53,204 - INFO - joeynmt.training - Epoch   3, Step:    20200, Batch Loss:     1.098671, Batch Acc: 0.672677, Tokens per Sec:    25012, Lr: 0.000300
2025-05-27 19:24:56,549 - INFO - joeynmt.training - Epoch   3, Step:    20300, Batch Loss:     1.262245, Batch Acc: 0.670158, Tokens per Sec:    23443, Lr: 0.000300
2025-05-27 19:24:59,899 - INFO - joeynmt.training - Epoch   3, Step:    20400, Batch Loss:     1.285209, Batch Acc: 0.669450, Tokens per Sec:    23707, Lr: 0.000300
2025-05-27 19:25:03,262 - INFO - joeynmt.training - Epoch   3, Step:    20500, Batch Loss:     1.240388, Batch Acc: 0.672535, Tokens per Sec:    23698, Lr: 0.000300
2025-05-27 19:25:03,263 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:25:03,263 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:25:18,746 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.14, ppl:   3.13, acc:   0.67, generation: 15.4740[sec], evaluation: 0.0000[sec]
2025-05-27 19:25:18,746 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:25:19,259 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/18000.ckpt
2025-05-27 19:25:19,277 - INFO - joeynmt.training - Example #0
2025-05-27 19:25:19,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:25:19,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:25:19,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'm@@', '<unk>', '@', 'oni', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'che', 'i', 'miei', 'f@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ori', 'per', 'per', 'il', 'f@@', '<unk>', '@', 'oll@@', '<unk>', '@', 'o', ',', 'per', 'i', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'i', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:25:19,278 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:25:19,278 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:25:19,278 - INFO - joeynmt.training - 	Hypothesis: E ho mostr<unk> @ ato questi due m<unk> @ oni , ho mostr<unk> @ ato a che i miei f<unk> @ att<unk> @ ori per per il f<unk> @ oll<unk> @ o , per i tre milioni di m<unk> @ oti<unk> @ vi per i tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , il 4<unk> @ 0 per c<unk> @ ento .
2025-05-27 19:25:19,278 - INFO - joeynmt.training - Example #1
2025-05-27 19:25:19,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:25:19,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:25:19,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'stato', 'il', 'problema', 'di', 'in@@', '<unk>', '@', 'st@@', '<unk>', '@', 'im@@', '<unk>', '@', 'ol@@', '<unk>', '@', 't@@', '<unk>', '@', 'ore', 'che', '', 'stato', 'in@@', '<unk>', '@', 'vent@@', '<unk>', '@', 'ato', ',', 'non', '', 'il', 'problema', 'di', 'un', 'problema', 'di', 'e@@', '<unk>', '@', 'qu@@', '<unk>', '@', 'i@@', '<unk>', '@', 'li@@', '<unk>', '@', 'zz@@', '<unk>', '@', 'ato', '.', '</s>']
2025-05-27 19:25:19,279 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:25:19,279 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:25:19,279 - INFO - joeynmt.training - 	Hypothesis: Ma non  stato il problema di in<unk> @ st<unk> @ im<unk> @ ol<unk> @ t<unk> @ ore che  stato in<unk> @ vent<unk> @ ato , non  il problema di un problema di e<unk> @ qu<unk> @ i<unk> @ li<unk> @ zz<unk> @ ato .
2025-05-27 19:25:19,279 - INFO - joeynmt.training - Example #2
2025-05-27 19:25:19,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:25:19,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:25:19,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', '<unk>', '@', 'ella', 's@@', '<unk>', '@', 'ett@@', '<unk>', '@', 'ore', '', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'mento', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ ella s<unk> @ ett<unk> @ ore  la s<unk> @ itu<unk> @ azione di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ mento glob<unk> @ ale .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - Example #3
2025-05-27 19:25:19,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:25:19,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:25:19,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'la', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', 'e', 'in', 's@@', '<unk>', '@', '', '.', '</s>']
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e la s<unk> @ om<unk> @ p<unk> @ a e in s<unk> @  .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - Example #4
2025-05-27 19:25:19,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:25:19,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:25:19,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'un', 'num@@', '<unk>', '@', 'ero', 'di', 'due', 'anni', '.', '</s>']
2025-05-27 19:25:19,281 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:25:19,281 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:25:19,281 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostr<unk> @ o che vi mostr<unk> @ o  che vi mostr<unk> @ o un num<unk> @ ero di due anni .
2025-05-27 19:25:22,641 - INFO - joeynmt.training - Epoch   3, Step:    20600, Batch Loss:     1.064212, Batch Acc: 0.669127, Tokens per Sec:    20354, Lr: 0.000300
2025-05-27 19:25:25,989 - INFO - joeynmt.training - Epoch   3, Step:    20700, Batch Loss:     1.135859, Batch Acc: 0.673611, Tokens per Sec:    23776, Lr: 0.000300
2025-05-27 19:25:29,338 - INFO - joeynmt.training - Epoch   3, Step:    20800, Batch Loss:     1.113295, Batch Acc: 0.674569, Tokens per Sec:    23406, Lr: 0.000300
2025-05-27 19:25:32,705 - INFO - joeynmt.training - Epoch   3, Step:    20900, Batch Loss:     1.137988, Batch Acc: 0.672831, Tokens per Sec:    24225, Lr: 0.000300
2025-05-27 19:25:36,041 - INFO - joeynmt.training - Epoch   3, Step:    21000, Batch Loss:     1.038801, Batch Acc: 0.672588, Tokens per Sec:    23635, Lr: 0.000300
2025-05-27 19:25:36,041 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:25:36,041 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:25:51,065 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.14, ppl:   3.12, acc:   0.67, generation: 15.0149[sec], evaluation: 0.0000[sec]
2025-05-27 19:25:51,065 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:25:51,645 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/18500.ckpt
2025-05-27 19:25:51,668 - INFO - joeynmt.training - Example #0
2025-05-27 19:25:51,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:25:51,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:25:51,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'che', 'il', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ce', 'per', 'fare', 'il', 'f@@', '<unk>', '@', 'ut@@', '<unk>', '@', 'uro', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'tre', 'anni', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', 'per', 'tre', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'anni', ',', 'che', 'av@@', '<unk>', '@', 'evo', 'tre', 'anni', '.', '</s>']
2025-05-27 19:25:51,669 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:25:51,669 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:25:51,669 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato a che il p<unk> @ es<unk> @ ce per fare il f<unk> @ ut<unk> @ uro che il g<unk> @ hi<unk> @ ac<unk> @ cio per tre anni , la c<unk> @ aus<unk> @ a di g<unk> @ am<unk> @ be per tre anni , per c<unk> @ ento di tre anni , che av<unk> @ evo tre anni .
2025-05-27 19:25:51,669 - INFO - joeynmt.training - Example #1
2025-05-27 19:25:51,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:25:51,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:25:51,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'un', 'po', '&apos;', 'di', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'che', 'la', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 't', 'di', 'questa', 'in@@', '<unk>', '@', 'forma@@', '<unk>', '@', 'zione', ',', 'non', '', 'un', 'problema', 'di', 'quello', 'che', 'non', '', 'il', 'd@@', '<unk>', '@', 'ato', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:25:51,670 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:25:51,670 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:25:51,671 - INFO - joeynmt.training - 	Hypothesis: Ma non  un po &apos; di ris<unk> @ ult<unk> @ ato che la ris<unk> @ ol<unk> @ t di questa in<unk> @ forma<unk> @ zione , non  un problema di quello che non  il d<unk> @ ato di questo problema .
2025-05-27 19:25:51,671 - INFO - joeynmt.training - Example #2
2025-05-27 19:25:51,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:25:51,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:25:51,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'f@@', '<unk>', '@', 'era', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'are', 'la', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:25:51,671 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ f<unk> @ era la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are la nostra c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - Example #3
2025-05-27 19:25:51,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:25:51,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:25:51,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'nel', 's@@', '<unk>', '@', '', '.', '</s>']
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , nel s<unk> @  .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - Example #4
2025-05-27 19:25:51,673 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:25:51,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:25:51,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'delle', 'prim@@', '<unk>', '@', 'e', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', '', 'quello', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'in', 'cui', 'l&apos;', 'ulti@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:25:51,673 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:25:51,673 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:25:51,673 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @  una delle prim<unk> @ e sc<unk> @ or<unk> @ so che  quello che  succ<unk> @ esso in sc<unk> @ or<unk> @ so in cui l&apos; ulti<unk> @ 5 anni .
2025-05-27 19:25:54,860 - INFO - joeynmt.training - Epoch   3, Step:    21100, Batch Loss:     1.063454, Batch Acc: 0.674099, Tokens per Sec:    20223, Lr: 0.000300
2025-05-27 19:25:58,102 - INFO - joeynmt.training - Epoch   3, Step:    21200, Batch Loss:     1.126101, Batch Acc: 0.674477, Tokens per Sec:    24716, Lr: 0.000300
2025-05-27 19:26:01,319 - INFO - joeynmt.training - Epoch   3, Step:    21300, Batch Loss:     1.160099, Batch Acc: 0.672968, Tokens per Sec:    24748, Lr: 0.000300
2025-05-27 19:26:04,572 - INFO - joeynmt.training - Epoch   3, Step:    21400, Batch Loss:     1.190800, Batch Acc: 0.675664, Tokens per Sec:    25046, Lr: 0.000300
2025-05-27 19:26:07,826 - INFO - joeynmt.training - Epoch   3, Step:    21500, Batch Loss:     1.079594, Batch Acc: 0.677491, Tokens per Sec:    24813, Lr: 0.000300
2025-05-27 19:26:07,826 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:26:07,826 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:26:21,596 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.13, ppl:   3.09, acc:   0.68, generation: 13.7616[sec], evaluation: 0.0000[sec]
2025-05-27 19:26:21,596 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:26:22,047 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/19000.ckpt
2025-05-27 19:26:22,065 - INFO - joeynmt.training - Example #0
2025-05-27 19:26:22,066 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:26:22,066 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:26:22,066 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'due', 'cose', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'due', 'due', 'due', 'anni', ',', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'le', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', 'per', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', 'di', 'tre', 'mili@@', '<unk>', '@', 'one', 'di', 'anni', ',', 'i', 'tre', 'mili@@', '<unk>', '@', 'one', 'di', 'di', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'st@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 19:26:22,066 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:26:22,066 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:26:22,066 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato queste due due cose che ho mostr<unk> @ ato questi due due due due anni , per ri<unk> @ dur<unk> @ re le g<unk> @ am<unk> @ be per la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ol<unk> @ i di tre mili<unk> @ one di anni , i tre mili<unk> @ one di di di anni , il 4<unk> @ 0 , 4<unk> @ 0 milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % di st<unk> @ at<unk> @ ura .
2025-05-27 19:26:22,066 - INFO - joeynmt.training - Example #1
2025-05-27 19:26:22,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:26:22,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:26:22,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'un', 'punto', 'di', 'vi@@', '<unk>', '@', 'sta', ',', 'non', '', 'la', 'ris@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'di', 'questa', 'con@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'enza', ',', 'non', '', 'il', 'fatto', 'che', 'non', '', 'il', 'fatto', 'che', 'non', '', 'il', 'de@@', '<unk>', '@', 'fin@@', '<unk>', '@', 'ito', ',', 'non', '', 'il', 'de@@', '<unk>', '@', 'ter@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ine', '.', '</s>']
2025-05-27 19:26:22,067 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:26:22,067 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:26:22,067 - INFO - joeynmt.training - 	Hypothesis: Ma non  un punto di vi<unk> @ sta , non  la ris<unk> @ or<unk> @ sa di questa con<unk> @ fer<unk> @ enza , non  il fatto che non  il fatto che non  il de<unk> @ fin<unk> @ ito , non  il de<unk> @ ter<unk> @ m<unk> @ ine .
2025-05-27 19:26:22,067 - INFO - joeynmt.training - Example #2
2025-05-27 19:26:22,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:26:22,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:26:22,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ma', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'nostra', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', ',', 'il', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:26:22,068 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:26:22,068 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:26:22,068 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la s<unk> @ om<unk> @ ma  la c<unk> @ aus<unk> @ a della nostra c<unk> @ las<unk> @ se , il nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:26:22,069 - INFO - joeynmt.training - Example #3
2025-05-27 19:26:22,069 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:26:22,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:26:22,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'la', 'cosa', 'che', 'si', '', 's@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ito', 'in', 'v@@', '<unk>', '@', 'it@@', '<unk>', '@', 'to', '.', '</s>']
2025-05-27 19:26:22,069 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:26:22,069 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:26:22,069 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , la cosa che si  s<unk> @ ent<unk> @ ito in v<unk> @ it<unk> @ to .
2025-05-27 19:26:22,069 - INFO - joeynmt.training - Example #4
2025-05-27 19:26:22,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:26:22,070 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:26:22,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'mi', 'mostr@@', '<unk>', '@', 'a', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'v@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'chi@@', '<unk>', '@', 'a', 'che', '', 'una', 'v@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'chi@@', '<unk>', '@', 'ata', 'di', 'quello', 'che', 'sta', 'succ@@', '<unk>', '@', 'e@@', '<unk>', '@', 'dendo', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:26:22,070 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:26:22,070 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:26:22,070 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa mi mostr<unk> @ a che vi mostr<unk> @ o  una v<unk> @ ec<unk> @ chi<unk> @ a che  una v<unk> @ ec<unk> @ chi<unk> @ ata di quello che sta succ<unk> @ e<unk> @ dendo in 2<unk> @ 5 anni .
2025-05-27 19:26:25,327 - INFO - joeynmt.training - Epoch   3, Step:    21600, Batch Loss:     1.107890, Batch Acc: 0.675775, Tokens per Sec:    21181, Lr: 0.000300
2025-05-27 19:26:28,543 - INFO - joeynmt.training - Epoch   3, Step:    21700, Batch Loss:     1.154062, Batch Acc: 0.673568, Tokens per Sec:    24219, Lr: 0.000300
2025-05-27 19:26:31,755 - INFO - joeynmt.training - Epoch   3, Step:    21800, Batch Loss:     1.072983, Batch Acc: 0.671800, Tokens per Sec:    24170, Lr: 0.000300
2025-05-27 19:26:35,005 - INFO - joeynmt.training - Epoch   3, Step:    21900, Batch Loss:     1.209550, Batch Acc: 0.675206, Tokens per Sec:    24967, Lr: 0.000300
2025-05-27 19:26:38,253 - INFO - joeynmt.training - Epoch   3, Step:    22000, Batch Loss:     1.233796, Batch Acc: 0.674246, Tokens per Sec:    24808, Lr: 0.000300
2025-05-27 19:26:38,254 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:26:38,254 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:26:51,879 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.13, ppl:   3.08, acc:   0.68, generation: 13.6173[sec], evaluation: 0.0000[sec]
2025-05-27 19:26:51,880 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:26:52,329 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/19500.ckpt
2025-05-27 19:26:52,353 - INFO - joeynmt.training - Example #0
2025-05-27 19:26:52,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:26:52,354 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:26:52,354 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', '<unk>', '@', 'el', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'due', 'anni', ',', 'per', 'costru@@', '<unk>', '@', 'ire', 'questi', 'due', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'persone', 'che', 'aveva', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'ato', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'le', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'v@@', '<unk>', '@', 'are', ',', 'per', 'le', '1@@', '<unk>', '@', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', '.', '</s>']
2025-05-27 19:26:52,354 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:26:52,354 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:26:52,354 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el anno sc<unk> @ or<unk> @ so che ho mostr<unk> @ ato questi due due anni , per costru<unk> @ ire questi due mili<unk> @ ar<unk> @ di di di persone che aveva di<unk> @ mostr<unk> @ ato che il g<unk> @ hi<unk> @ ac<unk> @ cio , per i tre milioni di anni , per le m<unk> @ oti<unk> @ v<unk> @ are , per le 1<unk> @ 4<unk> @ 0 milioni di persone che av<unk> @ evano tre milioni di m<unk> @ oti<unk> @ vi .
2025-05-27 19:26:52,354 - INFO - joeynmt.training - Example #1
2025-05-27 19:26:52,355 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:26:52,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:26:52,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'n@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ess@@', '<unk>', '@', 'ario', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', ',', 'la', 'di@@', '<unk>', '@', 'men@@', '<unk>', '@', 'sione', 'di', 'questa', 'di@@', '<unk>', '@', 'men@@', '<unk>', '@', 'sione', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:26:52,355 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:26:52,355 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:26:52,355 - INFO - joeynmt.training - 	Hypothesis: Ma non  n<unk> @ ec<unk> @ ess<unk> @ ario la ris<unk> @ post<unk> @ a , la di<unk> @ men<unk> @ sione di questa di<unk> @ men<unk> @ sione , non  il d<unk> @ ott<unk> @ ore , non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:26:52,355 - INFO - joeynmt.training - Example #2
2025-05-27 19:26:52,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:26:52,356 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:26:52,356 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', '<unk>', '@', 'el', 'sen@@', '<unk>', '@', 'so', '', 'la', 'ci@@', '<unk>', '@', 'ma', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'del', 'nostro', 'sistema', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:26:52,356 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:26:52,356 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:26:52,356 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el sen<unk> @ so  la ci<unk> @ ma  la c<unk> @ aus<unk> @ a del nostro sistema di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema glob<unk> @ ale glob<unk> @ ale glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:26:52,357 - INFO - joeynmt.training - Example #3
2025-05-27 19:26:52,357 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:26:52,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:26:52,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', 'e', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'e', 'il', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:26:52,357 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:26:52,357 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:26:52,357 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a e la c<unk> @ aus<unk> @ a e il p<unk> @ ezz<unk> @ o di s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:26:52,357 - INFO - joeynmt.training - Example #4
2025-05-27 19:26:52,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:26:52,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:26:52,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'vi', 'vi', 'mostr@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'e@@', '<unk>', '@', 'qu@@', '<unk>', '@', 'i@@', '<unk>', '@', 'li@@', '<unk>', '@', 'bri@@', '<unk>', '@', 'o', 'in', 'cui', 'abbiamo', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'in', 'cui', 'abbiamo', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:26:52,358 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:26:52,358 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:26:52,358 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ o vi vi mostr<unk> @ o che vi mostr<unk> @ o  una c<unk> @ e<unk> @ qu<unk> @ i<unk> @ li<unk> @ bri<unk> @ o in cui abbiamo sc<unk> @ or<unk> @ so in cui abbiamo 2<unk> @ 5 anni .
2025-05-27 19:26:55,698 - INFO - joeynmt.training - Epoch   3, Step:    22100, Batch Loss:     0.982399, Batch Acc: 0.675638, Tokens per Sec:    20272, Lr: 0.000300
2025-05-27 19:26:59,089 - INFO - joeynmt.training - Epoch   3, Step:    22200, Batch Loss:     1.147901, Batch Acc: 0.674515, Tokens per Sec:    23016, Lr: 0.000300
2025-05-27 19:27:02,437 - INFO - joeynmt.training - Epoch   3, Step:    22300, Batch Loss:     1.179490, Batch Acc: 0.676085, Tokens per Sec:    23770, Lr: 0.000300
2025-05-27 19:27:05,832 - INFO - joeynmt.training - Epoch   3, Step:    22400, Batch Loss:     1.123448, Batch Acc: 0.674667, Tokens per Sec:    23744, Lr: 0.000300
2025-05-27 19:27:09,202 - INFO - joeynmt.training - Epoch   3, Step:    22500, Batch Loss:     1.073788, Batch Acc: 0.674979, Tokens per Sec:    23555, Lr: 0.000300
2025-05-27 19:27:09,202 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:27:09,202 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:27:25,930 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.12, ppl:   3.07, acc:   0.68, generation: 16.7147[sec], evaluation: 0.0000[sec]
2025-05-27 19:27:25,931 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:27:26,469 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/20000.ckpt
2025-05-27 19:27:26,493 - INFO - joeynmt.training - Example #0
2025-05-27 19:27:26,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:27:26,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:27:26,494 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'milioni', 'di', 'persone', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'm@@', '<unk>', '@', 'ie', 'f@@', '<unk>', '@', 're@@', '<unk>', '@', 've', 'per', 'f@@', '<unk>', '@', 'ar', 'sc@@', '<unk>', '@', 'o@@', '<unk>', '@', 'pr@@', '<unk>', '@', 'ire', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'atori', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'v@@', '<unk>', '@', 'are', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'v@@', '<unk>', '@', 'are', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'persone', '.', '</s>']
2025-05-27 19:27:26,495 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:27:26,495 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:27:26,495 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato queste due milioni di persone , ho mostr<unk> @ ato queste due m<unk> @ ie f<unk> @ re<unk> @ ve per f<unk> @ ar sc<unk> @ o<unk> @ pr<unk> @ ire i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ atori per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ v<unk> @ are tre milioni di m<unk> @ oti<unk> @ v<unk> @ are 4<unk> @ 0 milioni di persone .
2025-05-27 19:27:26,495 - INFO - joeynmt.training - Example #1
2025-05-27 19:27:26,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:27:26,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:27:26,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questo', 'tipo', 'di', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', ',', 'che', 'non', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'queste', 'probl@@', '<unk>', '@', 'emi', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:27:26,496 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:27:26,496 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:27:26,496 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il ris<unk> @ ult<unk> @ ato di questo tipo di ris<unk> @ ult<unk> @ ato , che non  il ris<unk> @ ult<unk> @ ato di queste probl<unk> @ emi , non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:27:26,496 - INFO - joeynmt.training - Example #2
2025-05-27 19:27:26,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:27:26,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:27:26,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'nostra', 'c@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ura', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:27:26,497 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:27:26,497 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:27:26,497 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ con<unk> @ si<unk> @ der<unk> @ azione  la c<unk> @ aus<unk> @ a della nostra c<unk> @ at<unk> @ ura glob<unk> @ ale .
2025-05-27 19:27:26,497 - INFO - joeynmt.training - Example #3
2025-05-27 19:27:26,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:27:26,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:27:26,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 's@@', '<unk>', '@', '', '.', '</s>']
2025-05-27 19:27:26,498 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:27:26,498 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:27:26,498 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , si tr<unk> @ at<unk> @ ta di s<unk> @  .
2025-05-27 19:27:26,498 - INFO - joeynmt.training - Example #4
2025-05-27 19:27:26,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:27:26,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:27:26,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'delle', 'ar@@', '<unk>', '@', 'ee', 'che', '', 'una', 'delle', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'in', 'cui', 'abbiamo', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:27:26,499 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:27:26,499 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:27:26,499 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma  che vi mostr<unk> @ o che vi mostr<unk> @ o  una delle ar<unk> @ ee che  una delle sc<unk> @ or<unk> @ sa di quello che succ<unk> @ ede in cui abbiamo sc<unk> @ or<unk> @ so 2<unk> @ 5 anni .
2025-05-27 19:27:29,951 - INFO - joeynmt.training - Epoch   3, Step:    22600, Batch Loss:     1.211226, Batch Acc: 0.673539, Tokens per Sec:    20063, Lr: 0.000300
2025-05-27 19:27:33,381 - INFO - joeynmt.training - Epoch   3, Step:    22700, Batch Loss:     1.139867, Batch Acc: 0.676098, Tokens per Sec:    23820, Lr: 0.000300
2025-05-27 19:27:36,855 - INFO - joeynmt.training - Epoch   3, Step:    22800, Batch Loss:     1.132043, Batch Acc: 0.678326, Tokens per Sec:    22311, Lr: 0.000300
2025-05-27 19:27:40,265 - INFO - joeynmt.training - Epoch   3, Step:    22900, Batch Loss:     1.041087, Batch Acc: 0.674013, Tokens per Sec:    23065, Lr: 0.000300
2025-05-27 19:27:43,671 - INFO - joeynmt.training - Epoch   3, Step:    23000, Batch Loss:     1.164066, Batch Acc: 0.677214, Tokens per Sec:    22909, Lr: 0.000300
2025-05-27 19:27:43,671 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:27:43,671 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:27:59,303 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.12, ppl:   3.05, acc:   0.68, generation: 15.6226[sec], evaluation: 0.0000[sec]
2025-05-27 19:27:59,303 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:27:59,797 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/20500.ckpt
2025-05-27 19:27:59,820 - INFO - joeynmt.training - Example #0
2025-05-27 19:27:59,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:27:59,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:27:59,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'us@@', '<unk>', '@', 'are', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'ie', 'per', 'i', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'che', 'i', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'ni', 'per', 'i', 'tre', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'sc@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ato', 'per', 'tre', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', '.', '</s>']
2025-05-27 19:27:59,822 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:27:59,822 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:27:59,822 - INFO - joeynmt.training - 	Hypothesis: Ho mostr<unk> @ ato questa sc<unk> @ or<unk> @ sa , ho mostr<unk> @ ato questa fot<unk> @ o , per us<unk> @ are la p<unk> @ op<unk> @ ol<unk> @ ie per i tre milioni di persone che hanno sc<unk> @ oper<unk> @ to che i g<unk> @ over<unk> @ ni per i tre milioni di persone che av<unk> @ evano sc<unk> @ ar<unk> @ ic<unk> @ ato per tre milioni di persone che av<unk> @ evano sc<unk> @ oper<unk> @ to .
2025-05-27 19:27:59,822 - INFO - joeynmt.training - Example #1
2025-05-27 19:27:59,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:27:59,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:27:59,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'stato', 'il', 'fatto', 'che', 'non', '', 'la', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ata', 'di', 'questa', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 're@@', '<unk>', '@', 'zione', 'di', 'questa', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:27:59,823 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:27:59,823 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:27:59,823 - INFO - joeynmt.training - 	Hypothesis: Ma non  stato il fatto che non  la ris<unk> @ ult<unk> @ ata di questa in<unk> @ f<unk> @ re<unk> @ zione di questa di<unk> @ st<unk> @ anza , non  il d<unk> @ or<unk> @ ig<unk> @ in<unk> @ ale .
2025-05-27 19:27:59,823 - INFO - joeynmt.training - Example #2
2025-05-27 19:27:59,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:27:59,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:27:59,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 's@@', '<unk>', '@', 'edi@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', 'che', 'il', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:27:59,824 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:27:59,824 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:27:59,824 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la s<unk> @ edi<unk> @ a  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ale che il nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:27:59,824 - INFO - joeynmt.training - Example #3
2025-05-27 19:27:59,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:27:59,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:27:59,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'in', 'realt', ',', 'in', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:27:59,825 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:27:59,825 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:27:59,825 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in realt , in m<unk> @ ezz<unk> @ o di s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:27:59,825 - INFO - joeynmt.training - Example #4
2025-05-27 19:27:59,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:27:59,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:27:59,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'fot@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'una', 'delle', 'cose', 'che', '', 'una', 'delle', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'se', ',', 'in', 'realt', '', 'succ@@', '<unk>', '@', 'esso', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:27:59,826 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:27:59,826 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:27:59,826 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma fot<unk> @ o che vi mostr<unk> @ o una delle cose che  una delle sc<unk> @ or<unk> @ se , in realt  succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:28:03,179 - INFO - joeynmt.training - Epoch   3, Step:    23100, Batch Loss:     1.077878, Batch Acc: 0.679209, Tokens per Sec:    20475, Lr: 0.000300
2025-05-27 19:28:06,608 - INFO - joeynmt.training - Epoch   3, Step:    23200, Batch Loss:     1.078556, Batch Acc: 0.678151, Tokens per Sec:    23185, Lr: 0.000300
2025-05-27 19:28:09,995 - INFO - joeynmt.training - Epoch   3, Step:    23300, Batch Loss:     1.088844, Batch Acc: 0.675817, Tokens per Sec:    23390, Lr: 0.000300
2025-05-27 19:28:13,423 - INFO - joeynmt.training - Epoch   3, Step:    23400, Batch Loss:     1.061806, Batch Acc: 0.678408, Tokens per Sec:    23050, Lr: 0.000300
2025-05-27 19:28:16,831 - INFO - joeynmt.training - Epoch   3, Step:    23500, Batch Loss:     1.066957, Batch Acc: 0.678564, Tokens per Sec:    23082, Lr: 0.000300
2025-05-27 19:28:16,832 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:28:16,832 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:28:32,409 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.11, ppl:   3.05, acc:   0.68, generation: 15.5649[sec], evaluation: 0.0000[sec]
2025-05-27 19:28:32,410 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:28:32,940 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/21000.ckpt
2025-05-27 19:28:32,965 - INFO - joeynmt.training - Example #0
2025-05-27 19:28:32,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:28:32,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:28:32,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'cosa', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'per', 'la', 'f@@', '<unk>', '@', 'ar', 'sc@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'are', 'per', 'la', 'f@@', '<unk>', '@', 'est@@', '<unk>', '@', 'r@@', '<unk>', '@', 'azione', ',', 'che', 'i', 'su@@', '<unk>', '@', 'oi', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'fatto', 'per', 'i', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'av@@', '<unk>', '@', 'uto', 'i', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:28:32,966 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:28:32,966 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:28:32,966 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa cosa che ho mostr<unk> @ ato per la f<unk> @ ar sc<unk> @ ar<unk> @ ic<unk> @ are per la f<unk> @ est<unk> @ r<unk> @ azione , che i su<unk> @ oi tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di persone che hanno fatto per i 4<unk> @ 0 milioni di persone che av<unk> @ evano av<unk> @ uto i 4<unk> @ 0 milioni di persone che av<unk> @ evano av<unk> @ uto il 4<unk> @ 0 % .
2025-05-27 19:28:32,966 - INFO - joeynmt.training - Example #1
2025-05-27 19:28:32,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:28:32,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:28:32,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'n@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ess@@', '<unk>', '@', 'ario', 'per', 'la', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'u@@', '<unk>', '@', 'zione', 'di', 'questa', 'con@@', '<unk>', '@', 'n@@', '<unk>', '@', 'es@@', '<unk>', '@', 'sione', ',', 'non', '', 'il', 'fatto', 'di', 'sol@@', '<unk>', '@', 'ito', '.', '</s>']
2025-05-27 19:28:32,967 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:28:32,967 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:28:32,967 - INFO - joeynmt.training - 	Hypothesis: Ma non  n<unk> @ ec<unk> @ ess<unk> @ ario per la ris<unk> @ ol<unk> @ u<unk> @ zione di questa con<unk> @ n<unk> @ es<unk> @ sione , non  il fatto di sol<unk> @ ito .
2025-05-27 19:28:32,967 - INFO - joeynmt.training - Example #2
2025-05-27 19:28:32,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:28:32,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:28:32,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', '', 'la', 's@@', '<unk>', '@', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bile', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:28:32,968 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:28:32,968 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:28:32,968 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt ,  la s<unk> @ in<unk> @ cre<unk> @ di<unk> @ bile  la c<unk> @ li<unk> @ sta del nostro sistema glob<unk> @ ale .
2025-05-27 19:28:32,968 - INFO - joeynmt.training - Example #3
2025-05-27 19:28:32,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:28:32,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:28:32,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', 'e', 'la', 'sc@@', '<unk>', '@', 'el@@', '<unk>', '@', 'ta', '.', '</s>']
2025-05-27 19:28:32,969 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:28:32,969 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:28:32,969 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ om<unk> @ p<unk> @ a e la sc<unk> @ el<unk> @ ta .
2025-05-27 19:28:32,969 - INFO - joeynmt.training - Example #4
2025-05-27 19:28:32,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:28:32,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:28:32,969 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'delle', 'cose', 'che', '', 'una', 'cell@@', '<unk>', '@', 'u@@', '<unk>', '@', 'la', ',', 'che', '', 'una', 'delle', 'ulti@@', '<unk>', '@', 'me', 'due', 'anni', '.', '</s>']
2025-05-27 19:28:32,970 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:28:32,970 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:28:32,970 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una delle cose che  una cell<unk> @ u<unk> @ la , che  una delle ulti<unk> @ me due anni .
2025-05-27 19:28:36,400 - INFO - joeynmt.training - Epoch   3, Step:    23600, Batch Loss:     1.203959, Batch Acc: 0.677745, Tokens per Sec:    19813, Lr: 0.000300
2025-05-27 19:28:36,575 - INFO - joeynmt.training - Epoch   3: total training loss 9021.71
2025-05-27 19:28:36,576 - INFO - joeynmt.training - EPOCH 4
2025-05-27 19:28:39,845 - INFO - joeynmt.training - Epoch   4, Step:    23700, Batch Loss:     1.035920, Batch Acc: 0.686407, Tokens per Sec:    23756, Lr: 0.000300
2025-05-27 19:28:43,194 - INFO - joeynmt.training - Epoch   4, Step:    23800, Batch Loss:     1.004512, Batch Acc: 0.688198, Tokens per Sec:    23411, Lr: 0.000300
2025-05-27 19:28:46,529 - INFO - joeynmt.training - Epoch   4, Step:    23900, Batch Loss:     1.083313, Batch Acc: 0.687419, Tokens per Sec:    23591, Lr: 0.000300
2025-05-27 19:28:49,912 - INFO - joeynmt.training - Epoch   4, Step:    24000, Batch Loss:     1.136104, Batch Acc: 0.687703, Tokens per Sec:    23338, Lr: 0.000300
2025-05-27 19:28:49,913 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:28:49,913 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:29:05,520 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.11, ppl:   3.03, acc:   0.68, generation: 15.5927[sec], evaluation: 0.0000[sec]
2025-05-27 19:29:05,520 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:29:06,097 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/21500.ckpt
2025-05-27 19:29:06,124 - INFO - joeynmt.training - Example #0
2025-05-27 19:29:06,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:29:06,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:29:06,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'cui', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'l&apos;', 'eff@@', '<unk>', '@', 'etto', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'i', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'anni', ',', 'per', 'la', 'c@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'azione', 'per', 'i', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'di', 'anni', '.', '</s>']
2025-05-27 19:29:06,126 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:29:06,126 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:29:06,126 - INFO - joeynmt.training - 	Hypothesis: E in cui ho mostr<unk> @ ato questa sc<unk> @ or<unk> @ sa , ho mostr<unk> @ ato questa fot<unk> @ o per ri<unk> @ dur<unk> @ re l&apos; eff<unk> @ etto di g<unk> @ hi<unk> @ ac<unk> @ cio per i tre mili<unk> @ ar<unk> @ di di di anni , per la c<unk> @ op<unk> @ ol<unk> @ azione per i tre mili<unk> @ ar<unk> @ di di di di anni .
2025-05-27 19:29:06,126 - INFO - joeynmt.training - Example #1
2025-05-27 19:29:06,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:29:06,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:29:06,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questo', 'tipo', 'di', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'che', 'la', 'T@@', '<unk>', '@', 'erra', 'non', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questa', 'con@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'enza', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:29:06,127 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:29:06,127 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:29:06,127 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il ris<unk> @ ult<unk> @ ato di questo tipo di ris<unk> @ ult<unk> @ ato che la T<unk> @ erra non  il ris<unk> @ ult<unk> @ ato di questa con<unk> @ fer<unk> @ enza , non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:29:06,127 - INFO - joeynmt.training - Example #2
2025-05-27 19:29:06,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:29:06,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:29:06,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'cui', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', ',', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'ca', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:29:06,128 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:29:06,128 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:29:06,128 - INFO - joeynmt.training - 	Hypothesis: In realt , in cui la s<unk> @ itu<unk> @ azione  la c<unk> @ li<unk> @ sta , la c<unk> @ li<unk> @ m<unk> @ as<unk> @ ca del nostro sistema glob<unk> @ ale .
2025-05-27 19:29:06,128 - INFO - joeynmt.training - Example #3
2025-05-27 19:29:06,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:29:06,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:29:06,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'cosa', 'che', 'si', 'trov@@', '<unk>', '@', 'a', 'in', 'par@@', '<unk>', '@', 'ola', 'e', 'la', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:29:06,129 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:29:06,129 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:29:06,129 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una cosa che si trov<unk> @ a in par<unk> @ ola e la s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:29:06,129 - INFO - joeynmt.training - Example #4
2025-05-27 19:29:06,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:29:06,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:29:06,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'succ@@', '<unk>', '@', 'essi@@', '<unk>', '@', 'va', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'cell@@', '<unk>', '@', 'u@@', '<unk>', '@', 'la', ',', '', 'una', 'delle', 'ulti@@', '<unk>', '@', 'me', 'anni', '.', '</s>']
2025-05-27 19:29:06,130 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:29:06,130 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:29:06,130 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa succ<unk> @ essi<unk> @ va che vi mostr<unk> @ er<unk> @   una cell<unk> @ u<unk> @ la ,  una delle ulti<unk> @ me anni .
2025-05-27 19:29:09,535 - INFO - joeynmt.training - Epoch   4, Step:    24100, Batch Loss:     1.082881, Batch Acc: 0.687395, Tokens per Sec:    18863, Lr: 0.000300
2025-05-27 19:29:12,906 - INFO - joeynmt.training - Epoch   4, Step:    24200, Batch Loss:     1.060001, Batch Acc: 0.685246, Tokens per Sec:    22934, Lr: 0.000300
2025-05-27 19:29:16,296 - INFO - joeynmt.training - Epoch   4, Step:    24300, Batch Loss:     1.085350, Batch Acc: 0.684724, Tokens per Sec:    23997, Lr: 0.000300
2025-05-27 19:29:19,672 - INFO - joeynmt.training - Epoch   4, Step:    24400, Batch Loss:     1.207040, Batch Acc: 0.685230, Tokens per Sec:    23492, Lr: 0.000300
2025-05-27 19:29:23,061 - INFO - joeynmt.training - Epoch   4, Step:    24500, Batch Loss:     1.087266, Batch Acc: 0.689559, Tokens per Sec:    23415, Lr: 0.000300
2025-05-27 19:29:23,061 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:29:23,061 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:29:41,673 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.10, ppl:   3.02, acc:   0.68, generation: 18.5957[sec], evaluation: 0.0000[sec]
2025-05-27 19:29:41,674 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:29:42,237 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/22000.ckpt
2025-05-27 19:29:42,257 - INFO - joeynmt.training - Example #0
2025-05-27 19:29:42,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:29:42,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:29:42,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'l@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ter@@', '<unk>', '@', 'almente', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'cosa', 'che', 'l&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', 'la', 'g@@', '<unk>', '@', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ica', 'per', 'i', 'di@@', '<unk>', '@', 'segn@@', '<unk>', '@', 'ali', 'che', 'i', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'ni', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', '.', '</s>']
2025-05-27 19:29:42,259 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:29:42,259 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:29:42,259 - INFO - joeynmt.training - 	Hypothesis: E la l<unk> @ et<unk> @ ter<unk> @ almente ho mostr<unk> @ ato questa cosa che l&apos; anno sc<unk> @ or<unk> @ sa che la g<unk> @ ar<unk> @ t<unk> @ ica per i di<unk> @ segn<unk> @ ali che i g<unk> @ over<unk> @ ni per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di anni , che aveva 4<unk> @ 0 milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi .
2025-05-27 19:29:42,259 - INFO - joeynmt.training - Example #1
2025-05-27 19:29:42,260 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:29:42,260 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:29:42,260 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'un', 'po', '&apos;', 'di', 'questo', ',', 'non', '', 'un', 'po', '&apos;', 'di', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bil@@', '<unk>', '@', 'it', 'di', 'questo', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bile', 'in@@', '<unk>', '@', 'segn@@', '<unk>', '@', 'ale', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:29:42,260 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:29:42,260 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:29:42,260 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  un po &apos; di questo , non  un po &apos; di in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ it di questo in<unk> @ cre<unk> @ di<unk> @ bile in<unk> @ segn<unk> @ ale , non  il d<unk> @ ott<unk> @ ico .
2025-05-27 19:29:42,260 - INFO - joeynmt.training - Example #2
2025-05-27 19:29:42,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:29:42,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:29:42,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ando', 'il', 'nostro', 'sistema', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '', 'il', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:29:42,261 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:29:42,261 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:29:42,261 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la c<unk> @ li<unk> @ sta di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ando il nostro sistema di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale  il nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:29:42,261 - INFO - joeynmt.training - Example #3
2025-05-27 19:29:42,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:29:42,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:29:42,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['D@@', '<unk>', '@', 'ov@@', '<unk>', '@', 'ete', 's@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ito', ',', 'e', 'il', 'pi', 'b@@', '<unk>', '@', 'el', '.', '</s>']
2025-05-27 19:29:42,262 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:29:42,262 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:29:42,262 - INFO - joeynmt.training - 	Hypothesis: D<unk> @ ov<unk> @ ete s<unk> @ ent<unk> @ ito , e il pi b<unk> @ el .
2025-05-27 19:29:42,262 - INFO - joeynmt.training - Example #4
2025-05-27 19:29:42,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:29:42,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:29:42,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'la', 'prima', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'ede', 'in', 'cui', '', 'una', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'ede', 'in', 'cui', 'abbiamo', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'in', 'cui', 'abbiamo', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'il', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:29:42,263 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:29:42,263 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:29:42,263 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ a la prima cosa che  succ<unk> @ ede in cui  una cosa che  succ<unk> @ ede in cui abbiamo sc<unk> @ oper<unk> @ to in cui abbiamo sc<unk> @ or<unk> @ so il 2<unk> @ 5 anni .
2025-05-27 19:29:45,633 - INFO - joeynmt.training - Epoch   4, Step:    24600, Batch Loss:     1.010595, Batch Acc: 0.685902, Tokens per Sec:    20138, Lr: 0.000300
2025-05-27 19:29:49,011 - INFO - joeynmt.training - Epoch   4, Step:    24700, Batch Loss:     1.053700, Batch Acc: 0.686683, Tokens per Sec:    22860, Lr: 0.000300
2025-05-27 19:29:52,376 - INFO - joeynmt.training - Epoch   4, Step:    24800, Batch Loss:     0.994363, Batch Acc: 0.687284, Tokens per Sec:    22887, Lr: 0.000300
2025-05-27 19:29:55,751 - INFO - joeynmt.training - Epoch   4, Step:    24900, Batch Loss:     1.139652, Batch Acc: 0.683940, Tokens per Sec:    23203, Lr: 0.000300
2025-05-27 19:29:59,118 - INFO - joeynmt.training - Epoch   4, Step:    25000, Batch Loss:     1.071697, Batch Acc: 0.688119, Tokens per Sec:    23252, Lr: 0.000300
2025-05-27 19:29:59,119 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:29:59,119 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:30:14,904 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.10, ppl:   3.01, acc:   0.68, generation: 15.7710[sec], evaluation: 0.0000[sec]
2025-05-27 19:30:14,904 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:30:15,412 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/22500.ckpt
2025-05-27 19:30:15,433 - INFO - joeynmt.training - Example #0
2025-05-27 19:30:15,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:30:15,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:30:15,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'due', 'due', 'anni', ',', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'i', ',', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', ',', 'che', 'hanno', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'b@@', '<unk>', '@', 'ato', 'per', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'anni', ',', 'e', 'per', 'la', '4@@', '<unk>', '@', '0', 'anni', ',', '', 'stato', 'il', '4@@', '<unk>', '@', '0', 'e', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', '.', '</s>']
2025-05-27 19:30:15,434 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:30:15,434 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:30:15,434 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due due due anni , per ri<unk> @ dur<unk> @ re la p<unk> @ op<unk> @ i , che la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ol<unk> @ i , che hanno ri<unk> @ m<unk> @ b<unk> @ ato per tre mili<unk> @ ar<unk> @ di di di anni , e per la 4<unk> @ 0 anni ,  stato il 4<unk> @ 0 e m<unk> @ oti<unk> @ vi .
2025-05-27 19:30:15,434 - INFO - joeynmt.training - Example #1
2025-05-27 19:30:15,435 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:30:15,435 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:30:15,435 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'il', 't@@', '<unk>', '@', 'as@@', '<unk>', '@', 'so', 'di', 'questo', ',', 'la', 'cosa', 'che', 'non', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questo', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'en@@', '<unk>', '@', 'o', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', 'di', 'questo', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:30:15,435 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:30:15,435 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:30:15,435 - INFO - joeynmt.training - 	Hypothesis: Ma non  il t<unk> @ as<unk> @ so di questo , la cosa che non  il ris<unk> @ ult<unk> @ ato di questo in<unk> @ f<unk> @ lu<unk> @ en<unk> @ o , non  il d<unk> @ ott<unk> @ ore di questo , non  il d<unk> @ ott<unk> @ ico .
2025-05-27 19:30:15,435 - INFO - joeynmt.training - Example #2
2025-05-27 19:30:15,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:30:15,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:30:15,436 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'an@@', '<unk>', '@', 'it', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'di', 'un', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:30:15,436 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:30:15,436 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:30:15,436 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ an<unk> @ it  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore della nostra c<unk> @ li<unk> @ ma  il cu<unk> @ ore di un sistema glob<unk> @ ale .
2025-05-27 19:30:15,436 - INFO - joeynmt.training - Example #3
2025-05-27 19:30:15,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:30:15,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:30:15,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'c@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zion@@', '<unk>', '@', 'a', ',', 'e', 'la', 'cosa', 'che', 'si', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:30:15,437 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:30:15,437 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:30:15,437 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ c<unk> @ e<unk> @ zion<unk> @ a , e la cosa che si s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:30:15,437 - INFO - joeynmt.training - Example #4
2025-05-27 19:30:15,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:30:15,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:30:15,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', '', 'una', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'esso', ',', '', 'una', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:30:15,438 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:30:15,438 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:30:15,438 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma  una cosa che  succ<unk> @ esso ,  una cosa che  succ<unk> @ esso in sc<unk> @ or<unk> @ so che  succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:30:18,798 - INFO - joeynmt.training - Epoch   4, Step:    25100, Batch Loss:     1.094341, Batch Acc: 0.683679, Tokens per Sec:    20586, Lr: 0.000300
2025-05-27 19:30:22,150 - INFO - joeynmt.training - Epoch   4, Step:    25200, Batch Loss:     1.038399, Batch Acc: 0.688114, Tokens per Sec:    24190, Lr: 0.000300
2025-05-27 19:30:25,459 - INFO - joeynmt.training - Epoch   4, Step:    25300, Batch Loss:     1.039276, Batch Acc: 0.687454, Tokens per Sec:    23131, Lr: 0.000300
2025-05-27 19:30:28,786 - INFO - joeynmt.training - Epoch   4, Step:    25400, Batch Loss:     1.012030, Batch Acc: 0.689163, Tokens per Sec:    23966, Lr: 0.000300
2025-05-27 19:30:32,129 - INFO - joeynmt.training - Epoch   4, Step:    25500, Batch Loss:     1.083997, Batch Acc: 0.687525, Tokens per Sec:    23947, Lr: 0.000300
2025-05-27 19:30:32,129 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:30:32,129 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:30:45,964 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.10, ppl:   2.99, acc:   0.68, generation: 13.8268[sec], evaluation: 0.0000[sec]
2025-05-27 19:30:45,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:30:46,464 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/23000.ckpt
2025-05-27 19:30:46,488 - INFO - joeynmt.training - Example #0
2025-05-27 19:30:46,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:30:46,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:30:46,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'rete', 'di', 'queste', 'due', 'volte', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'g@@', '<unk>', '@', 'oc@@', '<unk>', '@', 'cia', ',', 'che', 'i', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'ni', 'per', 'tre', 'anni', ',', 'per', 'la', 'met@@', '<unk>', '@', '', 'di', 'tre', 'anni', ',', 'per', 'la', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'la', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'fatto', 'per', 'la', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:30:46,489 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:30:46,490 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:30:46,490 - INFO - joeynmt.training - 	Hypothesis: E la rete di queste due volte , ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o , per ri<unk> @ dur<unk> @ re la g<unk> @ oc<unk> @ cia , che i g<unk> @ over<unk> @ ni per tre anni , per la met<unk> @  di tre anni , per la 4<unk> @ 8 milioni di anni , per la 4<unk> @ 8 milioni di persone che av<unk> @ evano fatto per la 4<unk> @ 0 % .
2025-05-27 19:30:46,490 - INFO - joeynmt.training - Example #1
2025-05-27 19:30:46,490 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:30:46,490 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:30:46,490 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'un', 'problema', 'di', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', 'di', 'questa', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'enza', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:30:46,491 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:30:46,491 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:30:46,491 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  un problema di in<unk> @ ten<unk> @ zione di questa in<unk> @ f<unk> @ lu<unk> @ enza , non  il d<unk> @ ott<unk> @ ore , non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:30:46,491 - INFO - joeynmt.training - Example #2
2025-05-27 19:30:46,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:30:46,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:30:46,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', '', 'la', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', '', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'es@@', '<unk>', '@', 'sione', 'del', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:30:46,492 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:30:46,492 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:30:46,492 - INFO - joeynmt.training - 	Hypothesis: In realt , la c<unk> @ li<unk> @ sta  la c<unk> @ las<unk> @ se  la g<unk> @ hi<unk> @ es<unk> @ sione del sistema glob<unk> @ ale .
2025-05-27 19:30:46,492 - INFO - joeynmt.training - Example #3
2025-05-27 19:30:46,492 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:30:46,492 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:30:46,492 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'pi', 'al@@', '<unk>', '@', 'ta', ',', 'e', 'il', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', ',', 'e', 'il', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:30:46,493 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:30:46,493 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:30:46,493 - INFO - joeynmt.training - 	Hypothesis: E &apos; pi al<unk> @ ta , e il p<unk> @ ezz<unk> @ o , e il p<unk> @ ezz<unk> @ o .
2025-05-27 19:30:46,493 - INFO - joeynmt.training - Example #4
2025-05-27 19:30:46,493 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:30:46,493 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:30:46,493 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'p@@', '<unk>', '@', 'oco', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'delle', 'cose', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'a', 'quello', 'che', 'sta', 'succ@@', '<unk>', '@', 'e@@', '<unk>', '@', 'dendo', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:30:46,494 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:30:46,494 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:30:46,494 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo p<unk> @ oco che vi mostr<unk> @ o  una delle cose che ho mostr<unk> @ ato a quello che sta succ<unk> @ e<unk> @ dendo in 2<unk> @ 5 anni .
2025-05-27 19:30:49,805 - INFO - joeynmt.training - Epoch   4, Step:    25600, Batch Loss:     1.165602, Batch Acc: 0.689896, Tokens per Sec:    20977, Lr: 0.000300
2025-05-27 19:30:53,177 - INFO - joeynmt.training - Epoch   4, Step:    25700, Batch Loss:     1.099198, Batch Acc: 0.691517, Tokens per Sec:    24065, Lr: 0.000300
2025-05-27 19:30:56,550 - INFO - joeynmt.training - Epoch   4, Step:    25800, Batch Loss:     1.106754, Batch Acc: 0.687349, Tokens per Sec:    23440, Lr: 0.000300
2025-05-27 19:30:59,932 - INFO - joeynmt.training - Epoch   4, Step:    25900, Batch Loss:     1.033412, Batch Acc: 0.690626, Tokens per Sec:    23497, Lr: 0.000300
2025-05-27 19:31:03,332 - INFO - joeynmt.training - Epoch   4, Step:    26000, Batch Loss:     1.048194, Batch Acc: 0.688440, Tokens per Sec:    23838, Lr: 0.000300
2025-05-27 19:31:03,332 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:31:03,332 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:31:18,290 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.09, ppl:   2.98, acc:   0.69, generation: 14.9494[sec], evaluation: 0.0000[sec]
2025-05-27 19:31:18,290 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:31:18,753 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/23500.ckpt
2025-05-27 19:31:18,776 - INFO - joeynmt.training - Example #0
2025-05-27 19:31:18,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:31:18,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:31:18,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'do', 'a', 'questo', ',', 'per', 'esempio', ',', 'per', 'la', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'ta', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'la', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'v@@', '<unk>', '@', 'azione', ',', 'per', 'la', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'ta', 'del', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'che', '', 'stato', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 19:31:18,777 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:31:18,777 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:31:18,777 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questa fot<unk> @ o , per ri<unk> @ guar<unk> @ do a questo , per esempio , per la sc<unk> @ oper<unk> @ ta di g<unk> @ hi<unk> @ ac<unk> @ cio per i tre milioni di anni , per la m<unk> @ oti<unk> @ v<unk> @ azione , per la sc<unk> @ oper<unk> @ ta del 4<unk> @ 8 milioni di anni , il 4<unk> @ 8 , che  stato il 4<unk> @ 8 milioni di anni .
2025-05-27 19:31:18,777 - INFO - joeynmt.training - Example #1
2025-05-27 19:31:18,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:31:18,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:31:18,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'un', 'po', '&apos;', 'di', 'non', '', 'la', 'cosa', 'pi', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bile', ',', 'la', 'cosa', 'che', '', 'il', 'fatto', '', 'il', 't@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'ore', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:31:18,778 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:31:18,778 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:31:18,778 - INFO - joeynmt.training - 	Hypothesis: Ma non  un po &apos; di non  la cosa pi in<unk> @ cre<unk> @ di<unk> @ bile , la cosa che  il fatto  il t<unk> @ ot<unk> @ ore , non  il d<unk> @ ott<unk> @ ore , non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:31:18,778 - INFO - joeynmt.training - Example #2
2025-05-27 19:31:18,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:31:18,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:31:18,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 's@@', '<unk>', '@', 'qu@@', '<unk>', '@', 'ad@@', '<unk>', '@', 'ra', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:31:18,779 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:31:18,779 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:31:18,779 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la s<unk> @ qu<unk> @ ad<unk> @ ra  la c<unk> @ li<unk> @ sta  la c<unk> @ li<unk> @ sta del nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:31:18,779 - INFO - joeynmt.training - Example #3
2025-05-27 19:31:18,779 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:31:18,779 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:31:18,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'cosa', '.', '</s>']
2025-05-27 19:31:18,779 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , si tr<unk> @ at<unk> @ ta di una cosa .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - Example #4
2025-05-27 19:31:18,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:31:18,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:31:18,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'succ@@', '<unk>', '@', 'ede', ',', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'delle', 'cose', 'che', '', 'una', 'delle', 'due', 'anni', '.', '</s>']
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa succ<unk> @ ede , vi mostr<unk> @ er<unk> @  una delle cose che  una delle due anni .
2025-05-27 19:31:22,184 - INFO - joeynmt.training - Epoch   4, Step:    26100, Batch Loss:     1.118849, Batch Acc: 0.689869, Tokens per Sec:    21254, Lr: 0.000300
2025-05-27 19:31:25,588 - INFO - joeynmt.training - Epoch   4, Step:    26200, Batch Loss:     0.974267, Batch Acc: 0.687538, Tokens per Sec:    23729, Lr: 0.000300
2025-05-27 19:31:28,977 - INFO - joeynmt.training - Epoch   4, Step:    26300, Batch Loss:     1.017440, Batch Acc: 0.687288, Tokens per Sec:    23286, Lr: 0.000300
2025-05-27 19:31:32,336 - INFO - joeynmt.training - Epoch   4, Step:    26400, Batch Loss:     1.052030, Batch Acc: 0.689610, Tokens per Sec:    23532, Lr: 0.000300
2025-05-27 19:31:35,710 - INFO - joeynmt.training - Epoch   4, Step:    26500, Batch Loss:     1.143665, Batch Acc: 0.690406, Tokens per Sec:    24135, Lr: 0.000300
2025-05-27 19:31:35,710 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:31:35,710 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:31:50,924 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.09, ppl:   2.96, acc:   0.69, generation: 15.2010[sec], evaluation: 0.0000[sec]
2025-05-27 19:31:50,925 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:31:51,504 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/24000.ckpt
2025-05-27 19:31:51,529 - INFO - joeynmt.training - Example #0
2025-05-27 19:31:51,530 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:31:51,530 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:31:51,530 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In@@', '<unk>', '@', 'fine', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'per', 'c@@', '<unk>', '@', 'ento', 'che', 'i', 'si@@', '<unk>', '@', 'ano', 'st@@', '<unk>', '@', 'at@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ali', 'che', 'i', 'si@@', '<unk>', '@', 'ano', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'in@@', '<unk>', '@', 'gu@@', '<unk>', '@', 'e', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'la', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'v@@', '<unk>', '@', 'azione', '.', '</s>']
2025-05-27 19:31:51,531 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:31:51,531 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:31:51,531 - INFO - joeynmt.training - 	Hypothesis: In<unk> @ fine , ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o , per c<unk> @ ento per c<unk> @ ento che i si<unk> @ ano st<unk> @ at<unk> @ or<unk> @ ali che i si<unk> @ ano di<unk> @ st<unk> @ in<unk> @ gu<unk> @ e per c<unk> @ ento di tre milioni di anni , per la m<unk> @ oti<unk> @ v<unk> @ azione .
2025-05-27 19:31:51,531 - INFO - joeynmt.training - Example #1
2025-05-27 19:31:51,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:31:51,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:31:51,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'stato', 'un', 'po', '&apos;', 'di', 'qu@@', '<unk>', '@', 'ell&apos;', 'in@@', '<unk>', '@', 'tr@@', '<unk>', '@', 'op@@', '<unk>', '@', 'po', ',', 'la', 'ver@@', '<unk>', '@', 'it', 'di', 'questa', 'con@@', '<unk>', '@', 'n@@', '<unk>', '@', 'es@@', '<unk>', '@', 'it', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'i@@', '<unk>', '@', 'di@@', '<unk>', '@', 'o', 'del', 'gen@@', '<unk>', '@', 'ere', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 19:31:51,532 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:31:51,532 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:31:51,532 - INFO - joeynmt.training - 	Hypothesis: Ma non  stato un po &apos; di qu<unk> @ ell&apos; in<unk> @ tr<unk> @ op<unk> @ po , la ver<unk> @ it di questa con<unk> @ n<unk> @ es<unk> @ it , non  il D<unk> @ ic<unk> @ i<unk> @ di<unk> @ o del gen<unk> @ ere , non  il D<unk> @ ic<unk> @ io .
2025-05-27 19:31:51,532 - INFO - joeynmt.training - Example #2
2025-05-27 19:31:51,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:31:51,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:31:51,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 's@@', '<unk>', '@', 'perim@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:31:51,533 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:31:51,533 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:31:51,533 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la s<unk> @ perim<unk> @ ent<unk> @ azione  la c<unk> @ li<unk> @ sta del nostro sistema glob<unk> @ ale del nostro sistema glob<unk> @ ale glob<unk> @ ale del nostro sistema glob<unk> @ ale .
2025-05-27 19:31:51,533 - INFO - joeynmt.training - Example #3
2025-05-27 19:31:51,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:31:51,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:31:51,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ebbe', 'la', 's@@', '<unk>', '@', 'edi@@', '<unk>', '@', 'a', 'e', 'la', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:31:51,534 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:31:51,534 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:31:51,534 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ ebbe la s<unk> @ edi<unk> @ a e la s<unk> @ om<unk> @ ma .
2025-05-27 19:31:51,534 - INFO - joeynmt.training - Example #4
2025-05-27 19:31:51,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:31:51,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:31:51,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'la', 'mia', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'delle', 'cose', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', 'l&apos;', 'ulti@@', '<unk>', '@', 'mo', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:31:51,535 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:31:51,535 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:31:51,535 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o la mia cosa che vi mostr<unk> @ o  una delle cose che  succ<unk> @ esso in cui l&apos; ulti<unk> @ mo , che  succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:31:54,921 - INFO - joeynmt.training - Epoch   4, Step:    26600, Batch Loss:     1.065560, Batch Acc: 0.691241, Tokens per Sec:    20322, Lr: 0.000300
2025-05-27 19:31:58,244 - INFO - joeynmt.training - Epoch   4, Step:    26700, Batch Loss:     1.175195, Batch Acc: 0.689104, Tokens per Sec:    23697, Lr: 0.000300
2025-05-27 19:32:01,576 - INFO - joeynmt.training - Epoch   4, Step:    26800, Batch Loss:     0.997862, Batch Acc: 0.687696, Tokens per Sec:    24275, Lr: 0.000300
2025-05-27 19:32:04,932 - INFO - joeynmt.training - Epoch   4, Step:    26900, Batch Loss:     1.075265, Batch Acc: 0.688119, Tokens per Sec:    23660, Lr: 0.000300
2025-05-27 19:32:08,235 - INFO - joeynmt.training - Epoch   4, Step:    27000, Batch Loss:     1.029179, Batch Acc: 0.690199, Tokens per Sec:    24099, Lr: 0.000300
2025-05-27 19:32:08,235 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:32:08,235 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:32:24,063 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.09, ppl:   2.96, acc:   0.69, generation: 15.8153[sec], evaluation: 0.0000[sec]
2025-05-27 19:32:24,064 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:32:24,577 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/24500.ckpt
2025-05-27 19:32:24,601 - INFO - joeynmt.training - Example #0
2025-05-27 19:32:24,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:32:24,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:32:24,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'b@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', 'i', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', 'tre', 'anni', ',', 'per', 'la', 'b@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ag@@', '<unk>', '@', 'lia', ',', 'per', 'i', 'tre', 'anni', ',', 'per', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'del', '4@@', '<unk>', '@', '0', '%', 'di', 'questi', 'tre', 'anni', ',', 'per', 'la', 'maggi@@', '<unk>', '@', 'or', 'parte', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:32:24,602 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:32:24,602 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:32:24,602 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa sc<unk> @ or<unk> @ sa che ho mostr<unk> @ ato per ri<unk> @ dur<unk> @ re la b<unk> @ or<unk> @ sa che i c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , per i tre anni , per la b<unk> @ att<unk> @ ag<unk> @ lia , per i tre anni , per la maggi<unk> @ or parte del 4<unk> @ 0 % di questi tre anni , per la maggi<unk> @ or parte del 4<unk> @ 0 % .
2025-05-27 19:32:24,602 - INFO - joeynmt.training - Example #1
2025-05-27 19:32:24,603 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:32:24,603 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:32:24,603 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'stato', 'un', 'problema', '.', '</s>']
2025-05-27 19:32:24,603 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:32:24,603 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:32:24,604 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  stato un problema .
2025-05-27 19:32:24,604 - INFO - joeynmt.training - Example #2
2025-05-27 19:32:24,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:32:24,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:32:24,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'del', 'nostro', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:32:24,604 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ itu<unk> @ azione  la c<unk> @ aus<unk> @ a  la c<unk> @ aus<unk> @ a del nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - Example #3
2025-05-27 19:32:24,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:32:24,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:32:24,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'in', 'v@@', '<unk>', '@', 'ento', 'e', 'la', 'b@@', '<unk>', '@', 'ell@@', '<unk>', '@', 'issi@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in v<unk> @ ento e la b<unk> @ ell<unk> @ issi<unk> @ ma .
2025-05-27 19:32:24,606 - INFO - joeynmt.training - Example #4
2025-05-27 19:32:24,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:32:24,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:32:24,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'el@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ta', 'che', '', 'una', 'c@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'ta', 'in', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', '.', '</s>']
2025-05-27 19:32:24,606 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:32:24,606 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:32:24,606 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una c<unk> @ el<unk> @ et<unk> @ ta che  una c<unk> @ r<unk> @ ot<unk> @ ta in sc<unk> @ or<unk> @ so .
2025-05-27 19:32:28,004 - INFO - joeynmt.training - Epoch   4, Step:    27100, Batch Loss:     0.985654, Batch Acc: 0.687564, Tokens per Sec:    20220, Lr: 0.000300
2025-05-27 19:32:31,294 - INFO - joeynmt.training - Epoch   4, Step:    27200, Batch Loss:     1.050802, Batch Acc: 0.693522, Tokens per Sec:    24360, Lr: 0.000300
2025-05-27 19:32:34,612 - INFO - joeynmt.training - Epoch   4, Step:    27300, Batch Loss:     1.008321, Batch Acc: 0.689137, Tokens per Sec:    24354, Lr: 0.000300
2025-05-27 19:32:37,924 - INFO - joeynmt.training - Epoch   4, Step:    27400, Batch Loss:     1.027371, Batch Acc: 0.690849, Tokens per Sec:    23757, Lr: 0.000300
2025-05-27 19:32:41,286 - INFO - joeynmt.training - Epoch   4, Step:    27500, Batch Loss:     1.095005, Batch Acc: 0.689751, Tokens per Sec:    23183, Lr: 0.000300
2025-05-27 19:32:41,286 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:32:41,286 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:32:54,349 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.08, ppl:   2.95, acc:   0.69, generation: 13.0539[sec], evaluation: 0.0000[sec]
2025-05-27 19:32:54,349 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:32:54,832 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/25000.ckpt
2025-05-27 19:32:54,856 - INFO - joeynmt.training - Example #0
2025-05-27 19:32:54,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:32:54,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:32:54,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'milioni', 'di', 'persone', 'che', 'hanno', 'mostr@@', '<unk>', '@', 'ato', 'per', 'la', 'f@@', '<unk>', '@', 'av@@', '<unk>', '@', 'e', 'per', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'elli', 'che', 'hanno', 'in@@', '<unk>', '@', 'segn@@', '<unk>', '@', 'ato', 'per', 'i', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'elli', 'che', 'hanno', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '8', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'anni', '.', '</s>']
2025-05-27 19:32:54,857 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:32:54,857 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:32:54,857 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due milioni di persone che hanno mostr<unk> @ ato per la f<unk> @ av<unk> @ e per la c<unk> @ aus<unk> @ a di tre mili<unk> @ ar<unk> @ elli che hanno in<unk> @ segn<unk> @ ato per i tre mili<unk> @ ar<unk> @ elli che hanno fatto per il 4<unk> @ 8 mili<unk> @ ar<unk> @ di di di di di di di di anni .
2025-05-27 19:32:54,857 - INFO - joeynmt.training - Example #1
2025-05-27 19:32:54,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:32:54,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:32:54,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'stato', 'il', 'punto', 'di', 'vi@@', '<unk>', '@', 'sta', ',', 'non', '', 'stato', 'stato', 'stato', 'il', 'ter@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ine', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'che', '', 'il', 'ter@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ine', '.', '</s>']
2025-05-27 19:32:54,858 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:32:54,858 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:32:54,858 - INFO - joeynmt.training - 	Hypothesis: Ma non  stato il punto di vi<unk> @ sta , non  stato stato stato il ter<unk> @ m<unk> @ ine di questo problema , non  il che  il ter<unk> @ m<unk> @ ine .
2025-05-27 19:32:54,858 - INFO - joeynmt.training - Example #2
2025-05-27 19:32:54,859 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:32:54,859 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:32:54,859 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 'cosa', '', 'il', 'nostro', 'sistema', 'di', 'em@@', '<unk>', '@', 'er@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ere', 'il', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:32:54,859 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:32:54,859 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:32:54,859 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la cosa  il nostro sistema di em<unk> @ er<unk> @ g<unk> @ ri<unk> @ g<unk> @ ere il nostro sistema glob<unk> @ ale .
2025-05-27 19:32:54,859 - INFO - joeynmt.training - Example #3
2025-05-27 19:32:54,859 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:32:54,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:32:54,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ri@@', '<unk>', '@', 've', ',', 'e', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'in', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:32:54,860 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:32:54,860 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:32:54,860 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ c<unk> @ ri<unk> @ ve , e si tr<unk> @ at<unk> @ ta in s<unk> @ om<unk> @ ma .
2025-05-27 19:32:54,860 - INFO - joeynmt.training - Example #4
2025-05-27 19:32:54,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:32:54,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:32:54,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'f@@', '<unk>', '@', 'ar', 'vedere', 'la', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', '', 'una', 'cell@@', '<unk>', '@', 'u@@', '<unk>', '@', 'la', ',', '', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:32:54,861 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:32:54,861 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:32:54,861 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo f<unk> @ ar vedere la cosa che vi mostr<unk> @ a  una cell<unk> @ u<unk> @ la ,  che  succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:32:58,207 - INFO - joeynmt.training - Epoch   4, Step:    27600, Batch Loss:     1.062792, Batch Acc: 0.688821, Tokens per Sec:    20510, Lr: 0.000300
2025-05-27 19:33:01,602 - INFO - joeynmt.training - Epoch   4, Step:    27700, Batch Loss:     1.075925, Batch Acc: 0.686993, Tokens per Sec:    23732, Lr: 0.000300
2025-05-27 19:33:04,946 - INFO - joeynmt.training - Epoch   4, Step:    27800, Batch Loss:     1.228719, Batch Acc: 0.688935, Tokens per Sec:    23380, Lr: 0.000300
2025-05-27 19:33:08,331 - INFO - joeynmt.training - Epoch   4, Step:    27900, Batch Loss:     1.025400, Batch Acc: 0.687964, Tokens per Sec:    24017, Lr: 0.000300
2025-05-27 19:33:11,694 - INFO - joeynmt.training - Epoch   4, Step:    28000, Batch Loss:     1.047979, Batch Acc: 0.691640, Tokens per Sec:    23753, Lr: 0.000300
2025-05-27 19:33:11,694 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:33:11,694 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:33:24,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.08, ppl:   2.93, acc:   0.69, generation: 12.8677[sec], evaluation: 0.0000[sec]
2025-05-27 19:33:24,571 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:33:25,043 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/25500.ckpt
2025-05-27 19:33:25,067 - INFO - joeynmt.training - Example #0
2025-05-27 19:33:25,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:33:25,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:33:25,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'il', 'che', 'il', '4@@', '<unk>', '@', '0', '%', 'delle', 'em@@', '<unk>', '@', 'is@@', '<unk>', '@', 'c@@', '<unk>', '@', 'k@@', '<unk>', '@', 'ing', ',', 'per', 'i', 'tre', 'anni', ',', 'per', 'le', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'delle', 'persone', 'che', 'hanno', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'delle', 'persone', 'che', 'hanno', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'delle', 'persone', '.', '</s>']
2025-05-27 19:33:25,069 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:33:25,069 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:33:25,069 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , per il che il 4<unk> @ 0 % delle em<unk> @ is<unk> @ c<unk> @ k<unk> @ ing , per i tre anni , per le persone che hanno sc<unk> @ oper<unk> @ to per il 4<unk> @ 0 % delle persone che hanno fatto per il 4<unk> @ 0 % delle persone che hanno fatto per il 4<unk> @ 0 % delle persone .
2025-05-27 19:33:25,069 - INFO - joeynmt.training - Example #1
2025-05-27 19:33:25,069 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:33:25,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:33:25,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'fatto', '', 'il', 'ter@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ine', 'di', 'questo', 'problema', ',', 'il', 'che', 'non', '', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questo', 'probl@@', '<unk>', '@', 'emi', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:33:25,070 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:33:25,070 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:33:25,070 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il fatto  il ter<unk> @ m<unk> @ ine di questo problema , il che non  il ris<unk> @ ult<unk> @ ato di questo probl<unk> @ emi , non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:33:25,070 - INFO - joeynmt.training - Example #2
2025-05-27 19:33:25,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:33:25,070 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:33:25,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'il', 'nostro', 'sistema', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'c@@', '<unk>', '@', 'uno', 'dei', 'nostri', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'c@@', '<unk>', '@', 'uno', 'dei', 'nostri', 'sist@@', '<unk>', '@', 'emi', 'glob@@', '<unk>', '@', 'ali', '.', '</s>']
2025-05-27 19:33:25,071 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:33:25,071 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:33:25,071 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , il nostro sistema  la c<unk> @ li<unk> @ m<unk> @ as<unk> @ c<unk> @ uno dei nostri c<unk> @ li<unk> @ m<unk> @ as<unk> @ c<unk> @ uno dei nostri sist<unk> @ emi glob<unk> @ ali .
2025-05-27 19:33:25,071 - INFO - joeynmt.training - Example #3
2025-05-27 19:33:25,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:33:25,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:33:25,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&apos;', 'la', 'cosa', 'cosa', 'cosa', 'che', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', 'e', 'e', 'in', 'l@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ter@@', '<unk>', '@', 'almente', '.', '</s>']
2025-05-27 19:33:25,072 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:33:25,072 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:33:25,072 - INFO - joeynmt.training - 	Hypothesis: E &apos; la cosa cosa cosa che si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ p<unk> @ e e e in l<unk> @ et<unk> @ ter<unk> @ almente .
2025-05-27 19:33:25,072 - INFO - joeynmt.training - Example #4
2025-05-27 19:33:25,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:33:25,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:33:25,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'tel@@', '<unk>', '@', 'e@@', '<unk>', '@', 'fon@@', '<unk>', '@', 'do', ',', '', 'una', 'cell@@', '<unk>', '@', 'u@@', '<unk>', '@', 'la', '', 'una', 'cell@@', '<unk>', '@', 'u@@', '<unk>', '@', 'la', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:33:25,073 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:33:25,073 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:33:25,073 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo tel<unk> @ e<unk> @ fon<unk> @ do ,  una cell<unk> @ u<unk> @ la  una cell<unk> @ u<unk> @ la , che  succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:33:28,444 - INFO - joeynmt.training - Epoch   4, Step:    28100, Batch Loss:     1.050522, Batch Acc: 0.688771, Tokens per Sec:    20423, Lr: 0.000300
2025-05-27 19:33:31,810 - INFO - joeynmt.training - Epoch   4, Step:    28200, Batch Loss:     1.110902, Batch Acc: 0.683956, Tokens per Sec:    24119, Lr: 0.000300
2025-05-27 19:33:35,178 - INFO - joeynmt.training - Epoch   4, Step:    28300, Batch Loss:     1.047236, Batch Acc: 0.690302, Tokens per Sec:    23060, Lr: 0.000300
2025-05-27 19:33:38,528 - INFO - joeynmt.training - Epoch   4, Step:    28400, Batch Loss:     1.023646, Batch Acc: 0.687503, Tokens per Sec:    23809, Lr: 0.000300
2025-05-27 19:33:41,904 - INFO - joeynmt.training - Epoch   4, Step:    28500, Batch Loss:     1.117275, Batch Acc: 0.690655, Tokens per Sec:    23239, Lr: 0.000300
2025-05-27 19:33:41,904 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:33:41,904 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:33:57,483 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.93, acc:   0.69, generation: 15.5703[sec], evaluation: 0.0000[sec]
2025-05-27 19:33:57,483 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:33:57,984 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/26000.ckpt
2025-05-27 19:33:58,003 - INFO - joeynmt.training - Example #0
2025-05-27 19:33:58,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:33:58,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:33:58,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'due', 'milioni', 'di', 'persone', 'che', 'hanno', 'mostr@@', '<unk>', '@', 'ato', 'per', 'ri@@', '<unk>', '@', 'port@@', '<unk>', '@', 'are', 'le', 'em@@', '<unk>', '@', 'o@@', '<unk>', '@', 'zioni', 'che', 'le', 'em@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'i@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', 'che', 'hanno', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'esso', 'di', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'esso', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'sc@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'amente', ',', '', 'stato', 'sc@@', '<unk>', '@', 'rit@@', '<unk>', '@', 'to', '.', '</s>']
2025-05-27 19:33:58,004 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:33:58,004 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:33:58,004 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due due milioni di persone che hanno mostr<unk> @ ato per ri<unk> @ port<unk> @ are le em<unk> @ o<unk> @ zioni che le em<unk> @ ic<unk> @ i<unk> @ p<unk> @ e che hanno ri<unk> @ m<unk> @ esso di tre milioni di persone che hanno ri<unk> @ m<unk> @ esso , per il 4<unk> @ 8 milioni di persone che av<unk> @ evano sc<unk> @ ar<unk> @ ic<unk> @ amente ,  stato sc<unk> @ rit<unk> @ to .
2025-05-27 19:33:58,004 - INFO - joeynmt.training - Example #1
2025-05-27 19:33:58,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:33:58,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:33:58,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'stato', 'il', 'fatto', '', 'stato', 'in@@', '<unk>', '@', 'tor@@', '<unk>', '@', 'no', 'a', 'questo', 'problema', ',', 'la', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'u@@', '<unk>', '@', 'zione', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:33:58,005 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:33:58,005 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:33:58,005 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  stato il fatto  stato in<unk> @ tor<unk> @ no a questo problema , la ris<unk> @ ol<unk> @ u<unk> @ zione di questo problema , non  il d<unk> @ ott<unk> @ ore , non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:33:58,005 - INFO - joeynmt.training - Example #2
2025-05-27 19:33:58,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:33:58,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:33:58,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', '', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'un', 'sistema', 'di', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', 'di', 'un', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:33:58,006 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:33:58,006 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:33:58,006 - INFO - joeynmt.training - 	Hypothesis: In realt ,  la s<unk> @ fi<unk> @ da  la c<unk> @ aus<unk> @ a di un sistema di in<unk> @ ten<unk> @ zione di un sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:33:58,006 - INFO - joeynmt.training - Example #3
2025-05-27 19:33:58,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:33:58,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:33:58,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ta', 'tor@@', '<unk>', '@', 'n@@', '<unk>', '@', 'ando', 'a', 'W@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', 'e', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:33:58,007 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:33:58,007 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:33:58,007 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta tor<unk> @ n<unk> @ ando a W<unk> @ in<unk> @ ter e s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:33:58,007 - INFO - joeynmt.training - Example #4
2025-05-27 19:33:58,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:33:58,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:33:58,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'u', 'una', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'in', 'cui', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', '', 'succ@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 19:33:58,008 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:33:58,008 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:33:58,008 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ u una cosa che vi mostr<unk> @ a  una c<unk> @ aus<unk> @ a di quello che succ<unk> @ ede in cui  succ<unk> @ esso in cui  succ<unk> @ esso .
2025-05-27 19:34:01,319 - INFO - joeynmt.training - Epoch   4, Step:    28600, Batch Loss:     0.971825, Batch Acc: 0.692850, Tokens per Sec:    20610, Lr: 0.000300
2025-05-27 19:34:04,607 - INFO - joeynmt.training - Epoch   4, Step:    28700, Batch Loss:     1.151960, Batch Acc: 0.688212, Tokens per Sec:    23967, Lr: 0.000300
2025-05-27 19:34:07,922 - INFO - joeynmt.training - Epoch   4, Step:    28800, Batch Loss:     1.003408, Batch Acc: 0.689759, Tokens per Sec:    24176, Lr: 0.000300
2025-05-27 19:34:11,213 - INFO - joeynmt.training - Epoch   4, Step:    28900, Batch Loss:     1.121118, Batch Acc: 0.690049, Tokens per Sec:    24414, Lr: 0.000300
2025-05-27 19:34:14,443 - INFO - joeynmt.training - Epoch   4, Step:    29000, Batch Loss:     1.092637, Batch Acc: 0.688628, Tokens per Sec:    24774, Lr: 0.000300
2025-05-27 19:34:14,443 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:34:14,443 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:34:30,279 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.08, ppl:   2.93, acc:   0.69, generation: 15.8222[sec], evaluation: 0.0000[sec]
2025-05-27 19:34:30,614 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/26500.ckpt
2025-05-27 19:34:30,634 - INFO - joeynmt.training - Example #0
2025-05-27 19:34:30,635 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:34:30,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:34:30,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'due', 'due', 'due', 'due', 'anni', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'cui', 'la', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', ',', 'per', 'le', 'em@@', '<unk>', '@', 'o@@', '<unk>', '@', 'zioni', 'che', 'hanno', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'ato', 'che', 'le', 'em@@', '<unk>', '@', 'issi@@', '<unk>', '@', 'oni', 'che', 'hanno', 'fatto', 'per', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'anni', ',', 'aveva', 'tre', 'mili@@', 'mili@@', 'mili@@', 'mili@@', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evano', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', '', 'stato', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', '.', '</s>']
2025-05-27 19:34:30,636 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:34:30,636 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:34:30,636 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questi due due due due due anni , ho mostr<unk> @ ato questa fot<unk> @ o , per cui la f<unk> @ am<unk> @ ig<unk> @ lia , per le em<unk> @ o<unk> @ zioni che hanno di<unk> @ mostr<unk> @ ato che le em<unk> @ issi<unk> @ oni che hanno fatto per tre mili<unk> @ ar<unk> @ di di di anni , aveva tre milimilimilimilimili<unk> @ ar<unk> @ di di di persone che av<unk> @ evano sc<unk> @ oper<unk> @ to  stato sc<unk> @ oper<unk> @ to .
2025-05-27 19:34:30,636 - INFO - joeynmt.training - Example #1
2025-05-27 19:34:30,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:34:30,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:34:30,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'stato', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', 'di', 'questo', 'problema', ',', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', ',', 'non', '', 'il', 'problema', 'di', 'questo', 'problema', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'en@@', '<unk>', '@', 'om@@', '<unk>', '@', 'en@@', '<unk>', '@', 'o', 'non', '', 'il', 'd@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'olo', '.', '</s>']
2025-05-27 19:34:30,637 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:34:30,637 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:34:30,637 - INFO - joeynmt.training - 	Hypothesis: Ma non  stato in<unk> @ ten<unk> @ zione di questo problema , la ris<unk> @ post<unk> @ a , non  il problema di questo problema di in<unk> @ f<unk> @ en<unk> @ om<unk> @ en<unk> @ o non  il d<unk> @ ic<unk> @ olo .
2025-05-27 19:34:30,637 - INFO - joeynmt.training - Example #2
2025-05-27 19:34:30,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:34:30,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:34:30,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', 'la', 'sci@@', '<unk>', '@', 'enza', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ev@@', '<unk>', '@', 'ole', ',', 'il', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:34:30,638 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:34:30,638 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:34:30,638 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt , la sci<unk> @ enza  la c<unk> @ aus<unk> @ a di E<unk> @ is<unk> @ k<unk> @ p<unk> @ ev<unk> @ ole , il nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:34:30,638 - INFO - joeynmt.training - Example #3
2025-05-27 19:34:30,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:34:30,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:34:30,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'e', 'la', 'p@@', '<unk>', '@', 'elle', ',', 'e', 'si', '', 's@@', '<unk>', '@', 'otto', 'in', 'un', 'm@@', '<unk>', '@', 'ess@@', '<unk>', '@', 'aggio', '.', '</s>']
2025-05-27 19:34:30,639 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:34:30,639 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:34:30,639 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , e la p<unk> @ elle , e si  s<unk> @ otto in un m<unk> @ ess<unk> @ aggio .
2025-05-27 19:34:30,639 - INFO - joeynmt.training - Example #4
2025-05-27 19:34:30,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:34:30,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:34:30,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'u', 'la', 'mia', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', '', 'una', 'c@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ita', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:34:30,639 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:34:30,640 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:34:30,640 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ u la mia f<unk> @ am<unk> @ ig<unk> @ lia  una c<unk> @ ent<unk> @ ita di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:34:34,028 - INFO - joeynmt.training - Epoch   4, Step:    29100, Batch Loss:     1.034914, Batch Acc: 0.690883, Tokens per Sec:    21420, Lr: 0.000300
2025-05-27 19:34:37,415 - INFO - joeynmt.training - Epoch   4, Step:    29200, Batch Loss:     1.115932, Batch Acc: 0.691926, Tokens per Sec:    23374, Lr: 0.000300
2025-05-27 19:34:40,811 - INFO - joeynmt.training - Epoch   4, Step:    29300, Batch Loss:     1.124428, Batch Acc: 0.689345, Tokens per Sec:    23015, Lr: 0.000300
2025-05-27 19:34:44,158 - INFO - joeynmt.training - Epoch   4, Step:    29400, Batch Loss:     1.040303, Batch Acc: 0.694116, Tokens per Sec:    23496, Lr: 0.000300
2025-05-27 19:34:47,516 - INFO - joeynmt.training - Epoch   4, Step:    29500, Batch Loss:     1.138913, Batch Acc: 0.692031, Tokens per Sec:    23791, Lr: 0.000300
2025-05-27 19:34:47,516 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:34:47,517 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:35:04,138 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.92, acc:   0.69, generation: 16.6086[sec], evaluation: 0.0000[sec]
2025-05-27 19:35:04,139 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:35:04,795 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/27000.ckpt
2025-05-27 19:35:04,820 - INFO - joeynmt.training - Example #0
2025-05-27 19:35:04,820 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:35:04,820 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:35:04,820 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'f@@', '<unk>', '@', 'en@@', '<unk>', '@', 'om@@', '<unk>', '@', 'enti', 'per', 'la', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', 'per', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'della', 'st@@', '<unk>', '@', 'a@@', '<unk>', '@', 'z@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:35:04,821 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:35:04,821 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:35:04,821 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so che ho mostr<unk> @ ato questi due f<unk> @ en<unk> @ om<unk> @ enti per la f<unk> @ am<unk> @ be per la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano tre mili<unk> @ ar<unk> @ di di di anni , il 4<unk> @ 8 per c<unk> @ ento , il 4<unk> @ 0 % della st<unk> @ a<unk> @ z<unk> @ o .
2025-05-27 19:35:04,821 - INFO - joeynmt.training - Example #1
2025-05-27 19:35:04,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:35:04,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:35:04,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'fatto', 'che', 'la', 'ver@@', '<unk>', '@', 'it', 'di', 'essere', 'in@@', '<unk>', '@', 't@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ito', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'olo', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'lo', '.', '</s>']
2025-05-27 19:35:04,822 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:35:04,822 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:35:04,822 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il fatto che la ver<unk> @ it di essere in<unk> @ t<unk> @ eg<unk> @ u<unk> @ ito , non  il D<unk> @ ic<unk> @ olo di questo problema , non  il D<unk> @ ic<unk> @ lo .
2025-05-27 19:35:04,822 - INFO - joeynmt.training - Example #2
2025-05-27 19:35:04,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:35:04,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:35:04,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'la', 's@@', '<unk>', '@', 'edi@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', 'di', 'un', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:35:04,823 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:35:04,823 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:35:04,823 - INFO - joeynmt.training - 	Hypothesis: In realt , la s<unk> @ edi<unk> @ a  la c<unk> @ aus<unk> @ a di in<unk> @ ten<unk> @ zione di un sistema glob<unk> @ ale glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:35:04,823 - INFO - joeynmt.training - Example #3
2025-05-27 19:35:04,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:35:04,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:35:04,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'azione', 'in', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:35:04,824 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:35:04,824 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:35:04,824 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e la p<unk> @ op<unk> @ ol<unk> @ azione in m<unk> @ ezz<unk> @ o .
2025-05-27 19:35:04,824 - INFO - joeynmt.training - Example #4
2025-05-27 19:35:04,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:35:04,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:35:04,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'la', 'prima', 'prima', 'prima', 'cosa', 'che', 'vi', '', 'succ@@', '<unk>', '@', 'esso', 'a', 'cui', 'ho', 'pres@@', '<unk>', '@', 'o', 'una', 'c@@', '<unk>', '@', 'op@@', '<unk>', '@', 'pi@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:35:04,825 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:35:04,825 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:35:04,825 - INFO - joeynmt.training - 	Hypothesis: La prima prima cosa che vi mostr<unk> @ o la prima prima prima cosa che vi  succ<unk> @ esso a cui ho pres<unk> @ o una c<unk> @ op<unk> @ pi<unk> @ a che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:35:08,205 - INFO - joeynmt.training - Epoch   4, Step:    29600, Batch Loss:     0.916321, Batch Acc: 0.695426, Tokens per Sec:    19240, Lr: 0.000300
2025-05-27 19:35:11,579 - INFO - joeynmt.training - Epoch   4, Step:    29700, Batch Loss:     1.014105, Batch Acc: 0.691278, Tokens per Sec:    23360, Lr: 0.000300
2025-05-27 19:35:14,940 - INFO - joeynmt.training - Epoch   4, Step:    29800, Batch Loss:     1.057276, Batch Acc: 0.693243, Tokens per Sec:    23504, Lr: 0.000300
2025-05-27 19:35:18,301 - INFO - joeynmt.training - Epoch   4, Step:    29900, Batch Loss:     1.080278, Batch Acc: 0.690309, Tokens per Sec:    22933, Lr: 0.000300
2025-05-27 19:35:21,656 - INFO - joeynmt.training - Epoch   4, Step:    30000, Batch Loss:     0.997013, Batch Acc: 0.692016, Tokens per Sec:    22787, Lr: 0.000300
2025-05-27 19:35:21,656 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:35:21,656 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:35:37,733 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.91, acc:   0.69, generation: 16.0642[sec], evaluation: 0.0000[sec]
2025-05-27 19:35:37,734 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:35:38,324 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/27500.ckpt
2025-05-27 19:35:38,349 - INFO - joeynmt.training - Example #0
2025-05-27 19:35:38,349 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:35:38,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:35:38,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'due', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'due', 'o', ',', 'per', 'us@@', '<unk>', '@', 'are', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'ia', 'per', 'la', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ica', 'che', 'le', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', 'per', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'anni', ',', 'per', 'la', '4@@', '<unk>', '@', '8', '%', 'dei', 'dati', 'che', 'av@@', '<unk>', '@', 'evano', '1@@', '<unk>', '@', '5', '%', 'dei', '4@@', '<unk>', '@', '8', '%', 'dei', '4@@', '<unk>', '@', '8', 'per@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:35:38,350 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:35:38,350 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:35:38,350 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questa due o , ho mostr<unk> @ ato questa due o , per us<unk> @ are la p<unk> @ op<unk> @ ol<unk> @ ia per la f<unk> @ am<unk> @ ig<unk> @ ica che le g<unk> @ am<unk> @ be per tre mili<unk> @ ar<unk> @ di di anni , per la 4<unk> @ 8 % dei dati che av<unk> @ evano 1<unk> @ 5 % dei 4<unk> @ 8 % dei 4<unk> @ 8 per<unk> @ c<unk> @ ento .
2025-05-27 19:35:38,350 - INFO - joeynmt.training - Example #1
2025-05-27 19:35:38,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:35:38,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:35:38,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'una', 'cosa', 'che', 'la', 'cosa', 'che', '', 'che', 'la', 'T@@', '<unk>', '@', 'erra', ',', 'la', 'cosa', 'che', 'non', 'si', 'chiam@@', '<unk>', '@', 'a', 'questa', 'cosa', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'ma', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:35:38,351 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:35:38,351 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:35:38,351 - INFO - joeynmt.training - 	Hypothesis: Ma non  una cosa che la cosa che  che la T<unk> @ erra , la cosa che non si chiam<unk> @ a questa cosa spe<unk> @ ci<unk> @ ale , ma non  il d<unk> @ ott<unk> @ ore di questo problema .
2025-05-27 19:35:38,351 - INFO - joeynmt.training - Example #2
2025-05-27 19:35:38,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:35:38,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:35:38,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', '', 'la', 'cosa', 'che', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'sistema', 'di', 'f@@', '<unk>', '@', 'ar', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:35:38,352 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:35:38,352 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:35:38,352 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt ,  la cosa che  la c<unk> @ li<unk> @ sta del sistema di f<unk> @ ar c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a della nostra c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 19:35:38,352 - INFO - joeynmt.training - Example #3
2025-05-27 19:35:38,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:35:38,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:35:38,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'e', 'si', 'trov@@', '<unk>', '@', 'a', 'a', 'a', 'a', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:35:38,353 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:35:38,353 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:35:38,353 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , e si trov<unk> @ a a a a s<unk> @ om<unk> @ br<unk> @ a .
2025-05-27 19:35:38,353 - INFO - joeynmt.training - Example #4
2025-05-27 19:35:38,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:35:38,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:35:38,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'vi', 'mostr@@', '<unk>', '@', 'o', 'la', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:35:38,354 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:35:38,354 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:35:38,354 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa vi mostr<unk> @ o la cosa che vi mostr<unk> @ a  una c<unk> @ aus<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:35:41,756 - INFO - joeynmt.training - Epoch   4, Step:    30100, Batch Loss:     1.070397, Batch Acc: 0.690314, Tokens per Sec:    20351, Lr: 0.000300
2025-05-27 19:35:45,123 - INFO - joeynmt.training - Epoch   4, Step:    30200, Batch Loss:     1.029934, Batch Acc: 0.692770, Tokens per Sec:    23123, Lr: 0.000300
2025-05-27 19:35:48,431 - INFO - joeynmt.training - Epoch   4, Step:    30300, Batch Loss:     1.068291, Batch Acc: 0.692823, Tokens per Sec:    22747, Lr: 0.000300
2025-05-27 19:35:51,831 - INFO - joeynmt.training - Epoch   4, Step:    30400, Batch Loss:     1.085493, Batch Acc: 0.693905, Tokens per Sec:    23483, Lr: 0.000300
2025-05-27 19:35:55,200 - INFO - joeynmt.training - Epoch   4, Step:    30500, Batch Loss:     1.003633, Batch Acc: 0.692400, Tokens per Sec:    22890, Lr: 0.000300
2025-05-27 19:35:55,201 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:35:55,201 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:36:09,352 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.90, acc:   0.69, generation: 14.1425[sec], evaluation: 0.0000[sec]
2025-05-27 19:36:09,353 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:36:09,977 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/28000.ckpt
2025-05-27 19:36:09,994 - INFO - joeynmt.training - Example #0
2025-05-27 19:36:09,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:36:09,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:36:09,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'due', 'due', 'f@@', '<unk>', '@', 'ami@@', '<unk>', '@', 'gl@@', '<unk>', '@', 'ie', 'per', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'ia', ',', 'per', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ici', ',', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'la', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'la', '4@@', '<unk>', '@', '8', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', '4@@', '<unk>', '@', '8', '%', 'della', '4@@', '<unk>', '@', '0', '%', 'di', '4@@', '<unk>', '@', '8', '%', 'di', 'questi', 'due', 'per@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:36:09,995 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:36:09,995 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:36:09,995 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due due due f<unk> @ ami<unk> @ gl<unk> @ ie per la p<unk> @ op<unk> @ ol<unk> @ ia , per la c<unk> @ aus<unk> @ a di tre mili<unk> @ ar<unk> @ t<unk> @ ici , per i 4<unk> @ 8 milioni di anni , per la 4<unk> @ 8 milioni di anni , per la 4<unk> @ 8 , per c<unk> @ ento di 4<unk> @ 8 % della 4<unk> @ 0 % di 4<unk> @ 8 % di questi due per<unk> @ c<unk> @ ento .
2025-05-27 19:36:09,995 - INFO - joeynmt.training - Example #1
2025-05-27 19:36:09,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:36:09,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:36:09,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'molto', 'diff@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ile', ',', 'non', '', 'la', 'cap@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'it', 'di', 'questa', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', ',', 'non', '', 'il', 'problema', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'is@@', '<unk>', '@', 'es', 'non', '', 'il', 'd@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:36:09,996 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:36:09,996 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:36:09,996 - INFO - joeynmt.training - 	Hypothesis: Ma non  molto diff<unk> @ ic<unk> @ ile , non  la cap<unk> @ ac<unk> @ it di questa s<unk> @ itu<unk> @ azione , non  il problema di E<unk> @ is<unk> @ is<unk> @ es non  il d<unk> @ ot<unk> @ o .
2025-05-27 19:36:09,996 - INFO - joeynmt.training - Example #2
2025-05-27 19:36:09,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:36:09,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:36:09,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sen@@', '<unk>', '@', 'so', 'di', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ma', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mit@@', '<unk>', '@', 'ata', 'del', 'nostro', 'cu@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'so', '.', '</s>']
2025-05-27 19:36:09,997 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:36:09,997 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:36:09,997 - INFO - joeynmt.training - 	Hypothesis: In un sen<unk> @ so di s<unk> @ om<unk> @ ma  la c<unk> @ li<unk> @ sta  la c<unk> @ li<unk> @ mit<unk> @ ata del nostro cu<unk> @ ore c<unk> @ li<unk> @ m<unk> @ as<unk> @ so .
2025-05-27 19:36:09,997 - INFO - joeynmt.training - Example #3
2025-05-27 19:36:09,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:36:09,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:36:09,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'per@@', '<unk>', '@', 'a', 'e', 'si', 'trov@@', '<unk>', '@', 'a', 'in', 'v@@', '<unk>', '@', 'ento', 'e', 'si', '', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:36:09,998 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:36:09,998 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:36:09,998 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ per<unk> @ a e si trov<unk> @ a in v<unk> @ ento e si  s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:36:09,998 - INFO - joeynmt.training - Example #4
2025-05-27 19:36:09,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:36:09,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:36:09,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'ura', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:36:09,999 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:36:09,999 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:36:09,999 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ er<unk> @   una c<unk> @ ura che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:36:13,332 - INFO - joeynmt.training - Epoch   4, Step:    30600, Batch Loss:     1.087756, Batch Acc: 0.693993, Tokens per Sec:    20279, Lr: 0.000300
2025-05-27 19:36:16,688 - INFO - joeynmt.training - Epoch   4, Step:    30700, Batch Loss:     1.046287, Batch Acc: 0.695015, Tokens per Sec:    23687, Lr: 0.000300
2025-05-27 19:36:20,058 - INFO - joeynmt.training - Epoch   4, Step:    30800, Batch Loss:     1.170797, Batch Acc: 0.694960, Tokens per Sec:    23688, Lr: 0.000300
2025-05-27 19:36:23,475 - INFO - joeynmt.training - Epoch   4, Step:    30900, Batch Loss:     1.016402, Batch Acc: 0.695780, Tokens per Sec:    23958, Lr: 0.000300
2025-05-27 19:36:26,864 - INFO - joeynmt.training - Epoch   4, Step:    31000, Batch Loss:     1.067988, Batch Acc: 0.692140, Tokens per Sec:    24148, Lr: 0.000300
2025-05-27 19:36:26,864 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:36:26,864 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:36:39,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.06, ppl:   2.88, acc:   0.69, generation: 12.8438[sec], evaluation: 0.0000[sec]
2025-05-27 19:36:39,717 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:36:40,185 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/29000.ckpt
2025-05-27 19:36:40,203 - INFO - joeynmt.training - Example #0
2025-05-27 19:36:40,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:36:40,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:36:40,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'per', 'con@@', '<unk>', '@', 'to', 'che', 'i', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'c@@', '<unk>', '@', 'enti', 'per', 'i', 'con@@', '<unk>', '@', 'to', 'che', 'i', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'ni', 'per', 'i', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'i', 'due', 'milioni', 'di', 'anni', ',', 'per', 'i', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'i', 'due', 'milioni', 'di', 'anni', ',', 'i', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'qu@@', '<unk>', '@', 'ei', '4@@', '<unk>', '@', '8', '%', 'di', 'qu@@', '<unk>', '@', 'ei', '4@@', '<unk>', '@', '8', '%', 'di', 'qu@@', '<unk>', '@', 'ei', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:36:40,205 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:36:40,205 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:36:40,205 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per con<unk> @ to che i p<unk> @ es<unk> @ c<unk> @ enti per i con<unk> @ to che i g<unk> @ over<unk> @ ni per i m<unk> @ oti<unk> @ vi per i due milioni di anni , per i m<unk> @ oti<unk> @ vi per i due milioni di anni , i m<unk> @ oti<unk> @ vi per c<unk> @ ento di qu<unk> @ ei 4<unk> @ 8 % di qu<unk> @ ei 4<unk> @ 8 % di qu<unk> @ ei 4<unk> @ 8 % .
2025-05-27 19:36:40,205 - INFO - joeynmt.training - Example #1
2025-05-27 19:36:40,205 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:36:40,205 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:36:40,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'stato', 'un', 'po', '&apos;', 'di', 'pi', 'diff@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ile', 'per', 'la', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', 'probl@@', '<unk>', '@', 'emi', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ali', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'ti@@', '<unk>', '@', 'm@@', '<unk>', '@', 'enti', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'es', '.', '</s>']
2025-05-27 19:36:40,206 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:36:40,206 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:36:40,206 - INFO - joeynmt.training - 	Hypothesis: Ma non  stato un po &apos; di pi diff<unk> @ ic<unk> @ ile per la ris<unk> @ ol<unk> @ vere probl<unk> @ emi spe<unk> @ ci<unk> @ ali , non  il d<unk> @ ot<unk> @ ti<unk> @ m<unk> @ enti di E<unk> @ is<unk> @ es .
2025-05-27 19:36:40,206 - INFO - joeynmt.training - Example #2
2025-05-27 19:36:40,206 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:36:40,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:36:40,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'un', 'sen@@', '<unk>', '@', 'so', 'di', 'ci@@', '<unk>', '@', 'ma', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'mo', '.', '</s>']
2025-05-27 19:36:40,207 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:36:40,207 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:36:40,207 - INFO - joeynmt.training - 	Hypothesis: In realt , in un sen<unk> @ so di ci<unk> @ ma la s<unk> @ itu<unk> @ azione  la c<unk> @ li<unk> @ sta del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ mo .
2025-05-27 19:36:40,207 - INFO - joeynmt.training - Example #3
2025-05-27 19:36:40,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:36:40,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:36:40,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'si', '', 's@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ito', 'a', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:36:40,208 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:36:40,208 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:36:40,208 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , si  s<unk> @ ent<unk> @ ito a s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:36:40,208 - INFO - joeynmt.training - Example #4
2025-05-27 19:36:40,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:36:40,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:36:40,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'da', 'di', 'cosa', 'succ@@', '<unk>', '@', 'e@@', '<unk>', '@', 'da', ',', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'cui', 'succ@@', '<unk>', '@', 'ede', '.', '</s>']
2025-05-27 19:36:40,209 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:36:40,209 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:36:40,209 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che mostr<unk> @ o  una c<unk> @ las<unk> @ se  una c<unk> @ en<unk> @ da di cosa succ<unk> @ e<unk> @ da ,  succ<unk> @ esso in cui succ<unk> @ ede .
2025-05-27 19:36:43,493 - INFO - joeynmt.training - Epoch   4, Step:    31100, Batch Loss:     1.062386, Batch Acc: 0.693478, Tokens per Sec:    20751, Lr: 0.000300
2025-05-27 19:36:46,887 - INFO - joeynmt.training - Epoch   4, Step:    31200, Batch Loss:     1.095642, Batch Acc: 0.695083, Tokens per Sec:    22872, Lr: 0.000300
2025-05-27 19:36:50,250 - INFO - joeynmt.training - Epoch   4, Step:    31300, Batch Loss:     0.993557, Batch Acc: 0.689852, Tokens per Sec:    23492, Lr: 0.000300
2025-05-27 19:36:53,593 - INFO - joeynmt.training - Epoch   4, Step:    31400, Batch Loss:     1.105234, Batch Acc: 0.696545, Tokens per Sec:    23142, Lr: 0.000300
2025-05-27 19:36:56,498 - INFO - joeynmt.training - Epoch   4: total training loss 8445.86
2025-05-27 19:36:56,498 - INFO - joeynmt.training - EPOCH 5
2025-05-27 19:36:56,940 - INFO - joeynmt.training - Epoch   5, Step:    31500, Batch Loss:     1.056693, Batch Acc: 0.701887, Tokens per Sec:    22512, Lr: 0.000300
2025-05-27 19:36:56,940 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:36:56,940 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:37:11,204 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.06, ppl:   2.87, acc:   0.70, generation: 14.2553[sec], evaluation: 0.0000[sec]
2025-05-27 19:37:11,205 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:37:11,689 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/28500.ckpt
2025-05-27 19:37:11,707 - INFO - joeynmt.training - Example #0
2025-05-27 19:37:11,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:37:11,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:37:11,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'due', 'milioni', 'di', 'le@@', '<unk>', '@', 'a@@', '<unk>', '@', 'der', 'per', 'fare', 'la', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ia', 'per', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', '%', 'della', 'maggi@@', '<unk>', '@', 'or@@', '<unk>', '@', 'anza', 'di', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:37:11,708 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:37:11,708 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:37:11,708 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questa due milioni di le<unk> @ a<unk> @ der per fare la f<unk> @ ec<unk> @ or<unk> @ ia per c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano , per tre milioni di anni , che ha av<unk> @ uto 4<unk> @ 8 % della maggi<unk> @ or<unk> @ anza di 4<unk> @ 8 % .
2025-05-27 19:37:11,708 - INFO - joeynmt.training - Example #1
2025-05-27 19:37:11,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:37:11,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:37:11,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'ter@@', '<unk>', '@', 'ra', 'della', 'nostra', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'es@@', '<unk>', '@', 'sione', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', 'del', 'problema', '.', '</s>']
2025-05-27 19:37:11,709 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:37:11,709 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:37:11,709 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ ra della nostra in<unk> @ f<unk> @ es<unk> @ sione , perch non  il d<unk> @ ott<unk> @ ore del problema .
2025-05-27 19:37:11,709 - INFO - joeynmt.training - Example #2
2025-05-27 19:37:11,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:37:11,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:37:11,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'realt', ',', '', 'la', 'cosa', 'pi', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'ne', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'enti', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'enti', 'glob@@', '<unk>', '@', 'ali', '.', '</s>']
2025-05-27 19:37:11,710 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:37:11,710 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:37:11,710 - INFO - joeynmt.training - 	Hypothesis: In realt , in realt ,  la cosa pi in<unk> @ ten<unk> @ ne  la c<unk> @ li<unk> @ sta di c<unk> @ li<unk> @ enti c<unk> @ li<unk> @ enti glob<unk> @ ali .
2025-05-27 19:37:11,710 - INFO - joeynmt.training - Example #3
2025-05-27 19:37:11,710 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:37:11,710 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:37:11,710 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'cosa', 'che', 'si', '', 'ri@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sto', 'e', 'sc@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ato', '.', '</s>']
2025-05-27 19:37:11,711 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:37:11,711 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:37:11,711 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una cosa che si  ri<unk> @ ma<unk> @ sto e sc<unk> @ ar<unk> @ ic<unk> @ ato .
2025-05-27 19:37:11,711 - INFO - joeynmt.training - Example #4
2025-05-27 19:37:11,711 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:37:11,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:37:11,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ata', 'di', 'quello', 'che', 'sta', 'succ@@', '<unk>', '@', 'e@@', '<unk>', '@', 'dendo', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:37:11,712 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:37:11,712 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:37:11,712 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ o  che vi mostr<unk> @ o  una c<unk> @ ur<unk> @ ata di quello che sta succ<unk> @ e<unk> @ dendo negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:37:15,043 - INFO - joeynmt.training - Epoch   5, Step:    31600, Batch Loss:     1.017351, Batch Acc: 0.703405, Tokens per Sec:    20769, Lr: 0.000300
2025-05-27 19:37:18,439 - INFO - joeynmt.training - Epoch   5, Step:    31700, Batch Loss:     1.040787, Batch Acc: 0.702403, Tokens per Sec:    23756, Lr: 0.000300
2025-05-27 19:37:21,846 - INFO - joeynmt.training - Epoch   5, Step:    31800, Batch Loss:     0.955986, Batch Acc: 0.706280, Tokens per Sec:    23735, Lr: 0.000300
2025-05-27 19:37:25,235 - INFO - joeynmt.training - Epoch   5, Step:    31900, Batch Loss:     1.005589, Batch Acc: 0.703023, Tokens per Sec:    23294, Lr: 0.000300
2025-05-27 19:37:28,629 - INFO - joeynmt.training - Epoch   5, Step:    32000, Batch Loss:     1.002492, Batch Acc: 0.698212, Tokens per Sec:    23509, Lr: 0.000300
2025-05-27 19:37:28,629 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:37:28,629 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:37:43,468 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.87, acc:   0.70, generation: 14.8301[sec], evaluation: 0.0000[sec]
2025-05-27 19:37:43,468 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:37:43,948 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/29500.ckpt
2025-05-27 19:37:43,973 - INFO - joeynmt.training - Example #0
2025-05-27 19:37:43,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:37:43,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:37:43,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'due', 'milioni', 'di', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'per', 'cui', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'cui', 'il', '4@@', '<unk>', '@', '8', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'il', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:37:43,974 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:37:43,974 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:37:43,974 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno ho mostr<unk> @ ato questa due milioni di m<unk> @ ezz<unk> @ o che ho mostr<unk> @ ato questa fot<unk> @ o , per cui la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano tre milioni di m<unk> @ oti<unk> @ vi per cui il 4<unk> @ 8 c<unk> @ ento di tre milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , il 4<unk> @ 8 % .
2025-05-27 19:37:43,974 - INFO - joeynmt.training - Example #1
2025-05-27 19:37:43,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:37:43,975 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:37:43,975 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'un', 'po', '&apos;', 'di', 'pi', 'diff@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ile', 'che', 'la', 'T@@', '<unk>', '@', 'erra', '', 'la', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'u@@', '<unk>', '@', 'zione', 'di', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'k', '.', '</s>']
2025-05-27 19:37:43,975 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:37:43,975 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:37:43,975 - INFO - joeynmt.training - 	Hypothesis: Ma non  un po &apos; di pi diff<unk> @ ic<unk> @ ile che la T<unk> @ erra  la ris<unk> @ ol<unk> @ u<unk> @ zione di questa part<unk> @ icol<unk> @ are , perch non  il D<unk> @ ic<unk> @ e<unk> @ k .
2025-05-27 19:37:43,975 - INFO - joeynmt.training - Example #2
2025-05-27 19:37:43,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:37:43,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:37:43,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', '', 'la', 'c@@', '<unk>', '@', 'ura', 'di', 'str@@', '<unk>', '@', 'utt@@', '<unk>', '@', 'ura', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ter@@', '<unk>', '@', 'a', ',', 'il', 'nostro', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:37:43,976 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:37:43,976 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:37:43,976 - INFO - joeynmt.training - 	Hypothesis: In realt ,  la c<unk> @ ura di str<unk> @ utt<unk> @ ura  la c<unk> @ li<unk> @ sta di c<unk> @ li<unk> @ et<unk> @ ter<unk> @ a , il nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:37:43,976 - INFO - joeynmt.training - Example #3
2025-05-27 19:37:43,977 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:37:43,977 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:37:43,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ebbe', 'in', 'una', 'v@@', '<unk>', '@', 'ento', 'e', 'la', 'b@@', '<unk>', '@', 'ell@@', '<unk>', '@', 'issi@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:37:43,977 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:37:43,977 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:37:43,977 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ ebbe in una v<unk> @ ento e la b<unk> @ ell<unk> @ issi<unk> @ ma .
2025-05-27 19:37:43,977 - INFO - joeynmt.training - Example #4
2025-05-27 19:37:43,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:37:43,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:37:43,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', ',', '', 'una', 'c@@', '<unk>', '@', 'el@@', '<unk>', '@', 'eb@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ale', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'qu@@', '<unk>', '@', 'ell&apos;', 'ulti@@', '<unk>', '@', 'ma', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:37:43,978 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:37:43,978 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:37:43,978 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i ,  una c<unk> @ el<unk> @ eb<unk> @ r<unk> @ ale che vi mostr<unk> @ o  succ<unk> @ esso in qu<unk> @ ell&apos; ulti<unk> @ ma 2<unk> @ 5 anni .
2025-05-27 19:37:47,323 - INFO - joeynmt.training - Epoch   5, Step:    32100, Batch Loss:     0.996844, Batch Acc: 0.705724, Tokens per Sec:    20851, Lr: 0.000300
2025-05-27 19:37:50,696 - INFO - joeynmt.training - Epoch   5, Step:    32200, Batch Loss:     0.975519, Batch Acc: 0.701359, Tokens per Sec:    22516, Lr: 0.000300
2025-05-27 19:37:54,027 - INFO - joeynmt.training - Epoch   5, Step:    32300, Batch Loss:     1.004193, Batch Acc: 0.701453, Tokens per Sec:    23109, Lr: 0.000300
2025-05-27 19:37:57,419 - INFO - joeynmt.training - Epoch   5, Step:    32400, Batch Loss:     1.059476, Batch Acc: 0.701335, Tokens per Sec:    23780, Lr: 0.000300
2025-05-27 19:38:00,813 - INFO - joeynmt.training - Epoch   5, Step:    32500, Batch Loss:     0.940009, Batch Acc: 0.701797, Tokens per Sec:    23550, Lr: 0.000300
2025-05-27 19:38:00,814 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:38:00,814 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:38:16,085 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.86, acc:   0.70, generation: 15.2622[sec], evaluation: 0.0000[sec]
2025-05-27 19:38:16,085 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:38:16,578 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/30000.ckpt
2025-05-27 19:38:16,601 - INFO - joeynmt.training - Example #0
2025-05-27 19:38:16,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:38:16,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:38:16,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ie', 'per', 'f@@', '<unk>', '@', 'ar', 's@@', '<unk>', '@', '', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'str@@', '<unk>', '@', 'utt@@', '<unk>', '@', 'ura', ',', 'per', 'le', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'che', 'i', 'dati', 'per', 'circa', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', '.', '</s>']
2025-05-27 19:38:16,602 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:38:16,602 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:38:16,602 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questa f<unk> @ ec<unk> @ ie per f<unk> @ ar s<unk> @  che la c<unk> @ aus<unk> @ a di str<unk> @ utt<unk> @ ura , per le persone che hanno sc<unk> @ oper<unk> @ to che i dati per circa 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per tre milioni di di m<unk> @ oti<unk> @ vi per 4<unk> @ 8 milioni di di m<unk> @ oti<unk> @ vi .
2025-05-27 19:38:16,602 - INFO - joeynmt.training - Example #1
2025-05-27 19:38:16,603 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:38:16,603 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:38:16,603 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'cos', 'che', 'la', 'cosa', 'non', '', 'cos', 'che', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', '', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'azione', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ato', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:38:16,603 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:38:16,603 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:38:16,603 - INFO - joeynmt.training - 	Hypothesis: Ma non  cos che la cosa non  cos che la ris<unk> @ post<unk> @ a  la di<unk> @ st<unk> @ azione di questo problema spe<unk> @ ci<unk> @ ale , non  il d<unk> @ ato di questo problema .
2025-05-27 19:38:16,603 - INFO - joeynmt.training - Example #2
2025-05-27 19:38:16,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:38:16,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:38:16,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt', ',', 'in', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:38:16,604 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:38:16,604 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:38:16,604 - INFO - joeynmt.training - 	Hypothesis: In realt , in un cer<unk> @ to sen<unk> @ so  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema glob<unk> @ ale .
2025-05-27 19:38:16,605 - INFO - joeynmt.training - Example #3
2025-05-27 19:38:16,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:38:16,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:38:16,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'ma', 'di', 'tutto', 'il', 'mondo', ',', 'si', '', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ate', 'e', 'si', 'trov@@', '<unk>', '@', 'a', 'in', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'm@@', '<unk>', '@', 'are', '.', '</s>']
2025-05-27 19:38:16,605 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:38:16,605 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:38:16,605 - INFO - joeynmt.training - 	Hypothesis: P<unk> @ ri<unk> @ ma di tutto il mondo , si  s<unk> @ om<unk> @ p<unk> @ ate e si trov<unk> @ a in s<unk> @ om<unk> @ m<unk> @ are .
2025-05-27 19:38:16,605 - INFO - joeynmt.training - Example #4
2025-05-27 19:38:16,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:38:16,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:38:16,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'cosa', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:38:16,606 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:38:16,606 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:38:16,606 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una c<unk> @ aus<unk> @ a di cosa  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:38:19,931 - INFO - joeynmt.training - Epoch   5, Step:    32600, Batch Loss:     1.127135, Batch Acc: 0.704013, Tokens per Sec:    19940, Lr: 0.000300
2025-05-27 19:38:23,334 - INFO - joeynmt.training - Epoch   5, Step:    32700, Batch Loss:     1.070366, Batch Acc: 0.700162, Tokens per Sec:    23463, Lr: 0.000300
2025-05-27 19:38:26,712 - INFO - joeynmt.training - Epoch   5, Step:    32800, Batch Loss:     0.951402, Batch Acc: 0.699440, Tokens per Sec:    23061, Lr: 0.000300
2025-05-27 19:38:30,090 - INFO - joeynmt.training - Epoch   5, Step:    32900, Batch Loss:     0.981302, Batch Acc: 0.697892, Tokens per Sec:    22963, Lr: 0.000300
2025-05-27 19:38:33,480 - INFO - joeynmt.training - Epoch   5, Step:    33000, Batch Loss:     0.952078, Batch Acc: 0.701798, Tokens per Sec:    22992, Lr: 0.000300
2025-05-27 19:38:33,481 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:38:33,481 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:38:46,608 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.86, acc:   0.70, generation: 13.1196[sec], evaluation: 0.0000[sec]
2025-05-27 19:38:47,085 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/30500.ckpt
2025-05-27 19:38:47,107 - INFO - joeynmt.training - Example #0
2025-05-27 19:38:47,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:38:47,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:38:47,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'per', 'il', 'vol@@', '<unk>', '@', 'o', 'di', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'l&apos;', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ca', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'rag@@', '<unk>', '@', 'i@@', '<unk>', '@', 'oni', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', '4@@', '<unk>', '@', '8', 'anni', '.', '</s>']
2025-05-27 19:38:47,109 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:38:47,109 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:38:47,109 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per il vol<unk> @ o di un p<unk> @ ezz<unk> @ o di g<unk> @ hi<unk> @ ac<unk> @ cio che l&apos; E<unk> @ is<unk> @ c<unk> @ ca che ha av<unk> @ uto 4<unk> @ 8 milioni di rag<unk> @ i<unk> @ oni che ha av<unk> @ uto 4<unk> @ 8 anni , il 4<unk> @ 0 , 4<unk> @ 8 anni .
2025-05-27 19:38:47,109 - INFO - joeynmt.training - Example #1
2025-05-27 19:38:47,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:38:47,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:38:47,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'cos', 'che', 'la', 'gente', 'non', '', 'il', 'fatto', 'di', 'questo', 'problema', 'di', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bil@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'non', '', 'il', 'de@@', '<unk>', '@', 'ter@@', '<unk>', '@', 'min@@', '<unk>', '@', 'ato', '.', '</s>']
2025-05-27 19:38:47,110 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:38:47,110 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:38:47,110 - INFO - joeynmt.training - 	Hypothesis: Ma non  cos che la gente non  il fatto di questo problema di in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ it di questo problema spe<unk> @ ci<unk> @ ale , non  il de<unk> @ ter<unk> @ min<unk> @ ato .
2025-05-27 19:38:47,110 - INFO - joeynmt.training - Example #2
2025-05-27 19:38:47,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:38:47,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:38:47,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'sci@@', '<unk>', '@', 'enza', ',', 'la', 's@@', '<unk>', '@', 'fi@@', '<unk>', '@', 'da', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'il', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:38:47,111 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:38:47,111 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:38:47,111 - INFO - joeynmt.training - 	Hypothesis: In sci<unk> @ enza , la s<unk> @ fi<unk> @ da  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio il nostro sistema glob<unk> @ ale .
2025-05-27 19:38:47,111 - INFO - joeynmt.training - Example #3
2025-05-27 19:38:47,111 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:38:47,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:38:47,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', 'e', 'la', 'sc@@', '<unk>', '@', 'al@@', '<unk>', '@', 'a', 'e', 'la', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', '.', '</s>']
2025-05-27 19:38:47,112 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:38:47,112 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:38:47,112 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a e la sc<unk> @ al<unk> @ a e la sc<unk> @ u<unk> @ ola .
2025-05-27 19:38:47,112 - INFO - joeynmt.training - Example #4
2025-05-27 19:38:47,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:38:47,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:38:47,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'f@@', '<unk>', '@', 'ar', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:38:47,113 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:38:47,113 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:38:47,113 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo f<unk> @ ar mostr<unk> @ o  una sc<unk> @ or<unk> @ sa che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:38:50,454 - INFO - joeynmt.training - Epoch   5, Step:    33100, Batch Loss:     1.026917, Batch Acc: 0.700696, Tokens per Sec:    20808, Lr: 0.000300
2025-05-27 19:38:53,861 - INFO - joeynmt.training - Epoch   5, Step:    33200, Batch Loss:     1.036924, Batch Acc: 0.700421, Tokens per Sec:    22996, Lr: 0.000300
2025-05-27 19:38:57,215 - INFO - joeynmt.training - Epoch   5, Step:    33300, Batch Loss:     1.082449, Batch Acc: 0.701215, Tokens per Sec:    23501, Lr: 0.000300
2025-05-27 19:39:00,601 - INFO - joeynmt.training - Epoch   5, Step:    33400, Batch Loss:     1.175248, Batch Acc: 0.704891, Tokens per Sec:    23705, Lr: 0.000300
2025-05-27 19:39:04,002 - INFO - joeynmt.training - Epoch   5, Step:    33500, Batch Loss:     0.990603, Batch Acc: 0.700022, Tokens per Sec:    22998, Lr: 0.000300
2025-05-27 19:39:04,002 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:39:04,002 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:39:21,805 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.85, acc:   0.70, generation: 17.7895[sec], evaluation: 0.0000[sec]
2025-05-27 19:39:21,806 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:39:22,370 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/31000.ckpt
2025-05-27 19:39:22,396 - INFO - joeynmt.training - Example #0
2025-05-27 19:39:22,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:39:22,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:39:22,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'ia', 'per', 'la', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', ',', 'che', 'ha', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'ato', 'che', 'i', 'c@@', '<unk>', '@', 'av@@', '<unk>', '@', 'est@@', '<unk>', '@', 'i', ',', 'per', 'il', '4@@', '<unk>', '@', '8', '%', 'del', '4@@', '<unk>', '@', '8', '%', 'del', '4@@', '<unk>', '@', '8', '%', 'di', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:39:22,397 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:39:22,397 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:39:22,397 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questa fot<unk> @ o per ri<unk> @ dur<unk> @ re la p<unk> @ op<unk> @ ol<unk> @ ia per la f<unk> @ am<unk> @ ig<unk> @ lia , che ha di<unk> @ mostr<unk> @ ato che i c<unk> @ av<unk> @ est<unk> @ i , per il 4<unk> @ 8 % del 4<unk> @ 8 % del 4<unk> @ 8 % di 4<unk> @ 8 % .
2025-05-27 19:39:22,397 - INFO - joeynmt.training - Example #1
2025-05-27 19:39:22,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:39:22,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:39:22,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'pi', 'diff@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ile', ',', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', '', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', '', 'il', 'problema', 'di', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e', 'non', 'mostr@@', '<unk>', '@', 'a', 'la', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:39:22,398 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:39:22,398 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:39:22,399 - INFO - joeynmt.training - 	Hypothesis: Ma non  pi diff<unk> @ ic<unk> @ ile , la ris<unk> @ post<unk> @ a  la ris<unk> @ post<unk> @ a  il problema di D<unk> @ ic<unk> @ e non mostr<unk> @ a la di<unk> @ mostr<unk> @ a .
2025-05-27 19:39:22,399 - INFO - joeynmt.training - Example #2
2025-05-27 19:39:22,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:39:22,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:39:22,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 's@@', '<unk>', '@', 'edi@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'la', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:39:22,399 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:39:22,400 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:39:22,400 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ edi<unk> @ a  la c<unk> @ aus<unk> @ a di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a la nostra c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 19:39:22,400 - INFO - joeynmt.training - Example #3
2025-05-27 19:39:22,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:39:22,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:39:22,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'va', 'in', 'par@@', '<unk>', '@', 'ole', 'e', 'la', 's@@', '<unk>', '@', 'qu@@', '<unk>', '@', 'ad@@', '<unk>', '@', 'ra', '.', '</s>']
2025-05-27 19:39:22,400 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:39:22,400 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:39:22,401 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ c<unk> @ ri<unk> @ va in par<unk> @ ole e la s<unk> @ qu<unk> @ ad<unk> @ ra .
2025-05-27 19:39:22,401 - INFO - joeynmt.training - Example #4
2025-05-27 19:39:22,401 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:39:22,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:39:22,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'mostr@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', ',', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:39:22,401 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:39:22,401 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:39:22,402 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che mostr<unk> @ o che vi mostr<unk> @ o  una c<unk> @ en<unk> @ a ,  una c<unk> @ en<unk> @ a , che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:39:25,837 - INFO - joeynmt.training - Epoch   5, Step:    33600, Batch Loss:     1.004092, Batch Acc: 0.702557, Tokens per Sec:    19923, Lr: 0.000300
2025-05-27 19:39:29,258 - INFO - joeynmt.training - Epoch   5, Step:    33700, Batch Loss:     1.002109, Batch Acc: 0.700994, Tokens per Sec:    24055, Lr: 0.000300
2025-05-27 19:39:32,672 - INFO - joeynmt.training - Epoch   5, Step:    33800, Batch Loss:     1.017096, Batch Acc: 0.700564, Tokens per Sec:    23806, Lr: 0.000300
2025-05-27 19:39:36,061 - INFO - joeynmt.training - Epoch   5, Step:    33900, Batch Loss:     1.035754, Batch Acc: 0.705753, Tokens per Sec:    23434, Lr: 0.000300
2025-05-27 19:39:39,467 - INFO - joeynmt.training - Epoch   5, Step:    34000, Batch Loss:     1.039697, Batch Acc: 0.704307, Tokens per Sec:    23909, Lr: 0.000300
2025-05-27 19:39:39,468 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:39:39,468 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:39:56,932 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.84, acc:   0.70, generation: 17.4489[sec], evaluation: 0.0000[sec]
2025-05-27 19:39:56,932 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:39:57,486 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/31500.ckpt
2025-05-27 19:39:57,511 - INFO - joeynmt.training - Example #0
2025-05-27 19:39:57,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:39:57,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:39:57,512 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'fot@@', '<unk>', '@', 'o', 'per', 'per@@', '<unk>', '@', 'dere', ',', 'per', 'per@@', '<unk>', '@', 'dere', ',', 'per', 'i', 'di@@', '<unk>', '@', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'are', 'i', 'v@@', '<unk>', '@', 'oc@@', '<unk>', '@', 'ali', ',', 'per', 'i', 'due', 'anni', ',', 'per', 'i', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'i', ',', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'qu@@', '<unk>', '@', 'elli', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:39:57,513 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:39:57,513 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:39:57,513 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o per per<unk> @ dere , per per<unk> @ dere , per i di<unk> @ sp<unk> @ ost<unk> @ are i v<unk> @ oc<unk> @ ali , per i due anni , per i di<unk> @ st<unk> @ i , per i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 , per c<unk> @ ento di qu<unk> @ elli che ha av<unk> @ uto il 4<unk> @ 0 % .
2025-05-27 19:39:57,513 - INFO - joeynmt.training - Example #1
2025-05-27 19:39:57,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:39:57,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:39:57,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'un', 'punto', 'di', 'vi@@', '<unk>', '@', 'sta', ',', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', ',', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 't', '.', '</s>']
2025-05-27 19:39:57,514 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:39:57,514 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:39:57,514 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  un punto di vi<unk> @ sta , non  abb<unk> @ ast<unk> @ anza , questo problema spe<unk> @ ci<unk> @ ale , questo problema spe<unk> @ ci<unk> @ ale , non  il d<unk> @ ott<unk> @ ore di E<unk> @ is<unk> @ t .
2025-05-27 19:39:57,514 - INFO - joeynmt.training - Example #2
2025-05-27 19:39:57,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:39:57,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:39:57,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 's@@', '<unk>', '@', 'esso', '', 'la', 'cosa', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', '.', '</s>']
2025-05-27 19:39:57,515 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:39:57,515 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:39:57,515 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il s<unk> @ esso  la cosa in<unk> @ ten<unk> @ zione  la c<unk> @ aus<unk> @ a di c<unk> @ li<unk> @ m<unk> @ as<unk> @ si<unk> @ mo .
2025-05-27 19:39:57,515 - INFO - joeynmt.training - Example #3
2025-05-27 19:39:57,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:39:57,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:39:57,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ta', 'che', 'si', '', 's@@', '<unk>', '@', '', ',', 'e', 'la', 'p@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'o', 'in', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:39:57,516 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:39:57,516 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:39:57,516 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta che si  s<unk> @  , e la p<unk> @ eg<unk> @ gi<unk> @ o in m<unk> @ ezz<unk> @ o .
2025-05-27 19:39:57,516 - INFO - joeynmt.training - Example #4
2025-05-27 19:39:57,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:39:57,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:39:57,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'una', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', '', 'un', 'c@@', '<unk>', '@', 'entr@@', '<unk>', '@', 'o', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'e@@', '<unk>', '@', 'de@@', '<unk>', '@', 'va', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:39:57,517 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:39:57,517 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:39:57,517 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una c<unk> @ aus<unk> @ a di una c<unk> @ las<unk> @ se  un c<unk> @ entr<unk> @ o di quello che succ<unk> @ e<unk> @ de<unk> @ va negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:40:00,945 - INFO - joeynmt.training - Epoch   5, Step:    34100, Batch Loss:     0.976248, Batch Acc: 0.699790, Tokens per Sec:    19825, Lr: 0.000300
2025-05-27 19:40:04,197 - INFO - joeynmt.training - Epoch   5, Step:    34200, Batch Loss:     1.045823, Batch Acc: 0.701585, Tokens per Sec:    24129, Lr: 0.000300
2025-05-27 19:40:07,466 - INFO - joeynmt.training - Epoch   5, Step:    34300, Batch Loss:     1.153490, Batch Acc: 0.703165, Tokens per Sec:    24509, Lr: 0.000300
2025-05-27 19:40:10,713 - INFO - joeynmt.training - Epoch   5, Step:    34400, Batch Loss:     0.976346, Batch Acc: 0.704039, Tokens per Sec:    24858, Lr: 0.000300
2025-05-27 19:40:13,941 - INFO - joeynmt.training - Epoch   5, Step:    34500, Batch Loss:     1.065631, Batch Acc: 0.704820, Tokens per Sec:    24695, Lr: 0.000300
2025-05-27 19:40:13,941 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:40:13,941 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:40:30,487 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.83, acc:   0.70, generation: 16.5323[sec], evaluation: 0.0000[sec]
2025-05-27 19:40:30,488 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:40:31,068 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/32000.ckpt
2025-05-27 19:40:31,092 - INFO - joeynmt.training - Example #0
2025-05-27 19:40:31,093 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:40:31,093 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:40:31,093 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'per', 'fare', 'la', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'per', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'gli', 'str@@', '<unk>', '@', 'um@@', '<unk>', '@', 'enti', 'che', 'hanno', 'fatto', 'per', 'i', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'e', 'i', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'la', 'qu@@', '<unk>', '@', 'ant@@', '<unk>', '@', 'it', 'di', 'tre', 'milioni', 'di', 'di', 'di', 'di', 'di', 'persone', ',', 'ha', 'fatto', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'un', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:40:31,094 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:40:31,094 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:40:31,094 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per fare la f<unk> @ am<unk> @ ig<unk> @ lia per la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , per gli str<unk> @ um<unk> @ enti che hanno fatto per i c<unk> @ aus<unk> @ a di tre milioni di anni , e i m<unk> @ oti<unk> @ vi per la qu<unk> @ ant<unk> @ it di tre milioni di di di di di persone , ha fatto che ha av<unk> @ uto un 4<unk> @ 0 % .
2025-05-27 19:40:31,094 - INFO - joeynmt.training - Example #1
2025-05-27 19:40:31,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:40:31,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:40:31,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'punto', 'di', 'vi@@', '<unk>', '@', 'sta', 'non', '', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questa', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'fic@@', '<unk>', '@', 'enza', ',', 'e', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'io', 'di', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'io', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 19:40:31,095 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:40:31,095 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:40:31,095 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il punto di vi<unk> @ sta non  la di<unk> @ st<unk> @ anza di questa spe<unk> @ ci<unk> @ fic<unk> @ enza , e questo problema spe<unk> @ ci<unk> @ ale , non  il D<unk> @ ic<unk> @ io di D<unk> @ ic<unk> @ io , non  il D<unk> @ ic<unk> @ io .
2025-05-27 19:40:31,095 - INFO - joeynmt.training - Example #2
2025-05-27 19:40:31,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:40:31,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:40:31,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'c@@', '<unk>', '@', 'uno', 'di', 'questi', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'si', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'se', ',', 'il', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'so', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', '.', '</s>']
2025-05-27 19:40:31,096 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:40:31,096 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:40:31,096 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la nostra c<unk> @ li<unk> @ m<unk> @ as<unk> @ c<unk> @ uno di questi c<unk> @ li<unk> @ m<unk> @ as<unk> @ si di c<unk> @ li<unk> @ m<unk> @ as<unk> @ se , il nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ so di c<unk> @ li<unk> @ m<unk> @ as<unk> @ si<unk> @ mo .
2025-05-27 19:40:31,096 - INFO - joeynmt.training - Example #3
2025-05-27 19:40:31,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:40:31,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:40:31,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'ento', 'e', 'sc@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ere', 'e', 'la', 'p@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ric@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:40:31,097 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:40:31,097 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:40:31,097 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e sc<unk> @ eg<unk> @ li<unk> @ ere e la p<unk> @ at<unk> @ ric<unk> @ e .
2025-05-27 19:40:31,097 - INFO - joeynmt.training - Example #4
2025-05-27 19:40:31,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:40:31,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:40:31,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'el@@', '<unk>', '@', 'eb@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ale', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:40:31,098 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:40:31,098 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:40:31,098 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una c<unk> @ el<unk> @ eb<unk> @ r<unk> @ ale che vi mostr<unk> @ er<unk> @  cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:40:34,509 - INFO - joeynmt.training - Epoch   5, Step:    34600, Batch Loss:     0.992161, Batch Acc: 0.698099, Tokens per Sec:    19965, Lr: 0.000300
2025-05-27 19:40:37,885 - INFO - joeynmt.training - Epoch   5, Step:    34700, Batch Loss:     0.984120, Batch Acc: 0.700674, Tokens per Sec:    23924, Lr: 0.000300
2025-05-27 19:40:41,283 - INFO - joeynmt.training - Epoch   5, Step:    34800, Batch Loss:     1.022342, Batch Acc: 0.703398, Tokens per Sec:    24128, Lr: 0.000300
2025-05-27 19:40:44,678 - INFO - joeynmt.training - Epoch   5, Step:    34900, Batch Loss:     1.049352, Batch Acc: 0.701398, Tokens per Sec:    23602, Lr: 0.000300
2025-05-27 19:40:48,032 - INFO - joeynmt.training - Epoch   5, Step:    35000, Batch Loss:     1.030052, Batch Acc: 0.702226, Tokens per Sec:    23755, Lr: 0.000300
2025-05-27 19:40:48,032 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:40:48,032 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:41:03,282 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.83, acc:   0.70, generation: 15.2374[sec], evaluation: 0.0000[sec]
2025-05-27 19:41:03,283 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:41:03,898 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/33000.ckpt
2025-05-27 19:41:03,924 - INFO - joeynmt.training - Example #0
2025-05-27 19:41:03,924 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:41:03,924 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:41:03,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'f@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', 'per', 'con@@', '<unk>', '@', 'to', 'che', 'i', 'p@@', '<unk>', '@', 'oco', 'per', 'cui', 'i', 'f@@', '<unk>', '@', 'ar', 'c@@', '<unk>', '@', 'att@@', '<unk>', '@', 'are', 'la', 'c@@', '<unk>', '@', 'att@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ale', ',', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'la', 'qu@@', '<unk>', '@', 'ale', ',', 'per', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'e', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'persone', '.', '</s>']
2025-05-27 19:41:03,925 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:41:03,925 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:41:03,925 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so che ho mostr<unk> @ ato questi due f<unk> @ ec<unk> @ i f<unk> @ ol<unk> @ i per con<unk> @ to che i p<unk> @ oco per cui i f<unk> @ ar c<unk> @ att<unk> @ are la c<unk> @ att<unk> @ u<unk> @ ale , per i 4<unk> @ 8 milioni di anni , per la qu<unk> @ ale , per il 4<unk> @ 0 per c<unk> @ ento di tre milioni di anni , e il 4<unk> @ 0 per c<unk> @ ento di tre milioni di persone .
2025-05-27 19:41:03,925 - INFO - joeynmt.training - Example #1
2025-05-27 19:41:03,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:41:03,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:41:03,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'il', 'fatto', 'che', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', '', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ha@@', '<unk>', '@', 'i', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e', 'non', 'si', 'ri@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ce', '.', '</s>']
2025-05-27 19:41:03,926 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:41:03,926 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:41:03,926 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  il fatto che la ris<unk> @ post<unk> @ a  la di<unk> @ st<unk> @ ha<unk> @ i questa part<unk> @ icol<unk> @ are , non  il D<unk> @ ic<unk> @ e non si ri<unk> @ es<unk> @ ce .
2025-05-27 19:41:03,926 - INFO - joeynmt.training - Example #2
2025-05-27 19:41:03,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:41:03,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:41:03,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:41:03,927 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:41:03,927 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:41:03,927 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ li<unk> @ sta  la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 19:41:03,927 - INFO - joeynmt.training - Example #3
2025-05-27 19:41:03,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:41:03,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:41:03,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'di', 'par@@', '<unk>', '@', 'ole', '.', '</s>']
2025-05-27 19:41:03,928 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:41:03,928 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:41:03,928 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o di par<unk> @ ole .
2025-05-27 19:41:03,928 - INFO - joeynmt.training - Example #4
2025-05-27 19:41:03,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:41:03,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:41:03,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'ri@@', '<unk>', '@', 'pres@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:41:03,929 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:41:03,929 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:41:03,929 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una ser<unk> @ ie di ri<unk> @ pres<unk> @ a che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:41:07,304 - INFO - joeynmt.training - Epoch   5, Step:    35100, Batch Loss:     1.048132, Batch Acc: 0.702882, Tokens per Sec:    19943, Lr: 0.000300
2025-05-27 19:41:10,665 - INFO - joeynmt.training - Epoch   5, Step:    35200, Batch Loss:     1.031295, Batch Acc: 0.702867, Tokens per Sec:    23683, Lr: 0.000300
2025-05-27 19:41:14,037 - INFO - joeynmt.training - Epoch   5, Step:    35300, Batch Loss:     1.104566, Batch Acc: 0.701653, Tokens per Sec:    23292, Lr: 0.000300
2025-05-27 19:41:17,409 - INFO - joeynmt.training - Epoch   5, Step:    35400, Batch Loss:     0.918054, Batch Acc: 0.705179, Tokens per Sec:    23315, Lr: 0.000300
2025-05-27 19:41:20,777 - INFO - joeynmt.training - Epoch   5, Step:    35500, Batch Loss:     0.931359, Batch Acc: 0.699580, Tokens per Sec:    23343, Lr: 0.000300
2025-05-27 19:41:20,777 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:41:20,777 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:41:38,810 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.84, acc:   0.70, generation: 18.0192[sec], evaluation: 0.0000[sec]
2025-05-27 19:41:39,221 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/32500.ckpt
2025-05-27 19:41:39,246 - INFO - joeynmt.training - Example #0
2025-05-27 19:41:39,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:41:39,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:41:39,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'per', 'ri@@', '<unk>', '@', 'port@@', '<unk>', '@', 'are', 'i', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'i', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'a@@', '<unk>', '@', 'io', 'che', 'i', 'v@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'ano', 'per', 'i', '4@@', '<unk>', '@', '8', '<unk>', '@', '8', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'di', 'di', 'persone', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:41:39,248 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:41:39,248 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:41:39,248 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per ri<unk> @ port<unk> @ are i p<unk> @ ezz<unk> @ i di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io che i v<unk> @ u<unk> @ ot<unk> @ ano per i 4<unk> @ 8 <unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per tre milioni di di di persone che ha av<unk> @ uto 4<unk> @ 8 % .
2025-05-27 19:41:39,248 - INFO - joeynmt.training - Example #1
2025-05-27 19:41:39,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:41:39,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:41:39,249 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'den@@', '<unk>', '@', 'za', ',', 'la', 'ver@@', '<unk>', '@', 'it', 'di', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ot@@', '<unk>', '@', 'ti@@', '<unk>', '@', 'mo', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'p@@', '<unk>', '@', 'it@@', '<unk>', '@', 't@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 19:41:39,249 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:41:39,249 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:41:39,249 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ ten<unk> @ den<unk> @ za , la ver<unk> @ it di questa part<unk> @ icol<unk> @ are , non  il d<unk> @ ot<unk> @ ti<unk> @ mo di E<unk> @ is<unk> @ p<unk> @ it<unk> @ t<unk> @ ura .
2025-05-27 19:41:39,249 - INFO - joeynmt.training - Example #2
2025-05-27 19:41:39,250 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:41:39,250 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:41:39,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'p@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'ore', '', 'la', 'b@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ag@@', '<unk>', '@', 'ante', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', '.', '</s>']
2025-05-27 19:41:39,250 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:41:39,250 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:41:39,250 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la p<unk> @ eg<unk> @ gi<unk> @ ore  la b<unk> @ att<unk> @ ag<unk> @ ante della nostra c<unk> @ li<unk> @ sta .
2025-05-27 19:41:39,250 - INFO - joeynmt.training - Example #3
2025-05-27 19:41:39,250 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:41:39,250 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:41:39,251 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', '', 'in', 'ver@@', '<unk>', '@', 'no', 'e', 'la', 'p@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:41:39,251 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:41:39,251 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:41:39,251 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @  in ver<unk> @ no e la p<unk> @ eg<unk> @ gi<unk> @ ore .
2025-05-27 19:41:39,251 - INFO - joeynmt.training - Example #4
2025-05-27 19:41:39,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:41:39,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:41:39,251 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'ver@@', '<unk>', '@', 'a', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'la', 'sua', 'car@@', '<unk>', '@', 'ta', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'azione', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:41:39,252 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:41:39,252 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:41:39,252 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una ver<unk> @ a che vi mostr<unk> @ er<unk> @  la sua car<unk> @ ta  una ser<unk> @ ie di con<unk> @ si<unk> @ der<unk> @ azione che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:41:42,661 - INFO - joeynmt.training - Epoch   5, Step:    35600, Batch Loss:     1.065678, Batch Acc: 0.698835, Tokens per Sec:    20439, Lr: 0.000300
2025-05-27 19:41:46,061 - INFO - joeynmt.training - Epoch   5, Step:    35700, Batch Loss:     1.053087, Batch Acc: 0.701896, Tokens per Sec:    23145, Lr: 0.000300
2025-05-27 19:41:49,447 - INFO - joeynmt.training - Epoch   5, Step:    35800, Batch Loss:     0.986227, Batch Acc: 0.699020, Tokens per Sec:    23254, Lr: 0.000300
2025-05-27 19:41:52,822 - INFO - joeynmt.training - Epoch   5, Step:    35900, Batch Loss:     1.049119, Batch Acc: 0.701975, Tokens per Sec:    23355, Lr: 0.000300
2025-05-27 19:41:56,197 - INFO - joeynmt.training - Epoch   5, Step:    36000, Batch Loss:     0.999187, Batch Acc: 0.701679, Tokens per Sec:    23230, Lr: 0.000300
2025-05-27 19:41:56,197 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:41:56,197 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:42:12,230 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.84, acc:   0.70, generation: 16.0191[sec], evaluation: 0.0000[sec]
2025-05-27 19:42:12,628 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/33500.ckpt
2025-05-27 19:42:12,654 - INFO - joeynmt.training - Example #0
2025-05-27 19:42:12,655 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:42:12,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:42:12,655 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'f@@', '<unk>', '@', 'ogli@@', '<unk>', '@', 'hi', 'per', 'f@@', '<unk>', '@', 'ar', 's@@', '<unk>', '@', '', 'che', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'ia', 'che', 'i', 'g@@', '<unk>', '@', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ici', ',', 'per', 'i', '4@@', '<unk>', '@', '8', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'i', '4@@', '<unk>', '@', '8', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', '', 'stato', 'm@@', '<unk>', '@', 'and@@', '<unk>', '@', 'ato', 'a', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:42:12,655 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:42:12,655 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:42:12,656 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due f<unk> @ ogli<unk> @ hi per f<unk> @ ar s<unk> @  che la p<unk> @ op<unk> @ ol<unk> @ ia che i g<unk> @ ar<unk> @ t<unk> @ ici , per i 4<unk> @ 8 <unk> @ 8 milioni di anni , per i 4<unk> @ 8 <unk> @ 8 milioni di anni , per i 4<unk> @ 8 milioni di anni ,  stato m<unk> @ and<unk> @ ato a tre milioni di anni , per il 4<unk> @ 8 % .
2025-05-27 19:42:12,656 - INFO - joeynmt.training - Example #1
2025-05-27 19:42:12,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:42:12,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:42:12,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'della', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questa', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'fica', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', 'del', 'problema', '.', '</s>']
2025-05-27 19:42:12,656 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:42:12,657 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:42:12,657 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza il ris<unk> @ ult<unk> @ ato della di<unk> @ st<unk> @ anza di questa spe<unk> @ ci<unk> @ fica , perch non  il D<unk> @ ic<unk> @ e<unk> @ o del problema .
2025-05-27 19:42:12,657 - INFO - joeynmt.training - Example #2
2025-05-27 19:42:12,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:42:12,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:42:12,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sen@@', '<unk>', '@', 'so', 'di', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Hypothesis: In un sen<unk> @ so di sen<unk> @ so  la c<unk> @ li<unk> @ sta  la c<unk> @ li<unk> @ sta del nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - Example #3
2025-05-27 19:42:12,658 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:42:12,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:42:12,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'in', 'v@@', '<unk>', '@', 'inc@@', '<unk>', '@', 'ere', 'e', 'la', 'v@@', '<unk>', '@', 'oc@@', '<unk>', '@', 'e', '.', '</s>']
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in v<unk> @ inc<unk> @ ere e la v<unk> @ oc<unk> @ e .
2025-05-27 19:42:12,659 - INFO - joeynmt.training - Example #4
2025-05-27 19:42:12,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:42:12,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:42:12,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ate', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:42:12,659 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:42:12,659 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:42:12,659 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ate che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a che vi mostr<unk> @ er<unk> @  quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:42:16,083 - INFO - joeynmt.training - Epoch   5, Step:    36100, Batch Loss:     0.988846, Batch Acc: 0.704979, Tokens per Sec:    20666, Lr: 0.000300
2025-05-27 19:42:19,464 - INFO - joeynmt.training - Epoch   5, Step:    36200, Batch Loss:     1.083730, Batch Acc: 0.705511, Tokens per Sec:    23005, Lr: 0.000300
2025-05-27 19:42:22,839 - INFO - joeynmt.training - Epoch   5, Step:    36300, Batch Loss:     0.781799, Batch Acc: 0.706125, Tokens per Sec:    24006, Lr: 0.000300
2025-05-27 19:42:26,215 - INFO - joeynmt.training - Epoch   5, Step:    36400, Batch Loss:     1.112786, Batch Acc: 0.702919, Tokens per Sec:    23279, Lr: 0.000300
2025-05-27 19:42:29,582 - INFO - joeynmt.training - Epoch   5, Step:    36500, Batch Loss:     1.028872, Batch Acc: 0.701857, Tokens per Sec:    22635, Lr: 0.000300
2025-05-27 19:42:29,583 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:42:29,583 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:42:45,690 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.83, acc:   0.70, generation: 16.0938[sec], evaluation: 0.0000[sec]
2025-05-27 19:42:45,690 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:42:46,362 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/34000.ckpt
2025-05-27 19:42:46,387 - INFO - joeynmt.training - Example #0
2025-05-27 19:42:46,388 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:42:46,388 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:42:46,388 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'di', 'f@@', '<unk>', '@', 'ar', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'b@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', 'che', 'i', 'c@@', '<unk>', '@', 'att@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ci', 'che', 'i', 'si@@', '<unk>', '@', 'ano', 'le', 'persone', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'per', 'i', '4@@', '<unk>', '@', '0', 'anni', ',', 'per', 'la', '4@@', '<unk>', '@', '0', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'sc@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'are', ',', 'per', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:42:46,389 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:42:46,389 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:42:46,389 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i di f<unk> @ ar ri<unk> @ m<unk> @ b<unk> @ ol<unk> @ i che i c<unk> @ att<unk> @ es<unk> @ ci che i si<unk> @ ano le persone che hanno sc<unk> @ oper<unk> @ to per i 4<unk> @ 0 anni , per la 4<unk> @ 0 , per c<unk> @ ento di tre milioni di anni , per sc<unk> @ ar<unk> @ ic<unk> @ are , per 4<unk> @ 0 % .
2025-05-27 19:42:46,389 - INFO - joeynmt.training - Example #1
2025-05-27 19:42:46,390 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:42:46,390 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:42:46,390 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', ',', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ato', 'di', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ato', 'di', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 19:42:46,390 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:42:46,390 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:42:46,390 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza , la giu<unk> @ st<unk> @ izi<unk> @ a , non  il d<unk> @ ato di questa part<unk> @ icol<unk> @ are , non  il d<unk> @ ato di D<unk> @ ic<unk> @ io .
2025-05-27 19:42:46,390 - INFO - joeynmt.training - Example #2
2025-05-27 19:42:46,391 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:42:46,391 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:42:46,391 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', '', 'il', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'vello', 'di', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', 'del', 'nostro', 's@@', '<unk>', '@', 'ito', '.', '</s>']
2025-05-27 19:42:46,391 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:42:46,391 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:42:46,391 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la c<unk> @ li<unk> @ sta  il c<unk> @ li<unk> @ vello di ci<unk> @ b<unk> @ o del nostro s<unk> @ ito .
2025-05-27 19:42:46,391 - INFO - joeynmt.training - Example #3
2025-05-27 19:42:46,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:42:46,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:42:46,392 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:42:46,392 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:42:46,392 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:42:46,392 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o .
2025-05-27 19:42:46,392 - INFO - joeynmt.training - Example #4
2025-05-27 19:42:46,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:42:46,393 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:42:46,393 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'la', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'el@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:42:46,393 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:42:46,393 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:42:46,393 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o la cosa che vi mostr<unk> @ o  una c<unk> @ el<unk> @ a che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:42:49,757 - INFO - joeynmt.training - Epoch   5, Step:    36600, Batch Loss:     1.007432, Batch Acc: 0.698927, Tokens per Sec:    19018, Lr: 0.000300
2025-05-27 19:42:53,097 - INFO - joeynmt.training - Epoch   5, Step:    36700, Batch Loss:     1.259095, Batch Acc: 0.697684, Tokens per Sec:    24399, Lr: 0.000300
2025-05-27 19:42:56,383 - INFO - joeynmt.training - Epoch   5, Step:    36800, Batch Loss:     1.031609, Batch Acc: 0.703178, Tokens per Sec:    24150, Lr: 0.000300
2025-05-27 19:42:59,703 - INFO - joeynmt.training - Epoch   5, Step:    36900, Batch Loss:     0.987558, Batch Acc: 0.704923, Tokens per Sec:    23708, Lr: 0.000300
2025-05-27 19:43:03,025 - INFO - joeynmt.training - Epoch   5, Step:    37000, Batch Loss:     1.015571, Batch Acc: 0.704313, Tokens per Sec:    24008, Lr: 0.000300
2025-05-27 19:43:03,026 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:43:03,026 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:43:18,413 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.03, ppl:   2.81, acc:   0.70, generation: 15.3744[sec], evaluation: 0.0000[sec]
2025-05-27 19:43:18,414 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:43:18,920 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/36000.ckpt
2025-05-27 19:43:18,946 - INFO - joeynmt.training - Example #0
2025-05-27 19:43:18,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:43:18,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:43:18,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'ti', 'per', 'fare', 'questo', 'f@@', '<unk>', '@', 'en@@', '<unk>', '@', 'om@@', '<unk>', '@', 'en@@', '<unk>', '@', 'o', 'che', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'il', 'li@@', '<unk>', '@', 'vello', 'di', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', 'ore', '.', '</s>']
2025-05-27 19:43:18,947 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:43:18,947 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:43:18,947 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ ti per fare questo f<unk> @ en<unk> @ om<unk> @ en<unk> @ o che la g<unk> @ hi<unk> @ ac<unk> @ cio per il li<unk> @ vello di ci<unk> @ b<unk> @ o di tre milioni di anni , per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 ore .
2025-05-27 19:43:18,947 - INFO - joeynmt.training - Example #1
2025-05-27 19:43:18,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:43:18,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:43:18,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 19:43:18,948 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:43:18,948 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:43:18,948 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza il ris<unk> @ ult<unk> @ ato di questa part<unk> @ icol<unk> @ are la di<unk> @ st<unk> @ anza di questa part<unk> @ icol<unk> @ are , non  il D<unk> @ ic<unk> @ io .
2025-05-27 19:43:18,948 - INFO - joeynmt.training - Example #2
2025-05-27 19:43:18,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:43:18,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:43:18,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'lin@@', '<unk>', '@', 'gu@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:43:18,949 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:43:18,949 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:43:18,949 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la lin<unk> @ gu<unk> @ a  la c<unk> @ li<unk> @ sta del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 19:43:18,949 - INFO - joeynmt.training - Example #3
2025-05-27 19:43:18,950 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:43:18,950 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:43:18,950 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ei', 'sc@@', '<unk>', '@', 'o@@', '<unk>', '@', 'pr@@', '<unk>', '@', 'ire', 'il', 'p@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:43:18,950 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:43:18,950 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:43:18,950 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ei sc<unk> @ o<unk> @ pr<unk> @ ire il p<unk> @ eg<unk> @ gi<unk> @ o .
2025-05-27 19:43:18,950 - INFO - joeynmt.training - Example #4
2025-05-27 19:43:18,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:43:18,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:43:18,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'queste', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:43:18,951 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:43:18,951 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:43:18,951 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ a una ser<unk> @ ie di queste sc<unk> @ or<unk> @ sa che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:43:22,313 - INFO - joeynmt.training - Epoch   5, Step:    37100, Batch Loss:     1.083645, Batch Acc: 0.703863, Tokens per Sec:    20257, Lr: 0.000300
2025-05-27 19:43:25,681 - INFO - joeynmt.training - Epoch   5, Step:    37200, Batch Loss:     0.944459, Batch Acc: 0.702090, Tokens per Sec:    22808, Lr: 0.000300
2025-05-27 19:43:29,078 - INFO - joeynmt.training - Epoch   5, Step:    37300, Batch Loss:     1.001483, Batch Acc: 0.703914, Tokens per Sec:    23641, Lr: 0.000300
2025-05-27 19:43:32,454 - INFO - joeynmt.training - Epoch   5, Step:    37400, Batch Loss:     1.101585, Batch Acc: 0.707795, Tokens per Sec:    23141, Lr: 0.000300
2025-05-27 19:43:35,844 - INFO - joeynmt.training - Epoch   5, Step:    37500, Batch Loss:     1.048201, Batch Acc: 0.708003, Tokens per Sec:    22921, Lr: 0.000300
2025-05-27 19:43:35,844 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:43:35,844 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:43:49,539 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.03, ppl:   2.80, acc:   0.70, generation: 13.6860[sec], evaluation: 0.0000[sec]
2025-05-27 19:43:49,540 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:43:50,010 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/35500.ckpt
2025-05-27 19:43:50,028 - INFO - joeynmt.training - Example #0
2025-05-27 19:43:50,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:43:50,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:43:50,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ami@@', '<unk>', '@', 'gl@@', '<unk>', '@', 'ie', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'le', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'azioni', 'che', 'hanno', 'fatto', 'per', 'un', 'c@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'hanno', 'fatto', 'per', 'la', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'anni', '.', '</s>']
2025-05-27 19:43:50,029 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:43:50,029 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:43:50,029 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato queste due f<unk> @ ami<unk> @ gl<unk> @ ie per ri<unk> @ dur<unk> @ re le p<unk> @ op<unk> @ ol<unk> @ azioni che hanno fatto per un c<unk> @ ac<unk> @ co di tre milioni di anni , che hanno fatto per la sc<unk> @ u<unk> @ ola che ha av<unk> @ uto il 4<unk> @ 8 anni , per il 4<unk> @ 8 anni , per il 4<unk> @ 8 anni , per il 4<unk> @ 8 anni .
2025-05-27 19:43:50,029 - INFO - joeynmt.training - Example #1
2025-05-27 19:43:50,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:43:50,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:43:50,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'il', 't@@', '<unk>', '@', 'as@@', '<unk>', '@', 'so', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'problema', 'di', 'essere', 'un', 'problema', 'di', 'probl@@', '<unk>', '@', 'emi', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'lo', '.', '</s>']
2025-05-27 19:43:50,030 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:43:50,030 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:43:50,030 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza il t<unk> @ as<unk> @ so di questo problema , non  il problema di essere un problema di probl<unk> @ emi spe<unk> @ ci<unk> @ ale , non  il d<unk> @ ic<unk> @ lo .
2025-05-27 19:43:50,030 - INFO - joeynmt.training - Example #2
2025-05-27 19:43:50,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:43:50,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:43:50,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'ca', 'di', 's@@', '<unk>', '@', 'otto', 'str@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ta', 'di', 'un', 'sistema', 'glob@@', '<unk>', '@', 'ale', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ita', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:43:50,031 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:43:50,031 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:43:50,031 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di s<unk> @ otto str<unk> @ at<unk> @ ta  la c<unk> @ li<unk> @ et<unk> @ ta di un sistema glob<unk> @ ale c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ita di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 19:43:50,031 - INFO - joeynmt.training - Example #3
2025-05-27 19:43:50,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:43:50,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:43:50,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', '', 'in', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'cosa', '.', '</s>']
2025-05-27 19:43:50,032 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:43:50,032 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:43:50,032 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @  in v<unk> @ ento e si tr<unk> @ at<unk> @ ta di una cosa .
2025-05-27 19:43:50,032 - INFO - joeynmt.training - Example #4
2025-05-27 19:43:50,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:43:50,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:43:50,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'qu@@', '<unk>', '@', 'ell&apos;', 'ulti@@', '<unk>', '@', 'mo', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:43:50,033 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:43:50,033 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:43:50,033 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a che  succ<unk> @ esso in qu<unk> @ ell&apos; ulti<unk> @ mo 2<unk> @ 5 anni .
2025-05-27 19:43:53,385 - INFO - joeynmt.training - Epoch   5, Step:    37600, Batch Loss:     0.966200, Batch Acc: 0.702517, Tokens per Sec:    20150, Lr: 0.000300
2025-05-27 19:43:56,764 - INFO - joeynmt.training - Epoch   5, Step:    37700, Batch Loss:     1.012017, Batch Acc: 0.706502, Tokens per Sec:    23394, Lr: 0.000300
2025-05-27 19:44:00,197 - INFO - joeynmt.training - Epoch   5, Step:    37800, Batch Loss:     0.911164, Batch Acc: 0.701971, Tokens per Sec:    22714, Lr: 0.000300
2025-05-27 19:44:03,741 - INFO - joeynmt.training - Epoch   5, Step:    37900, Batch Loss:     1.109449, Batch Acc: 0.703921, Tokens per Sec:    22311, Lr: 0.000300
2025-05-27 19:44:07,134 - INFO - joeynmt.training - Epoch   5, Step:    38000, Batch Loss:     0.994119, Batch Acc: 0.703855, Tokens per Sec:    23365, Lr: 0.000300
2025-05-27 19:44:07,134 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:44:07,135 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:44:23,966 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 16.8172[sec], evaluation: 0.0000[sec]
2025-05-27 19:44:23,970 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:44:24,537 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/34500.ckpt
2025-05-27 19:44:24,565 - INFO - joeynmt.training - Example #0
2025-05-27 19:44:24,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:44:24,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:44:24,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'ta', 'per', 'entr@@', '<unk>', '@', 'amb@@', '<unk>', '@', 'i', 'per', 'fare', 'due', 'di@@', '<unk>', '@', 'ta', 'per', 'cui', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', 'per', 'la', 'c@@', '<unk>', '@', 'att@@', '<unk>', '@', 'en@@', '<unk>', '@', 'zione', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'ha', 'fatto', 'per', 'la', 'loro', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', '%', 'del', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'per', 'c@@', '<unk>', '@', 'ento', 'di', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:44:24,568 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:44:24,568 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:44:24,568 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ta per entr<unk> @ amb<unk> @ i per fare due di<unk> @ ta per cui la p<unk> @ op<unk> @ ol<unk> @ i per la c<unk> @ att<unk> @ en<unk> @ zione di tre milioni di anni , che ha fatto per la loro c<unk> @ aus<unk> @ a di tre milioni di anni , per il 4<unk> @ 8 % del 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 per c<unk> @ ento di 4<unk> @ 8 % .
2025-05-27 19:44:24,568 - INFO - joeynmt.training - Example #1
2025-05-27 19:44:24,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:44:24,569 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:44:24,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'stato', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'ver@@', '<unk>', '@', 'it', 'di', 'questa', 'con@@', '<unk>', '@', 'v@@', '<unk>', '@', 'in@@', '<unk>', '@', 'zione', 'di', 'questo', 'problema', ',', 'non', '', 'la', 'd@@', '<unk>', '@', 'oc@@', '<unk>', '@', 'cia', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 19:44:24,569 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:44:24,569 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:44:24,569 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  stato abb<unk> @ ast<unk> @ anza for<unk> @ te , la ver<unk> @ it di questa con<unk> @ v<unk> @ in<unk> @ zione di questo problema , non  la d<unk> @ oc<unk> @ cia del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 19:44:24,569 - INFO - joeynmt.training - Example #2
2025-05-27 19:44:24,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:44:24,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:44:24,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'lin@@', '<unk>', '@', 'gu@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:44:24,570 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:44:24,570 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:44:24,570 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ gu<unk> @ a  la c<unk> @ li<unk> @ mat<unk> @ ica  la c<unk> @ li<unk> @ mat<unk> @ ica del nostro c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:44:24,570 - INFO - joeynmt.training - Example #3
2025-05-27 19:44:24,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:44:24,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:44:24,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'ento', 'e', 'in', 'b@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ag@@', '<unk>', '@', 'lia', '.', '</s>']
2025-05-27 19:44:24,571 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:44:24,571 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:44:24,571 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e in b<unk> @ att<unk> @ ag<unk> @ lia .
2025-05-27 19:44:24,571 - INFO - joeynmt.training - Example #4
2025-05-27 19:44:24,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:44:24,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:44:24,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', ',', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'delle', 'con@@', '<unk>', '@', 'v@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ta', 'di', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', '.', '</s>']
2025-05-27 19:44:24,572 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:44:24,572 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:44:24,572 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i , vi mostr<unk> @ er<unk> @   una delle con<unk> @ v<unk> @ in<unk> @ ta di una ser<unk> @ ie di c<unk> @ las<unk> @ se .
2025-05-27 19:44:27,974 - INFO - joeynmt.training - Epoch   5, Step:    38100, Batch Loss:     1.006528, Batch Acc: 0.703630, Tokens per Sec:    20032, Lr: 0.000300
2025-05-27 19:44:31,356 - INFO - joeynmt.training - Epoch   5, Step:    38200, Batch Loss:     1.104752, Batch Acc: 0.703352, Tokens per Sec:    23398, Lr: 0.000300
2025-05-27 19:44:34,710 - INFO - joeynmt.training - Epoch   5, Step:    38300, Batch Loss:     0.935929, Batch Acc: 0.704651, Tokens per Sec:    23473, Lr: 0.000300
2025-05-27 19:44:38,065 - INFO - joeynmt.training - Epoch   5, Step:    38400, Batch Loss:     0.931884, Batch Acc: 0.704325, Tokens per Sec:    23781, Lr: 0.000300
2025-05-27 19:44:41,379 - INFO - joeynmt.training - Epoch   5, Step:    38500, Batch Loss:     0.869940, Batch Acc: 0.707657, Tokens per Sec:    23604, Lr: 0.000300
2025-05-27 19:44:41,379 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:44:41,380 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:44:56,394 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.79, acc:   0.70, generation: 15.0056[sec], evaluation: 0.0000[sec]
2025-05-27 19:44:56,693 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/35000.ckpt
2025-05-27 19:44:56,716 - INFO - joeynmt.training - Example #0
2025-05-27 19:44:56,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:44:56,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:44:56,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'f@@', '<unk>', '@', 'ung@@', '<unk>', '@', 'hi', 'per', 'l&apos;', 'anno', ',', 'per', 'cui', 'l&apos;', 'eff@@', '<unk>', '@', 'etto', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'che', 'i', 'g@@', '<unk>', '@', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'chi@@', '<unk>', '@', 'a', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'due', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'anni', '.', '</s>']
2025-05-27 19:44:56,717 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:44:56,717 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:44:56,717 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due f<unk> @ ung<unk> @ hi per l&apos; anno , per cui l&apos; eff<unk> @ etto di c<unk> @ aus<unk> @ a che i g<unk> @ ar<unk> @ t<unk> @ ic<unk> @ chi<unk> @ a , per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 milioni di anni , per c<unk> @ ento di due mili<unk> @ ar<unk> @ di di anni .
2025-05-27 19:44:56,717 - INFO - joeynmt.training - Example #1
2025-05-27 19:44:56,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:44:56,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:44:56,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bil@@', '<unk>', '@', 'mente', 'la', 'di@@', '<unk>', '@', 'men@@', '<unk>', '@', 'sione', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:44:56,718 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:44:56,718 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:44:56,718 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ mente la di<unk> @ men<unk> @ sione di questo problema , non  il d<unk> @ ott<unk> @ ore di questo problema .
2025-05-27 19:44:56,718 - INFO - joeynmt.training - Example #2
2025-05-27 19:44:56,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:44:56,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:44:56,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'ca', 'di', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:44:56,719 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:44:56,719 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:44:56,719 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di sen<unk> @ so  la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a  la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a del nostro sistema glob<unk> @ ale .
2025-05-27 19:44:56,719 - INFO - joeynmt.training - Example #3
2025-05-27 19:44:56,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:44:56,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:44:56,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'la', 'v@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:44:56,720 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:44:56,720 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:44:56,720 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e la v<unk> @ ento .
2025-05-27 19:44:56,720 - INFO - joeynmt.training - Example #4
2025-05-27 19:44:56,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:44:56,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:44:56,721 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'u', 'la', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'u', 'una', 'ri@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'zione', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:44:56,721 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:44:56,721 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:44:56,721 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ u la pros<unk> @ si<unk> @ ma f<unk> @ u una ri<unk> @ ma<unk> @ zione che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:45:00,005 - INFO - joeynmt.training - Epoch   5, Step:    38600, Batch Loss:     1.148260, Batch Acc: 0.707450, Tokens per Sec:    21386, Lr: 0.000300
2025-05-27 19:45:03,355 - INFO - joeynmt.training - Epoch   5, Step:    38700, Batch Loss:     1.015639, Batch Acc: 0.704338, Tokens per Sec:    23687, Lr: 0.000300
2025-05-27 19:45:06,701 - INFO - joeynmt.training - Epoch   5, Step:    38800, Batch Loss:     1.010447, Batch Acc: 0.703564, Tokens per Sec:    23924, Lr: 0.000300
2025-05-27 19:45:10,039 - INFO - joeynmt.training - Epoch   5, Step:    38900, Batch Loss:     1.034839, Batch Acc: 0.706106, Tokens per Sec:    23627, Lr: 0.000300
2025-05-27 19:45:13,372 - INFO - joeynmt.training - Epoch   5, Step:    39000, Batch Loss:     1.021238, Batch Acc: 0.711367, Tokens per Sec:    23788, Lr: 0.000300
2025-05-27 19:45:13,372 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:45:13,372 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:45:27,289 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 13.9078[sec], evaluation: 0.0000[sec]
2025-05-27 19:45:27,289 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:45:27,732 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/36500.ckpt
2025-05-27 19:45:27,751 - INFO - joeynmt.training - Example #0
2025-05-27 19:45:27,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:45:27,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:45:27,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ami@@', '<unk>', '@', 'gl@@', '<unk>', '@', 'ie', 'per', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ere', 'che', 'i', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'ni', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'gli', 'in@@', '<unk>', '@', 'segn@@', '<unk>', '@', 'ano', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'qu@@', '<unk>', '@', 'at@@', '<unk>', '@', 'tro', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:45:27,752 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:45:27,752 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:45:27,752 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ ami<unk> @ gl<unk> @ ie per sc<unk> @ or<unk> @ r<unk> @ ere che i g<unk> @ over<unk> @ ni di g<unk> @ hi<unk> @ ac<unk> @ cio che gli in<unk> @ segn<unk> @ ano per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 per c<unk> @ ento di qu<unk> @ at<unk> @ tro m<unk> @ oti<unk> @ vi per il 4<unk> @ 0 % .
2025-05-27 19:45:27,752 - INFO - joeynmt.training - Example #1
2025-05-27 19:45:27,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:45:27,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:45:27,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 't@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'r@@', '<unk>', '@', 'are', 'la', 'cap@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'it', 'di', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', 'questo', 'problema', ',', 'non', '', 'che', 'la', 'de@@', '<unk>', '@', 'fin@@', '<unk>', '@', 'ita', 'del', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'one', '.', '</s>']
2025-05-27 19:45:27,753 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:45:27,753 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:45:27,753 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ t<unk> @ eg<unk> @ r<unk> @ are la cap<unk> @ ac<unk> @ it di ris<unk> @ ol<unk> @ vere questo problema , non  che la de<unk> @ fin<unk> @ ita del D<unk> @ ic<unk> @ one .
2025-05-27 19:45:27,753 - INFO - joeynmt.training - Example #2
2025-05-27 19:45:27,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:45:27,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:45:27,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'ca', 'di', 's@@', '<unk>', '@', '', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'ma', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'mo', '.', '</s>']
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di s<unk> @  , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ mo .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - Example #3
2025-05-27 19:45:27,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:45:27,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:45:27,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'ano', 'in', 'un', 'peri@@', '<unk>', '@', 'o@@', '<unk>', '@', 'do', '.', '</s>']
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e si sp<unk> @ ost<unk> @ ano in un peri<unk> @ o<unk> @ do .
2025-05-27 19:45:27,755 - INFO - joeynmt.training - Example #4
2025-05-27 19:45:27,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:45:27,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:45:27,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'av@@', '<unk>', '@', 'ore', ',', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'st@@', '<unk>', '@', 'anza', 'di', 'con@@', '<unk>', '@', 'v@@', '<unk>', '@', 'in@@', '<unk>', '@', 'zione', 'che', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:45:27,755 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:45:27,755 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:45:27,755 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ av<unk> @ ore , che vi mostr<unk> @ er<unk> @   una st<unk> @ anza di con<unk> @ v<unk> @ in<unk> @ zione che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:45:31,068 - INFO - joeynmt.training - Epoch   5, Step:    39100, Batch Loss:     0.973794, Batch Acc: 0.703697, Tokens per Sec:    21059, Lr: 0.000300
2025-05-27 19:45:34,411 - INFO - joeynmt.training - Epoch   5, Step:    39200, Batch Loss:     1.020282, Batch Acc: 0.704406, Tokens per Sec:    24182, Lr: 0.000300
2025-05-27 19:45:37,765 - INFO - joeynmt.training - Epoch   5, Step:    39300, Batch Loss:     0.906127, Batch Acc: 0.707566, Tokens per Sec:    24230, Lr: 0.000300
2025-05-27 19:45:40,288 - INFO - joeynmt.training - Epoch   5: total training loss 8075.49
2025-05-27 19:45:40,288 - INFO - joeynmt.training - EPOCH 6
2025-05-27 19:45:41,103 - INFO - joeynmt.training - Epoch   6, Step:    39400, Batch Loss:     0.915078, Batch Acc: 0.714096, Tokens per Sec:    25031, Lr: 0.000300
2025-05-27 19:45:44,441 - INFO - joeynmt.training - Epoch   6, Step:    39500, Batch Loss:     1.075939, Batch Acc: 0.713132, Tokens per Sec:    23049, Lr: 0.000300
2025-05-27 19:45:44,441 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:45:44,441 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:45:59,831 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 15.3809[sec], evaluation: 0.0000[sec]
2025-05-27 19:45:59,831 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:46:00,291 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/37000.ckpt
2025-05-27 19:46:00,315 - INFO - joeynmt.training - Example #0
2025-05-27 19:46:00,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:46:00,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:46:00,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'li', 'ulti@@', '<unk>', '@', 'mi', 'sono', 'mostr@@', '<unk>', '@', 'ato', 'per', 'ri@@', '<unk>', '@', 'vel@@', '<unk>', '@', 'are', 'i', 'due', 'o', 'i', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'i', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ali', 'che', 'gli', 'u@@', '<unk>', '@', 'is@@', '<unk>', '@', 'c@@', '<unk>', '@', 'atori', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'i', 'qual@@', '<unk>', '@', 'i', 'aveva', 'tre', 'milioni', 'di', 'persone', 'che', 'aveva', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'persone', 'che', 'aveva', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:46:00,316 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:46:00,316 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ eg<unk> @ li ulti<unk> @ mi sono mostr<unk> @ ato per ri<unk> @ vel<unk> @ are i due o i p<unk> @ ezz<unk> @ i di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ali che gli u<unk> @ is<unk> @ c<unk> @ atori di g<unk> @ hi<unk> @ ac<unk> @ cio per i qual<unk> @ i aveva tre milioni di persone che aveva fatto per il 4<unk> @ 8 milioni di persone che aveva av<unk> @ uto il 4<unk> @ 0 % .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - Example #1
2025-05-27 19:46:00,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:46:00,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:46:00,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'della', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'olo', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 19:46:00,317 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza della giu<unk> @ st<unk> @ izi<unk> @ a , perch non  il D<unk> @ ic<unk> @ olo del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - Example #2
2025-05-27 19:46:00,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:46:00,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:46:00,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'ca', 'di', 'sin@@', '<unk>', '@', 'g@@', '<unk>', '@', 'olo', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:46:00,318 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:46:00,318 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:46:00,318 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di sin<unk> @ g<unk> @ olo , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:46:00,318 - INFO - joeynmt.training - Example #3
2025-05-27 19:46:00,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:46:00,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:46:00,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'anno', 'in', 'v@@', '<unk>', '@', 'it@@', '<unk>', '@', 'tor@@', '<unk>', '@', 'no', 'al', 'v@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:46:00,319 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:46:00,319 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:46:00,319 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ anno in v<unk> @ it<unk> @ tor<unk> @ no al v<unk> @ ento .
2025-05-27 19:46:00,319 - INFO - joeynmt.training - Example #4
2025-05-27 19:46:00,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:46:00,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:46:00,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ra@@', '<unk>', '@', 'ff@@', '<unk>', '@', 'a', ',', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'qu@@', '<unk>', '@', 'ale', 'succ@@', '<unk>', '@', 'essi@@', '<unk>', '@', 'vo', '.', '</s>']
2025-05-27 19:46:00,320 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:46:00,320 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:46:00,320 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ ra<unk> @ ff<unk> @ a , una c<unk> @ en<unk> @ a che  succ<unk> @ esso in qu<unk> @ ale succ<unk> @ essi<unk> @ vo .
2025-05-27 19:46:03,553 - INFO - joeynmt.training - Epoch   6, Step:    39600, Batch Loss:     0.956309, Batch Acc: 0.715008, Tokens per Sec:    21420, Lr: 0.000300
2025-05-27 19:46:06,806 - INFO - joeynmt.training - Epoch   6, Step:    39700, Batch Loss:     1.081409, Batch Acc: 0.714331, Tokens per Sec:    24310, Lr: 0.000300
2025-05-27 19:46:10,056 - INFO - joeynmt.training - Epoch   6, Step:    39800, Batch Loss:     0.977097, Batch Acc: 0.710388, Tokens per Sec:    24306, Lr: 0.000300
2025-05-27 19:46:13,304 - INFO - joeynmt.training - Epoch   6, Step:    39900, Batch Loss:     0.945780, Batch Acc: 0.716647, Tokens per Sec:    25225, Lr: 0.000300
2025-05-27 19:46:16,384 - INFO - joeynmt.training - Epoch   6, Step:    40000, Batch Loss:     0.970733, Batch Acc: 0.716024, Tokens per Sec:    25176, Lr: 0.000300
2025-05-27 19:46:16,384 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:46:16,385 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:46:31,099 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.77, acc:   0.71, generation: 14.7009[sec], evaluation: 0.0000[sec]
2025-05-27 19:46:31,100 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:46:31,591 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/37500.ckpt
2025-05-27 19:46:31,615 - INFO - joeynmt.training - Example #0
2025-05-27 19:46:31,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:46:31,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:46:31,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', 'questi', 'due', 'di@@', '<unk>', '@', 'f@@', '<unk>', '@', 'en@@', '<unk>', '@', 'om@@', '<unk>', '@', 'en@@', '<unk>', '@', 'i', 'che', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'azione', 'per', 'la', 'sc@@', '<unk>', '@', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ica', 'che', 'la', 'chiam@@', '<unk>', '@', 'ata', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'c@@', '<unk>', '@', 'app@@', '<unk>', '@', 'e', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:46:31,616 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:46:31,616 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:46:31,616 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno questi due di<unk> @ f<unk> @ en<unk> @ om<unk> @ en<unk> @ i che la p<unk> @ op<unk> @ ol<unk> @ azione per la sc<unk> @ ar<unk> @ t<unk> @ ica che la chiam<unk> @ ata E<unk> @ is<unk> @ c<unk> @ app<unk> @ e che ha av<unk> @ uto i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 , il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 19:46:31,616 - INFO - joeynmt.training - Example #1
2025-05-27 19:46:31,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:46:31,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:46:31,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 't@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'r@@', '<unk>', '@', 'it', 'di', 'questi', 'probl@@', '<unk>', '@', 'emi', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ali', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'almente', 'il', 'problema', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'es', '.', '</s>']
2025-05-27 19:46:31,617 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:46:31,617 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:46:31,617 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza in<unk> @ t<unk> @ eg<unk> @ r<unk> @ it di questi probl<unk> @ emi spe<unk> @ ci<unk> @ ali spe<unk> @ ci<unk> @ almente il problema di E<unk> @ is<unk> @ es .
2025-05-27 19:46:31,617 - INFO - joeynmt.training - Example #2
2025-05-27 19:46:31,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:46:31,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:46:31,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'ca', 'di', 's@@', '<unk>', '@', '', ',', 'la', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', '', 'la', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:46:31,618 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:46:31,618 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:46:31,618 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di s<unk> @  , la c<unk> @ las<unk> @ se  la c<unk> @ las<unk> @ se  la c<unk> @ aus<unk> @ a del nostro sistema glob<unk> @ ale .
2025-05-27 19:46:31,618 - INFO - joeynmt.training - Example #3
2025-05-27 19:46:31,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:46:31,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:46:31,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'v@@', '<unk>', '@', 'ento', 'e', 'sp@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 19:46:31,619 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:46:31,619 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:46:31,619 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e sp<unk> @ esso .
2025-05-27 19:46:31,619 - INFO - joeynmt.training - Example #4
2025-05-27 19:46:31,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:46:31,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:46:31,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ero', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'di@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'enza', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:46:31,620 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:46:31,620 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:46:31,620 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ ero che vi mostr<unk> @ o  una ser<unk> @ ie di di<unk> @ f<unk> @ lu<unk> @ enza che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:46:34,796 - INFO - joeynmt.training - Epoch   6, Step:    40100, Batch Loss:     0.975426, Batch Acc: 0.708260, Tokens per Sec:    20766, Lr: 0.000300
2025-05-27 19:46:37,982 - INFO - joeynmt.training - Epoch   6, Step:    40200, Batch Loss:     0.932832, Batch Acc: 0.714145, Tokens per Sec:    25258, Lr: 0.000300
2025-05-27 19:46:41,161 - INFO - joeynmt.training - Epoch   6, Step:    40300, Batch Loss:     0.993497, Batch Acc: 0.711992, Tokens per Sec:    24225, Lr: 0.000300
2025-05-27 19:46:44,357 - INFO - joeynmt.training - Epoch   6, Step:    40400, Batch Loss:     0.946739, Batch Acc: 0.712467, Tokens per Sec:    25156, Lr: 0.000300
2025-05-27 19:46:47,541 - INFO - joeynmt.training - Epoch   6, Step:    40500, Batch Loss:     0.920450, Batch Acc: 0.710537, Tokens per Sec:    24728, Lr: 0.000300
2025-05-27 19:46:47,542 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:46:47,542 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:47:03,242 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 15.6912[sec], evaluation: 0.0000[sec]
2025-05-27 19:47:03,670 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/38500.ckpt
2025-05-27 19:47:03,692 - INFO - joeynmt.training - Example #0
2025-05-27 19:47:03,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:47:03,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:47:03,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'due', 'f@@', '<unk>', '@', 'anno', 'per', 'fare', 'la', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'per', 'la', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'per', 'i', 'g@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'g@@', '<unk>', '@', 'etti', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'a@@', '<unk>', '@', 'io', ',', 'per', 'i', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', '4@@', '<unk>', '@', '8', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', '4@@', '<unk>', '@', '8', 'anni', '.', '</s>']
2025-05-27 19:47:03,693 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:47:03,694 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:47:03,694 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questa due f<unk> @ anno per fare la f<unk> @ am<unk> @ ig<unk> @ lia per la f<unk> @ am<unk> @ ig<unk> @ lia per i g<unk> @ ri<unk> @ g<unk> @ etti , che aveva tre milioni di anni , per i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io , per i 4<unk> @ 8 anni , per 4<unk> @ 8 , per c<unk> @ ento , per 4<unk> @ 8 anni .
2025-05-27 19:47:03,694 - INFO - joeynmt.training - Example #1
2025-05-27 19:47:03,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:47:03,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:47:03,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ha@@', '<unk>', '@', 'i', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ato', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 19:47:03,694 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:47:03,694 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:47:03,695 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la di<unk> @ st<unk> @ ha<unk> @ i questo problema spe<unk> @ ci<unk> @ ale , non  il d<unk> @ ato di questo problema .
2025-05-27 19:47:03,695 - INFO - joeynmt.training - Example #2
2025-05-27 19:47:03,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:47:03,695 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:47:03,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'cosa', 'pi', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'ma', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'del', 'nostro', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:47:03,696 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:47:03,696 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:47:03,696 - INFO - joeynmt.training - 	Hypothesis: In sen<unk> @ so , la cosa pi in<unk> @ ten<unk> @ zione  la c<unk> @ li<unk> @ sta del sistema di c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma  il cu<unk> @ ore del nostro sistema di c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma .
2025-05-27 19:47:03,696 - INFO - joeynmt.training - Example #3
2025-05-27 19:47:03,696 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:47:03,696 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:47:03,696 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'inter@@', '<unk>', '@', 'no', 'e', 'si', 'trov@@', '<unk>', '@', 'a', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 19:47:03,696 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un inter<unk> @ no e si trov<unk> @ a in est<unk> @ ate .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - Example #4
2025-05-27 19:47:03,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:47:03,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:47:03,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'anno', 'la', 'mia', 'prima', 'f@@', '<unk>', '@', 'est@@', '<unk>', '@', 'a', ',', '', 'una', 'c@@', '<unk>', '@', 'ura', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'ri@@', '<unk>', '@', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ anno la mia prima f<unk> @ est<unk> @ a ,  una c<unk> @ ura che vi mostr<unk> @ o  una ser<unk> @ ie di ri<unk> @ g<unk> @ am<unk> @ be , che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:47:06,905 - INFO - joeynmt.training - Epoch   6, Step:    40600, Batch Loss:     0.923593, Batch Acc: 0.714932, Tokens per Sec:    22023, Lr: 0.000300
2025-05-27 19:47:10,198 - INFO - joeynmt.training - Epoch   6, Step:    40700, Batch Loss:     0.939308, Batch Acc: 0.711349, Tokens per Sec:    24566, Lr: 0.000300
2025-05-27 19:47:13,516 - INFO - joeynmt.training - Epoch   6, Step:    40800, Batch Loss:     0.911384, Batch Acc: 0.708633, Tokens per Sec:    23838, Lr: 0.000300
2025-05-27 19:47:16,851 - INFO - joeynmt.training - Epoch   6, Step:    40900, Batch Loss:     0.913877, Batch Acc: 0.713175, Tokens per Sec:    24466, Lr: 0.000300
2025-05-27 19:47:20,154 - INFO - joeynmt.training - Epoch   6, Step:    41000, Batch Loss:     0.982886, Batch Acc: 0.711012, Tokens per Sec:    23576, Lr: 0.000300
2025-05-27 19:47:20,154 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:47:20,154 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:47:36,589 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.70, generation: 16.4217[sec], evaluation: 0.0000[sec]
2025-05-27 19:47:36,936 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/38000.ckpt
2025-05-27 19:47:36,962 - INFO - joeynmt.training - Example #0
2025-05-27 19:47:36,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:47:36,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:47:36,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'att@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ie', 'per', 's@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'are', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'la', 'qu@@', '<unk>', '@', 'ale', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', 'per', 'cui', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'la', 'rag@@', '<unk>', '@', 'ione', 'per', 'cui', 'aveva', '1@@', '<unk>', '@', '3', 'milioni', 'di', 'anni', ',', 'per', 'cui', 'aveva', '4@@', '<unk>', '@', '0', ',', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:47:36,964 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:47:36,964 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:47:36,964 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ att<unk> @ or<unk> @ ie per s<unk> @ ent<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio per la qu<unk> @ ale di m<unk> @ oti<unk> @ vo per cui aveva tre milioni di anni , per la rag<unk> @ ione per cui aveva 1<unk> @ 3 milioni di anni , per cui aveva 4<unk> @ 0 , aveva tre milioni di anni , per c<unk> @ ento per c<unk> @ ento , per c<unk> @ ento .
2025-05-27 19:47:36,964 - INFO - joeynmt.training - Example #1
2025-05-27 19:47:36,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:47:36,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:47:36,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'ver@@', '<unk>', '@', 'it', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ato', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'lo', '.', '</s>']
2025-05-27 19:47:36,965 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:47:36,965 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:47:36,965 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la ver<unk> @ it non  abb<unk> @ ast<unk> @ anza , perch non  il d<unk> @ ato di questo problema , non  il d<unk> @ ic<unk> @ lo .
2025-05-27 19:47:36,965 - INFO - joeynmt.training - Example #2
2025-05-27 19:47:36,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:47:36,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:47:36,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'lin@@', '<unk>', '@', 'ea', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'em@@', '<unk>', '@', 'er@@', '<unk>', '@', 'gen@@', '<unk>', '@', 'za', ',', 'il', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:47:36,966 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:47:36,966 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:47:36,966 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ ea  la c<unk> @ atti<unk> @ va em<unk> @ er<unk> @ gen<unk> @ za , il nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 19:47:36,967 - INFO - joeynmt.training - Example #3
2025-05-27 19:47:36,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:47:36,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:47:36,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'v@@', '<unk>', '@', 'ento', 'e', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'o', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 19:47:36,967 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:47:36,967 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:47:36,967 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e p<unk> @ es<unk> @ o in est<unk> @ ate .
2025-05-27 19:47:36,967 - INFO - joeynmt.training - Example #4
2025-05-27 19:47:36,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:47:36,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:47:36,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'lin@@', '<unk>', '@', 'ea', 'di', 'ri@@', '<unk>', '@', 'vi@@', '<unk>', '@', 'sta', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:47:36,968 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:47:36,968 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:47:36,968 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ er<unk> @   una lin<unk> @ ea di ri<unk> @ vi<unk> @ sta che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:47:40,314 - INFO - joeynmt.training - Epoch   6, Step:    41100, Batch Loss:     0.973762, Batch Acc: 0.708386, Tokens per Sec:    21105, Lr: 0.000300
2025-05-27 19:47:43,620 - INFO - joeynmt.training - Epoch   6, Step:    41200, Batch Loss:     1.102358, Batch Acc: 0.715113, Tokens per Sec:    23920, Lr: 0.000300
2025-05-27 19:47:46,923 - INFO - joeynmt.training - Epoch   6, Step:    41300, Batch Loss:     0.992423, Batch Acc: 0.713868, Tokens per Sec:    23942, Lr: 0.000300
2025-05-27 19:47:50,224 - INFO - joeynmt.training - Epoch   6, Step:    41400, Batch Loss:     1.018340, Batch Acc: 0.710152, Tokens per Sec:    23339, Lr: 0.000300
2025-05-27 19:47:53,556 - INFO - joeynmt.training - Epoch   6, Step:    41500, Batch Loss:     0.889909, Batch Acc: 0.708863, Tokens per Sec:    24323, Lr: 0.000300
2025-05-27 19:47:53,556 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:47:53,556 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:48:08,860 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.77, acc:   0.71, generation: 15.2914[sec], evaluation: 0.0000[sec]
2025-05-27 19:48:09,334 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/41000.ckpt
2025-05-27 19:48:09,357 - INFO - joeynmt.training - Example #0
2025-05-27 19:48:09,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:48:09,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:48:09,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', ',', 'per', 'cui', '', 'stato', 'in@@', '<unk>', '@', 'segn@@', '<unk>', '@', 'ato', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'il', 'fatto', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'il', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ano', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', '4@@', '<unk>', '@', '8', '%', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', '4@@', '<unk>', '@', '0', '%', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:48:09,358 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:48:09,359 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:48:09,359 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose , per cui  stato in<unk> @ segn<unk> @ ato per ri<unk> @ dur<unk> @ re il fatto che il g<unk> @ hi<unk> @ ac<unk> @ cio , che il p<unk> @ es<unk> @ c<unk> @ ano per i 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per 4<unk> @ 8 % , per c<unk> @ ento , 4<unk> @ 0 % , per c<unk> @ ento , il 4<unk> @ 0 % di c<unk> @ ento .
2025-05-27 19:48:09,359 - INFO - joeynmt.training - Example #1
2025-05-27 19:48:09,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:48:09,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:48:09,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'enza', ',', 'il', 'problema', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ito', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'qu@@', '<unk>', '@', 'i@@', '<unk>', '@', 'v@@', '<unk>', '@', 'ale', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:48:09,360 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:48:09,360 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:48:09,360 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza di in<unk> @ f<unk> @ lu<unk> @ enza , il problema di E<unk> @ is<unk> @ c<unk> @ ito non  il D<unk> @ ic<unk> @ e<unk> @ qu<unk> @ i<unk> @ v<unk> @ ale non  il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:48:09,360 - INFO - joeynmt.training - Example #2
2025-05-27 19:48:09,360 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:48:09,360 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:48:09,360 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'lin@@', '<unk>', '@', 'ea', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', 'di', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:48:09,361 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:48:09,361 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:48:09,361 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ ea in<unk> @ ten<unk> @ zione di ci<unk> @ b<unk> @ o , il cu<unk> @ ore glob<unk> @ ale  il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:48:09,361 - INFO - joeynmt.training - Example #3
2025-05-27 19:48:09,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:48:09,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:48:09,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'po', '&apos;', 'di', 'p@@', '<unk>', '@', 'oco', 'di', 'v@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 19:48:09,361 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un po &apos; di p<unk> @ oco di v<unk> @ in<unk> @ ver<unk> @ no .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - Example #4
2025-05-27 19:48:09,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:48:09,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:48:09,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'un', 'cer@@', '<unk>', '@', 'to', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una ser<unk> @ ie di sc<unk> @ or<unk> @ so che  succ<unk> @ esso in un cer<unk> @ to di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:48:12,718 - INFO - joeynmt.training - Epoch   6, Step:    41600, Batch Loss:     0.920644, Batch Acc: 0.712992, Tokens per Sec:    21069, Lr: 0.000300
2025-05-27 19:48:16,051 - INFO - joeynmt.training - Epoch   6, Step:    41700, Batch Loss:     0.904138, Batch Acc: 0.709555, Tokens per Sec:    23500, Lr: 0.000300
2025-05-27 19:48:19,380 - INFO - joeynmt.training - Epoch   6, Step:    41800, Batch Loss:     0.982042, Batch Acc: 0.709775, Tokens per Sec:    24247, Lr: 0.000300
2025-05-27 19:48:22,712 - INFO - joeynmt.training - Epoch   6, Step:    41900, Batch Loss:     0.961464, Batch Acc: 0.711346, Tokens per Sec:    23931, Lr: 0.000300
2025-05-27 19:48:26,040 - INFO - joeynmt.training - Epoch   6, Step:    42000, Batch Loss:     1.056597, Batch Acc: 0.715668, Tokens per Sec:    23975, Lr: 0.000300
2025-05-27 19:48:26,041 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:48:26,041 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:48:40,525 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.77, acc:   0.71, generation: 14.4710[sec], evaluation: 0.0000[sec]
2025-05-27 19:48:40,526 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:48:41,035 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/40500.ckpt
2025-05-27 19:48:41,060 - INFO - joeynmt.training - Example #0
2025-05-27 19:48:41,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:48:41,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:48:41,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'sono', 'entr@@', '<unk>', '@', 'amb@@', '<unk>', '@', 'i', 'per', 'ri@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'im@@', '<unk>', '@', 'enti', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'ici', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'ici', 'che', 'gli', 'an@@', '<unk>', '@', 'ti@@', '<unk>', '@', 'chi', 'di', 'qu@@', '<unk>', '@', 'elli', 'che', 'hanno', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', 'per', 'il', '4@@', '<unk>', '@', '8', 'ore', 'del', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:48:41,062 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:48:41,062 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:48:41,062 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due sono entr<unk> @ amb<unk> @ i per ri<unk> @ fer<unk> @ im<unk> @ enti che gli ar<unk> @ t<unk> @ t<unk> @ ici che gli ar<unk> @ t<unk> @ t<unk> @ ici che gli an<unk> @ ti<unk> @ chi di qu<unk> @ elli che hanno sc<unk> @ oper<unk> @ to per il 4<unk> @ 8 ore del 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 19:48:41,062 - INFO - joeynmt.training - Example #1
2025-05-27 19:48:41,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:48:41,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:48:41,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bile', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'azione', 'di', 'questo', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:48:41,063 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:48:41,063 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:48:41,063 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ cre<unk> @ di<unk> @ bile la di<unk> @ st<unk> @ azione di questo spe<unk> @ ci<unk> @ f<unk> @ ico non  il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 19:48:41,063 - INFO - joeynmt.training - Example #2
2025-05-27 19:48:41,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:48:41,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:48:41,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', '', 'la', 'str@@', '<unk>', '@', 'utt@@', '<unk>', '@', 'ura', 'del', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:48:41,064 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:48:41,064 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:48:41,064 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa in<unk> @ ten<unk> @ zione  la str<unk> @ utt<unk> @ ura del sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a del nostro sistema glob<unk> @ ale .
2025-05-27 19:48:41,064 - INFO - joeynmt.training - Example #3
2025-05-27 19:48:41,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:48:41,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:48:41,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'v@@', '<unk>', '@', 'ento', 'e', 'p@@', '<unk>', '@', 'oco', ',', 'e', 'sp@@', '<unk>', '@', 'esso', ',', 'il', 'v@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:48:41,065 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:48:41,065 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:48:41,065 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e p<unk> @ oco , e sp<unk> @ esso , il v<unk> @ ento .
2025-05-27 19:48:41,065 - INFO - joeynmt.training - Example #4
2025-05-27 19:48:41,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:48:41,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:48:41,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:48:41,065 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:48:41,066 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:48:41,066 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una c<unk> @ en<unk> @ a che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:48:44,433 - INFO - joeynmt.training - Epoch   6, Step:    42100, Batch Loss:     0.988765, Batch Acc: 0.711307, Tokens per Sec:    20686, Lr: 0.000300
2025-05-27 19:48:47,774 - INFO - joeynmt.training - Epoch   6, Step:    42200, Batch Loss:     1.002575, Batch Acc: 0.711778, Tokens per Sec:    24188, Lr: 0.000300
2025-05-27 19:48:51,113 - INFO - joeynmt.training - Epoch   6, Step:    42300, Batch Loss:     0.840640, Batch Acc: 0.711487, Tokens per Sec:    24413, Lr: 0.000300
2025-05-27 19:48:54,424 - INFO - joeynmt.training - Epoch   6, Step:    42400, Batch Loss:     1.033729, Batch Acc: 0.711376, Tokens per Sec:    23645, Lr: 0.000300
2025-05-27 19:48:57,742 - INFO - joeynmt.training - Epoch   6, Step:    42500, Batch Loss:     0.964622, Batch Acc: 0.710679, Tokens per Sec:    23429, Lr: 0.000300
2025-05-27 19:48:57,743 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:48:57,743 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:49:11,815 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 14.0638[sec], evaluation: 0.0000[sec]
2025-05-27 19:49:11,815 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:49:12,281 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/39000.ckpt
2025-05-27 19:49:12,297 - INFO - joeynmt.training - Example #0
2025-05-27 19:49:12,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:49:12,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:49:12,298 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', ',', 'per', 'cerc@@', '<unk>', '@', 'are', 'di', 'con@@', '<unk>', '@', 'to', 'che', 'le', 'cose', 'f@@', '<unk>', '@', 'ami@@', '<unk>', '@', 'gl@@', '<unk>', '@', 'ie', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'are', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:49:12,299 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:49:12,299 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:49:12,299 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i , per cerc<unk> @ are di con<unk> @ to che le cose f<unk> @ ami<unk> @ gl<unk> @ ie c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are i 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per il 4<unk> @ 0 % .
2025-05-27 19:49:12,299 - INFO - joeynmt.training - Example #1
2025-05-27 19:49:12,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:49:12,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:49:12,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'di', 'tutto', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'la', 'de@@', '<unk>', '@', 'fin@@', '<unk>', '@', 'i@@', '<unk>', '@', 'zione', 'dell&apos;', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'es', '.', '</s>']
2025-05-27 19:49:12,300 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:49:12,300 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:49:12,300 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza di tutto il ris<unk> @ ult<unk> @ ato di questo problema , perch non  la de<unk> @ fin<unk> @ i<unk> @ zione dell&apos; E<unk> @ is<unk> @ es .
2025-05-27 19:49:12,300 - INFO - joeynmt.training - Example #2
2025-05-27 19:49:12,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:49:12,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:49:12,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'grande', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:49:12,301 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:49:12,301 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:49:12,301 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi grande in<unk> @ ten<unk> @ zione  la c<unk> @ li<unk> @ sta del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a del nostro sistema glob<unk> @ ale .
2025-05-27 19:49:12,301 - INFO - joeynmt.training - Example #3
2025-05-27 19:49:12,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:49:12,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:49:12,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'v@@', '<unk>', '@', 'ento', 'e', 'la', 'v@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:49:12,302 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:49:12,302 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:49:12,302 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e la v<unk> @ ento .
2025-05-27 19:49:12,302 - INFO - joeynmt.training - Example #4
2025-05-27 19:49:12,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:49:12,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:49:12,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'cosa', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'qu@@', '<unk>', '@', 'ale', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:49:12,303 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:49:12,303 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:49:12,303 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa vi mostr<unk> @ er<unk> @   una c<unk> @ aus<unk> @ a di cosa  succ<unk> @ esso in qu<unk> @ ale  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:49:15,670 - INFO - joeynmt.training - Epoch   6, Step:    42600, Batch Loss:     1.018079, Batch Acc: 0.712480, Tokens per Sec:    20769, Lr: 0.000300
2025-05-27 19:49:19,036 - INFO - joeynmt.training - Epoch   6, Step:    42700, Batch Loss:     0.987539, Batch Acc: 0.712018, Tokens per Sec:    24069, Lr: 0.000300
2025-05-27 19:49:22,381 - INFO - joeynmt.training - Epoch   6, Step:    42800, Batch Loss:     0.902094, Batch Acc: 0.712251, Tokens per Sec:    23621, Lr: 0.000300
2025-05-27 19:49:25,708 - INFO - joeynmt.training - Epoch   6, Step:    42900, Batch Loss:     1.018026, Batch Acc: 0.712610, Tokens per Sec:    23474, Lr: 0.000300
2025-05-27 19:49:29,064 - INFO - joeynmt.training - Epoch   6, Step:    43000, Batch Loss:     0.835032, Batch Acc: 0.713454, Tokens per Sec:    23794, Lr: 0.000300
2025-05-27 19:49:29,064 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:49:29,065 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:49:43,321 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 14.2478[sec], evaluation: 0.0000[sec]
2025-05-27 19:49:43,321 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:49:43,790 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/39500.ckpt
2025-05-27 19:49:43,813 - INFO - joeynmt.training - Example #0
2025-05-27 19:49:43,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:49:43,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:49:43,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'due', 'cas@@', '<unk>', '@', 'e', ',', 'per', 'arriv@@', '<unk>', '@', 'are', 'a', 'fare', 'due', 'cas@@', '<unk>', '@', 'e', 'di', 'pr@@', '<unk>', '@', 'on@@', '<unk>', '@', 'ti', 'che', 'i', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', 'le', 'cose', 'che', 'hanno', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', 'il', '4@@', '<unk>', '@', '8', '%', 'di', 'qu@@', '<unk>', '@', '4@@', '<unk>', '@', '8', '%', 'di', 'qu@@', '<unk>', '@', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:49:43,814 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:49:43,814 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:49:43,814 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due due cas<unk> @ e , per arriv<unk> @ are a fare due cas<unk> @ e di pr<unk> @ on<unk> @ ti che i g<unk> @ am<unk> @ be le cose che hanno fatto per il 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , per i 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , per c<unk> @ ento , per il 4<unk> @ 8 % di qu<unk> @ 4<unk> @ 8 % di qu<unk> @ 4<unk> @ 8 % .
2025-05-27 19:49:43,814 - INFO - joeynmt.training - Example #1
2025-05-27 19:49:43,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:49:43,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:49:43,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', ',', 'perch', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bil@@', '<unk>', '@', 'it', 'di', 'probl@@', '<unk>', '@', 'emi', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:49:43,815 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:49:43,815 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:49:43,815 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza , perch non  abb<unk> @ ast<unk> @ anza in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ it di probl<unk> @ emi , perch non  il d<unk> @ ott<unk> @ ore di E<unk> @ is<unk> @ s<unk> @ ore .
2025-05-27 19:49:43,815 - INFO - joeynmt.training - Example #2
2025-05-27 19:49:43,816 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:49:43,816 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:49:43,816 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sen@@', '<unk>', '@', 'so', ',', '', 'la', 'cosa', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'da', '', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'un', 'sistema', 'di', 'ris@@', '<unk>', '@', 'chio', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:49:43,816 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:49:43,816 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:49:43,816 - INFO - joeynmt.training - 	Hypothesis: In un sen<unk> @ so ,  la cosa in<unk> @ ten<unk> @ da  la di<unk> @ st<unk> @ anza di un sistema di ris<unk> @ chio di c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 19:49:43,816 - INFO - joeynmt.training - Example #3
2025-05-27 19:49:43,816 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:49:43,817 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:49:43,817 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'la', 'v@@', '<unk>', '@', 'in@@', '<unk>', '@', 'am@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:49:43,817 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:49:43,817 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:49:43,817 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e la v<unk> @ in<unk> @ am<unk> @ a .
2025-05-27 19:49:43,817 - INFO - joeynmt.training - Example #4
2025-05-27 19:49:43,817 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:49:43,818 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:49:43,818 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ma', ',', '', 'una', 'sc@@', '<unk>', '@', 'rit@@', '<unk>', '@', 'ta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:49:43,818 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:49:43,818 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:49:43,818 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ am<unk> @ ma ,  una sc<unk> @ rit<unk> @ ta che vi mostr<unk> @ er<unk> @  cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:49:47,083 - INFO - joeynmt.training - Epoch   6, Step:    43100, Batch Loss:     0.994172, Batch Acc: 0.714079, Tokens per Sec:    20393, Lr: 0.000300
2025-05-27 19:49:50,415 - INFO - joeynmt.training - Epoch   6, Step:    43200, Batch Loss:     0.866510, Batch Acc: 0.715704, Tokens per Sec:    23260, Lr: 0.000300
2025-05-27 19:49:53,739 - INFO - joeynmt.training - Epoch   6, Step:    43300, Batch Loss:     0.922122, Batch Acc: 0.712647, Tokens per Sec:    23251, Lr: 0.000300
2025-05-27 19:49:57,071 - INFO - joeynmt.training - Epoch   6, Step:    43400, Batch Loss:     0.981141, Batch Acc: 0.714273, Tokens per Sec:    24058, Lr: 0.000300
2025-05-27 19:50:00,434 - INFO - joeynmt.training - Epoch   6, Step:    43500, Batch Loss:     1.012473, Batch Acc: 0.712238, Tokens per Sec:    23826, Lr: 0.000300
2025-05-27 19:50:00,434 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:50:00,434 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:50:15,580 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 15.1324[sec], evaluation: 0.0000[sec]
2025-05-27 19:50:15,580 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:50:16,190 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/41500.ckpt
2025-05-27 19:50:16,213 - INFO - joeynmt.training - Example #0
2025-05-27 19:50:16,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:50:16,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:50:16,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'due', 'cas@@', '<unk>', '@', 'i', ',', 'per', 'f@@', '<unk>', '@', 'ar', 's@@', '<unk>', '@', '', 'che', 'le', 'c@@', '<unk>', '@', 'ure', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', ',', 'che', 'i', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'ano', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', '%', 'del', '4@@', '<unk>', '@', '8', '%', 'delle', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:50:16,214 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:50:16,214 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:50:16,214 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due due cas<unk> @ i , per f<unk> @ ar s<unk> @  che le c<unk> @ ure po<unk> @ ver<unk> @ i , che i c<unk> @ aus<unk> @ ano i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 % del 4<unk> @ 8 % delle 4<unk> @ 8 % .
2025-05-27 19:50:16,214 - INFO - joeynmt.training - Example #1
2025-05-27 19:50:16,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:50:16,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:50:16,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', ',', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questi', 'probl@@', '<unk>', '@', 'emi', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ali', ',', 'perch', 'non', 'mostr@@', '<unk>', '@', 'a', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:50:16,215 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:50:16,215 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:50:16,216 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza , non  abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questi probl<unk> @ emi spe<unk> @ ci<unk> @ ali , perch non mostr<unk> @ a il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 19:50:16,216 - INFO - joeynmt.training - Example #2
2025-05-27 19:50:16,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:50:16,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:50:16,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'lin@@', '<unk>', '@', 'ea', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', '', 'la', 'ci@@', '<unk>', '@', 'ma', 'alla', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:50:16,216 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ ea in<unk> @ ten<unk> @ zione  la ci<unk> @ ma alla nostra c<unk> @ li<unk> @ sta del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - Example #3
2025-05-27 19:50:16,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:50:16,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:50:16,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'sp@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e sp<unk> @ esso .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - Example #4
2025-05-27 19:50:16,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:50:16,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:50:16,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'due', 'anni', '.', '</s>']
2025-05-27 19:50:16,218 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:50:16,218 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:50:16,218 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ o  che vi mostr<unk> @ er<unk> @   una ser<unk> @ ie di due anni .
2025-05-27 19:50:19,573 - INFO - joeynmt.training - Epoch   6, Step:    43600, Batch Loss:     1.034857, Batch Acc: 0.710115, Tokens per Sec:    19767, Lr: 0.000300
2025-05-27 19:50:22,884 - INFO - joeynmt.training - Epoch   6, Step:    43700, Batch Loss:     1.062245, Batch Acc: 0.716441, Tokens per Sec:    23086, Lr: 0.000300
2025-05-27 19:50:26,212 - INFO - joeynmt.training - Epoch   6, Step:    43800, Batch Loss:     0.877512, Batch Acc: 0.710551, Tokens per Sec:    23752, Lr: 0.000300
2025-05-27 19:50:29,567 - INFO - joeynmt.training - Epoch   6, Step:    43900, Batch Loss:     0.945952, Batch Acc: 0.709442, Tokens per Sec:    24175, Lr: 0.000300
2025-05-27 19:50:32,908 - INFO - joeynmt.training - Epoch   6, Step:    44000, Batch Loss:     1.130818, Batch Acc: 0.707058, Tokens per Sec:    23228, Lr: 0.000300
2025-05-27 19:50:32,908 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:50:32,908 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:50:46,871 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 13.9539[sec], evaluation: 0.0000[sec]
2025-05-27 19:50:47,181 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/40000.ckpt
2025-05-27 19:50:47,204 - INFO - joeynmt.training - Example #0
2025-05-27 19:50:47,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:50:47,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:50:47,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'per', 'ri@@', '<unk>', '@', 'vel@@', '<unk>', '@', 'are', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'c@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'amente', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'i', 'b@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ag@@', '<unk>', '@', 'gi', ',', 'che', 'ha', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:50:47,205 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:50:47,205 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:50:47,205 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per ri<unk> @ vel<unk> @ are il 4<unk> @ 0 % di c<unk> @ att<unk> @ ic<unk> @ amente che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono i b<unk> @ att<unk> @ ag<unk> @ gi , che ha fatto per il 4<unk> @ 0 % .
2025-05-27 19:50:47,205 - INFO - joeynmt.training - Example #1
2025-05-27 19:50:47,205 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:50:47,206 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:50:47,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'da', 'non', 'c&apos;', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'is@@', '<unk>', '@', 'ce', '.', '</s>']
2025-05-27 19:50:47,206 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:50:47,206 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:50:47,206 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza di questa part<unk> @ icol<unk> @ are , perch non  il D<unk> @ ic<unk> @ e<unk> @ da non c&apos;  il D<unk> @ ic<unk> @ e<unk> @ E<unk> @ is<unk> @ is<unk> @ ce .
2025-05-27 19:50:47,206 - INFO - joeynmt.training - Example #2
2025-05-27 19:50:47,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:50:47,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:50:47,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', 'del', 'nostro', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:50:47,207 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:50:47,207 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:50:47,207 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il c<unk> @ li<unk> @ mat<unk> @ ico  il g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore glob<unk> @ ale del nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:50:47,207 - INFO - joeynmt.training - Example #3
2025-05-27 19:50:47,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:50:47,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:50:47,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'cosa', ',', 'e', 'sp@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 19:50:47,208 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:50:47,208 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:50:47,208 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una cosa , e sp<unk> @ esso .
2025-05-27 19:50:47,208 - INFO - joeynmt.training - Example #4
2025-05-27 19:50:47,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:50:47,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:50:47,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'ri@@', '<unk>', '@', 'chi@@', '<unk>', '@', 'est@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:50:47,209 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:50:47,209 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:50:47,209 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una ri<unk> @ chi<unk> @ est<unk> @ a che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:50:50,467 - INFO - joeynmt.training - Epoch   6, Step:    44100, Batch Loss:     1.047242, Batch Acc: 0.712157, Tokens per Sec:    22400, Lr: 0.000300
2025-05-27 19:50:53,728 - INFO - joeynmt.training - Epoch   6, Step:    44200, Batch Loss:     0.971652, Batch Acc: 0.708965, Tokens per Sec:    24304, Lr: 0.000300
2025-05-27 19:50:56,995 - INFO - joeynmt.training - Epoch   6, Step:    44300, Batch Loss:     1.073068, Batch Acc: 0.713844, Tokens per Sec:    23762, Lr: 0.000300
2025-05-27 19:51:00,277 - INFO - joeynmt.training - Epoch   6, Step:    44400, Batch Loss:     0.944246, Batch Acc: 0.714165, Tokens per Sec:    24156, Lr: 0.000300
2025-05-27 19:51:03,561 - INFO - joeynmt.training - Epoch   6, Step:    44500, Batch Loss:     1.057765, Batch Acc: 0.712576, Tokens per Sec:    22853, Lr: 0.000300
2025-05-27 19:51:03,561 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:51:03,561 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:51:17,953 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.74, acc:   0.71, generation: 14.3789[sec], evaluation: 0.0000[sec]
2025-05-27 19:51:17,953 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:51:18,472 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/42000.ckpt
2025-05-27 19:51:18,497 - INFO - joeynmt.training - Example #0
2025-05-27 19:51:18,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:51:18,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:51:18,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'li', 'anni', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'per', 'in@@', '<unk>', '@', 'segn@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'i', 'con@@', '<unk>', '@', 'to', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ati', ',', 'per', 'i', 'cas@@', '<unk>', '@', 'i', 'di', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'av@@', '<unk>', '@', 'evano', 'fatto', ',', 'il', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:51:18,499 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:51:18,499 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:51:18,499 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ eg<unk> @ li anni , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per in<unk> @ segn<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i con<unk> @ to che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati , per i cas<unk> @ i di tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di anni , che av<unk> @ evano fatto , il 4<unk> @ 8 % .
2025-05-27 19:51:18,499 - INFO - joeynmt.training - Example #1
2025-05-27 19:51:18,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:51:18,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:51:18,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'molto', 'pi', 'for@@', '<unk>', '@', 'te', ',', 'non', '', 'molto', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ica', 'di', 'questo', 'problema', ',', 'che', 'non', '', 'la', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'non', 'ci', 'mostr@@', '<unk>', '@', 'a', 'il', 'problema', '.', '</s>']
2025-05-27 19:51:18,500 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:51:18,500 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:51:18,500 - INFO - joeynmt.training - 	Hypothesis: Ma non  molto pi for<unk> @ te , non  molto la di<unk> @ st<unk> @ ica di questo problema , che non  la di<unk> @ mostr<unk> @ a di questo problema , non ci mostr<unk> @ a il problema .
2025-05-27 19:51:18,500 - INFO - joeynmt.training - Example #2
2025-05-27 19:51:18,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:51:18,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:51:18,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ch', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'es@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ente', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ente', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:51:18,501 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:51:18,501 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:51:18,501 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ i<unk> @ ch la g<unk> @ hi<unk> @ es<unk> @ c<unk> @ ente  la c<unk> @ li<unk> @ ente del nostro c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:51:18,501 - INFO - joeynmt.training - Example #3
2025-05-27 19:51:18,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:51:18,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:51:18,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ta', 'divent@@', '<unk>', '@', 'ando', 'un', 'p@@', '<unk>', '@', 'om@@', '<unk>', '@', 'o', 'e', 'si', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:51:18,502 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:51:18,502 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:51:18,502 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta divent<unk> @ ando un p<unk> @ om<unk> @ o e si sp<unk> @ ost<unk> @ a .
2025-05-27 19:51:18,502 - INFO - joeynmt.training - Example #4
2025-05-27 19:51:18,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:51:18,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:51:18,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'di', 'cosa', 'sta', 'per', 'mostr@@', '<unk>', '@', 'are', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'cosa', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:51:18,503 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:51:18,503 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:51:18,503 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i di cosa sta per mostr<unk> @ are  una ser<unk> @ ie di cosa che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:51:21,824 - INFO - joeynmt.training - Epoch   6, Step:    44600, Batch Loss:     1.004138, Batch Acc: 0.711657, Tokens per Sec:    19404, Lr: 0.000300
2025-05-27 19:51:25,159 - INFO - joeynmt.training - Epoch   6, Step:    44700, Batch Loss:     1.027022, Batch Acc: 0.713241, Tokens per Sec:    23874, Lr: 0.000300
2025-05-27 19:51:28,483 - INFO - joeynmt.training - Epoch   6, Step:    44800, Batch Loss:     0.891977, Batch Acc: 0.712686, Tokens per Sec:    24444, Lr: 0.000300
2025-05-27 19:51:31,782 - INFO - joeynmt.training - Epoch   6, Step:    44900, Batch Loss:     0.940800, Batch Acc: 0.715694, Tokens per Sec:    23596, Lr: 0.000300
2025-05-27 19:51:35,098 - INFO - joeynmt.training - Epoch   6, Step:    45000, Batch Loss:     1.107118, Batch Acc: 0.710944, Tokens per Sec:    23768, Lr: 0.000300
2025-05-27 19:51:35,098 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:51:35,098 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:51:49,744 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.74, acc:   0.71, generation: 14.6321[sec], evaluation: 0.0000[sec]
2025-05-27 19:51:49,744 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:51:50,282 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/44000.ckpt
2025-05-27 19:51:50,307 - INFO - joeynmt.training - Example #0
2025-05-27 19:51:50,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:51:50,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:51:50,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'cui', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', 'prim@@', '<unk>', '@', 'i', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'il', '4@@', '<unk>', '@', '8', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'il', '4@@', '<unk>', '@', '8', '%', 'del', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'il', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', '.', '</s>']
2025-05-27 19:51:50,308 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:51:50,308 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:51:50,308 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due cas<unk> @ i , per c<unk> @ ento di cui i g<unk> @ hi<unk> @ ac<unk> @ cio , per il g<unk> @ hi<unk> @ ac<unk> @ cio , per i g<unk> @ hi<unk> @ ac<unk> @ cio , per i prim<unk> @ i anni , il 4<unk> @ 8 milioni di di anni , il 4<unk> @ 8 , il 4<unk> @ 8 milioni di anni , il 4<unk> @ 8 , il 4<unk> @ 8 anni , il 4<unk> @ 8 , il 4<unk> @ 8 , il 4<unk> @ 8 % del 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , il 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti .
2025-05-27 19:51:50,308 - INFO - joeynmt.training - Example #1
2025-05-27 19:51:50,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:51:50,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:51:50,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'ter@@', '<unk>', '@', 'm@@', '<unk>', '@', 'em@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ia', 'di', 'questi', 'probl@@', '<unk>', '@', 'emi', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ali', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:51:50,309 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:51:50,309 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:51:50,310 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la ter<unk> @ m<unk> @ em<unk> @ or<unk> @ ia di questi probl<unk> @ emi spe<unk> @ ci<unk> @ ali , perch non  il d<unk> @ ott<unk> @ ore .
2025-05-27 19:51:50,310 - INFO - joeynmt.training - Example #2
2025-05-27 19:51:50,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:51:50,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:51:50,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 'str@@', '<unk>', '@', 'um@@', '<unk>', '@', 'ento', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ato', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 19:51:50,310 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il s<unk> @ ac<unk> @ co di str<unk> @ um<unk> @ ento  il g<unk> @ hi<unk> @ ac<unk> @ cio c<unk> @ li<unk> @ ato della nostra c<unk> @ li<unk> @ sta del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - Example #3
2025-05-27 19:51:50,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:51:50,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:51:50,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'sc@@', '<unk>', '@', 'u@@', '<unk>', '@', 'ola', '.', '</s>']
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un s<unk> @ ac<unk> @ co di v<unk> @ ento e sc<unk> @ u<unk> @ ola .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - Example #4
2025-05-27 19:51:50,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:51:50,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:51:50,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'ia', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'lin@@', '<unk>', '@', 'ea', 'che', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:51:50,312 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:51:50,312 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:51:50,312 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ol<unk> @ ia che vi mostr<unk> @ er<unk> @  una ser<unk> @ ie di lin<unk> @ ea che mostr<unk> @ a cosa che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:51:53,663 - INFO - joeynmt.training - Epoch   6, Step:    45100, Batch Loss:     0.930807, Batch Acc: 0.714058, Tokens per Sec:    20509, Lr: 0.000300
2025-05-27 19:51:56,963 - INFO - joeynmt.training - Epoch   6, Step:    45200, Batch Loss:     1.095223, Batch Acc: 0.712028, Tokens per Sec:    24454, Lr: 0.000300
2025-05-27 19:52:00,299 - INFO - joeynmt.training - Epoch   6, Step:    45300, Batch Loss:     1.203117, Batch Acc: 0.715022, Tokens per Sec:    24330, Lr: 0.000300
2025-05-27 19:52:03,629 - INFO - joeynmt.training - Epoch   6, Step:    45400, Batch Loss:     1.020797, Batch Acc: 0.709885, Tokens per Sec:    24092, Lr: 0.000300
2025-05-27 19:52:06,939 - INFO - joeynmt.training - Epoch   6, Step:    45500, Batch Loss:     0.922666, Batch Acc: 0.711967, Tokens per Sec:    23961, Lr: 0.000300
2025-05-27 19:52:06,939 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:52:06,939 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:52:20,514 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.73, acc:   0.71, generation: 13.5670[sec], evaluation: 0.0000[sec]
2025-05-27 19:52:20,515 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:52:20,989 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/42500.ckpt
2025-05-27 19:52:21,012 - INFO - joeynmt.training - Example #0
2025-05-27 19:52:21,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:52:21,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:52:21,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', ',', 'per', 'pot@@', '<unk>', '@', 'er', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'la', 'c@@', '<unk>', '@', 'ura', 'ci', 'ha', 'mostr@@', '<unk>', '@', 'ato', 'che', 'la', 'c@@', '<unk>', '@', 'ura', 'ci', 'ha', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'ato', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'to', ',', 'che', 'aveva', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'e', '&apos;', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'ati', ',', '', 'stato', 'm@@', '<unk>', '@', 'and@@', '<unk>', '@', 'ato', 'a', 'qu@@', '<unk>', '@', 'asi', '.', '</s>']
2025-05-27 19:52:21,013 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:52:21,013 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:52:21,013 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i , per pot<unk> @ er di<unk> @ mostr<unk> @ are che la c<unk> @ ura ci ha mostr<unk> @ ato che la c<unk> @ ura ci ha con<unk> @ si<unk> @ der<unk> @ ato che il g<unk> @ hi<unk> @ ac<unk> @ cio di tre milioni di anni , che aveva sc<unk> @ oper<unk> @ to , che aveva 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , e &apos; 4<unk> @ 8 St<unk> @ ati Un<unk> @ ati ,  stato m<unk> @ and<unk> @ ato a qu<unk> @ asi .
2025-05-27 19:52:21,013 - INFO - joeynmt.training - Example #1
2025-05-27 19:52:21,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:52:21,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:52:21,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ica', 'di', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'questo', 'problema', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'em@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 19:52:21,014 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:52:21,014 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:52:21,014 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ ica di questa part<unk> @ icol<unk> @ are questa part<unk> @ icol<unk> @ are questo problema , non  il D<unk> @ ic<unk> @ em<unk> @ io .
2025-05-27 19:52:21,014 - INFO - joeynmt.training - Example #2
2025-05-27 19:52:21,015 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:52:21,015 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:52:21,015 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ente', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:52:21,015 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:52:21,015 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:52:21,015 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ li<unk> @ sta del sistema c<unk> @ li<unk> @ ente  la c<unk> @ li<unk> @ sta del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:52:21,015 - INFO - joeynmt.training - Example #3
2025-05-27 19:52:21,015 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:52:21,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:52:21,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'trov@@', '<unk>', '@', 'a', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 19:52:21,016 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:52:21,016 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:52:21,016 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e si trov<unk> @ a in est<unk> @ ate .
2025-05-27 19:52:21,016 - INFO - joeynmt.training - Example #4
2025-05-27 19:52:21,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:52:21,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:52:21,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ero', ',', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:52:21,017 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:52:21,017 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:52:21,017 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ ero , che vi mostr<unk> @ er<unk> @   una sc<unk> @ or<unk> @ sa che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:52:24,274 - INFO - joeynmt.training - Epoch   6, Step:    45600, Batch Loss:     1.036303, Batch Acc: 0.713704, Tokens per Sec:    20844, Lr: 0.000300
2025-05-27 19:52:27,541 - INFO - joeynmt.training - Epoch   6, Step:    45700, Batch Loss:     0.984434, Batch Acc: 0.709844, Tokens per Sec:    23581, Lr: 0.000300
2025-05-27 19:52:30,775 - INFO - joeynmt.training - Epoch   6, Step:    45800, Batch Loss:     1.062224, Batch Acc: 0.714300, Tokens per Sec:    24646, Lr: 0.000300
2025-05-27 19:52:34,011 - INFO - joeynmt.training - Epoch   6, Step:    45900, Batch Loss:     0.970977, Batch Acc: 0.713643, Tokens per Sec:    25071, Lr: 0.000300
2025-05-27 19:52:37,236 - INFO - joeynmt.training - Epoch   6, Step:    46000, Batch Loss:     1.009284, Batch Acc: 0.714878, Tokens per Sec:    23946, Lr: 0.000300
2025-05-27 19:52:37,236 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:52:37,236 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:52:52,309 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.74, acc:   0.71, generation: 15.0593[sec], evaluation: 0.0000[sec]
2025-05-27 19:52:52,668 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/43000.ckpt
2025-05-27 19:52:52,694 - INFO - joeynmt.training - Example #0
2025-05-27 19:52:52,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:52:52,695 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:52:52,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', 'sono', 'arriv@@', '<unk>', '@', 'ati', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'le', 'col@@', '<unk>', '@', 'ie', 'di', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', ',', 'che', 'i', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'are', 'i', 'due', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', '.', '</s>']
2025-05-27 19:52:52,695 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:52:52,695 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:52:52,695 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due cas<unk> @ i sono arriv<unk> @ ati per ri<unk> @ dur<unk> @ re le col<unk> @ ie di p<unk> @ op<unk> @ ol<unk> @ i , che i c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are i due milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento di tre milioni di m<unk> @ oti<unk> @ vi .
2025-05-27 19:52:52,695 - INFO - joeynmt.training - Example #1
2025-05-27 19:52:52,696 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:52:52,696 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:52:52,696 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:52:52,696 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:52:52,696 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:52:52,696 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:52:52,696 - INFO - joeynmt.training - Example #2
2025-05-27 19:52:52,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:52:52,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:52:52,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'sen@@', '<unk>', '@', 'so', ',', 'il', 's@@', '<unk>', '@', 'ett@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '', 'il', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:52:52,697 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:52:52,697 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:52:52,697 - INFO - joeynmt.training - 	Hypothesis: In questo sen<unk> @ so , il s<unk> @ ett<unk> @ ore c<unk> @ li<unk> @ mat<unk> @ ico  il c<unk> @ li<unk> @ m<unk> @ as<unk> @ si<unk> @ mo glob<unk> @ ale .
2025-05-27 19:52:52,698 - INFO - joeynmt.training - Example #3
2025-05-27 19:52:52,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:52:52,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:52:52,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'sp@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 19:52:52,698 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:52:52,698 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:52:52,698 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e si sp<unk> @ esso .
2025-05-27 19:52:52,698 - INFO - joeynmt.training - Example #4
2025-05-27 19:52:52,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:52:52,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:52:52,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'fin@@', '<unk>', '@', 'ito', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'lin@@', '<unk>', '@', 'ea', 'di', 'ri@@', '<unk>', '@', 'vol@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ere', 'una', 'ri@@', '<unk>', '@', 'vi@@', '<unk>', '@', 'sta', ',', 'che', '', 'succ@@', '<unk>', '@', 'e@@', '<unk>', '@', 'dendo', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:52:52,699 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:52:52,699 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:52:52,699 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma fin<unk> @ ito che vi mostr<unk> @ er<unk> @  una lin<unk> @ ea di ri<unk> @ vol<unk> @ g<unk> @ ere una ri<unk> @ vi<unk> @ sta , che  succ<unk> @ e<unk> @ dendo negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:52:56,033 - INFO - joeynmt.training - Epoch   6, Step:    46100, Batch Loss:     0.956820, Batch Acc: 0.712317, Tokens per Sec:    20930, Lr: 0.000300
2025-05-27 19:52:59,360 - INFO - joeynmt.training - Epoch   6, Step:    46200, Batch Loss:     0.876255, Batch Acc: 0.711524, Tokens per Sec:    23960, Lr: 0.000300
2025-05-27 19:53:02,678 - INFO - joeynmt.training - Epoch   6, Step:    46300, Batch Loss:     0.980503, Batch Acc: 0.713840, Tokens per Sec:    23753, Lr: 0.000300
2025-05-27 19:53:06,013 - INFO - joeynmt.training - Epoch   6, Step:    46400, Batch Loss:     0.801335, Batch Acc: 0.713013, Tokens per Sec:    24066, Lr: 0.000300
2025-05-27 19:53:09,342 - INFO - joeynmt.training - Epoch   6, Step:    46500, Batch Loss:     0.989470, Batch Acc: 0.712453, Tokens per Sec:    23309, Lr: 0.000300
2025-05-27 19:53:09,343 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:53:09,343 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:53:24,154 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.73, acc:   0.71, generation: 14.7984[sec], evaluation: 0.0000[sec]
2025-05-27 19:53:24,155 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:53:24,699 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/43500.ckpt
2025-05-27 19:53:24,719 - INFO - joeynmt.training - Example #0
2025-05-27 19:53:24,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:53:24,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:53:24,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', 'questi', 'due', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ure', 'che', 'sono', 'stati', 'mostr@@', '<unk>', '@', 'ati', 'per', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'i', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ere', ',', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:53:24,721 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:53:24,721 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:53:24,721 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so anno questi due f<unk> @ ig<unk> @ ure che sono stati mostr<unk> @ ati per con<unk> @ si<unk> @ der<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono che gli ar<unk> @ t<unk> @ icol<unk> @ i , per il 4<unk> @ 8 anni , per il 4<unk> @ 8 anni , per c<unk> @ ento di sc<unk> @ or<unk> @ r<unk> @ ere , 4<unk> @ 8 % .
2025-05-27 19:53:24,721 - INFO - joeynmt.training - Example #1
2025-05-27 19:53:24,721 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:53:24,722 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:53:24,722 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bil@@', '<unk>', '@', 'it', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ente', '.', '</s>']
2025-05-27 19:53:24,722 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:53:24,722 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:53:24,722 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ it di questo part<unk> @ icol<unk> @ are di questo part<unk> @ icol<unk> @ are , perch non  il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ ente .
2025-05-27 19:53:24,722 - INFO - joeynmt.training - Example #2
2025-05-27 19:53:24,723 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:53:24,723 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:53:24,723 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:53:24,723 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:53:24,723 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:53:24,723 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il g<unk> @ hi<unk> @ ac<unk> @ cio  il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 19:53:24,723 - INFO - joeynmt.training - Example #3
2025-05-27 19:53:24,724 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:53:24,724 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:53:24,724 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ta', 'in', 'v@@', '<unk>', '@', 'ento', 'e', 'la', 'v@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:53:24,724 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:53:24,724 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:53:24,724 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta in v<unk> @ ento e la v<unk> @ ento .
2025-05-27 19:53:24,724 - INFO - joeynmt.training - Example #4
2025-05-27 19:53:24,725 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:53:24,725 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:53:24,725 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'u', ',', 'la', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'u', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:53:24,725 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:53:24,725 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:53:24,725 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ u , la pros<unk> @ si<unk> @ ma f<unk> @ u una ser<unk> @ ie di c<unk> @ en<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:53:28,073 - INFO - joeynmt.training - Epoch   6, Step:    46600, Batch Loss:     0.920914, Batch Acc: 0.711636, Tokens per Sec:    20669, Lr: 0.000300
2025-05-27 19:53:31,406 - INFO - joeynmt.training - Epoch   6, Step:    46700, Batch Loss:     0.988418, Batch Acc: 0.711800, Tokens per Sec:    24140, Lr: 0.000300
2025-05-27 19:53:34,729 - INFO - joeynmt.training - Epoch   6, Step:    46800, Batch Loss:     1.014533, Batch Acc: 0.710192, Tokens per Sec:    23938, Lr: 0.000300
2025-05-27 19:53:38,011 - INFO - joeynmt.training - Epoch   6, Step:    46900, Batch Loss:     1.078282, Batch Acc: 0.712970, Tokens per Sec:    23490, Lr: 0.000300
2025-05-27 19:53:41,349 - INFO - joeynmt.training - Epoch   6, Step:    47000, Batch Loss:     1.001593, Batch Acc: 0.709393, Tokens per Sec:    23741, Lr: 0.000300
2025-05-27 19:53:41,349 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:53:41,349 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:53:55,047 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.72, acc:   0.71, generation: 13.6850[sec], evaluation: 0.0000[sec]
2025-05-27 19:53:55,048 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:53:55,570 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/44500.ckpt
2025-05-27 19:53:55,594 - INFO - joeynmt.training - Example #0
2025-05-27 19:53:55,595 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:53:55,595 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:53:55,595 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ie', 'per', 'c@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'are', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ato', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ici', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'il', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', 'di', 'c@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'b@@', '<unk>', '@', 'i', ',', 'per', 'circa', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 19:53:55,595 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:53:55,596 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:53:55,596 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ ie per c<unk> @ att<unk> @ ur<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ato che gli ar<unk> @ t<unk> @ ici per i tre milioni di anni , per il ci<unk> @ b<unk> @ o di c<unk> @ att<unk> @ ur<unk> @ b<unk> @ i , per circa 4<unk> @ 8 milioni di anni .
2025-05-27 19:53:55,596 - INFO - joeynmt.training - Example #1
2025-05-27 19:53:55,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:53:55,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:53:55,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ha@@', '<unk>', '@', 'i', 'questa', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'fic@@', '<unk>', '@', 'azione', 'di', 'questo', 'problema', ',', 'non', '', 'il', 'd@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'lo', '.', '</s>']
2025-05-27 19:53:55,597 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:53:55,597 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:53:55,597 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la di<unk> @ st<unk> @ ha<unk> @ i questa spe<unk> @ ci<unk> @ fic<unk> @ azione di questo problema , non  il d<unk> @ ic<unk> @ lo .
2025-05-27 19:53:55,597 - INFO - joeynmt.training - Example #2
2025-05-27 19:53:55,597 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:53:55,597 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:53:55,597 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:53:55,598 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:53:55,598 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:53:55,598 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio  il cu<unk> @ ore della nostra c<unk> @ li<unk> @ sta del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma .
2025-05-27 19:53:55,598 - INFO - joeynmt.training - Example #3
2025-05-27 19:53:55,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:53:55,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:53:55,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ta', 's@@', '<unk>', '@', 'com@@', '<unk>', '@', 'met@@', '<unk>', '@', 'te', 'di', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ine', 'e', 'sp@@', '<unk>', '@', 'edi@@', '<unk>', '@', 're', '.', '</s>']
2025-05-27 19:53:55,599 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:53:55,599 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:53:55,599 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta s<unk> @ com<unk> @ met<unk> @ te di ri<unk> @ m<unk> @ ine e sp<unk> @ edi<unk> @ re .
2025-05-27 19:53:55,599 - INFO - joeynmt.training - Example #4
2025-05-27 19:53:55,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:53:55,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:53:55,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', 'vi', 'mostr@@', '<unk>', '@', 'o', ',', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'queste', 'par@@', '<unk>', '@', 'ti', ',', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:53:55,599 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:53:55,600 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:53:55,600 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o vi mostr<unk> @ o ,  una c<unk> @ ura di queste par<unk> @ ti ,  una c<unk> @ en<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:53:58,960 - INFO - joeynmt.training - Epoch   6, Step:    47100, Batch Loss:     1.031964, Batch Acc: 0.712316, Tokens per Sec:    20378, Lr: 0.000300
2025-05-27 19:54:02,258 - INFO - joeynmt.training - Epoch   6, Step:    47200, Batch Loss:     0.944164, Batch Acc: 0.710039, Tokens per Sec:    23761, Lr: 0.000300
2025-05-27 19:54:04,651 - INFO - joeynmt.training - Epoch   6: total training loss 7812.54
2025-05-27 19:54:04,651 - INFO - joeynmt.training - EPOCH 7
2025-05-27 19:54:05,591 - INFO - joeynmt.training - Epoch   7, Step:    47300, Batch Loss:     1.017185, Batch Acc: 0.719619, Tokens per Sec:    24036, Lr: 0.000300
2025-05-27 19:54:08,923 - INFO - joeynmt.training - Epoch   7, Step:    47400, Batch Loss:     0.846242, Batch Acc: 0.724797, Tokens per Sec:    24151, Lr: 0.000300
2025-05-27 19:54:12,229 - INFO - joeynmt.training - Epoch   7, Step:    47500, Batch Loss:     0.843096, Batch Acc: 0.723164, Tokens per Sec:    22843, Lr: 0.000300
2025-05-27 19:54:12,229 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:54:12,229 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:54:27,353 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.73, acc:   0.71, generation: 15.1103[sec], evaluation: 0.0000[sec]
2025-05-27 19:54:27,694 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/45000.ckpt
2025-05-27 19:54:27,718 - INFO - joeynmt.training - Example #0
2025-05-27 19:54:27,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:54:27,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:54:27,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'ie', 'per', 'far@@', '<unk>', '@', 'lo', 'per', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'stati', ',', '4@@', '<unk>', '@', '8', 'stati', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', '.', '</s>']
2025-05-27 19:54:27,719 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:54:27,719 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:54:27,719 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ ie per far<unk> @ lo per con<unk> @ si<unk> @ der<unk> @ are che la c<unk> @ aus<unk> @ a di con<unk> @ si<unk> @ der<unk> @ are la c<unk> @ aus<unk> @ a di tre milioni di anni , per la c<unk> @ aus<unk> @ a di tre milioni di anni , il 4<unk> @ 8 stati , 4<unk> @ 8 stati , per c<unk> @ ento di tre milioni di m<unk> @ oti<unk> @ vi .
2025-05-27 19:54:27,720 - INFO - joeynmt.training - Example #1
2025-05-27 19:54:27,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:54:27,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:54:27,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'ter@@', '<unk>', '@', 'n@@', '<unk>', '@', 'it', 'di', 'questo', 'probl@@', '<unk>', '@', 'em@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ico', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'lo', '.', '</s>']
2025-05-27 19:54:27,720 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:54:27,720 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:54:27,720 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la ter<unk> @ n<unk> @ it di questo probl<unk> @ em<unk> @ at<unk> @ ico , non  il D<unk> @ ic<unk> @ lo .
2025-05-27 19:54:27,721 - INFO - joeynmt.training - Example #2
2025-05-27 19:54:27,721 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:54:27,721 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:54:27,721 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'ci@@', '<unk>', '@', 'ma', '', 'la', 'ci@@', '<unk>', '@', 'ma', '', 'la', 'ci@@', '<unk>', '@', 'ma', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'del', 'cu@@', '<unk>', '@', 'ore', '.', '</s>']
2025-05-27 19:54:27,721 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:54:27,721 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la ci<unk> @ ma  la ci<unk> @ ma  la ci<unk> @ ma  la c<unk> @ aus<unk> @ a del cu<unk> @ ore .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - Example #3
2025-05-27 19:54:27,722 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:54:27,722 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:54:27,722 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'ento', 'e', 'p@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:54:27,722 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e p<unk> @ eg<unk> @ gi<unk> @ o .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - Example #4
2025-05-27 19:54:27,723 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:54:27,723 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:54:27,723 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'oc@@', '<unk>', '@', 'sione', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:54:27,723 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:54:27,723 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:54:27,723 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ oc<unk> @ sione che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a di cosa che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:54:31,079 - INFO - joeynmt.training - Epoch   7, Step:    47600, Batch Loss:     0.937515, Batch Acc: 0.721090, Tokens per Sec:    21168, Lr: 0.000300
2025-05-27 19:54:34,408 - INFO - joeynmt.training - Epoch   7, Step:    47700, Batch Loss:     0.923773, Batch Acc: 0.719630, Tokens per Sec:    24055, Lr: 0.000300
2025-05-27 19:54:37,746 - INFO - joeynmt.training - Epoch   7, Step:    47800, Batch Loss:     1.038290, Batch Acc: 0.720740, Tokens per Sec:    24274, Lr: 0.000300
2025-05-27 19:54:41,086 - INFO - joeynmt.training - Epoch   7, Step:    47900, Batch Loss:     0.897056, Batch Acc: 0.720792, Tokens per Sec:    24153, Lr: 0.000300
2025-05-27 19:54:44,415 - INFO - joeynmt.training - Epoch   7, Step:    48000, Batch Loss:     0.904347, Batch Acc: 0.722577, Tokens per Sec:    23891, Lr: 0.000300
2025-05-27 19:54:44,416 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:54:44,416 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:55:00,767 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 16.3379[sec], evaluation: 0.0000[sec]
2025-05-27 19:55:00,768 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:55:01,424 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/46000.ckpt
2025-05-27 19:55:01,448 - INFO - joeynmt.training - Example #0
2025-05-27 19:55:01,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:55:01,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:55:01,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', 'questi', 'due', 'f@@', '<unk>', '@', 'ami@@', '<unk>', '@', 'gl@@', '<unk>', '@', 'ie', 'per', 'ri@@', '<unk>', '@', 'l@@', '<unk>', '@', 'ev@@', '<unk>', '@', 'are', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'anni', '.', '</s>']
2025-05-27 19:55:01,450 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:55:01,450 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:55:01,450 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno questi due f<unk> @ ami<unk> @ gl<unk> @ ie per ri<unk> @ l<unk> @ ev<unk> @ are per ri<unk> @ dur<unk> @ re la g<unk> @ hi<unk> @ ac<unk> @ cio per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre anni .
2025-05-27 19:55:01,450 - INFO - joeynmt.training - Example #1
2025-05-27 19:55:01,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:55:01,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:55:01,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', ',', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'lo', '.', '</s>']
2025-05-27 19:55:01,451 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:55:01,451 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:55:01,451 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza , la di<unk> @ st<unk> @ anza di questo problema , perch non  la di<unk> @ st<unk> @ anza di questo problema , perch non  il d<unk> @ ic<unk> @ lo .
2025-05-27 19:55:01,451 - INFO - joeynmt.training - Example #2
2025-05-27 19:55:01,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:55:01,452 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:55:01,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'str@@', '<unk>', '@', 'utt@@', '<unk>', '@', 'ura', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'so', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:55:01,452 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:55:01,452 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:55:01,452 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ aus<unk> @ a di str<unk> @ utt<unk> @ ura  la c<unk> @ aus<unk> @ a della nostra c<unk> @ li<unk> @ mat<unk> @ ica del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ so glob<unk> @ ale .
2025-05-27 19:55:01,452 - INFO - joeynmt.training - Example #3
2025-05-27 19:55:01,452 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:55:01,452 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:55:01,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'sc@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'amente', 'nella', 'v@@', '<unk>', '@', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 19:55:01,453 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:55:01,453 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:55:01,453 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e sc<unk> @ ar<unk> @ ic<unk> @ amente nella v<unk> @ est<unk> @ ate .
2025-05-27 19:55:01,453 - INFO - joeynmt.training - Example #4
2025-05-27 19:55:01,453 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:55:01,453 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:55:01,453 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'fr@@', '<unk>', '@', 'on@@', '<unk>', '@', 'te', 'a', 'quello', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:55:01,454 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:55:01,454 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:55:01,454 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i che vi mostr<unk> @ a una ser<unk> @ ie di fr<unk> @ on<unk> @ te a quello che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:55:04,772 - INFO - joeynmt.training - Epoch   7, Step:    48100, Batch Loss:     0.928656, Batch Acc: 0.722501, Tokens per Sec:    18991, Lr: 0.000300
2025-05-27 19:55:08,092 - INFO - joeynmt.training - Epoch   7, Step:    48200, Batch Loss:     0.984023, Batch Acc: 0.722955, Tokens per Sec:    24350, Lr: 0.000300
2025-05-27 19:55:11,408 - INFO - joeynmt.training - Epoch   7, Step:    48300, Batch Loss:     0.960830, Batch Acc: 0.720857, Tokens per Sec:    23349, Lr: 0.000300
2025-05-27 19:55:14,725 - INFO - joeynmt.training - Epoch   7, Step:    48400, Batch Loss:     1.092453, Batch Acc: 0.720792, Tokens per Sec:    23730, Lr: 0.000300
2025-05-27 19:55:18,041 - INFO - joeynmt.training - Epoch   7, Step:    48500, Batch Loss:     0.913644, Batch Acc: 0.722453, Tokens per Sec:    24203, Lr: 0.000300
2025-05-27 19:55:18,042 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:55:18,042 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:55:32,744 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.72, acc:   0.71, generation: 14.6897[sec], evaluation: 0.0000[sec]
2025-05-27 19:55:33,106 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/45500.ckpt
2025-05-27 19:55:33,129 - INFO - joeynmt.training - Example #0
2025-05-27 19:55:33,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:55:33,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:55:33,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In@@', '<unk>', '@', 'fine', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', 'sono', 'st@@', '<unk>', '@', 'ate', 'mostr@@', '<unk>', '@', 'ando', 'per', 'ri@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'ire', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'i', '4@@', '<unk>', '@', '8', 'anni', ',', 'che', 'l&apos;', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'olo', 'per', 'i', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', '4@@', '<unk>', '@', '8', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', ',', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:55:33,131 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:55:33,131 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:55:33,131 - INFO - joeynmt.training - 	Hypothesis: In<unk> @ fine , ho mostr<unk> @ ato queste due cose sono st<unk> @ ate mostr<unk> @ ando per ri<unk> @ fer<unk> @ ire per ri<unk> @ dur<unk> @ re il g<unk> @ hi<unk> @ ac<unk> @ cio per i 4<unk> @ 8 anni , che l&apos; ar<unk> @ t<unk> @ ic<unk> @ olo per i 4<unk> @ 8 anni , per il 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , 4<unk> @ 8 anni , il 4<unk> @ 8 , 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per il 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per il 4<unk> @ 0 % .
2025-05-27 19:55:33,131 - INFO - joeynmt.training - Example #1
2025-05-27 19:55:33,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:55:33,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:55:33,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'ter@@', '<unk>', '@', 'r@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:55:33,132 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:55:33,132 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:55:33,132 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ r<unk> @ it di questo problema spe<unk> @ ci<unk> @ ale , questo problema , perch non  il D<unk> @ ic<unk> @ e<unk> @ o , perch non  il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 19:55:33,132 - INFO - joeynmt.training - Example #2
2025-05-27 19:55:33,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:55:33,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:55:33,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:55:33,133 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:55:33,133 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:55:33,133 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ aus<unk> @ a di un cer<unk> @ to sen<unk> @ so , il cu<unk> @ ore del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 19:55:33,133 - INFO - joeynmt.training - Example #3
2025-05-27 19:55:33,133 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:55:33,133 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:55:33,133 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'il', 'p@@', '<unk>', '@', 'ul@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ter', '.', '</s>']
2025-05-27 19:55:33,134 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:55:33,134 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:55:33,134 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e il p<unk> @ ul<unk> @ in<unk> @ ter .
2025-05-27 19:55:33,134 - INFO - joeynmt.training - Example #4
2025-05-27 19:55:33,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:55:33,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:55:33,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:55:33,135 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:55:33,135 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:55:33,135 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ er<unk> @  una c<unk> @ en<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:55:36,459 - INFO - joeynmt.training - Epoch   7, Step:    48600, Batch Loss:     0.896581, Batch Acc: 0.721263, Tokens per Sec:    21320, Lr: 0.000300
2025-05-27 19:55:39,766 - INFO - joeynmt.training - Epoch   7, Step:    48700, Batch Loss:     1.062214, Batch Acc: 0.718866, Tokens per Sec:    23942, Lr: 0.000300
2025-05-27 19:55:43,082 - INFO - joeynmt.training - Epoch   7, Step:    48800, Batch Loss:     0.988642, Batch Acc: 0.718605, Tokens per Sec:    24502, Lr: 0.000300
2025-05-27 19:55:46,423 - INFO - joeynmt.training - Epoch   7, Step:    48900, Batch Loss:     1.082211, Batch Acc: 0.716929, Tokens per Sec:    23930, Lr: 0.000300
2025-05-27 19:55:49,738 - INFO - joeynmt.training - Epoch   7, Step:    49000, Batch Loss:     0.996822, Batch Acc: 0.719882, Tokens per Sec:    23647, Lr: 0.000300
2025-05-27 19:55:49,738 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:55:49,738 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:56:06,095 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 16.3424[sec], evaluation: 0.0000[sec]
2025-05-27 19:56:06,095 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:56:06,603 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/46500.ckpt
2025-05-27 19:56:06,628 - INFO - joeynmt.training - Example #0
2025-05-27 19:56:06,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:56:06,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:56:06,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'e', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'le', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 're', 'per', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'i', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'v@@', '<unk>', '@', 'are', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'circa', 'il', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:56:06,630 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:56:06,630 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:56:06,630 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due p<unk> @ ezz<unk> @ e per ri<unk> @ dur<unk> @ re le ci<unk> @ b<unk> @ re per il g<unk> @ hi<unk> @ ac<unk> @ cio , che il g<unk> @ hi<unk> @ ac<unk> @ cio per i tre mili<unk> @ ar<unk> @ di di di di m<unk> @ oti<unk> @ v<unk> @ are il 4<unk> @ 0 % del 4<unk> @ 8 anni , per il 4<unk> @ 8 , per c<unk> @ ento di circa il 4<unk> @ 8 % .
2025-05-27 19:56:06,630 - INFO - joeynmt.training - Example #1
2025-05-27 19:56:06,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:56:06,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:56:06,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 't@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'r@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:56:06,631 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:56:06,631 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:56:06,631 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza in<unk> @ t<unk> @ eg<unk> @ r<unk> @ it di questo problema spe<unk> @ ci<unk> @ ale .
2025-05-27 19:56:06,631 - INFO - joeynmt.training - Example #2
2025-05-27 19:56:06,631 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:56:06,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:56:06,632 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'k@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ing', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:56:06,632 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:56:06,632 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:56:06,632 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a  la c<unk> @ aus<unk> @ a di E<unk> @ is<unk> @ k<unk> @ p<unk> @ ing , il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:56:06,632 - INFO - joeynmt.training - Example #3
2025-05-27 19:56:06,632 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:56:06,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:56:06,632 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pu', 'essere', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'la', 'v@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 19:56:06,633 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:56:06,633 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:56:06,633 - INFO - joeynmt.training - 	Hypothesis: Si pu essere in est<unk> @ ate e la v<unk> @ in<unk> @ ver<unk> @ no .
2025-05-27 19:56:06,633 - INFO - joeynmt.training - Example #4
2025-05-27 19:56:06,633 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:56:06,633 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:56:06,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ura', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'e@@', '<unk>', '@', 'de@@', '<unk>', '@', 'va', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:56:06,634 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:56:06,634 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:56:06,634 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ ura che vi mostr<unk> @ er<unk> @   una c<unk> @ aus<unk> @ a di quello che succ<unk> @ e<unk> @ de<unk> @ va negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:56:09,913 - INFO - joeynmt.training - Epoch   7, Step:    49100, Batch Loss:     0.906914, Batch Acc: 0.717846, Tokens per Sec:    20751, Lr: 0.000300
2025-05-27 19:56:13,141 - INFO - joeynmt.training - Epoch   7, Step:    49200, Batch Loss:     0.993157, Batch Acc: 0.717604, Tokens per Sec:    23964, Lr: 0.000300
2025-05-27 19:56:16,325 - INFO - joeynmt.training - Epoch   7, Step:    49300, Batch Loss:     0.904869, Batch Acc: 0.718545, Tokens per Sec:    25086, Lr: 0.000300
2025-05-27 19:56:19,543 - INFO - joeynmt.training - Epoch   7, Step:    49400, Batch Loss:     0.961923, Batch Acc: 0.718802, Tokens per Sec:    24208, Lr: 0.000300
2025-05-27 19:56:22,767 - INFO - joeynmt.training - Epoch   7, Step:    49500, Batch Loss:     0.952128, Batch Acc: 0.718578, Tokens per Sec:    24672, Lr: 0.000300
2025-05-27 19:56:22,767 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:56:22,768 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:56:37,174 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.70, acc:   0.71, generation: 14.3980[sec], evaluation: 0.0000[sec]
2025-05-27 19:56:37,175 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:56:37,604 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/47500.ckpt
2025-05-27 19:56:37,625 - INFO - joeynmt.training - Example #0
2025-05-27 19:56:37,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:56:37,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:56:37,626 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'p@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ci', 'per', 'ri@@', '<unk>', '@', 'chi@@', '<unk>', '@', 'ede', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'del', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vo', 'per', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'sol@@', '<unk>', '@', 'ito', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'anni', '.', '</s>']
2025-05-27 19:56:37,626 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:56:37,626 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:56:37,626 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due p<unk> @ es<unk> @ ci per ri<unk> @ chi<unk> @ ede che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che aveva tre milioni di anni , per il 4<unk> @ 0 % del m<unk> @ oti<unk> @ vo per 4<unk> @ 8 anni , per il 4<unk> @ 8 , per c<unk> @ ento di sol<unk> @ ito , per il 4<unk> @ 8 anni .
2025-05-27 19:56:37,626 - INFO - joeynmt.training - Example #1
2025-05-27 19:56:37,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:56:37,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:56:37,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'ter@@', '<unk>', '@', 'ra', 'di', 'ter@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ini', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', 'che', 'non', 'ci', 'mostr@@', '<unk>', '@', 'a', 'il', 'problema', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ke', '.', '</s>']
2025-05-27 19:56:37,627 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:56:37,627 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:56:37,627 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ ra di ter<unk> @ m<unk> @ ini di questo problema spe<unk> @ ci<unk> @ ci<unk> @ ale che non ci mostr<unk> @ a il problema di E<unk> @ is<unk> @ p<unk> @ ke .
2025-05-27 19:56:37,627 - INFO - joeynmt.training - Example #2
2025-05-27 19:56:37,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:56:37,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:56:37,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'so', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:56:37,628 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:56:37,628 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:56:37,628 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  il g<unk> @ hi<unk> @ ac<unk> @ cio  il g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ so glob<unk> @ ale .
2025-05-27 19:56:37,629 - INFO - joeynmt.training - Example #3
2025-05-27 19:56:37,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:56:37,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:56:37,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'etro', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 19:56:37,629 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:56:37,629 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:56:37,629 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ etro e in<unk> @ ver<unk> @ no .
2025-05-27 19:56:37,629 - INFO - joeynmt.training - Example #4
2025-05-27 19:56:37,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:56:37,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:56:37,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', ',', '', 'una', 'lin@@', '<unk>', '@', 'ea', 'di', 'queste', 'cose', '', 'succ@@', '<unk>', '@', 'essi@@', '<unk>', '@', 've', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:56:37,630 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:56:37,630 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:56:37,630 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ er<unk> @  ,  una lin<unk> @ ea di queste cose  succ<unk> @ essi<unk> @ ve negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:56:40,878 - INFO - joeynmt.training - Epoch   7, Step:    49600, Batch Loss:     0.866403, Batch Acc: 0.719806, Tokens per Sec:    21784, Lr: 0.000300
2025-05-27 19:56:44,033 - INFO - joeynmt.training - Epoch   7, Step:    49700, Batch Loss:     1.054184, Batch Acc: 0.721658, Tokens per Sec:    25257, Lr: 0.000300
2025-05-27 19:56:47,231 - INFO - joeynmt.training - Epoch   7, Step:    49800, Batch Loss:     0.996471, Batch Acc: 0.721132, Tokens per Sec:    24720, Lr: 0.000300
2025-05-27 19:56:50,403 - INFO - joeynmt.training - Epoch   7, Step:    49900, Batch Loss:     0.925125, Batch Acc: 0.718474, Tokens per Sec:    24987, Lr: 0.000300
2025-05-27 19:56:53,609 - INFO - joeynmt.training - Epoch   7, Step:    50000, Batch Loss:     0.975262, Batch Acc: 0.717855, Tokens per Sec:    24793, Lr: 0.000300
2025-05-27 19:56:53,610 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:56:53,610 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:57:07,026 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 13.4074[sec], evaluation: 0.0000[sec]
2025-05-27 19:57:07,314 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/47000.ckpt
2025-05-27 19:57:07,330 - INFO - joeynmt.training - Example #0
2025-05-27 19:57:07,331 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:57:07,331 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:57:07,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'pun@@', '<unk>', '@', 'ti', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'str@@', '<unk>', '@', 'utt@@', '<unk>', '@', 'ura', 'che', 'i', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', 'per', 'la', 'qu@@', '<unk>', '@', 'ale', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '8', '%', 'di', 'qu@@', '<unk>', '@', 'ei', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'in@@', '<unk>', '@', 'gu@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ni', ',', 'ha', 'fatto', 'il', '4@@', '<unk>', '@', '8', '%', 'di', 'tutti', 'i', 'stati', 'in', 'gra@@', '<unk>', '@', 'do', 'di', 'fare', 'il', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 19:57:07,331 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:57:07,332 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:57:07,332 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato questi due pun<unk> @ ti per ri<unk> @ dur<unk> @ re la str<unk> @ utt<unk> @ ura che i g<unk> @ am<unk> @ be per la qu<unk> @ ale che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i tre milioni di anni , che aveva fatto per il 4<unk> @ 8 % di qu<unk> @ ei di<unk> @ st<unk> @ in<unk> @ gu<unk> @ ig<unk> @ ni , ha fatto il 4<unk> @ 8 % di tutti i stati in gra<unk> @ do di fare il 4<unk> @ 8 % .
2025-05-27 19:57:07,332 - INFO - joeynmt.training - Example #1
2025-05-27 19:57:07,332 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:57:07,332 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:57:07,332 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'l&apos;', 'in@@', '<unk>', '@', 'st@@', '<unk>', '@', 'a@@', '<unk>', '@', 'da', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'l&apos;', 'in@@', '<unk>', '@', 'tr@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'i@@', '<unk>', '@', 'anto', 'di', 'qu@@', '<unk>', '@', 'ei', 'probl@@', '<unk>', '@', 'emi', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'are', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 19:57:07,332 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:57:07,332 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:57:07,333 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza l&apos; in<unk> @ st<unk> @ a<unk> @ da di questo problema , perch non  l&apos; in<unk> @ tr<unk> @ ap<unk> @ i<unk> @ anto di qu<unk> @ ei probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 19:57:07,333 - INFO - joeynmt.training - Example #2
2025-05-27 19:57:07,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:57:07,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:57:07,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:57:07,333 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:57:07,333 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:57:07,333 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore glob<unk> @ ale del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 19:57:07,334 - INFO - joeynmt.training - Example #3
2025-05-27 19:57:07,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:57:07,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:57:07,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ta', 's@@', '<unk>', '@', 'com@@', '<unk>', '@', 'par@@', '<unk>', '@', 'si', 'e', 'in', 'est@@', '<unk>', '@', 'ate', 'nel', 'sen@@', '<unk>', '@', 'so', '.', '</s>']
2025-05-27 19:57:07,334 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:57:07,334 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:57:07,334 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta s<unk> @ com<unk> @ par<unk> @ si e in est<unk> @ ate nel sen<unk> @ so .
2025-05-27 19:57:07,334 - INFO - joeynmt.training - Example #4
2025-05-27 19:57:07,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:57:07,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:57:07,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'st@@', '<unk>', '@', 'anza', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'la', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:57:07,335 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:57:07,335 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:57:07,335 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una st<unk> @ anza che vi mostr<unk> @ er<unk> @  la sc<unk> @ or<unk> @ sa che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:57:10,566 - INFO - joeynmt.training - Epoch   7, Step:    50100, Batch Loss:     0.882641, Batch Acc: 0.721609, Tokens per Sec:    22305, Lr: 0.000300
2025-05-27 19:57:13,735 - INFO - joeynmt.training - Epoch   7, Step:    50200, Batch Loss:     0.871790, Batch Acc: 0.720433, Tokens per Sec:    24476, Lr: 0.000300
2025-05-27 19:57:16,925 - INFO - joeynmt.training - Epoch   7, Step:    50300, Batch Loss:     0.917008, Batch Acc: 0.718225, Tokens per Sec:    25166, Lr: 0.000300
2025-05-27 19:57:20,145 - INFO - joeynmt.training - Epoch   7, Step:    50400, Batch Loss:     0.944351, Batch Acc: 0.719042, Tokens per Sec:    24736, Lr: 0.000300
2025-05-27 19:57:23,346 - INFO - joeynmt.training - Epoch   7, Step:    50500, Batch Loss:     0.917323, Batch Acc: 0.716335, Tokens per Sec:    24512, Lr: 0.000300
2025-05-27 19:57:23,346 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:57:23,346 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:57:39,061 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 15.7009[sec], evaluation: 0.0000[sec]
2025-05-27 19:57:39,550 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/48500.ckpt
2025-05-27 19:57:39,575 - INFO - joeynmt.training - Example #0
2025-05-27 19:57:39,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:57:39,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:57:39,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', 'sono', 'stati', 'mostr@@', '<unk>', '@', 'ati', 'per', 'ri@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'm@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', '4@@', '<unk>', '@', '8', 'anni', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'qu@@', '<unk>', '@', 'elli', 'che', 'hanno', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'anni', ',', 'aveva', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:57:39,576 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:57:39,577 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:57:39,577 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due cas<unk> @ i sono stati mostr<unk> @ ati per ri<unk> @ fer<unk> @ m<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ cio , per i g<unk> @ hi<unk> @ ac<unk> @ cio , per i 4<unk> @ 8 anni , per c<unk> @ ento di qu<unk> @ elli che hanno av<unk> @ uto 4<unk> @ 8 anni , aveva av<unk> @ uto 4<unk> @ 8 , per c<unk> @ ento di 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per c<unk> @ ento .
2025-05-27 19:57:39,577 - INFO - joeynmt.training - Example #1
2025-05-27 19:57:39,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:57:39,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:57:39,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'ter@@', '<unk>', '@', 'n@@', '<unk>', '@', 'ra', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', 'mostr@@', '<unk>', '@', 'a', 'il', 'problema', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'es', '.', '</s>']
2025-05-27 19:57:39,577 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:57:39,578 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:57:39,578 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ n<unk> @ ra di questo problema spe<unk> @ ci<unk> @ ale , perch non mostr<unk> @ a il problema di E<unk> @ is<unk> @ es .
2025-05-27 19:57:39,578 - INFO - joeynmt.training - Example #2
2025-05-27 19:57:39,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:57:39,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:57:39,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'o', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:57:39,578 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ itu<unk> @ azione  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ o glob<unk> @ ale .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - Example #3
2025-05-27 19:57:39,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:57:39,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:57:39,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'ento', 'e', 'p@@', '<unk>', '@', 'oco', ',', 'e', 'poi', 'si', 'trov@@', '<unk>', '@', 'a', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e p<unk> @ oco , e poi si trov<unk> @ a in est<unk> @ ate .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - Example #4
2025-05-27 19:57:39,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:57:39,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:57:39,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'a', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'st@@', '<unk>', '@', 'anza', 'di', 'tra@@', '<unk>', '@', 'ff@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ente', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:57:39,580 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:57:39,580 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:57:39,580 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ am<unk> @ a che vi mostr<unk> @ er<unk> @  una st<unk> @ anza di tra<unk> @ ff<unk> @ ic<unk> @ i<unk> @ ente , che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:57:42,940 - INFO - joeynmt.training - Epoch   7, Step:    50600, Batch Loss:     0.923917, Batch Acc: 0.716311, Tokens per Sec:    20316, Lr: 0.000300
2025-05-27 19:57:45,396 - INFO - joeynmt.training - Epoch   7, Step:    50700, Batch Loss:     1.021105, Batch Acc: 0.718706, Tokens per Sec:    33233, Lr: 0.000300
2025-05-27 19:57:47,299 - INFO - joeynmt.training - Epoch   7, Step:    50800, Batch Loss:     0.961667, Batch Acc: 0.716964, Tokens per Sec:    42201, Lr: 0.000300
2025-05-27 19:57:49,217 - INFO - joeynmt.training - Epoch   7, Step:    50900, Batch Loss:     1.029240, Batch Acc: 0.719173, Tokens per Sec:    41163, Lr: 0.000300
2025-05-27 19:57:51,129 - INFO - joeynmt.training - Epoch   7, Step:    51000, Batch Loss:     0.973920, Batch Acc: 0.722641, Tokens per Sec:    42673, Lr: 0.000300
2025-05-27 19:57:51,130 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:57:51,130 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:58:05,950 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 14.8085[sec], evaluation: 0.0000[sec]
2025-05-27 19:58:06,286 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/48000.ckpt
2025-05-27 19:58:06,310 - INFO - joeynmt.training - Example #0
2025-05-27 19:58:06,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:58:06,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:58:06,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cas@@', '<unk>', '@', 'e', ',', 'per', 'far@@', '<unk>', '@', 'lo', 'per', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'en@@', '<unk>', '@', 'z@@', '<unk>', '@', 'i', ',', 'che', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cia', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'qu@@', '<unk>', '@', 'elli', 'di', '4@@', '<unk>', '@', '8', '%', 'di', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'c@@', '<unk>', '@', 'ento', ',', '4@@', '<unk>', '@', '0', '%', 'di', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:58:06,312 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:58:06,312 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:58:06,312 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cas<unk> @ e , per far<unk> @ lo per c<unk> @ aus<unk> @ a di in<unk> @ f<unk> @ lu<unk> @ en<unk> @ z<unk> @ i , che la g<unk> @ hi<unk> @ ac<unk> @ cia , per il 4<unk> @ 0 % di qu<unk> @ elli di 4<unk> @ 8 % di 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , 4<unk> @ 0 % di m<unk> @ ezz<unk> @ o .
2025-05-27 19:58:06,312 - INFO - joeynmt.training - Example #1
2025-05-27 19:58:06,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:58:06,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:58:06,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'cos', 'for@@', '<unk>', '@', 't@@', '<unk>', '@', 'un@@', '<unk>', '@', 'at@@', '<unk>', '@', 'amente', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ha@@', '<unk>', '@', 'i', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'che', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:58:06,313 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:58:06,313 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:58:06,313 - INFO - joeynmt.training - 	Hypothesis: Ma non  cos for<unk> @ t<unk> @ un<unk> @ at<unk> @ amente la di<unk> @ st<unk> @ ha<unk> @ i questa part<unk> @ icol<unk> @ are , che non  il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:58:06,313 - INFO - joeynmt.training - Example #2
2025-05-27 19:58:06,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:58:06,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:58:06,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'sen@@', '<unk>', '@', 'so', '', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ata', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:58:06,314 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:58:06,314 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:58:06,314 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa c<unk> @ aus<unk> @ a di sen<unk> @ so  la g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ata del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico glob<unk> @ ale .
2025-05-27 19:58:06,314 - INFO - joeynmt.training - Example #3
2025-05-27 19:58:06,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:58:06,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:58:06,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'si', '', 'sp@@', '<unk>', '@', 'esso', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 19:58:06,315 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:58:06,315 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:58:06,315 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si  sp<unk> @ esso in est<unk> @ ate .
2025-05-27 19:58:06,315 - INFO - joeynmt.training - Example #4
2025-05-27 19:58:06,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:58:06,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:58:06,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'anno', 'la', 'mia', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'u', 'una', 'st@@', '<unk>', '@', 'anza', 'di', 'in@@', '<unk>', '@', 'contr@@', '<unk>', '@', 'o', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:58:06,316 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:58:06,316 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:58:06,316 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ anno la mia pros<unk> @ si<unk> @ ma f<unk> @ u una st<unk> @ anza di in<unk> @ contr<unk> @ o , che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:58:07,855 - INFO - joeynmt.training - Epoch   7, Step:    51100, Batch Loss:     1.058849, Batch Acc: 0.718445, Tokens per Sec:    42247, Lr: 0.000300
2025-05-27 19:58:09,443 - INFO - joeynmt.training - Epoch   7, Step:    51200, Batch Loss:     0.938377, Batch Acc: 0.717991, Tokens per Sec:    50118, Lr: 0.000300
2025-05-27 19:58:11,009 - INFO - joeynmt.training - Epoch   7, Step:    51300, Batch Loss:     0.988798, Batch Acc: 0.718162, Tokens per Sec:    50263, Lr: 0.000300
2025-05-27 19:58:12,627 - INFO - joeynmt.training - Epoch   7, Step:    51400, Batch Loss:     1.033448, Batch Acc: 0.716381, Tokens per Sec:    47414, Lr: 0.000300
2025-05-27 19:58:14,171 - INFO - joeynmt.training - Epoch   7, Step:    51500, Batch Loss:     0.905081, Batch Acc: 0.717815, Tokens per Sec:    50584, Lr: 0.000300
2025-05-27 19:58:14,171 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:58:14,171 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:58:26,861 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 12.6821[sec], evaluation: 0.0000[sec]
2025-05-27 19:58:27,268 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/50500.ckpt
2025-05-27 19:58:27,286 - INFO - joeynmt.training - Example #0
2025-05-27 19:58:27,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:58:27,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:58:27,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'i', 'di', 'p@@', '<unk>', '@', 'om@@', '<unk>', '@', 'enti', 'per', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'in@@', '<unk>', '@', 'gu@@', '<unk>', '@', 'ere', ',', 'che', 'l&apos;', 'or@@', '<unk>', '@', 't@@', '<unk>', '@', 'is@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ina', ',', 'che', 'ha', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'questi', 'tre', 'milioni', 'di', 'rag@@', '<unk>', '@', 'i@@', '<unk>', '@', 'oni', 'di', 'rag@@', '<unk>', '@', 'i@@', '<unk>', '@', 'oni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:58:27,287 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:58:27,287 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:58:27,287 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due p<unk> @ ezz<unk> @ i di p<unk> @ om<unk> @ enti per di<unk> @ st<unk> @ in<unk> @ gu<unk> @ ere , che l&apos; or<unk> @ t<unk> @ is<unk> @ c<unk> @ ina , che ha fatto per il 4<unk> @ 0 % di questi tre milioni di rag<unk> @ i<unk> @ oni di rag<unk> @ i<unk> @ oni , per il 4<unk> @ 0 % .
2025-05-27 19:58:27,287 - INFO - joeynmt.training - Example #1
2025-05-27 19:58:27,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:58:27,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:58:27,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:58:27,288 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:58:27,288 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:58:27,288 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perch non  il d<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:58:27,288 - INFO - joeynmt.training - Example #2
2025-05-27 19:58:27,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:58:27,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:58:27,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'la', 'cu@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ina', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'e', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 19:58:27,289 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:58:27,289 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:58:27,289 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , la cu<unk> @ c<unk> @ ina del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ e del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico .
2025-05-27 19:58:27,289 - INFO - joeynmt.training - Example #3
2025-05-27 19:58:27,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:58:27,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:58:27,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ta', 'divent@@', '<unk>', '@', 'a', 'un', 'v@@', '<unk>', '@', 'ento', 'e', 'p@@', '<unk>', '@', 'oco', ',', 'e', 'p@@', '<unk>', '@', 'oco', '.', '</s>']
2025-05-27 19:58:27,290 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:58:27,290 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:58:27,290 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta divent<unk> @ a un v<unk> @ ento e p<unk> @ oco , e p<unk> @ oco .
2025-05-27 19:58:27,290 - INFO - joeynmt.training - Example #4
2025-05-27 19:58:27,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:58:27,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:58:27,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 're@@', '<unk>', '@', 'qu@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ale', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'queste', 'cose', '', 'succ@@', '<unk>', '@', 'esso', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'ci', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:58:27,291 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:58:27,291 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:58:27,291 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ re<unk> @ qu<unk> @ ent<unk> @ ale  una c<unk> @ en<unk> @ a di queste cose  succ<unk> @ esso una c<unk> @ en<unk> @ a di ci che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:58:28,823 - INFO - joeynmt.training - Epoch   7, Step:    51600, Batch Loss:     0.892131, Batch Acc: 0.719960, Tokens per Sec:    39443, Lr: 0.000300
2025-05-27 19:58:30,330 - INFO - joeynmt.training - Epoch   7, Step:    51700, Batch Loss:     0.937356, Batch Acc: 0.721311, Tokens per Sec:    50985, Lr: 0.000300
2025-05-27 19:58:31,819 - INFO - joeynmt.training - Epoch   7, Step:    51800, Batch Loss:     0.932051, Batch Acc: 0.716875, Tokens per Sec:    51303, Lr: 0.000300
2025-05-27 19:58:33,362 - INFO - joeynmt.training - Epoch   7, Step:    51900, Batch Loss:     0.944488, Batch Acc: 0.717506, Tokens per Sec:    51111, Lr: 0.000300
2025-05-27 19:58:34,939 - INFO - joeynmt.training - Epoch   7, Step:    52000, Batch Loss:     0.915180, Batch Acc: 0.719544, Tokens per Sec:    50272, Lr: 0.000300
2025-05-27 19:58:34,939 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:58:34,939 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:58:48,551 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.69, acc:   0.71, generation: 13.6041[sec], evaluation: 0.0000[sec]
2025-05-27 19:58:48,552 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:58:49,005 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/49000.ckpt
2025-05-27 19:58:49,028 - INFO - joeynmt.training - Example #0
2025-05-27 19:58:49,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:58:49,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:58:49,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cas@@', '<unk>', '@', 'i', 'di', 'c@@', '<unk>', '@', 'op@@', '<unk>', '@', 'pi@@', '<unk>', '@', 'a', 'per', 'ven@@', '<unk>', '@', 'ire', 'in', 'gra@@', '<unk>', '@', 'do', 'di', 'f@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'ale', ',', 'che', 'l&apos;', 'or@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'is@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ina', 'per', 'le', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'av@@', '<unk>', '@', 'evo', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'del', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:58:49,030 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:58:49,030 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:58:49,030 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cas<unk> @ i di c<unk> @ op<unk> @ pi<unk> @ a per ven<unk> @ ire in gra<unk> @ do di f<unk> @ att<unk> @ ur<unk> @ ale , che l&apos; or<unk> @ ig<unk> @ is<unk> @ c<unk> @ ina per le tre milioni di anni , che av<unk> @ evo tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % del c<unk> @ ento .
2025-05-27 19:58:49,030 - INFO - joeynmt.training - Example #1
2025-05-27 19:58:49,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:58:49,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:58:49,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'ter@@', '<unk>', '@', 'za', 'in@@', '<unk>', '@', 'tel@@', '<unk>', '@', 'li@@', '<unk>', '@', 'gente', ',', 'perch', 'non', 'ci', 'mostr@@', '<unk>', '@', 'a', 'il', 'problema', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 19:58:49,031 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:58:49,031 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:58:49,031 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ za in<unk> @ tel<unk> @ li<unk> @ gente , perch non ci mostr<unk> @ a il problema di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 19:58:49,031 - INFO - joeynmt.training - Example #2
2025-05-27 19:58:49,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:58:49,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:58:49,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'cio', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 19:58:49,032 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:58:49,032 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:58:49,032 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ li<unk> @ mat<unk> @ ica  la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio .
2025-05-27 19:58:49,032 - INFO - joeynmt.training - Example #3
2025-05-27 19:58:49,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:58:49,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:58:49,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 19:58:49,033 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:58:49,033 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:58:49,033 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e in<unk> @ ver<unk> @ no .
2025-05-27 19:58:49,033 - INFO - joeynmt.training - Example #4
2025-05-27 19:58:49,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:58:49,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:58:49,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'oll@@', '<unk>', '@', 'ia', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', ',', '', 'una', 'st@@', '<unk>', '@', 'anza', 'di', 'queste', 'ulti@@', '<unk>', '@', 'me', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:58:49,034 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:58:49,034 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:58:49,034 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ oll<unk> @ ia che vi mostr<unk> @ er<unk> @  ,  una st<unk> @ anza di queste ulti<unk> @ me 2<unk> @ 5 anni .
2025-05-27 19:58:50,618 - INFO - joeynmt.training - Epoch   7, Step:    52100, Batch Loss:     1.048749, Batch Acc: 0.720453, Tokens per Sec:    37457, Lr: 0.000300
2025-05-27 19:58:52,152 - INFO - joeynmt.training - Epoch   7, Step:    52200, Batch Loss:     0.912745, Batch Acc: 0.719662, Tokens per Sec:    52475, Lr: 0.000300
2025-05-27 19:58:53,735 - INFO - joeynmt.training - Epoch   7, Step:    52300, Batch Loss:     0.974463, Batch Acc: 0.716770, Tokens per Sec:    48573, Lr: 0.000300
2025-05-27 19:58:55,255 - INFO - joeynmt.training - Epoch   7, Step:    52400, Batch Loss:     0.889552, Batch Acc: 0.721057, Tokens per Sec:    51280, Lr: 0.000300
2025-05-27 19:58:56,784 - INFO - joeynmt.training - Epoch   7, Step:    52500, Batch Loss:     1.093569, Batch Acc: 0.719462, Tokens per Sec:    51373, Lr: 0.000300
2025-05-27 19:58:56,784 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:58:56,784 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:59:09,505 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.72, generation: 12.7137[sec], evaluation: 0.0000[sec]
2025-05-27 19:59:09,506 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:59:09,985 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/51000.ckpt
2025-05-27 19:59:10,003 - INFO - joeynmt.training - Example #0
2025-05-27 19:59:10,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:59:10,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:59:10,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'pol@@', '<unk>', '@', 'iti@@', '<unk>', '@', 'che', ',', 'per', 'l&apos;', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'che', 'le', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', 'per', 'la', 'qu@@', '<unk>', '@', 'ale', 'ri@@', '<unk>', '@', 'chi@@', '<unk>', '@', 'ede', 'che', 'l&apos;', 'or@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ine', 'di', 'circa', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'che', 'av@@', '<unk>', '@', 'evo', 'per', 'il', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'per', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'per', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'per', '4@@', '<unk>', '@', '8', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bile', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:59:10,004 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:59:10,004 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:59:10,004 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due pol<unk> @ iti<unk> @ che , per l&apos; ho mostr<unk> @ ato che le g<unk> @ am<unk> @ be per la qu<unk> @ ale ri<unk> @ chi<unk> @ ede che l&apos; or<unk> @ ig<unk> @ ine di circa 4<unk> @ 8 milioni di anni , che av<unk> @ evo per il 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per 4<unk> @ 8 c<unk> @ ento  stato in<unk> @ cre<unk> @ di<unk> @ bile per c<unk> @ ento .
2025-05-27 19:59:10,004 - INFO - joeynmt.training - Example #1
2025-05-27 19:59:10,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:59:10,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:59:10,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'cos', 'for@@', '<unk>', '@', 'te', 'l&apos;', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bile', 'problema', 'che', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'in@@', '<unk>', '@', 'zione', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:59:10,005 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:59:10,005 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:59:10,005 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  cos for<unk> @ te l&apos; in<unk> @ cre<unk> @ di<unk> @ bile problema che la di<unk> @ st<unk> @ in<unk> @ zione di questo part<unk> @ icol<unk> @ are , perch non  il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:59:10,005 - INFO - joeynmt.training - Example #2
2025-05-27 19:59:10,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:59:10,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:59:10,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'ur@@', '<unk>', '@', 'i@@', '<unk>', '@', 'os@@', '<unk>', '@', 'it', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 19:59:10,006 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:59:10,006 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:59:10,006 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a  la c<unk> @ ur<unk> @ i<unk> @ os<unk> @ it del nostro c<unk> @ li<unk> @ ma del nostro c<unk> @ li<unk> @ ma .
2025-05-27 19:59:10,006 - INFO - joeynmt.training - Example #3
2025-05-27 19:59:10,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:59:10,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:59:10,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'la', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'azione', '.', '</s>']
2025-05-27 19:59:10,007 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:59:10,007 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:59:10,007 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e la p<unk> @ op<unk> @ ol<unk> @ azione .
2025-05-27 19:59:10,007 - INFO - joeynmt.training - Example #4
2025-05-27 19:59:10,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:59:10,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:59:10,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'am@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'lin@@', '<unk>', '@', 'ea', 'di', 'in@@', '<unk>', '@', 'contr@@', '<unk>', '@', 'o', 'l&apos;', 'ulti@@', '<unk>', '@', 'ma', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:59:10,008 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:59:10,008 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:59:10,008 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ am<unk> @ ig<unk> @ lia che vi mostr<unk> @ o  una lin<unk> @ ea di in<unk> @ contr<unk> @ o l&apos; ulti<unk> @ ma 2<unk> @ 5 anni .
2025-05-27 19:59:11,595 - INFO - joeynmt.training - Epoch   7, Step:    52600, Batch Loss:     1.052136, Batch Acc: 0.721824, Tokens per Sec:    39003, Lr: 0.000300
2025-05-27 19:59:13,182 - INFO - joeynmt.training - Epoch   7, Step:    52700, Batch Loss:     0.969910, Batch Acc: 0.722401, Tokens per Sec:    50837, Lr: 0.000300
2025-05-27 19:59:14,753 - INFO - joeynmt.training - Epoch   7, Step:    52800, Batch Loss:     0.946687, Batch Acc: 0.714761, Tokens per Sec:    49395, Lr: 0.000300
2025-05-27 19:59:16,365 - INFO - joeynmt.training - Epoch   7, Step:    52900, Batch Loss:     0.947894, Batch Acc: 0.717765, Tokens per Sec:    50276, Lr: 0.000300
2025-05-27 19:59:17,949 - INFO - joeynmt.training - Epoch   7, Step:    53000, Batch Loss:     0.857063, Batch Acc: 0.721369, Tokens per Sec:    50260, Lr: 0.000300
2025-05-27 19:59:17,950 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:59:17,950 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:59:29,769 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.72, generation: 11.8121[sec], evaluation: 0.0000[sec]
2025-05-27 19:59:30,093 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/51500.ckpt
2025-05-27 19:59:30,115 - INFO - joeynmt.training - Example #0
2025-05-27 19:59:30,116 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:59:30,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:59:30,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cas@@', '<unk>', '@', 'e', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'per', 'il', '4@@', '<unk>', '@', '0', 'anni', ',', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '0', '%', 'di', 'questi', 'stati', ',', 'per', '4@@', '<unk>', '@', '0', '%', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', '4@@', '<unk>', '@', '0', '%', ',', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due cas<unk> @ e per ri<unk> @ dur<unk> @ re la g<unk> @ hi<unk> @ ac<unk> @ cio che il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio che ha av<unk> @ uto per il 4<unk> @ 0 anni , che ha av<unk> @ uto 4<unk> @ 0 % di questi stati , per 4<unk> @ 0 % , per c<unk> @ ento , per 4<unk> @ 0 % , per c<unk> @ ento .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - Example #1
2025-05-27 19:59:30,117 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:59:30,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:59:30,117 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'molto', 'for@@', '<unk>', '@', 'te', ',', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'in@@', '<unk>', '@', 'zione', 'di', 'questo', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  molto for<unk> @ te , la di<unk> @ st<unk> @ in<unk> @ zione di questo spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:59:30,118 - INFO - joeynmt.training - Example #2
2025-05-27 19:59:30,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:59:30,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:59:30,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ica', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ente', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:59:30,118 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:59:30,118 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:59:30,118 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a  la g<unk> @ hi<unk> @ ar<unk> @ t<unk> @ ica del nostro c<unk> @ li<unk> @ ente glob<unk> @ ale .
2025-05-27 19:59:30,118 - INFO - joeynmt.training - Example #3
2025-05-27 19:59:30,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:59:30,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:59:30,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'e', 'p@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 19:59:30,119 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:59:30,119 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:59:30,119 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e p<unk> @ eg<unk> @ gi<unk> @ o .
2025-05-27 19:59:30,119 - INFO - joeynmt.training - Example #4
2025-05-27 19:59:30,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:59:30,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:59:30,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:59:30,120 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:59:30,120 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:59:30,120 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una c<unk> @ ura di sc<unk> @ or<unk> @ so di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:59:31,728 - INFO - joeynmt.training - Epoch   7, Step:    53100, Batch Loss:     0.969383, Batch Acc: 0.715483, Tokens per Sec:    38701, Lr: 0.000300
2025-05-27 19:59:33,274 - INFO - joeynmt.training - Epoch   7, Step:    53200, Batch Loss:     0.974634, Batch Acc: 0.716615, Tokens per Sec:    50635, Lr: 0.000300
2025-05-27 19:59:34,869 - INFO - joeynmt.training - Epoch   7, Step:    53300, Batch Loss:     0.975251, Batch Acc: 0.719924, Tokens per Sec:    51403, Lr: 0.000300
2025-05-27 19:59:36,449 - INFO - joeynmt.training - Epoch   7, Step:    53400, Batch Loss:     1.083496, Batch Acc: 0.719999, Tokens per Sec:    49307, Lr: 0.000300
2025-05-27 19:59:37,977 - INFO - joeynmt.training - Epoch   7, Step:    53500, Batch Loss:     1.029567, Batch Acc: 0.720755, Tokens per Sec:    53138, Lr: 0.000300
2025-05-27 19:59:37,977 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:59:37,977 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 19:59:53,028 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.73, acc:   0.71, generation: 15.0432[sec], evaluation: 0.0000[sec]
2025-05-27 19:59:53,038 - INFO - joeynmt.training - Example #0
2025-05-27 19:59:53,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 19:59:53,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 19:59:53,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'per', 'fare', 'una', 'b@@', '<unk>', '@', 'arri@@', '<unk>', '@', 'era', 'che', 'le', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'be', 'per', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'dei', 'due', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', 'di', '4@@', '<unk>', '@', '0', '%', ',', 'per', 'circa', '4@@', '<unk>', '@', '0', '%', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 19:59:53,039 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:59:53,039 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:59:53,039 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per fare una b<unk> @ arri<unk> @ era che le g<unk> @ am<unk> @ be per i g<unk> @ hi<unk> @ ac<unk> @ cio , per il g<unk> @ hi<unk> @ ac<unk> @ cio , per il 4<unk> @ 0 % dei due anni , per il 4<unk> @ 0 per c<unk> @ ento di 4<unk> @ 0 % , per circa 4<unk> @ 0 % , per il 4<unk> @ 0 % .
2025-05-27 19:59:53,039 - INFO - joeynmt.training - Example #1
2025-05-27 19:59:53,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 19:59:53,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 19:59:53,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'i@@', '<unk>', '@', 'di@@', '<unk>', '@', 't', '.', '</s>']
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza di questo problema spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ i<unk> @ di<unk> @ t .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - Example #2
2025-05-27 19:59:53,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 19:59:53,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 19:59:53,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'ca', 'di', 'sen@@', '<unk>', '@', 'so', '', 'la', 'propr@@', '<unk>', '@', 'ia', 'c@@', '<unk>', '@', 'ura', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ica', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'ma', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di sen<unk> @ so  la propr<unk> @ ia c<unk> @ ura ar<unk> @ t<unk> @ ica del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma glob<unk> @ ale .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - Example #3
2025-05-27 19:59:53,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 19:59:53,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 19:59:53,041 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'e', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', '.', '</s>']
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e sc<unk> @ or<unk> @ so .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - Example #4
2025-05-27 19:59:53,041 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 19:59:53,041 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 19:59:53,041 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ er<unk> @   una sc<unk> @ or<unk> @ sa che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:59:54,623 - INFO - joeynmt.training - Epoch   7, Step:    53600, Batch Loss:     1.051299, Batch Acc: 0.716289, Tokens per Sec:    48787, Lr: 0.000300
2025-05-27 19:59:56,155 - INFO - joeynmt.training - Epoch   7, Step:    53700, Batch Loss:     0.904229, Batch Acc: 0.716551, Tokens per Sec:    51460, Lr: 0.000300
2025-05-27 19:59:57,717 - INFO - joeynmt.training - Epoch   7, Step:    53800, Batch Loss:     0.939724, Batch Acc: 0.719157, Tokens per Sec:    49396, Lr: 0.000300
2025-05-27 19:59:59,252 - INFO - joeynmt.training - Epoch   7, Step:    53900, Batch Loss:     1.005880, Batch Acc: 0.717717, Tokens per Sec:    51363, Lr: 0.000300
2025-05-27 20:00:00,850 - INFO - joeynmt.training - Epoch   7, Step:    54000, Batch Loss:     1.073071, Batch Acc: 0.716572, Tokens per Sec:    50353, Lr: 0.000300
2025-05-27 20:00:00,850 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:00:00,850 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:00:13,928 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.68, acc:   0.72, generation: 13.0701[sec], evaluation: 0.0000[sec]
2025-05-27 20:00:13,928 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:00:14,413 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/50000.ckpt
2025-05-27 20:00:14,436 - INFO - joeynmt.training - Example #0
2025-05-27 20:00:14,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:00:14,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:00:14,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'col@@', '<unk>', '@', 'ie', ',', 'per', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'dei', 'm@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'i', 'di', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:00:14,438 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:00:14,438 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:00:14,438 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due col<unk> @ ie , per c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , che i g<unk> @ hi<unk> @ ac<unk> @ cio , per i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 % dei m<unk> @ ezz<unk> @ i di 4<unk> @ 0 % , il 4<unk> @ 0 % , il 4<unk> @ 0 % , il 4<unk> @ 0 % .
2025-05-27 20:00:14,438 - INFO - joeynmt.training - Example #1
2025-05-27 20:00:14,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:00:14,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:00:14,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'che', 'la', 'cap@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ato', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'lo', ',', 'perch', 'non', 'mostr@@', '<unk>', '@', 'a', 'il', 'li@@', '<unk>', '@', 'vello', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:00:14,439 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:00:14,439 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:00:14,439 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza che la cap<unk> @ ac<unk> @ it di questo problema , perch non  il d<unk> @ ato di questo problema , perch non  il d<unk> @ ic<unk> @ lo , perch non mostr<unk> @ a il li<unk> @ vello del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:00:14,439 - INFO - joeynmt.training - Example #2
2025-05-27 20:00:14,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:00:14,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:00:14,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ia', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:00:14,440 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:00:14,440 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:00:14,440 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a  la g<unk> @ hi<unk> @ es<unk> @ ia del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:00:14,440 - INFO - joeynmt.training - Example #3
2025-05-27 20:00:14,441 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:00:14,441 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:00:14,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', '', 'in', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'ri@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ce', 'a', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ma', '.', '</s>']
2025-05-27 20:00:14,441 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:00:14,441 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:00:14,441 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @  in v<unk> @ ento e si ri<unk> @ es<unk> @ ce a s<unk> @ om<unk> @ ma .
2025-05-27 20:00:14,441 - INFO - joeynmt.training - Example #4
2025-05-27 20:00:14,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:00:14,442 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:00:14,442 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'ni', '', 'una', 'ri@@', '<unk>', '@', 'vi@@', '<unk>', '@', 'sta', 'di', 'quello', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:00:14,442 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:00:14,442 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:00:14,442 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una ser<unk> @ ie di di<unk> @ seg<unk> @ ni  una ri<unk> @ vi<unk> @ sta di quello che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:00:17,706 - INFO - joeynmt.training - Epoch   7, Step:    54100, Batch Loss:     1.103794, Batch Acc: 0.718718, Tokens per Sec:    20240, Lr: 0.000300
2025-05-27 20:00:21,028 - INFO - joeynmt.training - Epoch   7, Step:    54200, Batch Loss:     0.924506, Batch Acc: 0.718096, Tokens per Sec:    23304, Lr: 0.000300
2025-05-27 20:00:24,368 - INFO - joeynmt.training - Epoch   7, Step:    54300, Batch Loss:     1.001195, Batch Acc: 0.717553, Tokens per Sec:    23496, Lr: 0.000300
2025-05-27 20:00:27,723 - INFO - joeynmt.training - Epoch   7, Step:    54400, Batch Loss:     0.922021, Batch Acc: 0.718443, Tokens per Sec:    23457, Lr: 0.000300
2025-05-27 20:00:31,074 - INFO - joeynmt.training - Epoch   7, Step:    54500, Batch Loss:     1.125536, Batch Acc: 0.721234, Tokens per Sec:    23962, Lr: 0.000300
2025-05-27 20:00:31,074 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:00:31,074 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:00:45,012 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.71, generation: 13.9296[sec], evaluation: 0.0000[sec]
2025-05-27 20:00:45,314 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/49500.ckpt
2025-05-27 20:00:45,330 - INFO - joeynmt.training - Example #0
2025-05-27 20:00:45,331 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:00:45,331 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:00:45,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', 'che', 'si', 'sono', 'ri@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sto', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', 'g@@', '<unk>', '@', 'am@@', '<unk>', '@', 'enti', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', 'di', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:00:45,331 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:00:45,331 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:00:45,331 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due cas<unk> @ i che si sono ri<unk> @ ma<unk> @ sto per di<unk> @ mostr<unk> @ are che la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , per i g<unk> @ am<unk> @ enti di tre milioni di anni , per il 4<unk> @ 0 per c<unk> @ ento di 4<unk> @ 0 % del 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:00:45,332 - INFO - joeynmt.training - Example #1
2025-05-27 20:00:45,332 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:00:45,332 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:00:45,332 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'cosa', 'che', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'de@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ino', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 20:00:45,332 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:00:45,332 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:00:45,332 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la cosa che non  abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perch non  il de<unk> @ st<unk> @ ino di questo problema .
2025-05-27 20:00:45,332 - INFO - joeynmt.training - Example #2
2025-05-27 20:00:45,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:00:45,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:00:45,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:00:45,333 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:00:45,333 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:00:45,333 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:00:45,333 - INFO - joeynmt.training - Example #3
2025-05-27 20:00:45,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:00:45,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:00:45,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'sen@@', '<unk>', '@', 'so', '.', '</s>']
2025-05-27 20:00:45,334 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:00:45,334 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:00:45,334 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un sen<unk> @ so .
2025-05-27 20:00:45,334 - INFO - joeynmt.training - Example #4
2025-05-27 20:00:45,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:00:45,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:00:45,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'una', 'c@@', '<unk>', '@', 'las@@', '<unk>', '@', 'se', 'che', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:00:45,335 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:00:45,335 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:00:45,335 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i che vi mostr<unk> @ er<unk> @   una c<unk> @ aus<unk> @ a di una c<unk> @ las<unk> @ se che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:00:48,600 - INFO - joeynmt.training - Epoch   7, Step:    54600, Batch Loss:     0.864507, Batch Acc: 0.724240, Tokens per Sec:    22037, Lr: 0.000300
2025-05-27 20:00:51,945 - INFO - joeynmt.training - Epoch   7, Step:    54700, Batch Loss:     0.942118, Batch Acc: 0.719107, Tokens per Sec:    23862, Lr: 0.000300
2025-05-27 20:00:55,273 - INFO - joeynmt.training - Epoch   7, Step:    54800, Batch Loss:     1.020761, Batch Acc: 0.718342, Tokens per Sec:    23794, Lr: 0.000300
2025-05-27 20:00:58,620 - INFO - joeynmt.training - Epoch   7, Step:    54900, Batch Loss:     1.024190, Batch Acc: 0.719716, Tokens per Sec:    23958, Lr: 0.000300
2025-05-27 20:01:01,940 - INFO - joeynmt.training - Epoch   7, Step:    55000, Batch Loss:     1.074166, Batch Acc: 0.722933, Tokens per Sec:    23434, Lr: 0.000300
2025-05-27 20:01:01,940 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:01:01,940 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:01:17,124 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.68, acc:   0.71, generation: 15.1715[sec], evaluation: 0.0000[sec]
2025-05-27 20:01:17,462 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/52000.ckpt
2025-05-27 20:01:17,486 - INFO - joeynmt.training - Example #0
2025-05-27 20:01:17,487 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:01:17,487 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:01:17,487 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'di', 'questi', 'due', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'i', ',', 'per', 'ot@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'ere', 'i', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'ato', 'per', 'i', 'con@@', '<unk>', '@', 'to', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'per', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'bas@@', '<unk>', '@', 'e', 'per', 'tre', 'mili@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'di', 'di', 'di', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'per', '4@@', '<unk>', '@', '8', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 20:01:17,488 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:01:17,488 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:01:17,488 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so di questi due p<unk> @ ezz<unk> @ i , per ot<unk> @ ten<unk> @ ere i con<unk> @ si<unk> @ der<unk> @ ato per i con<unk> @ to che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano per tre mili<unk> @ ar<unk> @ di di di bas<unk> @ e per tre mili<unk> @ ar<unk> @ di di di di tre milioni di anni , per 4<unk> @ 8 per c<unk> @ ento di tre milioni di anni .
2025-05-27 20:01:17,488 - INFO - joeynmt.training - Example #1
2025-05-27 20:01:17,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:01:17,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:01:17,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ha@@', '<unk>', '@', 'i', 'un', 'problema', ',', 'non', 'ci', 'mostr@@', '<unk>', '@', 'a', 'il', 'fatto', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 'es', '.', '</s>']
2025-05-27 20:01:17,489 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:01:17,489 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:01:17,489 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza di questo problema , perch non  la di<unk> @ st<unk> @ ha<unk> @ i un problema , non ci mostr<unk> @ a il fatto di E<unk> @ is<unk> @ es .
2025-05-27 20:01:17,489 - INFO - joeynmt.training - Example #2
2025-05-27 20:01:17,490 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:01:17,490 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:01:17,490 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'are', 'il', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:01:17,490 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:01:17,490 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:01:17,490 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , la c<unk> @ aus<unk> @ a del nostro c<unk> @ li<unk> @ m<unk> @ are il nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:01:17,490 - INFO - joeynmt.training - Example #3
2025-05-27 20:01:17,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:01:17,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:01:17,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:01:17,491 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:01:17,491 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:01:17,491 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ in<unk> @ ver<unk> @ no .
2025-05-27 20:01:17,491 - INFO - joeynmt.training - Example #4
2025-05-27 20:01:17,492 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:01:17,492 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:01:17,492 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'ura', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', '', 'acc@@', '<unk>', '@', 'a@@', '<unk>', '@', 'du@@', '<unk>', '@', 'to', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:01:17,492 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:01:17,492 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:01:17,492 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una c<unk> @ ura sc<unk> @ or<unk> @ sa che  acc<unk> @ a<unk> @ du<unk> @ to in 2<unk> @ 5 anni .
2025-05-27 20:01:20,877 - INFO - joeynmt.training - Epoch   7, Step:    55100, Batch Loss:     0.970567, Batch Acc: 0.720251, Tokens per Sec:    22090, Lr: 0.000300
2025-05-27 20:01:23,404 - INFO - joeynmt.training - Epoch   7: total training loss 7609.72
2025-05-27 20:01:23,405 - INFO - joeynmt.training - EPOCH 8
2025-05-27 20:01:24,244 - INFO - joeynmt.training - Epoch   8, Step:    55200, Batch Loss:     0.832647, Batch Acc: 0.726619, Tokens per Sec:    24229, Lr: 0.000300
2025-05-27 20:01:27,596 - INFO - joeynmt.training - Epoch   8, Step:    55300, Batch Loss:     0.835632, Batch Acc: 0.726820, Tokens per Sec:    24147, Lr: 0.000300
2025-05-27 20:01:30,922 - INFO - joeynmt.training - Epoch   8, Step:    55400, Batch Loss:     0.916764, Batch Acc: 0.730144, Tokens per Sec:    23275, Lr: 0.000300
2025-05-27 20:01:34,279 - INFO - joeynmt.training - Epoch   8, Step:    55500, Batch Loss:     1.006729, Batch Acc: 0.732935, Tokens per Sec:    24829, Lr: 0.000300
2025-05-27 20:01:34,279 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:01:34,280 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:01:51,652 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.67, acc:   0.72, generation: 17.3585[sec], evaluation: 0.0000[sec]
2025-05-27 20:01:51,653 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:01:52,188 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/53000.ckpt
2025-05-27 20:01:52,210 - INFO - joeynmt.training - Example #0
2025-05-27 20:01:52,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:01:52,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:01:52,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'di', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', ',', 'che', 'non', 'av@@', '<unk>', '@', 'evo', 'l&apos;', 'in@@', '<unk>', '@', 'du@@', '<unk>', '@', 'stri@@', '<unk>', '@', 'ale', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'che', 'i', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'ni', ',', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', 'del', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'sp@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 20:01:52,212 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:01:52,212 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:01:52,212 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so di questi due cas<unk> @ i , ho mostr<unk> @ ato queste due cose , che non av<unk> @ evo l&apos; in<unk> @ du<unk> @ stri<unk> @ ale , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano che i g<unk> @ over<unk> @ ni , per i tre milioni di anni , che aveva il 4<unk> @ 0 per c<unk> @ ento del 4<unk> @ 0 per c<unk> @ ento , per c<unk> @ ento  stato sp<unk> @ esso .
2025-05-27 20:01:52,212 - INFO - joeynmt.training - Example #1
2025-05-27 20:01:52,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:01:52,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:01:52,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'azione', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'perch', 'non', '', 'il', 'fatto', 'che', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:01:52,213 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:01:52,213 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:01:52,213 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ azione di questo part<unk> @ icol<unk> @ are , perch non  il fatto che il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:01:52,213 - INFO - joeynmt.training - Example #2
2025-05-27 20:01:52,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:01:52,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:01:52,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 't@@', '<unk>', '@', 'amente', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mi@@', '<unk>', '@', 'zz@@', '<unk>', '@', 'ante', ',', 'la', 'c@@', '<unk>', '@', 'ura', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 20:01:52,214 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:01:52,214 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:01:52,214 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ t<unk> @ amente , la cosa pi po<unk> @ ver<unk> @ a , la c<unk> @ aus<unk> @ a del nostro c<unk> @ li<unk> @ mi<unk> @ zz<unk> @ ante , la c<unk> @ ura del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico .
2025-05-27 20:01:52,214 - INFO - joeynmt.training - Example #3
2025-05-27 20:01:52,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:01:52,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:01:52,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'g@@', '<unk>', '@', 'og@@', '<unk>', '@', 'na', '.', '</s>']
2025-05-27 20:01:52,215 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:01:52,215 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:01:52,215 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si in<unk> @ ver<unk> @ g<unk> @ og<unk> @ na .
2025-05-27 20:01:52,215 - INFO - joeynmt.training - Example #4
2025-05-27 20:01:52,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:01:52,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:01:52,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ant@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'ica', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:01:52,216 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:01:52,216 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:01:52,216 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ant<unk> @ ast<unk> @ ica che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:01:55,555 - INFO - joeynmt.training - Epoch   8, Step:    55600, Batch Loss:     0.865546, Batch Acc: 0.728781, Tokens per Sec:    20332, Lr: 0.000300
2025-05-27 20:01:58,885 - INFO - joeynmt.training - Epoch   8, Step:    55700, Batch Loss:     0.901741, Batch Acc: 0.728456, Tokens per Sec:    24115, Lr: 0.000300
2025-05-27 20:02:02,207 - INFO - joeynmt.training - Epoch   8, Step:    55800, Batch Loss:     0.836093, Batch Acc: 0.724106, Tokens per Sec:    23753, Lr: 0.000300
2025-05-27 20:02:05,541 - INFO - joeynmt.training - Epoch   8, Step:    55900, Batch Loss:     0.906986, Batch Acc: 0.729602, Tokens per Sec:    24153, Lr: 0.000300
2025-05-27 20:02:08,855 - INFO - joeynmt.training - Epoch   8, Step:    56000, Batch Loss:     0.982921, Batch Acc: 0.723710, Tokens per Sec:    24034, Lr: 0.000300
2025-05-27 20:02:08,856 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:02:08,856 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:02:21,991 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.69, acc:   0.71, generation: 13.1262[sec], evaluation: 0.0000[sec]
2025-05-27 20:02:21,997 - INFO - joeynmt.training - Example #0
2025-05-27 20:02:21,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:02:21,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:02:21,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'per', 'l&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'per', 'pot@@', '<unk>', '@', 'er', 'fare', 'queste', 'due', 'f@@', '<unk>', '@', 'att@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ie', 'per', 'la', 'f@@', '<unk>', '@', 'att@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ia', 'di', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'l@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ta', 'per', 'i', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'la', 'fine', 'del', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so per l&apos; anno sc<unk> @ or<unk> @ so per pot<unk> @ er fare queste due f<unk> @ att<unk> @ or<unk> @ ie per la f<unk> @ att<unk> @ or<unk> @ ia di ar<unk> @ t<unk> @ ic<unk> @ l<unk> @ et<unk> @ ta per i ris<unk> @ ol<unk> @ vere i 4<unk> @ 8 milioni di anni , per la fine del 4<unk> @ 0 per c<unk> @ ento .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - Example #1
2025-05-27 20:02:21,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:02:21,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:02:21,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'l&apos;', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bil@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'd@@', '<unk>', '@', 'ato', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza l&apos; in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ it di questo problema spe<unk> @ ci<unk> @ ale , perch non  il d<unk> @ ato del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - Example #2
2025-05-27 20:02:21,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:02:21,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:02:21,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'amente', 'la', 'c@@', '<unk>', '@', 'ura', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa po<unk> @ ver<unk> @ a ar<unk> @ t<unk> @ t<unk> @ ic<unk> @ amente la c<unk> @ ura po<unk> @ ver<unk> @ a glob<unk> @ ale .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - Example #3
2025-05-27 20:02:21,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:02:21,999 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:02:21,999 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'mu@@', '<unk>', '@', 'ov@@', '<unk>', '@', 'ono', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si mu<unk> @ ov<unk> @ ono in est<unk> @ ate .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - Example #4
2025-05-27 20:02:21,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:02:21,999 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:02:21,999 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'ri@@', '<unk>', '@', 'pres@@', '<unk>', '@', 'sione', 'che', '', 'acc@@', '<unk>', '@', 'a@@', '<unk>', '@', 'du@@', '<unk>', '@', 'to', 'in', 'qu@@', '<unk>', '@', 'ale', '', 'acc@@', '<unk>', '@', 'a@@', '<unk>', '@', 'du@@', '<unk>', '@', 'to', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i che vi mostr<unk> @ er<unk> @   una ser<unk> @ ie di ri<unk> @ pres<unk> @ sione che  acc<unk> @ a<unk> @ du<unk> @ to in qu<unk> @ ale  acc<unk> @ a<unk> @ du<unk> @ to negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:02:25,396 - INFO - joeynmt.training - Epoch   8, Step:    56100, Batch Loss:     0.970964, Batch Acc: 0.729042, Tokens per Sec:    22976, Lr: 0.000300
2025-05-27 20:02:28,887 - INFO - joeynmt.training - Epoch   8, Step:    56200, Batch Loss:     0.977907, Batch Acc: 0.725521, Tokens per Sec:    22918, Lr: 0.000300
2025-05-27 20:02:32,220 - INFO - joeynmt.training - Epoch   8, Step:    56300, Batch Loss:     0.960168, Batch Acc: 0.726512, Tokens per Sec:    23570, Lr: 0.000300
2025-05-27 20:02:35,569 - INFO - joeynmt.training - Epoch   8, Step:    56400, Batch Loss:     0.876900, Batch Acc: 0.726602, Tokens per Sec:    23885, Lr: 0.000300
2025-05-27 20:02:38,927 - INFO - joeynmt.training - Epoch   8, Step:    56500, Batch Loss:     0.953993, Batch Acc: 0.728034, Tokens per Sec:    24046, Lr: 0.000300
2025-05-27 20:02:38,928 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:02:38,928 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:02:54,523 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.67, acc:   0.72, generation: 15.5807[sec], evaluation: 0.0000[sec]
2025-05-27 20:02:54,526 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:02:55,066 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/54500.ckpt
2025-05-27 20:02:55,093 - INFO - joeynmt.training - Example #0
2025-05-27 20:02:55,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:02:55,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:02:55,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', 'le', 'due', 'volte', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'col@@', '<unk>', '@', 'i', 'f@@', '<unk>', '@', 'ami@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ari', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'circa', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', '.', '</s>']
2025-05-27 20:02:55,095 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:02:55,095 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:02:55,095 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so che le due volte ho mostr<unk> @ ato questi due col<unk> @ i f<unk> @ ami<unk> @ li<unk> @ ari per ri<unk> @ dur<unk> @ re il g<unk> @ hi<unk> @ ac<unk> @ cio che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per circa 4<unk> @ 8 milioni di anni , che aveva tre milioni di anni , che aveva tre milioni di anni , il 4<unk> @ 8 .
2025-05-27 20:02:55,095 - INFO - joeynmt.training - Example #1
2025-05-27 20:02:55,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:02:55,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:02:55,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'enza', ',', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ke', ',', 'perch', 'non', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:02:55,096 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:02:55,096 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:02:55,096 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la in<unk> @ f<unk> @ lu<unk> @ enza , la giu<unk> @ st<unk> @ izi<unk> @ a , perch non  il D<unk> @ ic<unk> @ ke , perch non  il g<unk> @ hi<unk> @ ac<unk> @ cio del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:02:55,096 - INFO - joeynmt.training - Example #2
2025-05-27 20:02:55,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:02:55,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:02:55,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'ura', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'c@@', '<unk>', '@', 'entr@@', '<unk>', '@', 'ale', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:02:55,097 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:02:55,097 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:02:55,097 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ ura po<unk> @ ver<unk> @ a  il g<unk> @ hi<unk> @ ac<unk> @ cio c<unk> @ entr<unk> @ ale del nostro c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:02:55,097 - INFO - joeynmt.training - Example #3
2025-05-27 20:02:55,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:02:55,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:02:55,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:02:55,098 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:02:55,098 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:02:55,098 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e in<unk> @ ver<unk> @ no .
2025-05-27 20:02:55,098 - INFO - joeynmt.training - Example #4
2025-05-27 20:02:55,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:02:55,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:02:55,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ami@@', '<unk>', '@', 'li@@', '<unk>', '@', 'are', '', 'che', ',', '', 'succ@@', '<unk>', '@', 'esso', 'in', 'un', 'cam@@', '<unk>', '@', 'po', '&apos;', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:02:55,099 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:02:55,099 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:02:55,099 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ami<unk> @ li<unk> @ are  che ,  succ<unk> @ esso in un cam<unk> @ po &apos; di sc<unk> @ or<unk> @ so che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:02:58,454 - INFO - joeynmt.training - Epoch   8, Step:    56600, Batch Loss:     0.845121, Batch Acc: 0.729236, Tokens per Sec:    20067, Lr: 0.000300
2025-05-27 20:03:01,778 - INFO - joeynmt.training - Epoch   8, Step:    56700, Batch Loss:     0.955137, Batch Acc: 0.726356, Tokens per Sec:    23004, Lr: 0.000300
2025-05-27 20:03:05,110 - INFO - joeynmt.training - Epoch   8, Step:    56800, Batch Loss:     1.059188, Batch Acc: 0.721777, Tokens per Sec:    24145, Lr: 0.000300
2025-05-27 20:03:08,425 - INFO - joeynmt.training - Epoch   8, Step:    56900, Batch Loss:     1.047122, Batch Acc: 0.722755, Tokens per Sec:    23470, Lr: 0.000300
2025-05-27 20:03:11,762 - INFO - joeynmt.training - Epoch   8, Step:    57000, Batch Loss:     0.918987, Batch Acc: 0.725991, Tokens per Sec:    23887, Lr: 0.000300
2025-05-27 20:03:11,762 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:03:11,762 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:03:27,874 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.72, generation: 16.0977[sec], evaluation: 0.0000[sec]
2025-05-27 20:03:27,880 - INFO - joeynmt.training - Example #0
2025-05-27 20:03:27,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:03:27,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:03:27,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'di', 'questi', 'due', 'sono', 'i', 'tre', 'milioni', 'di', 'persone', 'che', 'av@@', '<unk>', '@', 'evo', 'due', 'o', ',', 'per', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'l&apos;', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', ',', 'che', 'l&apos;', 'ho', 'av@@', '<unk>', '@', 'uto', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'av@@', '<unk>', '@', 'uto', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'in@@', '<unk>', '@', 'tr@@', '<unk>', '@', 'att@@', '<unk>', '@', 'ato', '.', '</s>']
2025-05-27 20:03:27,880 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:03:27,880 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:03:27,880 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so di questi due sono i tre milioni di persone che av<unk> @ evo due o , per con<unk> @ si<unk> @ der<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio che l&apos; ar<unk> @ t<unk> @ ic<unk> @ e<unk> @ o , che l&apos; ho av<unk> @ uto tre milioni di anni , che aveva tre milioni di anni , che aveva av<unk> @ uto tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 , il 4<unk> @ 0 per c<unk> @ ento  stato in<unk> @ tr<unk> @ att<unk> @ ato .
2025-05-27 20:03:27,880 - INFO - joeynmt.training - Example #1
2025-05-27 20:03:27,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:03:27,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:03:27,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'ver@@', '<unk>', '@', 'it', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'il', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ato', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza la ver<unk> @ it non  abb<unk> @ ast<unk> @ anza il ris<unk> @ ult<unk> @ ato di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:03:27,881 - INFO - joeynmt.training - Example #2
2025-05-27 20:03:27,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:03:27,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:03:27,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ch', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ i<unk> @ ch la c<unk> @ li<unk> @ mat<unk> @ ica  il g<unk> @ hi<unk> @ ac<unk> @ cio del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - Example #3
2025-05-27 20:03:27,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:03:27,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:03:27,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'oc@@', '<unk>', '@', 'e', 'e', 'sp@@', '<unk>', '@', 'azz@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ura', '.', '</s>']
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ oc<unk> @ e e sp<unk> @ azz<unk> @ at<unk> @ ura .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - Example #4
2025-05-27 20:03:27,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:03:27,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:03:27,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'sc@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ola', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i che vi mostr<unk> @ o  una sc<unk> @ at<unk> @ ola che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:03:31,233 - INFO - joeynmt.training - Epoch   8, Step:    57100, Batch Loss:     0.977826, Batch Acc: 0.720254, Tokens per Sec:    23864, Lr: 0.000300
2025-05-27 20:03:34,560 - INFO - joeynmt.training - Epoch   8, Step:    57200, Batch Loss:     0.982867, Batch Acc: 0.722773, Tokens per Sec:    23112, Lr: 0.000300
2025-05-27 20:03:37,789 - INFO - joeynmt.training - Epoch   8, Step:    57300, Batch Loss:     0.830619, Batch Acc: 0.727495, Tokens per Sec:    24419, Lr: 0.000300
2025-05-27 20:03:40,990 - INFO - joeynmt.training - Epoch   8, Step:    57400, Batch Loss:     0.967940, Batch Acc: 0.722503, Tokens per Sec:    24202, Lr: 0.000300
2025-05-27 20:03:44,237 - INFO - joeynmt.training - Epoch   8, Step:    57500, Batch Loss:     1.075971, Batch Acc: 0.726320, Tokens per Sec:    24901, Lr: 0.000300
2025-05-27 20:03:44,237 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:03:44,238 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:03:58,839 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 14.5883[sec], evaluation: 0.0000[sec]
2025-05-27 20:03:58,840 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:03:59,319 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/52500.ckpt
2025-05-27 20:03:59,337 - INFO - joeynmt.training - Example #0
2025-05-27 20:03:59,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:03:59,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:03:59,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'ec@@', '<unk>', '@', 'i', ',', 'per', 'tras@@', '<unk>', '@', 'cor@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ere', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'per', 'tre', 'milioni', 'di', 'volte', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'persone', 'che', 'aveva', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:03:59,339 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:03:59,339 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:03:59,339 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ec<unk> @ i , per tras<unk> @ cor<unk> @ r<unk> @ ere il g<unk> @ hi<unk> @ ac<unk> @ cio che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano per tre milioni di volte , che aveva tre milioni di persone che hanno av<unk> @ uto il 4<unk> @ 0 % di persone che aveva av<unk> @ uto 4<unk> @ 0 % .
2025-05-27 20:03:59,339 - INFO - joeynmt.training - Example #1
2025-05-27 20:03:59,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:03:59,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:03:59,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'tel@@', '<unk>', '@', 'li@@', '<unk>', '@', 'g@@', '<unk>', '@', 'enti', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'problema', '.', '</s>']
2025-05-27 20:03:59,340 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:03:59,340 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:03:59,340 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza in<unk> @ tel<unk> @ li<unk> @ g<unk> @ enti di questo problema spe<unk> @ ci<unk> @ ale , perch non  il problema .
2025-05-27 20:03:59,340 - INFO - joeynmt.training - Example #2
2025-05-27 20:03:59,340 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:03:59,340 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:03:59,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 's@@', '<unk>', '@', 'perim@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'azione', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', 'il', 'nostro', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:03:59,341 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:03:59,341 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:03:59,341 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ perim<unk> @ ent<unk> @ azione po<unk> @ ver<unk> @ a il nostro s<unk> @ ac<unk> @ co di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale .
2025-05-27 20:03:59,341 - INFO - joeynmt.training - Example #3
2025-05-27 20:03:59,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:03:59,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:03:59,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'si', 'ri@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ce', 'nel', 'v@@', '<unk>', '@', 'ento', 'e', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'arsi', 'nel', 'sen@@', '<unk>', '@', 'so', 'di', '.', '</s>']
2025-05-27 20:03:59,342 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:03:59,342 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:03:59,342 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , si ri<unk> @ es<unk> @ ce nel v<unk> @ ento e sp<unk> @ ost<unk> @ arsi nel sen<unk> @ so di .
2025-05-27 20:03:59,342 - INFO - joeynmt.training - Example #4
2025-05-27 20:03:59,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:03:59,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:03:59,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'f@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:03:59,342 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:03:59,343 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:03:59,343 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ er<unk> @   una sc<unk> @ or<unk> @ sa che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:04:02,621 - INFO - joeynmt.training - Epoch   8, Step:    57600, Batch Loss:     0.861217, Batch Acc: 0.724293, Tokens per Sec:    21165, Lr: 0.000300
2025-05-27 20:04:05,891 - INFO - joeynmt.training - Epoch   8, Step:    57700, Batch Loss:     0.829147, Batch Acc: 0.725260, Tokens per Sec:    24595, Lr: 0.000300
2025-05-27 20:04:09,220 - INFO - joeynmt.training - Epoch   8, Step:    57800, Batch Loss:     0.926882, Batch Acc: 0.727870, Tokens per Sec:    24787, Lr: 0.000300
2025-05-27 20:04:12,550 - INFO - joeynmt.training - Epoch   8, Step:    57900, Batch Loss:     0.934220, Batch Acc: 0.725572, Tokens per Sec:    23953, Lr: 0.000300
2025-05-27 20:04:15,869 - INFO - joeynmt.training - Epoch   8, Step:    58000, Batch Loss:     0.987032, Batch Acc: 0.720879, Tokens per Sec:    23728, Lr: 0.000300
2025-05-27 20:04:15,869 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:04:15,869 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:04:31,298 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 15.4162[sec], evaluation: 0.0000[sec]
2025-05-27 20:04:31,669 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/55000.ckpt
2025-05-27 20:04:31,695 - INFO - joeynmt.training - Example #0
2025-05-27 20:04:31,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:04:31,696 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:04:31,696 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questa', 'due', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'che', 'le', 'due', 'di@@', '<unk>', '@', 'ta', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'che', '', 'stato', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', '.', '</s>']
2025-05-27 20:04:31,696 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:04:31,696 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:04:31,696 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questa due di<unk> @ mostr<unk> @ a che le due di<unk> @ ta di tre milioni di anni , che  stato il g<unk> @ hi<unk> @ ac<unk> @ cio , che il g<unk> @ hi<unk> @ ac<unk> @ cio , che ha fatto per tre milioni di anni , che ha fatto per tre milioni di anni , che aveva tre milioni di anni , che aveva tre milioni di anni , il 4<unk> @ 0 .
2025-05-27 20:04:31,696 - INFO - joeynmt.training - Example #1
2025-05-27 20:04:31,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:04:31,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:04:31,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'sembr@@', '<unk>', '@', 'a', 'essere', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', ',', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'di', 'E@@', '<unk>', '@', 'is@@', '<unk>', '@', 's@@', '<unk>', '@', 'sa', '.', '</s>']
2025-05-27 20:04:31,697 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:04:31,697 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:04:31,697 - INFO - joeynmt.training - 	Hypothesis: Ma questo non sembr<unk> @ a essere abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perch non  il D<unk> @ ic<unk> @ co di E<unk> @ is<unk> @ s<unk> @ sa .
2025-05-27 20:04:31,697 - INFO - joeynmt.training - Example #2
2025-05-27 20:04:31,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:04:31,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:04:31,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 'suo', 'f@@', '<unk>', '@', 'en@@', '<unk>', '@', 'om@@', '<unk>', '@', 'en@@', '<unk>', '@', 'o', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', 'il', 'nostro', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:04:31,698 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:04:31,698 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:04:31,698 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il suo f<unk> @ en<unk> @ om<unk> @ en<unk> @ o  il g<unk> @ hi<unk> @ ac<unk> @ cio pi po<unk> @ ver<unk> @ a il nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:04:31,699 - INFO - joeynmt.training - Example #3
2025-05-27 20:04:31,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:04:31,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:04:31,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'ento', 'e', 'sp@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'n@@', '<unk>', '@', 'ata', '.', '</s>']
2025-05-27 20:04:31,699 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:04:31,699 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:04:31,699 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e sp<unk> @ eg<unk> @ n<unk> @ ata .
2025-05-27 20:04:31,699 - INFO - joeynmt.training - Example #4
2025-05-27 20:04:31,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:04:31,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:04:31,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', ',', '', 'una', 'sc@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ola', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:04:31,700 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:04:31,700 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:04:31,700 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o ,  una sc<unk> @ at<unk> @ ola che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:04:35,041 - INFO - joeynmt.training - Epoch   8, Step:    58100, Batch Loss:     0.869903, Batch Acc: 0.721736, Tokens per Sec:    20906, Lr: 0.000300
2025-05-27 20:04:38,365 - INFO - joeynmt.training - Epoch   8, Step:    58200, Batch Loss:     0.945279, Batch Acc: 0.727009, Tokens per Sec:    24092, Lr: 0.000300
2025-05-27 20:04:41,680 - INFO - joeynmt.training - Epoch   8, Step:    58300, Batch Loss:     0.983631, Batch Acc: 0.724972, Tokens per Sec:    23371, Lr: 0.000300
2025-05-27 20:04:45,039 - INFO - joeynmt.training - Epoch   8, Step:    58400, Batch Loss:     0.950355, Batch Acc: 0.727241, Tokens per Sec:    24576, Lr: 0.000300
2025-05-27 20:04:48,393 - INFO - joeynmt.training - Epoch   8, Step:    58500, Batch Loss:     0.867925, Batch Acc: 0.727380, Tokens per Sec:    24187, Lr: 0.000300
2025-05-27 20:04:48,393 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:04:48,393 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:05:00,785 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 12.3832[sec], evaluation: 0.0000[sec]
2025-05-27 20:05:00,786 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:05:01,280 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/54000.ckpt
2025-05-27 20:05:01,305 - INFO - joeynmt.training - Example #0
2025-05-27 20:05:01,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:05:01,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:05:01,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', 'che', 'si', 'sono', 'ri@@', '<unk>', '@', 'ma@@', '<unk>', '@', 'sto', 'per', 's@@', '<unk>', '@', 'par@@', '<unk>', '@', 'are', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'a@@', '<unk>', '@', 'io', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'l&apos;', 'hanno', 'av@@', '<unk>', '@', 'uto', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '8', 'o', 'del', '4@@', '<unk>', '@', '8', 'pa@@', '<unk>', '@', 'esi', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:05:01,306 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:05:01,306 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:05:01,306 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose che si sono ri<unk> @ ma<unk> @ sto per s<unk> @ par<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io di tre milioni di anni , che l&apos; hanno av<unk> @ uto tre milioni di anni , che aveva tre milioni di anni , che aveva tre milioni di anni , che aveva fatto per il 4<unk> @ 8 o del 4<unk> @ 8 pa<unk> @ esi , per il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:05:01,306 - INFO - joeynmt.training - Example #1
2025-05-27 20:05:01,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:05:01,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:05:01,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'ris@@', '<unk>', '@', 'post@@', '<unk>', '@', 'a', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ke', '.', '</s>']
2025-05-27 20:05:01,307 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:05:01,307 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:05:01,307 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza la ris<unk> @ post<unk> @ a  abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are , perch non  il D<unk> @ ic<unk> @ ke .
2025-05-27 20:05:01,307 - INFO - joeynmt.training - Example #2
2025-05-27 20:05:01,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:05:01,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:05:01,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'c@@', '<unk>', '@', 'ura', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '', 'il', 'sistema', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:05:01,308 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:05:01,308 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:05:01,308 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ ura di g<unk> @ hi<unk> @ ac<unk> @ cio  il sistema di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 20:05:01,308 - INFO - joeynmt.training - Example #3
2025-05-27 20:05:01,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:05:01,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:05:01,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:05:01,309 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:05:01,309 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:05:01,309 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e in<unk> @ ver<unk> @ no .
2025-05-27 20:05:01,309 - INFO - joeynmt.training - Example #4
2025-05-27 20:05:01,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:05:01,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:05:01,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'sc@@', '<unk>', '@', 'oper@@', '<unk>', '@', 'ta', 'di', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:05:01,310 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:05:01,310 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:05:01,310 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una sc<unk> @ oper<unk> @ ta di una ser<unk> @ ie di sc<unk> @ or<unk> @ so che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:05:04,604 - INFO - joeynmt.training - Epoch   8, Step:    58600, Batch Loss:     0.906940, Batch Acc: 0.727501, Tokens per Sec:    20869, Lr: 0.000300
2025-05-27 20:05:07,928 - INFO - joeynmt.training - Epoch   8, Step:    58700, Batch Loss:     0.896413, Batch Acc: 0.721611, Tokens per Sec:    23144, Lr: 0.000300
2025-05-27 20:05:11,253 - INFO - joeynmt.training - Epoch   8, Step:    58800, Batch Loss:     0.948070, Batch Acc: 0.723784, Tokens per Sec:    23812, Lr: 0.000300
2025-05-27 20:05:14,571 - INFO - joeynmt.training - Epoch   8, Step:    58900, Batch Loss:     0.882876, Batch Acc: 0.727058, Tokens per Sec:    23831, Lr: 0.000300
2025-05-27 20:05:17,921 - INFO - joeynmt.training - Epoch   8, Step:    59000, Batch Loss:     0.955374, Batch Acc: 0.719520, Tokens per Sec:    23653, Lr: 0.000300
2025-05-27 20:05:17,921 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:05:17,921 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:05:33,268 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 15.3382[sec], evaluation: 0.0000[sec]
2025-05-27 20:05:33,597 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/55500.ckpt
2025-05-27 20:05:33,619 - INFO - joeynmt.training - Example #0
2025-05-27 20:05:33,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:05:33,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:05:33,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', '@', 'o', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', ',', 'per', 'fare', 'per', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'i', 'ter@@', '<unk>', '@', 'n@@', '<unk>', '@', 'ati@@', '<unk>', '@', 'vi', ',', 'per', 'i', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'm@@', '<unk>', '@', 'and@@', '<unk>', '@', 'ato', 'a', 'tre', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 20:05:33,620 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:05:33,620 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:05:33,620 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due cose , per fare per c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i ter<unk> @ n<unk> @ ati<unk> @ vi , per i tre milioni di anni , il 4<unk> @ 8 milioni di anni , il 4<unk> @ 0 per c<unk> @ ento  stato m<unk> @ and<unk> @ ato a tre milioni di anni .
2025-05-27 20:05:33,620 - INFO - joeynmt.training - Example #1
2025-05-27 20:05:33,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:05:33,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:05:33,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:05:33,621 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:05:33,621 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:05:33,621 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ f<unk> @ ico , perch non  il D<unk> @ ic<unk> @ co di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:05:33,622 - INFO - joeynmt.training - Example #2
2025-05-27 20:05:33,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:05:33,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:05:33,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ata', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:05:33,622 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:05:33,622 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:05:33,623 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ata del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 20:05:33,623 - INFO - joeynmt.training - Example #3
2025-05-27 20:05:33,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:05:33,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:05:33,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'sp@@', '<unk>', '@', 'or@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ere', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:05:33,623 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:05:33,623 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:05:33,623 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e sp<unk> @ or<unk> @ g<unk> @ ere in est<unk> @ ate .
2025-05-27 20:05:33,624 - INFO - joeynmt.training - Example #4
2025-05-27 20:05:33,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:05:33,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:05:33,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'di@@', '<unk>', '@', 'men@@', '<unk>', '@', 'sione', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'no', ',', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:05:33,624 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:05:33,624 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:05:33,624 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una di<unk> @ men<unk> @ sione che vi mostr<unk> @ er<unk> @  una ser<unk> @ ie di di<unk> @ seg<unk> @ no ,  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:05:36,905 - INFO - joeynmt.training - Epoch   8, Step:    59100, Batch Loss:     1.046824, Batch Acc: 0.723724, Tokens per Sec:    21393, Lr: 0.000300
2025-05-27 20:05:40,235 - INFO - joeynmt.training - Epoch   8, Step:    59200, Batch Loss:     0.952020, Batch Acc: 0.723345, Tokens per Sec:    23746, Lr: 0.000300
2025-05-27 20:05:43,571 - INFO - joeynmt.training - Epoch   8, Step:    59300, Batch Loss:     1.006374, Batch Acc: 0.723797, Tokens per Sec:    23362, Lr: 0.000300
2025-05-27 20:05:46,905 - INFO - joeynmt.training - Epoch   8, Step:    59400, Batch Loss:     0.960032, Batch Acc: 0.725800, Tokens per Sec:    23790, Lr: 0.000300
2025-05-27 20:05:50,234 - INFO - joeynmt.training - Epoch   8, Step:    59500, Batch Loss:     0.891898, Batch Acc: 0.720716, Tokens per Sec:    24143, Lr: 0.000300
2025-05-27 20:05:50,234 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:05:50,235 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:06:06,731 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.65, acc:   0.72, generation: 16.4831[sec], evaluation: 0.0000[sec]
2025-05-27 20:06:07,091 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/56500.ckpt
2025-05-27 20:06:07,117 - INFO - joeynmt.training - Example #0
2025-05-27 20:06:07,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:06:07,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:06:07,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', 'che', 'sono', 'per', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'i', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ati', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'per', 'i', 'ris@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'vere', ',', 'per', 'i', 'cas@@', '<unk>', '@', 'i', 'di', 'circa', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'aveva', 'fatto', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 's@@', '<unk>', '@', 'otto', 'i', '4@@', '<unk>', '@', '8', '%', ',', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'in@@', '<unk>', '@', 'segn@@', '<unk>', '@', 'ato', '.', '</s>']
2025-05-27 20:06:07,118 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:06:07,118 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:06:07,118 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due cose che sono per per di<unk> @ mostr<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ cio per i ris<unk> @ ult<unk> @ ati , che i g<unk> @ hi<unk> @ ac<unk> @ cio che ha av<unk> @ uto per i ris<unk> @ ol<unk> @ vere , per i cas<unk> @ i di circa 4<unk> @ 8 milioni di anni , aveva fatto , il 4<unk> @ 8 , per c<unk> @ ento  stato s<unk> @ otto i 4<unk> @ 8 % , per c<unk> @ ento  stato in<unk> @ segn<unk> @ ato .
2025-05-27 20:06:07,119 - INFO - joeynmt.training - Example #1
2025-05-27 20:06:07,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:06:07,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:06:07,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 't@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'o', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'perch', 'non', 'ci', 'mostr@@', '<unk>', '@', 'a', 'il', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:06:07,120 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:06:07,120 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:06:07,120 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ t<unk> @ eg<unk> @ gi<unk> @ o la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perch non ci mostr<unk> @ a il ci<unk> @ b<unk> @ o del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:06:07,120 - INFO - joeynmt.training - Example #2
2025-05-27 20:06:07,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:06:07,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:06:07,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cu@@', '<unk>', '@', 'ore', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:06:07,121 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:06:07,121 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:06:07,121 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cu<unk> @ ore po<unk> @ ver<unk> @ a  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 20:06:07,121 - INFO - joeynmt.training - Example #3
2025-05-27 20:06:07,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:06:07,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:06:07,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'in@@', '<unk>', '@', 'no', 'e', 'sp@@', '<unk>', '@', 'or@@', '<unk>', '@', 'co', '.', '</s>']
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ in<unk> @ no e sp<unk> @ or<unk> @ co .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - Example #4
2025-05-27 20:06:07,122 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:06:07,122 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:06:07,122 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'queste', 'cose', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'queste', 'ulti@@', '<unk>', '@', 'me', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una c<unk> @ ura di queste cose  una c<unk> @ ura di queste ulti<unk> @ me 2<unk> @ 5 anni .
2025-05-27 20:06:10,471 - INFO - joeynmt.training - Epoch   8, Step:    59600, Batch Loss:     0.956957, Batch Acc: 0.725553, Tokens per Sec:    21586, Lr: 0.000300
2025-05-27 20:06:13,797 - INFO - joeynmt.training - Epoch   8, Step:    59700, Batch Loss:     0.967702, Batch Acc: 0.725328, Tokens per Sec:    23907, Lr: 0.000300
2025-05-27 20:06:17,096 - INFO - joeynmt.training - Epoch   8, Step:    59800, Batch Loss:     0.937669, Batch Acc: 0.726265, Tokens per Sec:    23363, Lr: 0.000300
2025-05-27 20:06:20,424 - INFO - joeynmt.training - Epoch   8, Step:    59900, Batch Loss:     0.947396, Batch Acc: 0.729186, Tokens per Sec:    24275, Lr: 0.000300
2025-05-27 20:06:23,718 - INFO - joeynmt.training - Epoch   8, Step:    60000, Batch Loss:     0.915935, Batch Acc: 0.726619, Tokens per Sec:    23531, Lr: 0.000300
2025-05-27 20:06:23,719 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:06:23,719 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:06:39,825 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 16.0918[sec], evaluation: 0.0000[sec]
2025-05-27 20:06:40,210 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/58000.ckpt
2025-05-27 20:06:40,236 - INFO - joeynmt.training - Example #0
2025-05-27 20:06:40,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:06:40,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:06:40,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 'ut@@', '<unk>', '@', 'ure', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'a@@', '<unk>', '@', 'io', 'di', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'v@@', '<unk>', '@', 'azioni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', '%', 'dei', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 20:06:40,237 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:06:40,238 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:06:40,238 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ ut<unk> @ ure per di<unk> @ mostr<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io di milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ v<unk> @ azioni , per il 4<unk> @ 8 % dei 4<unk> @ 8 % .
2025-05-27 20:06:40,238 - INFO - joeynmt.training - Example #1
2025-05-27 20:06:40,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:06:40,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:06:40,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', '-@@', '<unk>', '@', 'o@@', '<unk>', '@', '-@@', '<unk>', '@', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'il', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 20:06:40,239 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:06:40,239 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:06:40,239 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza di questo problema spe<unk> @ ci<unk> @ f<unk> @ ico , perch non  il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ -<unk> @ o<unk> @ -<unk> @ di<unk> @ mostr<unk> @ a il ci<unk> @ b<unk> @ o .
2025-05-27 20:06:40,239 - INFO - joeynmt.training - Example #2
2025-05-27 20:06:40,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:06:40,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:06:40,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:06:40,240 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:06:40,240 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:06:40,240 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:06:40,240 - INFO - joeynmt.training - Example #3
2025-05-27 20:06:40,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:06:40,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:06:40,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 's@@', '<unk>', '@', 'otto', ',', 'e', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'a', 'in', 'ter@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ini', 'di', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 20:06:40,241 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:06:40,241 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:06:40,241 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di s<unk> @ otto , e sp<unk> @ ost<unk> @ a in ter<unk> @ m<unk> @ ini di sp<unk> @ ost<unk> @ a .
2025-05-27 20:06:40,241 - INFO - joeynmt.training - Example #4
2025-05-27 20:06:40,241 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:06:40,241 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:06:40,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'che', 'mostr@@', '<unk>', '@', 'a', 'la', 'cosa', 'che', '', 'acc@@', '<unk>', '@', 'a@@', '<unk>', '@', 'du@@', '<unk>', '@', 'to', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:06:40,242 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:06:40,242 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:06:40,242 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a che mostr<unk> @ a la cosa che  acc<unk> @ a<unk> @ du<unk> @ to negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:06:43,596 - INFO - joeynmt.training - Epoch   8, Step:    60100, Batch Loss:     0.907745, Batch Acc: 0.727528, Tokens per Sec:    21608, Lr: 0.000300
2025-05-27 20:06:46,934 - INFO - joeynmt.training - Epoch   8, Step:    60200, Batch Loss:     0.876212, Batch Acc: 0.725155, Tokens per Sec:    23550, Lr: 0.000300
2025-05-27 20:06:50,249 - INFO - joeynmt.training - Epoch   8, Step:    60300, Batch Loss:     1.051937, Batch Acc: 0.725409, Tokens per Sec:    23730, Lr: 0.000300
2025-05-27 20:06:53,562 - INFO - joeynmt.training - Epoch   8, Step:    60400, Batch Loss:     0.970691, Batch Acc: 0.727848, Tokens per Sec:    24092, Lr: 0.000300
2025-05-27 20:06:56,901 - INFO - joeynmt.training - Epoch   8, Step:    60500, Batch Loss:     1.004747, Batch Acc: 0.726003, Tokens per Sec:    24243, Lr: 0.000300
2025-05-27 20:06:56,902 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:06:56,902 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:07:12,547 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 15.6360[sec], evaluation: 0.0000[sec]
2025-05-27 20:07:12,863 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/57500.ckpt
2025-05-27 20:07:12,886 - INFO - joeynmt.training - Example #0
2025-05-27 20:07:12,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:07:12,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:07:12,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'f@@', '<unk>', '@', 're', ',', 'per', 'ri@@', '<unk>', '@', 'un@@', '<unk>', '@', 'ire', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'a@@', '<unk>', '@', 'io', 'di', 'anni', ',', 'per', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'i', 'tre', 'milioni', 'di', 'di', 'di', 'di', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', '.', '</s>']
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ re , per ri<unk> @ un<unk> @ ire per di<unk> @ mostr<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io di anni , per il g<unk> @ hi<unk> @ ac<unk> @ cio , per i tre milioni di di di di di m<unk> @ oti<unk> @ vi per tre milioni di anni , il 4<unk> @ 8 .
2025-05-27 20:07:12,888 - INFO - joeynmt.training - Example #1
2025-05-27 20:07:12,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:07:12,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:07:12,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'i@@', '<unk>', '@', 'di@@', '<unk>', '@', 'rit@@', '<unk>', '@', 't@@', '<unk>', '@', 'ura', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', '-@@', '<unk>', '@', 'e@@', '<unk>', '@', '-@@', '<unk>', '@', 'e@@', '<unk>', '@', '-@@', '<unk>', '@', 'e@@', '<unk>', '@', '-@@', '<unk>', '@', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:07:12,889 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perch non  il D<unk> @ ic<unk> @ i<unk> @ di<unk> @ rit<unk> @ t<unk> @ ura perch non  il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ -<unk> @ e<unk> @ -<unk> @ e<unk> @ -<unk> @ e<unk> @ -<unk> @ di<unk> @ mostr<unk> @ a .
2025-05-27 20:07:12,889 - INFO - joeynmt.training - Example #2
2025-05-27 20:07:12,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:07:12,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:07:12,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', 'il', 'con@@', '<unk>', '@', 'su@@', '<unk>', '@', 'mo', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mit@@', '<unk>', '@', 'ato', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:07:12,889 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:07:12,889 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:07:12,890 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa po<unk> @ ver<unk> @ a il con<unk> @ su<unk> @ mo di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ mit<unk> @ ato glob<unk> @ ale .
2025-05-27 20:07:12,890 - INFO - joeynmt.training - Example #3
2025-05-27 20:07:12,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:07:12,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:07:12,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'nel', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'ri@@', '<unk>', '@', 'un@@', '<unk>', '@', 'is@@', '<unk>', '@', 'ce', 'nel', 'sen@@', '<unk>', '@', 'so', '.', '</s>']
2025-05-27 20:07:12,890 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:07:12,890 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:07:12,890 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di nel v<unk> @ ento e si ri<unk> @ un<unk> @ is<unk> @ ce nel sen<unk> @ so .
2025-05-27 20:07:12,891 - INFO - joeynmt.training - Example #4
2025-05-27 20:07:12,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:07:12,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:07:12,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 's@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ata', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:07:12,891 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:07:12,891 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:07:12,891 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ ata che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:07:16,171 - INFO - joeynmt.training - Epoch   8, Step:    60600, Batch Loss:     0.968528, Batch Acc: 0.722152, Tokens per Sec:    21307, Lr: 0.000300
2025-05-27 20:07:19,510 - INFO - joeynmt.training - Epoch   8, Step:    60700, Batch Loss:     0.889202, Batch Acc: 0.724981, Tokens per Sec:    24085, Lr: 0.000300
2025-05-27 20:07:22,840 - INFO - joeynmt.training - Epoch   8, Step:    60800, Batch Loss:     0.993212, Batch Acc: 0.726207, Tokens per Sec:    24072, Lr: 0.000300
2025-05-27 20:07:26,189 - INFO - joeynmt.training - Epoch   8, Step:    60900, Batch Loss:     0.883454, Batch Acc: 0.719330, Tokens per Sec:    23756, Lr: 0.000300
2025-05-27 20:07:29,501 - INFO - joeynmt.training - Epoch   8, Step:    61000, Batch Loss:     0.918673, Batch Acc: 0.724677, Tokens per Sec:    23559, Lr: 0.000300
2025-05-27 20:07:29,501 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:07:29,501 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:07:45,337 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.65, acc:   0.72, generation: 15.8215[sec], evaluation: 0.0000[sec]
2025-05-27 20:07:45,703 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/60000.ckpt
2025-05-27 20:07:45,729 - INFO - joeynmt.training - Example #0
2025-05-27 20:07:45,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:07:45,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:07:45,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', 'sono', 'stati', 'in@@', '<unk>', '@', 'contr@@', '<unk>', '@', 'ati', 'per', 'port@@', '<unk>', '@', 'are', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'per', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', '%', ',', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:07:45,730 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:07:45,730 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:07:45,730 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due cas<unk> @ i sono stati in<unk> @ contr<unk> @ ati per port<unk> @ are il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio , per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di anni , che aveva tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di persone che hanno av<unk> @ uto 4<unk> @ 8 % , per c<unk> @ ento .
2025-05-27 20:07:45,730 - INFO - joeynmt.training - Example #1
2025-05-27 20:07:45,731 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:07:45,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:07:45,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'tel@@', '<unk>', '@', 'li@@', '<unk>', '@', 'gente', 'che', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'per', 'il', 'problema', '.', '</s>']
2025-05-27 20:07:45,731 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:07:45,731 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:07:45,731 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza in<unk> @ tel<unk> @ li<unk> @ gente che non  abb<unk> @ ast<unk> @ anza per il problema .
2025-05-27 20:07:45,731 - INFO - joeynmt.training - Example #2
2025-05-27 20:07:45,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:07:45,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:07:45,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'so', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'so', 'di', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'are', '.', '</s>']
2025-05-27 20:07:45,732 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:07:45,732 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il nostro sistema c<unk> @ li<unk> @ m<unk> @ as<unk> @ so di c<unk> @ li<unk> @ m<unk> @ as<unk> @ so di c<unk> @ li<unk> @ m<unk> @ are .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - Example #3
2025-05-27 20:07:45,733 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:07:45,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:07:45,733 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'olo', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:07:45,733 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ op<unk> @ olo e in<unk> @ ver<unk> @ no .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - Example #4
2025-05-27 20:07:45,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:07:45,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:07:45,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'l@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:07:45,734 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:07:45,734 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:07:45,734 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una c<unk> @ ic<unk> @ l<unk> @ et<unk> @ ta che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:07:49,067 - INFO - joeynmt.training - Epoch   8, Step:    61100, Batch Loss:     1.028203, Batch Acc: 0.727743, Tokens per Sec:    20358, Lr: 0.000300
2025-05-27 20:07:52,442 - INFO - joeynmt.training - Epoch   8, Step:    61200, Batch Loss:     1.033765, Batch Acc: 0.718878, Tokens per Sec:    24171, Lr: 0.000300
2025-05-27 20:07:55,672 - INFO - joeynmt.training - Epoch   8, Step:    61300, Batch Loss:     0.970850, Batch Acc: 0.727347, Tokens per Sec:    24009, Lr: 0.000300
2025-05-27 20:07:58,869 - INFO - joeynmt.training - Epoch   8, Step:    61400, Batch Loss:     0.859320, Batch Acc: 0.726590, Tokens per Sec:    24562, Lr: 0.000300
2025-05-27 20:08:02,087 - INFO - joeynmt.training - Epoch   8, Step:    61500, Batch Loss:     1.006210, Batch Acc: 0.724052, Tokens per Sec:    25192, Lr: 0.000300
2025-05-27 20:08:02,087 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:08:02,087 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:08:17,403 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.3023[sec], evaluation: 0.0000[sec]
2025-05-27 20:08:17,404 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:08:17,946 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/60500.ckpt
2025-05-27 20:08:17,966 - INFO - joeynmt.training - Example #0
2025-05-27 20:08:17,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:08:17,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:08:17,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', 'per', 'cui', 'sono', 'st@@', '<unk>', '@', 'ate', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'l&apos;', 'or@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ine', 'per', 'qu@@', '<unk>', '@', 'elli', 'che', 'f@@', '<unk>', '@', 'anno', 'le', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ate', 'che', 'gli', 'or@@', '<unk>', '@', 'b@@', '<unk>', '@', 'i', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:08:17,967 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:08:17,967 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:08:17,967 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose per cui sono st<unk> @ ate per di<unk> @ mostr<unk> @ are che l&apos; or<unk> @ ig<unk> @ ine per qu<unk> @ elli che f<unk> @ anno le g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ate che gli or<unk> @ b<unk> @ i di tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % , il 4<unk> @ 0 % del 4<unk> @ 0 % , il 4<unk> @ 0 % , il 4<unk> @ 0 % .
2025-05-27 20:08:17,968 - INFO - joeynmt.training - Example #1
2025-05-27 20:08:17,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:08:17,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:08:17,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'in@@', '<unk>', '@', 'zione', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', '.', '</s>']
2025-05-27 20:08:17,968 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:08:17,969 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:08:17,969 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ in<unk> @ zione di questo part<unk> @ icol<unk> @ are probl<unk> @ emi , perch non  il D<unk> @ ic<unk> @ co .
2025-05-27 20:08:17,969 - INFO - joeynmt.training - Example #2
2025-05-27 20:08:17,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:08:17,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:08:17,969 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'sta', 'di', 'in@@', '<unk>', '@', 'ten@@', '<unk>', '@', 'zione', 'di', 'ci@@', '<unk>', '@', 'o@@', '<unk>', '@', '', 'che', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:08:17,970 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:08:17,970 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:08:17,970 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ li<unk> @ sta di in<unk> @ ten<unk> @ zione di ci<unk> @ o<unk> @  che la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:08:17,970 - INFO - joeynmt.training - Example #3
2025-05-27 20:08:17,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:08:17,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:08:17,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', '<unk>', '@', 'ce', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'si', 's@@', '<unk>', '@', 'ente', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'si', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 20:08:17,970 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:08:17,971 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:08:17,971 - INFO - joeynmt.training - 	Hypothesis: Si cres<unk> @ ce in est<unk> @ ate e si s<unk> @ ente in est<unk> @ ate e si sp<unk> @ ost<unk> @ a .
2025-05-27 20:08:17,971 - INFO - joeynmt.training - Example #4
2025-05-27 20:08:17,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:08:17,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:08:17,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'st@@', '<unk>', '@', 'anza', 'di', 'sc@@', '<unk>', '@', 'al@@', '<unk>', '@', 'a', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:08:17,971 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:08:17,971 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:08:17,972 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una st<unk> @ anza di sc<unk> @ al<unk> @ a che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:08:21,321 - INFO - joeynmt.training - Epoch   8, Step:    61600, Batch Loss:     0.964379, Batch Acc: 0.723971, Tokens per Sec:    19894, Lr: 0.000300
2025-05-27 20:08:24,643 - INFO - joeynmt.training - Epoch   8, Step:    61700, Batch Loss:     0.914526, Batch Acc: 0.721261, Tokens per Sec:    23220, Lr: 0.000300
2025-05-27 20:08:27,994 - INFO - joeynmt.training - Epoch   8, Step:    61800, Batch Loss:     0.958155, Batch Acc: 0.726194, Tokens per Sec:    24164, Lr: 0.000300
2025-05-27 20:08:31,353 - INFO - joeynmt.training - Epoch   8, Step:    61900, Batch Loss:     0.989612, Batch Acc: 0.721152, Tokens per Sec:    23262, Lr: 0.000300
2025-05-27 20:08:34,706 - INFO - joeynmt.training - Epoch   8, Step:    62000, Batch Loss:     1.064082, Batch Acc: 0.726258, Tokens per Sec:    23495, Lr: 0.000300
2025-05-27 20:08:34,707 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:08:34,707 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:08:51,430 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 16.7091[sec], evaluation: 0.0000[sec]
2025-05-27 20:08:51,788 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/59000.ckpt
2025-05-27 20:08:51,809 - INFO - joeynmt.training - Example #0
2025-05-27 20:08:51,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:08:51,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:08:51,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', 'sono', 'i', 'due', 'cas@@', '<unk>', '@', 'i', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'av@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', 'che', 'i', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'av@@', '<unk>', '@', 'amo', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'i', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'ati', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'dei', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'tre', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 20:08:51,811 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:08:51,811 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:08:51,811 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due cas<unk> @ i sono i due cas<unk> @ i che gli ar<unk> @ t<unk> @ av<unk> @ ol<unk> @ i che i po<unk> @ ver<unk> @ i che gli ar<unk> @ t<unk> @ t<unk> @ av<unk> @ amo per tre milioni di anni , i con<unk> @ si<unk> @ der<unk> @ ati , per tre milioni di anni , il 4<unk> @ 0 % dei m<unk> @ oti<unk> @ vi per tre milioni di anni .
2025-05-27 20:08:51,811 - INFO - joeynmt.training - Example #1
2025-05-27 20:08:51,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:08:51,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:08:51,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'l&apos;', 'in@@', '<unk>', '@', 'cre@@', '<unk>', '@', 'di@@', '<unk>', '@', 'bil@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'la', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', '.', '</s>']
2025-05-27 20:08:51,812 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:08:51,812 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:08:51,812 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te l&apos; in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ it di questo problema , perch non  la di<unk> @ mostr<unk> @ a il D<unk> @ ic<unk> @ co .
2025-05-27 20:08:51,812 - INFO - joeynmt.training - Example #2
2025-05-27 20:08:51,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:08:51,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:08:51,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 't', ',', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ente', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:08:51,813 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:08:51,813 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:08:51,813 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa po<unk> @ ver<unk> @ t , la c<unk> @ atti<unk> @ va  la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ ente glob<unk> @ ale .
2025-05-27 20:08:51,814 - INFO - joeynmt.training - Example #3
2025-05-27 20:08:51,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:08:51,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:08:51,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', '<unk>', '@', 'ce', 'in', 'gi@@', '<unk>', '@', 'ro', '<unk>', '@', '', 'e', 'la', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'r@@', '<unk>', '@', 'azione', '.', '</s>']
2025-05-27 20:08:51,814 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:08:51,814 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:08:51,814 - INFO - joeynmt.training - 	Hypothesis: Si cres<unk> @ ce in gi<unk> @ ro <unk> @  e la sc<unk> @ or<unk> @ r<unk> @ azione .
2025-05-27 20:08:51,814 - INFO - joeynmt.training - Example #4
2025-05-27 20:08:51,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:08:51,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:08:51,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', ',', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'lin@@', '<unk>', '@', 'ea', 'di', 'ri@@', '<unk>', '@', 'pres@@', '<unk>', '@', 'a', 'che', ',', 'in', 'realt', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:08:51,815 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:08:51,815 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:08:51,815 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o , che vi mostr<unk> @ er<unk> @   una lin<unk> @ ea di ri<unk> @ pres<unk> @ a che , in realt  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:08:55,182 - INFO - joeynmt.training - Epoch   8, Step:    62100, Batch Loss:     0.944730, Batch Acc: 0.728110, Tokens per Sec:    21396, Lr: 0.000300
2025-05-27 20:08:58,522 - INFO - joeynmt.training - Epoch   8, Step:    62200, Batch Loss:     0.932534, Batch Acc: 0.726813, Tokens per Sec:    24623, Lr: 0.000300
2025-05-27 20:09:01,877 - INFO - joeynmt.training - Epoch   8, Step:    62300, Batch Loss:     0.935615, Batch Acc: 0.724272, Tokens per Sec:    23385, Lr: 0.000300
2025-05-27 20:09:05,243 - INFO - joeynmt.training - Epoch   8, Step:    62400, Batch Loss:     0.869099, Batch Acc: 0.725053, Tokens per Sec:    23298, Lr: 0.000300
2025-05-27 20:09:08,583 - INFO - joeynmt.training - Epoch   8, Step:    62500, Batch Loss:     0.945453, Batch Acc: 0.724223, Tokens per Sec:    23678, Lr: 0.000300
2025-05-27 20:09:08,583 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:09:08,583 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:09:23,389 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 14.7937[sec], evaluation: 0.0000[sec]
2025-05-27 20:09:23,390 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:09:23,916 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/59500.ckpt
2025-05-27 20:09:23,943 - INFO - joeynmt.training - Example #0
2025-05-27 20:09:23,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:09:23,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:09:23,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'ano', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'av@@', '<unk>', '@', 'i', ',', 'per', 'i', 'qu@@', '<unk>', '@', 'elli', 'che', 'av@@', '<unk>', '@', 'evano', 'fatto', 'il', '4@@', '<unk>', '@', '0', '%', 'dei', 'qu@@', '<unk>', '@', 'at@@', '<unk>', '@', 'tro', 'anni', '.', '</s>']
2025-05-27 20:09:23,944 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:09:23,944 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:09:23,944 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due di<unk> @ mostr<unk> @ ano che il g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i che gli ar<unk> @ t<unk> @ av<unk> @ i , per i qu<unk> @ elli che av<unk> @ evano fatto il 4<unk> @ 0 % dei qu<unk> @ at<unk> @ tro anni .
2025-05-27 20:09:23,944 - INFO - joeynmt.training - Example #1
2025-05-27 20:09:23,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:09:23,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:09:23,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'ente', ',', 'perch', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'per', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:09:23,945 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:09:23,945 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:09:23,945 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza in<unk> @ f<unk> @ lu<unk> @ ente , perch non  abb<unk> @ ast<unk> @ anza per questo problema spe<unk> @ ci<unk> @ ale .
2025-05-27 20:09:23,945 - INFO - joeynmt.training - Example #2
2025-05-27 20:09:23,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:09:23,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:09:23,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', '', 'l&apos;', 'ec@@', '<unk>', '@', 'c@@', '<unk>', '@', 'e@@', '<unk>', '@', 'zione', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:09:23,946 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:09:23,946 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:09:23,946 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ atti<unk> @ va  l&apos; ec<unk> @ c<unk> @ e<unk> @ zione ar<unk> @ t<unk> @ ico , il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:09:23,946 - INFO - joeynmt.training - Example #3
2025-05-27 20:09:23,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:09:23,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:09:23,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'si', 'ri@@', '<unk>', '@', 'es@@', '<unk>', '@', 'ce', 'a', 'fare', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:09:23,947 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:09:23,947 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:09:23,947 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e si ri<unk> @ es<unk> @ ce a fare in est<unk> @ ate .
2025-05-27 20:09:23,947 - INFO - joeynmt.training - Example #4
2025-05-27 20:09:23,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:09:23,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:09:23,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'ri@@', '<unk>', '@', 'vi@@', '<unk>', '@', 'sta', 'di', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'che', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:09:23,948 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:09:23,948 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:09:23,948 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o  una ri<unk> @ vi<unk> @ sta di una ser<unk> @ ie di sc<unk> @ or<unk> @ so che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:09:27,318 - INFO - joeynmt.training - Epoch   8, Step:    62600, Batch Loss:     0.974163, Batch Acc: 0.721454, Tokens per Sec:    20704, Lr: 0.000300
2025-05-27 20:09:30,645 - INFO - joeynmt.training - Epoch   8, Step:    62700, Batch Loss:     0.866050, Batch Acc: 0.727997, Tokens per Sec:    23485, Lr: 0.000300
2025-05-27 20:09:33,960 - INFO - joeynmt.training - Epoch   8, Step:    62800, Batch Loss:     0.927264, Batch Acc: 0.725510, Tokens per Sec:    23866, Lr: 0.000300
2025-05-27 20:09:37,284 - INFO - joeynmt.training - Epoch   8, Step:    62900, Batch Loss:     0.839326, Batch Acc: 0.724435, Tokens per Sec:    23672, Lr: 0.000300
2025-05-27 20:09:40,592 - INFO - joeynmt.training - Epoch   8, Step:    63000, Batch Loss:     0.869455, Batch Acc: 0.723693, Tokens per Sec:    23962, Lr: 0.000300
2025-05-27 20:09:40,593 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:09:40,593 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:09:59,274 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 18.6668[sec], evaluation: 0.0000[sec]
2025-05-27 20:09:59,275 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:09:59,909 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/61000.ckpt
2025-05-27 20:09:59,933 - INFO - joeynmt.training - Example #0
2025-05-27 20:09:59,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:09:59,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:09:59,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'col@@', '<unk>', '@', 'ie', 'che', 'mostr@@', '<unk>', '@', 'a', 'per', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'i', 'due', 'milioni', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ati', ',', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'av@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', '<unk>', '@', '8', 'anni', '.', '</s>']
2025-05-27 20:09:59,935 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:09:59,935 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:09:59,935 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due col<unk> @ ie che mostr<unk> @ a per con<unk> @ si<unk> @ der<unk> @ are i due milioni di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati , che gli ar<unk> @ t<unk> @ av<unk> @ ol<unk> @ i , per tre milioni di anni , il 4<unk> @ 8 <unk> @ 8 anni .
2025-05-27 20:09:59,935 - INFO - joeynmt.training - Example #1
2025-05-27 20:09:59,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:09:59,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:09:59,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questa', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:09:59,936 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:09:59,936 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:09:59,936 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questa spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ co di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:09:59,936 - INFO - joeynmt.training - Example #2
2025-05-27 20:09:59,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:09:59,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:09:59,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cer@@', '<unk>', '@', 'ta', 'di', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'vo', 'al', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:09:59,937 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:09:59,937 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:09:59,937 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cer<unk> @ ta di un cer<unk> @ to sen<unk> @ so  la c<unk> @ atti<unk> @ va  il cu<unk> @ ore c<unk> @ atti<unk> @ vo al cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:09:59,937 - INFO - joeynmt.training - Example #3
2025-05-27 20:09:59,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:09:59,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:09:59,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'em@@', '<unk>', '@', 'br@@', '<unk>', '@', 'a', ',', 'e', 'si', 'ri@@', '<unk>', '@', 'vol@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ano', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:09:59,938 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:09:59,938 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:09:59,938 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e si ri<unk> @ vol<unk> @ g<unk> @ ano in est<unk> @ ate .
2025-05-27 20:09:59,938 - INFO - joeynmt.training - Example #4
2025-05-27 20:09:59,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:09:59,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:09:59,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:09:59,939 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:09:59,939 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:09:59,939 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o  una c<unk> @ ura di di<unk> @ seg<unk> @ na che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:10:01,811 - INFO - joeynmt.training - Epoch   8: total training loss 7420.14
2025-05-27 20:10:01,811 - INFO - joeynmt.training - EPOCH 9
2025-05-27 20:10:03,255 - INFO - joeynmt.training - Epoch   9, Step:    63100, Batch Loss:     0.922769, Batch Acc: 0.729110, Tokens per Sec:    23835, Lr: 0.000300
2025-05-27 20:10:06,464 - INFO - joeynmt.training - Epoch   9, Step:    63200, Batch Loss:     0.801125, Batch Acc: 0.734902, Tokens per Sec:    24542, Lr: 0.000300
2025-05-27 20:10:09,789 - INFO - joeynmt.training - Epoch   9, Step:    63300, Batch Loss:     0.981043, Batch Acc: 0.733147, Tokens per Sec:    23574, Lr: 0.000300
2025-05-27 20:10:13,103 - INFO - joeynmt.training - Epoch   9, Step:    63400, Batch Loss:     0.901834, Batch Acc: 0.732712, Tokens per Sec:    23662, Lr: 0.000300
2025-05-27 20:10:16,401 - INFO - joeynmt.training - Epoch   9, Step:    63500, Batch Loss:     0.929982, Batch Acc: 0.735861, Tokens per Sec:    23490, Lr: 0.000300
2025-05-27 20:10:16,402 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:10:16,402 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:10:31,626 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 15.2099[sec], evaluation: 0.0000[sec]
2025-05-27 20:10:31,993 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/62000.ckpt
2025-05-27 20:10:32,017 - INFO - joeynmt.training - Example #0
2025-05-27 20:10:32,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:10:32,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:10:32,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'rit@@', '<unk>', '@', 'ti', 'per', 'far@@', '<unk>', '@', 'lo', 'per', 'fare', 'due', 'di@@', '<unk>', '@', 'os@@', '<unk>', '@', 'i', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'gli', 'st@@', '<unk>', '@', 'avano', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'il', '4@@', '<unk>', '@', '8', 'stati', 'di', 'qu@@', '<unk>', '@', 'asi', '4@@', '<unk>', '@', '8', 'stati', ',', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'in@@', '<unk>', '@', 'tor@@', '<unk>', '@', 'no', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', '.', '</s>']
2025-05-27 20:10:32,018 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:10:32,018 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:10:32,018 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ rit<unk> @ ti per far<unk> @ lo per fare due di<unk> @ os<unk> @ i , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che gli st<unk> @ avano per tre milioni di anni , che aveva tre milioni di anni , il 4<unk> @ 8 , il 4<unk> @ 8 stati di qu<unk> @ asi 4<unk> @ 8 stati , per c<unk> @ ento  stato in<unk> @ tor<unk> @ no , per tre milioni di anni , il 4<unk> @ 0 .
2025-05-27 20:10:32,018 - INFO - joeynmt.training - Example #1
2025-05-27 20:10:32,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:10:32,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:10:32,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'f@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'enza', 'la', 'giu@@', '<unk>', '@', 'sta', ',', 'perch', 'non', '', 'la', 'de@@', '<unk>', '@', 'ter@@', '<unk>', '@', 'min@@', '<unk>', '@', 'azione', 'che', 'non', 'mostr@@', '<unk>', '@', 'a', 'la', 'de@@', '<unk>', '@', 'ter@@', '<unk>', '@', 'min@@', '<unk>', '@', 'azione', '.', '</s>']
2025-05-27 20:10:32,019 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:10:32,019 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:10:32,019 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ f<unk> @ lu<unk> @ enza la giu<unk> @ sta , perch non  la de<unk> @ ter<unk> @ min<unk> @ azione che non mostr<unk> @ a la de<unk> @ ter<unk> @ min<unk> @ azione .
2025-05-27 20:10:32,019 - INFO - joeynmt.training - Example #2
2025-05-27 20:10:32,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:10:32,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:10:32,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'ica', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 20:10:32,020 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:10:32,020 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:10:32,020 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ itu<unk> @ azione ar<unk> @ t<unk> @ t<unk> @ ica  la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 20:10:32,020 - INFO - joeynmt.training - Example #3
2025-05-27 20:10:32,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:10:32,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:10:32,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:10:32,021 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:10:32,021 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:10:32,021 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:10:32,021 - INFO - joeynmt.training - Example #4
2025-05-27 20:10:32,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:10:32,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:10:32,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', ',', '', 'una', 'st@@', '<unk>', '@', 'anza', 'di', 'cor@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ente', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:10:32,022 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:10:32,022 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:10:32,022 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @  ,  una st<unk> @ anza di cor<unk> @ r<unk> @ ente che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:10:35,379 - INFO - joeynmt.training - Epoch   9, Step:    63600, Batch Loss:     0.845048, Batch Acc: 0.732903, Tokens per Sec:    21493, Lr: 0.000300
2025-05-27 20:10:38,706 - INFO - joeynmt.training - Epoch   9, Step:    63700, Batch Loss:     1.009884, Batch Acc: 0.727767, Tokens per Sec:    23674, Lr: 0.000300
2025-05-27 20:10:42,054 - INFO - joeynmt.training - Epoch   9, Step:    63800, Batch Loss:     0.849872, Batch Acc: 0.735904, Tokens per Sec:    23844, Lr: 0.000300
2025-05-27 20:10:45,373 - INFO - joeynmt.training - Epoch   9, Step:    63900, Batch Loss:     0.973657, Batch Acc: 0.733241, Tokens per Sec:    24272, Lr: 0.000300
2025-05-27 20:10:48,696 - INFO - joeynmt.training - Epoch   9, Step:    64000, Batch Loss:     0.903640, Batch Acc: 0.736774, Tokens per Sec:    24570, Lr: 0.000300
2025-05-27 20:10:48,696 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:10:48,696 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:11:05,089 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 16.3790[sec], evaluation: 0.0000[sec]
2025-05-27 20:11:05,475 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/63500.ckpt
2025-05-27 20:11:05,500 - INFO - joeynmt.training - Example #0
2025-05-27 20:11:05,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:11:05,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:11:05,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'rit@@', '<unk>', '@', 'ti', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'questi', 'due', 'di@@', '<unk>', '@', 'ti', 'per', 'con@@', '<unk>', '@', 'to', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'a@@', '<unk>', '@', 'io', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'il', '4@@', '<unk>', '@', '8', 'ore', 'di', '4@@', '<unk>', '@', '8', 'ore', ',', 'il', '4@@', '<unk>', '@', '8', 'ore', 'di', '4@@', '<unk>', '@', '8', 'ore', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'di', '4@@', '<unk>', '@', '8', 'ore', '.', '</s>']
2025-05-27 20:11:05,502 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:11:05,502 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:11:05,502 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ rit<unk> @ ti per ri<unk> @ dur<unk> @ re questi due di<unk> @ ti per con<unk> @ to che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io di anni , il 4<unk> @ 8 , il 4<unk> @ 8 ore di 4<unk> @ 8 ore , il 4<unk> @ 8 ore di 4<unk> @ 8 ore , il 4<unk> @ 0 % di 4<unk> @ 8 ore .
2025-05-27 20:11:05,502 - INFO - joeynmt.training - Example #1
2025-05-27 20:11:05,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:11:05,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:11:05,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'lo', '.', '</s>']
2025-05-27 20:11:05,503 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:11:05,503 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:11:05,503 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ lo .
2025-05-27 20:11:05,503 - INFO - joeynmt.training - Example #2
2025-05-27 20:11:05,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:11:05,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:11:05,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 's@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'azione', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'ica', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 20:11:05,504 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:11:05,504 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:11:05,504 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la s<unk> @ itu<unk> @ azione po<unk> @ ver<unk> @ ica  la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 20:11:05,504 - INFO - joeynmt.training - Example #3
2025-05-27 20:11:05,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:11:05,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:11:05,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', '', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:11:05,505 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:11:05,505 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:11:05,505 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @  in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:11:05,505 - INFO - joeynmt.training - Example #4
2025-05-27 20:11:05,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:11:05,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:11:05,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'sc@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ola', ',', '', 'una', 'sc@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ola', 'di', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'di@@', '<unk>', '@', 'men@@', '<unk>', '@', 'sione', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:11:05,506 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:11:05,506 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:11:05,506 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o  una sc<unk> @ at<unk> @ ola ,  una sc<unk> @ at<unk> @ ola di ri<unk> @ dur<unk> @ re la di<unk> @ men<unk> @ sione negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:11:08,860 - INFO - joeynmt.training - Epoch   9, Step:    64100, Batch Loss:     0.859963, Batch Acc: 0.729641, Tokens per Sec:    20848, Lr: 0.000300
2025-05-27 20:11:12,178 - INFO - joeynmt.training - Epoch   9, Step:    64200, Batch Loss:     0.847830, Batch Acc: 0.729255, Tokens per Sec:    23826, Lr: 0.000300
2025-05-27 20:11:15,512 - INFO - joeynmt.training - Epoch   9, Step:    64300, Batch Loss:     0.927588, Batch Acc: 0.734656, Tokens per Sec:    23468, Lr: 0.000300
2025-05-27 20:11:18,841 - INFO - joeynmt.training - Epoch   9, Step:    64400, Batch Loss:     0.952501, Batch Acc: 0.734671, Tokens per Sec:    23820, Lr: 0.000300
2025-05-27 20:11:22,167 - INFO - joeynmt.training - Epoch   9, Step:    64500, Batch Loss:     0.983788, Batch Acc: 0.732569, Tokens per Sec:    23998, Lr: 0.000300
2025-05-27 20:11:22,167 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:11:22,167 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:11:37,672 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.4910[sec], evaluation: 0.0000[sec]
2025-05-27 20:11:38,066 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/58500.ckpt
2025-05-27 20:11:38,090 - INFO - joeynmt.training - Example #0
2025-05-27 20:11:38,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:11:38,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:11:38,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'col@@', '<unk>', '@', 'azioni', 'per', 'in@@', '<unk>', '@', 'tr@@', '<unk>', '@', 'o@@', '<unk>', '@', 'd@@', '<unk>', '@', 'otto', 'le', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ati', 'per', 'i', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'che', 'st@@', '<unk>', '@', 'avano', 'fac@@', '<unk>', '@', 'endo', 'questi', 'due', 'milioni', 'di', 'anni', ',', 'ha', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'ha', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'ore', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'qu@@', '<unk>', '@', 'at@@', '<unk>', '@', 'tro', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', '', 'stato', 'sp@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 20:11:38,091 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:11:38,092 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:11:38,092 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato queste due col<unk> @ azioni per in<unk> @ tr<unk> @ o<unk> @ d<unk> @ otto le g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati per i po<unk> @ ver<unk> @ i che st<unk> @ avano fac<unk> @ endo questi due milioni di anni , ha av<unk> @ uto 4<unk> @ 8 milioni di anni , ha av<unk> @ uto 4<unk> @ 8 ore , il 4<unk> @ 0 % di qu<unk> @ at<unk> @ tro St<unk> @ ati Un<unk> @ iti ,  stato sp<unk> @ esso .
2025-05-27 20:11:38,092 - INFO - joeynmt.training - Example #1
2025-05-27 20:11:38,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:11:38,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:11:38,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'tor@@', '<unk>', '@', 'no', 'a', 'questa', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'a', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 20:11:38,093 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:11:38,093 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:11:38,093 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ tor<unk> @ no a questa part<unk> @ icol<unk> @ are probl<unk> @ emi a questo problema spe<unk> @ ci<unk> @ f<unk> @ ico , perch non  il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 20:11:38,093 - INFO - joeynmt.training - Example #2
2025-05-27 20:11:38,093 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:11:38,093 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:11:38,093 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a  la c<unk> @ atti<unk> @ va  la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 20:11:38,094 - INFO - joeynmt.training - Example #3
2025-05-27 20:11:38,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:11:38,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:11:38,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'anno', 'in', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'e', 'sc@@', '<unk>', '@', 'ar@@', '<unk>', '@', 's@@', '<unk>', '@', 'are', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:11:38,095 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ anno in in<unk> @ ver<unk> @ no e sc<unk> @ ar<unk> @ s<unk> @ are in est<unk> @ ate .
2025-05-27 20:11:38,095 - INFO - joeynmt.training - Example #4
2025-05-27 20:11:38,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:11:38,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:11:38,095 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:11:38,095 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:11:38,095 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:11:38,095 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a di di<unk> @ seg<unk> @ na che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:11:41,466 - INFO - joeynmt.training - Epoch   9, Step:    64600, Batch Loss:     0.912761, Batch Acc: 0.722823, Tokens per Sec:    21202, Lr: 0.000300
2025-05-27 20:11:44,810 - INFO - joeynmt.training - Epoch   9, Step:    64700, Batch Loss:     0.843649, Batch Acc: 0.732641, Tokens per Sec:    24381, Lr: 0.000300
2025-05-27 20:11:48,127 - INFO - joeynmt.training - Epoch   9, Step:    64800, Batch Loss:     0.920851, Batch Acc: 0.731160, Tokens per Sec:    23505, Lr: 0.000300
2025-05-27 20:11:51,444 - INFO - joeynmt.training - Epoch   9, Step:    64900, Batch Loss:     0.983616, Batch Acc: 0.735219, Tokens per Sec:    24443, Lr: 0.000300
2025-05-27 20:11:54,778 - INFO - joeynmt.training - Epoch   9, Step:    65000, Batch Loss:     0.952441, Batch Acc: 0.730865, Tokens per Sec:    23914, Lr: 0.000300
2025-05-27 20:11:54,778 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:11:54,778 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:12:12,074 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 17.2827[sec], evaluation: 0.0000[sec]
2025-05-27 20:12:12,075 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:12:12,706 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/61500.ckpt
2025-05-27 20:12:12,730 - INFO - joeynmt.training - Example #0
2025-05-27 20:12:12,731 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:12:12,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:12:12,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'ti', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'che', 'i', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', ',', 'che', 'i', 'c@@', '<unk>', '@', 'av@@', '<unk>', '@', 'evano', 'circa', '3', 'milioni', 'di', 'anni', ',', 'per', 'circa', '3', 'milioni', 'di', 'anni', ',', 'per', 'circa', '3', 'milioni', 'di', 'anni', ',', 'per', 'circa', '4@@', '<unk>', '@', '0', ',', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'in@@', '<unk>', '@', 'tor@@', '<unk>', '@', 'no', 'a', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', ',', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:12:12,732 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:12:12,732 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:12:12,732 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ ti per di<unk> @ mostr<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i che i po<unk> @ ver<unk> @ i , che i c<unk> @ av<unk> @ evano circa 3 milioni di anni , per circa 3 milioni di anni , per circa 3 milioni di anni , per circa 4<unk> @ 0 , per c<unk> @ ento  stato in<unk> @ tor<unk> @ no a 4<unk> @ 0 % del 4<unk> @ 0 % , per c<unk> @ ento .
2025-05-27 20:12:12,732 - INFO - joeynmt.training - Example #1
2025-05-27 20:12:12,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:12:12,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:12:12,733 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'a@@', '<unk>', '@', 'der', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'des', '.', '</s>']
2025-05-27 20:12:12,733 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:12:12,733 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:12:12,733 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ a<unk> @ der non  il D<unk> @ ic<unk> @ des .
2025-05-27 20:12:12,733 - INFO - joeynmt.training - Example #2
2025-05-27 20:12:12,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:12:12,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:12:12,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'c@@', '<unk>', '@', 'ura', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'av@@', '<unk>', '@', 'olo', 'il', 'cu@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:12:12,734 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:12:12,734 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:12:12,734 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ ura ar<unk> @ t<unk> @ t<unk> @ av<unk> @ olo il cu<unk> @ ore c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:12:12,734 - INFO - joeynmt.training - Example #3
2025-05-27 20:12:12,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:12:12,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:12:12,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'chi', 'e', 'sc@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'e', 'sp@@', '<unk>', '@', 'av@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ato', '.', '</s>']
2025-05-27 20:12:12,735 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:12:12,735 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:12:12,735 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di chi e sc<unk> @ en<unk> @ a e sp<unk> @ av<unk> @ ent<unk> @ ato .
2025-05-27 20:12:12,735 - INFO - joeynmt.training - Example #4
2025-05-27 20:12:12,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:12:12,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:12:12,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', '', 'una', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', ',', '', 'un', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'no', 'di', 'quello', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:12:12,736 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:12:12,736 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:12:12,736 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a  una sc<unk> @ or<unk> @ sa ,  un di<unk> @ seg<unk> @ no di quello che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:12:16,076 - INFO - joeynmt.training - Epoch   9, Step:    65100, Batch Loss:     0.852091, Batch Acc: 0.733417, Tokens per Sec:    19981, Lr: 0.000300
2025-05-27 20:12:19,417 - INFO - joeynmt.training - Epoch   9, Step:    65200, Batch Loss:     0.895582, Batch Acc: 0.731275, Tokens per Sec:    23976, Lr: 0.000300
2025-05-27 20:12:22,744 - INFO - joeynmt.training - Epoch   9, Step:    65300, Batch Loss:     0.888161, Batch Acc: 0.729299, Tokens per Sec:    23118, Lr: 0.000300
2025-05-27 20:12:26,047 - INFO - joeynmt.training - Epoch   9, Step:    65400, Batch Loss:     0.860217, Batch Acc: 0.731670, Tokens per Sec:    23439, Lr: 0.000300
2025-05-27 20:12:29,383 - INFO - joeynmt.training - Epoch   9, Step:    65500, Batch Loss:     1.000361, Batch Acc: 0.727818, Tokens per Sec:    23944, Lr: 0.000300
2025-05-27 20:12:29,383 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:12:29,383 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:12:44,657 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.2610[sec], evaluation: 0.0000[sec]
2025-05-27 20:12:45,154 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/64500.ckpt
2025-05-27 20:12:45,178 - INFO - joeynmt.training - Example #0
2025-05-27 20:12:45,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:12:45,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:12:45,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'un', 'c@@', '<unk>', '@', 'entr@@', '<unk>', '@', 'o', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'gli', 'e@@', '<unk>', '@', 'qu@@', '<unk>', '@', 'i@@', '<unk>', '@', 'li@@', '<unk>', '@', 'bri@@', '<unk>', '@', 'o', 'per', 'tre', 'mili@@', '<unk>', '@', 'one', 'di', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:12:45,179 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:12:45,179 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:12:45,179 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno sc<unk> @ or<unk> @ so per ri<unk> @ dur<unk> @ re la c<unk> @ aus<unk> @ a di un c<unk> @ entr<unk> @ o di g<unk> @ hi<unk> @ ac<unk> @ cio che gli e<unk> @ qu<unk> @ i<unk> @ li<unk> @ bri<unk> @ o per tre mili<unk> @ one di di anni , il 4<unk> @ 0 , per c<unk> @ ento  stato il 4<unk> @ 0 % del 4<unk> @ 0 % , per il 4<unk> @ 0 % .
2025-05-27 20:12:45,179 - INFO - joeynmt.training - Example #1
2025-05-27 20:12:45,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:12:45,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:12:45,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:12:45,180 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:12:45,180 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:12:45,181 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:12:45,181 - INFO - joeynmt.training - Example #2
2025-05-27 20:12:45,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:12:45,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:12:45,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la c<unk> @ atti<unk> @ va di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - Example #3
2025-05-27 20:12:45,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:12:45,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:12:45,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 's@@', '<unk>', '@', 'con@@', '<unk>', '@', 'f@@', '<unk>', '@', 'it@@', '<unk>', '@', 'ta', '.', '</s>']
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e s<unk> @ con<unk> @ f<unk> @ it<unk> @ ta .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - Example #4
2025-05-27 20:12:45,183 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:12:45,183 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:12:45,183 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'che', 'vi', '', 'acc@@', '<unk>', '@', 'a@@', '<unk>', '@', 'du@@', '<unk>', '@', 'to', ',', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', 'che', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:12:45,183 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:12:45,183 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:12:45,183 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a che vi  acc<unk> @ a<unk> @ du<unk> @ to ,  una c<unk> @ en<unk> @ a di ci<unk> @ b<unk> @ o che negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:12:48,504 - INFO - joeynmt.training - Epoch   9, Step:    65600, Batch Loss:     0.844443, Batch Acc: 0.729972, Tokens per Sec:    20336, Lr: 0.000300
2025-05-27 20:12:51,842 - INFO - joeynmt.training - Epoch   9, Step:    65700, Batch Loss:     0.985376, Batch Acc: 0.728889, Tokens per Sec:    24285, Lr: 0.000300
2025-05-27 20:12:55,151 - INFO - joeynmt.training - Epoch   9, Step:    65800, Batch Loss:     0.887936, Batch Acc: 0.731812, Tokens per Sec:    23936, Lr: 0.000300
2025-05-27 20:12:58,465 - INFO - joeynmt.training - Epoch   9, Step:    65900, Batch Loss:     1.016670, Batch Acc: 0.730447, Tokens per Sec:    24110, Lr: 0.000300
2025-05-27 20:13:01,809 - INFO - joeynmt.training - Epoch   9, Step:    66000, Batch Loss:     0.938673, Batch Acc: 0.728055, Tokens per Sec:    24186, Lr: 0.000300
2025-05-27 20:13:01,809 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:13:01,810 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:13:17,086 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.2632[sec], evaluation: 0.0000[sec]
2025-05-27 20:13:17,439 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/64000.ckpt
2025-05-27 20:13:17,465 - INFO - joeynmt.training - Example #0
2025-05-27 20:13:17,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:13:17,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:13:17,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'f@@', '<unk>', '@', 'att@@', '<unk>', '@', 'or@@', '<unk>', '@', 'no', 'a', 'questo', 'punto', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'la', 'str@@', '<unk>', '@', 'utt@@', '<unk>', '@', 'ura', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'tre', 'milioni', 'di', 'persone', 'che', 'aveva', 'fatto', 'per', 'tre', 'milioni', 'di', 'persone', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'tre', 'milioni', 'di', 'persone', ',', 'il', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:13:17,467 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:13:17,467 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:13:17,467 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due f<unk> @ att<unk> @ or<unk> @ no a questo punto , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per la str<unk> @ utt<unk> @ ura , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di persone che aveva fatto per tre milioni di persone , il 4<unk> @ 0 % di tre milioni di persone , il 4<unk> @ 0 % , il 4<unk> @ 0 % .
2025-05-27 20:13:17,467 - INFO - joeynmt.training - Example #1
2025-05-27 20:13:17,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:13:17,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:13:17,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:13:17,468 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:13:17,468 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:13:17,468 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ ent<unk> @ ale .
2025-05-27 20:13:17,468 - INFO - joeynmt.training - Example #2
2025-05-27 20:13:17,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:13:17,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:13:17,469 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:13:17,469 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:13:17,469 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:13:17,469 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ li<unk> @ mat<unk> @ ica  il g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:13:17,469 - INFO - joeynmt.training - Example #3
2025-05-27 20:13:17,469 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:13:17,469 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:13:17,469 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pu', 'essere', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 's@@', '<unk>', '@', 'par@@', '<unk>', '@', 'ito', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'sp@@', '<unk>', '@', 'av@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 20:13:17,470 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:13:17,470 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:13:17,470 - INFO - joeynmt.training - 	Hypothesis: Si pu essere in est<unk> @ ate e s<unk> @ par<unk> @ ito in est<unk> @ ate e sp<unk> @ av<unk> @ ent<unk> @ a .
2025-05-27 20:13:17,470 - INFO - joeynmt.training - Example #4
2025-05-27 20:13:17,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:13:17,470 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:13:17,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'o', 'che', 'vi', '', 'un', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'no', 'di', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'ni', '.', '</s>']
2025-05-27 20:13:17,471 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:13:17,471 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:13:17,471 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o che vi  un di<unk> @ seg<unk> @ no di una c<unk> @ en<unk> @ a di di<unk> @ seg<unk> @ ni .
2025-05-27 20:13:20,849 - INFO - joeynmt.training - Epoch   9, Step:    66100, Batch Loss:     0.953296, Batch Acc: 0.729474, Tokens per Sec:    21317, Lr: 0.000300
2025-05-27 20:13:24,186 - INFO - joeynmt.training - Epoch   9, Step:    66200, Batch Loss:     0.835214, Batch Acc: 0.732816, Tokens per Sec:    23570, Lr: 0.000300
2025-05-27 20:13:27,533 - INFO - joeynmt.training - Epoch   9, Step:    66300, Batch Loss:     0.867090, Batch Acc: 0.731933, Tokens per Sec:    23798, Lr: 0.000300
2025-05-27 20:13:30,846 - INFO - joeynmt.training - Epoch   9, Step:    66400, Batch Loss:     0.900891, Batch Acc: 0.728543, Tokens per Sec:    23331, Lr: 0.000300
2025-05-27 20:13:34,173 - INFO - joeynmt.training - Epoch   9, Step:    66500, Batch Loss:     0.893106, Batch Acc: 0.730057, Tokens per Sec:    23199, Lr: 0.000300
2025-05-27 20:13:34,173 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:13:34,173 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:13:49,972 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 15.7858[sec], evaluation: 0.0000[sec]
2025-05-27 20:13:49,985 - INFO - joeynmt.training - Example #0
2025-05-27 20:13:49,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:13:49,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:13:49,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', 'per', 'f@@', '<unk>', '@', 'ar', 'vedere', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'tre', 'milioni', 'di', 'persone', ',', 'e', 'i', 'di@@', '<unk>', '@', 'sp@@', '<unk>', '@', 'on@@', '<unk>', '@', 'i@@', '<unk>', '@', 'bili', ',', 'il', '4@@', '<unk>', '@', '0', '%', ',', 'aveva', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'St@@', '<unk>', '@', 'ati', 'Un@@', '<unk>', '@', 'iti', ',', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:13:49,986 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:13:49,987 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:13:49,987 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose , ho mostr<unk> @ ato queste due cose per f<unk> @ ar vedere che i g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio , che i g<unk> @ hi<unk> @ ac<unk> @ cio per tre milioni di persone , e i di<unk> @ sp<unk> @ on<unk> @ i<unk> @ bili , il 4<unk> @ 0 % , aveva av<unk> @ uto 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , il 4<unk> @ 0 % .
2025-05-27 20:13:49,987 - INFO - joeynmt.training - Example #1
2025-05-27 20:13:49,987 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:13:49,987 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:13:49,987 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'molto', 'for@@', '<unk>', '@', 'te', ',', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questo', 'problema', ',', 'perch', 'non', 'si', 'mostr@@', '<unk>', '@', 'a', 'il', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:13:49,988 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:13:49,988 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:13:49,988 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  molto for<unk> @ te , la di<unk> @ st<unk> @ anza di questo problema , perch non  la di<unk> @ st<unk> @ anza di questo problema , perch non si mostr<unk> @ a il ci<unk> @ b<unk> @ o del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:13:49,988 - INFO - joeynmt.training - Example #2
2025-05-27 20:13:49,988 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:13:49,988 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:13:49,988 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'lin@@', '<unk>', '@', 'ea', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ica', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:13:49,989 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:13:49,989 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:13:49,989 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la lin<unk> @ ea c<unk> @ aus<unk> @ a della c<unk> @ li<unk> @ mat<unk> @ ica della nostra c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 20:13:49,989 - INFO - joeynmt.training - Example #3
2025-05-27 20:13:49,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:13:49,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:13:49,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'a', 'in', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:13:49,990 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:13:49,990 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:13:49,990 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si sp<unk> @ ost<unk> @ a in in<unk> @ ver<unk> @ no .
2025-05-27 20:13:49,990 - INFO - joeynmt.training - Example #4
2025-05-27 20:13:49,990 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:13:49,990 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:13:49,990 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', ',', '', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'tr@@', '<unk>', '@', 'att@@', '<unk>', '@', 'amento', 'di', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'fr@@', '<unk>', '@', 'on@@', '<unk>', '@', 'te', 'a', 'qu@@', '<unk>', '@', 'ale', '', 'succ@@', '<unk>', '@', 'esso', '.', '</s>']
2025-05-27 20:13:49,991 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:13:49,991 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:13:49,991 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @  che vi mostr<unk> @ er<unk> @  ,  una ser<unk> @ ie di tr<unk> @ att<unk> @ amento di una ser<unk> @ ie di fr<unk> @ on<unk> @ te a qu<unk> @ ale  succ<unk> @ esso .
2025-05-27 20:13:53,353 - INFO - joeynmt.training - Epoch   9, Step:    66600, Batch Loss:     0.942054, Batch Acc: 0.726150, Tokens per Sec:    22993, Lr: 0.000300
2025-05-27 20:13:56,703 - INFO - joeynmt.training - Epoch   9, Step:    66700, Batch Loss:     0.926220, Batch Acc: 0.730332, Tokens per Sec:    23638, Lr: 0.000300
2025-05-27 20:14:00,077 - INFO - joeynmt.training - Epoch   9, Step:    66800, Batch Loss:     0.975681, Batch Acc: 0.730656, Tokens per Sec:    24396, Lr: 0.000300
2025-05-27 20:14:03,404 - INFO - joeynmt.training - Epoch   9, Step:    66900, Batch Loss:     0.839983, Batch Acc: 0.733124, Tokens per Sec:    23957, Lr: 0.000300
2025-05-27 20:14:06,740 - INFO - joeynmt.training - Epoch   9, Step:    67000, Batch Loss:     0.957166, Batch Acc: 0.724728, Tokens per Sec:    23611, Lr: 0.000300
2025-05-27 20:14:06,740 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:14:06,740 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:14:24,378 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 17.6239[sec], evaluation: 0.0000[sec]
2025-05-27 20:14:24,383 - INFO - joeynmt.training - Example #0
2025-05-27 20:14:24,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:14:24,383 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:14:24,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', 'che', 'hanno', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', 'di', 'c@@', '<unk>', '@', 'av@@', '<unk>', '@', 'i', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'che', 'hanno', 'fatto', 'per', 'tre', 't@@', '<unk>', '@', 'as@@', '<unk>', '@', 'se', 'di', '4@@', '<unk>', '@', '0', '%', 'di', 'qu@@', '<unk>', '@', 'elli', 'che', 'av@@', '<unk>', '@', 'evano', '4@@', '<unk>', '@', '0', '%', ',', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'cui', '', 'stato', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:14:24,383 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:14:24,383 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:14:24,383 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose che hanno mostr<unk> @ ato questi due cas<unk> @ i di c<unk> @ av<unk> @ i per di<unk> @ mostr<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i che hanno fatto per tre t<unk> @ as<unk> @ se di 4<unk> @ 0 % di qu<unk> @ elli che av<unk> @ evano 4<unk> @ 0 % , 4<unk> @ 0 % , il 4<unk> @ 0 % di cui  stato il 4<unk> @ 0 % .
2025-05-27 20:14:24,383 - INFO - joeynmt.training - Example #1
2025-05-27 20:14:24,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:14:24,383 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:14:24,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o , perch non  il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - Example #2
2025-05-27 20:14:24,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:14:24,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:14:24,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 'punto', ',', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il punto , la c<unk> @ atti<unk> @ va del g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico , il cu<unk> @ ore del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - Example #3
2025-05-27 20:14:24,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:14:24,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:14:24,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pu', 'cres@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ere', 'in', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Hypothesis: Si pu cres<unk> @ c<unk> @ ere in in<unk> @ ver<unk> @ no e in<unk> @ ver<unk> @ no .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - Example #4
2025-05-27 20:14:24,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:14:24,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:14:24,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'di', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:14:24,385 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:14:24,385 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:14:24,385 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @  che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a di sc<unk> @ or<unk> @ so di 2<unk> @ 5 anni .
2025-05-27 20:14:27,753 - INFO - joeynmt.training - Epoch   9, Step:    67100, Batch Loss:     0.806152, Batch Acc: 0.731652, Tokens per Sec:    23722, Lr: 0.000300
2025-05-27 20:14:31,099 - INFO - joeynmt.training - Epoch   9, Step:    67200, Batch Loss:     0.989279, Batch Acc: 0.728875, Tokens per Sec:    23931, Lr: 0.000300
2025-05-27 20:14:34,431 - INFO - joeynmt.training - Epoch   9, Step:    67300, Batch Loss:     0.924313, Batch Acc: 0.731349, Tokens per Sec:    23682, Lr: 0.000300
2025-05-27 20:14:37,745 - INFO - joeynmt.training - Epoch   9, Step:    67400, Batch Loss:     0.864258, Batch Acc: 0.729423, Tokens per Sec:    23107, Lr: 0.000300
2025-05-27 20:14:41,093 - INFO - joeynmt.training - Epoch   9, Step:    67500, Batch Loss:     0.869777, Batch Acc: 0.729168, Tokens per Sec:    24532, Lr: 0.000300
2025-05-27 20:14:41,093 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:14:41,093 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:14:57,510 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 16.4029[sec], evaluation: 0.0000[sec]
2025-05-27 20:14:57,510 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:14:58,014 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/66000.ckpt
2025-05-27 20:14:58,033 - INFO - joeynmt.training - Example #0
2025-05-27 20:14:58,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:14:58,034 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:14:58,034 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', 'che', 'hanno', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', ',', 'per', 'cui', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'per', 'c@@', '<unk>', '@', 'ento', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:14:58,034 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:14:58,035 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:14:58,035 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose che hanno mostr<unk> @ ato queste due cose , per cui i g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i po<unk> @ ver<unk> @ i po<unk> @ ver<unk> @ i , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , il 4<unk> @ 0 , per c<unk> @ ento di tre milioni di anni , il 4<unk> @ 0 , per c<unk> @ ento del 4<unk> @ 0 % .
2025-05-27 20:14:58,035 - INFO - joeynmt.training - Example #1
2025-05-27 20:14:58,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:14:58,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:14:58,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 20:14:58,036 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:14:58,036 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:14:58,036 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio , perch non  il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:14:58,036 - INFO - joeynmt.training - Example #2
2025-05-27 20:14:58,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:14:58,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:14:58,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 't', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:14:58,037 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:14:58,037 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:14:58,037 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il cu<unk> @ ore po<unk> @ ver<unk> @ t po<unk> @ ver<unk> @ i po<unk> @ ver<unk> @ i po<unk> @ ver<unk> @ i del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:14:58,037 - INFO - joeynmt.training - Example #3
2025-05-27 20:14:58,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:14:58,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:14:58,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'e', 'nel', 'v@@', '<unk>', '@', 'ento', 'e', 'nel', 'v@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:14:58,038 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:14:58,038 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:14:58,038 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un in<unk> @ ver<unk> @ no e nel v<unk> @ ento e nel v<unk> @ ento .
2025-05-27 20:14:58,038 - INFO - joeynmt.training - Example #4
2025-05-27 20:14:58,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:14:58,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:14:58,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'en@@', '<unk>', '@', 'a', 'di', 'ri@@', '<unk>', '@', 'chi@@', '<unk>', '@', 'est@@', '<unk>', '@', 'a', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:14:58,039 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:14:58,039 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:14:58,039 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @   una c<unk> @ en<unk> @ a di ri<unk> @ chi<unk> @ est<unk> @ a , che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:15:01,422 - INFO - joeynmt.training - Epoch   9, Step:    67600, Batch Loss:     0.980151, Batch Acc: 0.731523, Tokens per Sec:    20953, Lr: 0.000300
2025-05-27 20:15:04,734 - INFO - joeynmt.training - Epoch   9, Step:    67700, Batch Loss:     0.828859, Batch Acc: 0.732079, Tokens per Sec:    23445, Lr: 0.000300
2025-05-27 20:15:08,061 - INFO - joeynmt.training - Epoch   9, Step:    67800, Batch Loss:     0.884305, Batch Acc: 0.731860, Tokens per Sec:    23343, Lr: 0.000300
2025-05-27 20:15:11,387 - INFO - joeynmt.training - Epoch   9, Step:    67900, Batch Loss:     0.955600, Batch Acc: 0.730176, Tokens per Sec:    23288, Lr: 0.000300
2025-05-27 20:15:14,704 - INFO - joeynmt.training - Epoch   9, Step:    68000, Batch Loss:     0.991202, Batch Acc: 0.725738, Tokens per Sec:    24037, Lr: 0.000300
2025-05-27 20:15:14,705 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:15:14,705 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:15:30,931 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.76, acc:   0.71, generation: 16.2126[sec], evaluation: 0.0000[sec]
2025-05-27 20:15:30,936 - INFO - joeynmt.training - Example #0
2025-05-27 20:15:30,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:15:30,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:15:30,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'ta', ',', 'per', 'in@@', '<unk>', '@', 'contr@@', '<unk>', '@', 'are', 'le', 'due', 'di@@', '<unk>', '@', 'ta', ',', 'per', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'hanno', 'fatto', 'per', 'circa', 'tre', 'milioni', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', 'ci@@', '<unk>', '@', 'b@@', '<unk>', '@', 'o', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'per', 'c@@', '<unk>', '@', 'ento', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due di<unk> @ ta , per in<unk> @ contr<unk> @ are le due di<unk> @ ta , per con<unk> @ si<unk> @ der<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che hanno fatto per circa tre milioni di tre milioni di anni , il ci<unk> @ b<unk> @ o , per tre milioni di anni , il 4<unk> @ 0 , per c<unk> @ ento , il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:15:30,937 - INFO - joeynmt.training - Example #1
2025-05-27 20:15:30,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:15:30,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:15:30,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'res@@', '<unk>', '@', 'ist@@', '<unk>', '@', 'enza', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', 'mostr@@', '<unk>', '@', 'a', 'il', 'fatto', 'che', 'non', 'mostr@@', '<unk>', '@', 'a', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la res<unk> @ ist<unk> @ enza di questo problema spe<unk> @ ci<unk> @ ale , perch non mostr<unk> @ a il fatto che non mostr<unk> @ a il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - Example #2
2025-05-27 20:15:30,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:15:30,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:15:30,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'po@@', '<unk>', '@', 'vere', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'po@@', '<unk>', '@', 'vere', 'il', 'cu@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'vo', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:15:30,938 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so ,  il cu<unk> @ ore po<unk> @ vere  il cu<unk> @ ore po<unk> @ vere il cu<unk> @ ore c<unk> @ atti<unk> @ vo del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - Example #3
2025-05-27 20:15:30,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:15:30,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:15:30,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'v@@', '<unk>', '@', 'ento', 'e', 'nel', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'a', 'nel', 'sen@@', '<unk>', '@', 'so', 'di', '.', '</s>']
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Hypothesis: Si trtr<unk> @ at<unk> @ ta di un v<unk> @ ento e nel v<unk> @ ento e si sp<unk> @ ost<unk> @ a nel sen<unk> @ so di .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - Example #4
2025-05-27 20:15:30,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:15:30,939 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:15:30,939 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'pros@@', 'pros@@', 'pros@@', 'pros@@', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'ato', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Hypothesis: Il prosprosprosprosprospros<unk> @ si<unk> @ mo di<unk> @ mostr<unk> @ ato che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:15:34,282 - INFO - joeynmt.training - Epoch   9, Step:    68100, Batch Loss:     1.068740, Batch Acc: 0.729075, Tokens per Sec:    23187, Lr: 0.000300
2025-05-27 20:15:37,619 - INFO - joeynmt.training - Epoch   9, Step:    68200, Batch Loss:     0.943880, Batch Acc: 0.728827, Tokens per Sec:    23854, Lr: 0.000300
2025-05-27 20:15:40,927 - INFO - joeynmt.training - Epoch   9, Step:    68300, Batch Loss:     0.933599, Batch Acc: 0.731898, Tokens per Sec:    23495, Lr: 0.000300
2025-05-27 20:15:44,273 - INFO - joeynmt.training - Epoch   9, Step:    68400, Batch Loss:     0.940603, Batch Acc: 0.726211, Tokens per Sec:    24052, Lr: 0.000300
2025-05-27 20:15:47,578 - INFO - joeynmt.training - Epoch   9, Step:    68500, Batch Loss:     0.927231, Batch Acc: 0.729388, Tokens per Sec:    23287, Lr: 0.000300
2025-05-27 20:15:47,578 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:15:47,578 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:16:04,985 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 17.3937[sec], evaluation: 0.0000[sec]
2025-05-27 20:16:04,986 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:16:05,467 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/65500.ckpt
2025-05-27 20:16:05,492 - INFO - joeynmt.training - Example #0
2025-05-27 20:16:05,492 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:16:05,492 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:16:05,493 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'chi', 'per', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'are', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ato', ',', 'che', 'gli', 'e@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'ani', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'ha', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '8', 'stati', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'stati', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:16:05,493 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:16:05,493 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:16:05,493 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due s<unk> @ ac<unk> @ chi per c<unk> @ aus<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ato , che gli e<unk> @ ic<unk> @ e<unk> @ ani , per tre milioni di anni , che ha fatto per il 4<unk> @ 8 stati di tre milioni di anni , il 4<unk> @ 8 stati di tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:16:05,493 - INFO - joeynmt.training - Example #1
2025-05-27 20:16:05,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:16:05,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:16:05,494 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'm@@', '<unk>', '@', 'em@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ia', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 20:16:05,494 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:16:05,494 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:16:05,494 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la m<unk> @ em<unk> @ or<unk> @ ia di questo problema spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:16:05,494 - INFO - joeynmt.training - Example #2
2025-05-27 20:16:05,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:16:05,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:16:05,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'cosa', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'ica', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'della', 'nostra', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'one', '.', '</s>']
2025-05-27 20:16:05,495 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:16:05,495 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:16:05,495 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la cosa ar<unk> @ t<unk> @ t<unk> @ ica  il cu<unk> @ ore ar<unk> @ t<unk> @ ico della nostra c<unk> @ li<unk> @ one .
2025-05-27 20:16:05,496 - INFO - joeynmt.training - Example #3
2025-05-27 20:16:05,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:16:05,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:16:05,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'cres@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ere', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:16:05,496 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:16:05,496 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:16:05,496 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e cres<unk> @ c<unk> @ ere in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:16:05,496 - INFO - joeynmt.training - Example #4
2025-05-27 20:16:05,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:16:05,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:16:05,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', '', 'una', 'c@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'l@@', '<unk>', '@', 'et@@', '<unk>', '@', 'ta', 'di', 'quello', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'acc@@', '<unk>', '@', 'ade', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:16:05,497 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:16:05,497 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:16:05,497 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a  una c<unk> @ ic<unk> @ l<unk> @ et<unk> @ ta di quello che vi mostr<unk> @ a cosa acc<unk> @ ade negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:16:08,836 - INFO - joeynmt.training - Epoch   9, Step:    68600, Batch Loss:     0.891236, Batch Acc: 0.728643, Tokens per Sec:    20377, Lr: 0.000300
2025-05-27 20:16:12,152 - INFO - joeynmt.training - Epoch   9, Step:    68700, Batch Loss:     0.864435, Batch Acc: 0.729300, Tokens per Sec:    23072, Lr: 0.000300
2025-05-27 20:16:15,474 - INFO - joeynmt.training - Epoch   9, Step:    68800, Batch Loss:     1.087281, Batch Acc: 0.729270, Tokens per Sec:    23557, Lr: 0.000300
2025-05-27 20:16:18,824 - INFO - joeynmt.training - Epoch   9, Step:    68900, Batch Loss:     0.950204, Batch Acc: 0.727381, Tokens per Sec:    24044, Lr: 0.000300
2025-05-27 20:16:22,141 - INFO - joeynmt.training - Epoch   9, Step:    69000, Batch Loss:     0.928588, Batch Acc: 0.726555, Tokens per Sec:    22992, Lr: 0.000300
2025-05-27 20:16:22,141 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:16:22,141 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:16:39,425 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 17.2698[sec], evaluation: 0.0000[sec]
2025-05-27 20:16:39,786 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/62500.ckpt
2025-05-27 20:16:39,807 - INFO - joeynmt.training - Example #0
2025-05-27 20:16:39,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:16:39,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:16:39,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', ',', 'per', 'f@@', '<unk>', '@', 'ir@@', '<unk>', '@', 'm@@', '<unk>', '@', 'enti', 'per', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'i', 'qu@@', '<unk>', '@', 'elli', 'che', 'hanno', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'dei', 'm@@', '<unk>', '@', 'oti@@', '<unk>', '@', 'vi', 'per', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', 'dei', 'sol@@', '<unk>', '@', 'di', ',', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:16:39,809 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:16:39,809 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:16:39,809 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose , per f<unk> @ ir<unk> @ m<unk> @ enti per c<unk> @ aus<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i qu<unk> @ elli che hanno fatto per tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % dei m<unk> @ oti<unk> @ vi per il 4<unk> @ 0 % del 4<unk> @ 0 % dei sol<unk> @ di , 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:16:39,809 - INFO - joeynmt.training - Example #1
2025-05-27 20:16:39,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:16:39,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:16:39,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e', 'non', 'lo', 'mostr@@', '<unk>', '@', 'a', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 20:16:39,810 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:16:39,810 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:16:39,810 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza di questo part<unk> @ icol<unk> @ are spe<unk> @ ci<unk> @ f<unk> @ ico , perch non  il D<unk> @ ic<unk> @ e non lo mostr<unk> @ a il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:16:39,810 - INFO - joeynmt.training - Example #2
2025-05-27 20:16:39,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:16:39,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:16:39,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 's@@', '<unk>', '@', 'ito', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'del', 'nostro', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:16:39,811 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:16:39,811 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:16:39,811 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ atti<unk> @ va del nostro s<unk> @ ito  il cu<unk> @ ore del nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:16:39,811 - INFO - joeynmt.training - Example #3
2025-05-27 20:16:39,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:16:39,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:16:39,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'or@@', '<unk>', '@', 'r@@', '<unk>', '@', 'endo', 'in', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'e', 'si', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:16:39,812 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:16:39,812 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:16:39,812 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ or<unk> @ r<unk> @ endo in in<unk> @ ver<unk> @ no e si in<unk> @ ver<unk> @ no .
2025-05-27 20:16:39,812 - INFO - joeynmt.training - Example #4
2025-05-27 20:16:39,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:16:39,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:16:39,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', ',', '', 'una', 'di@@', '<unk>', '@', 'segn@@', '<unk>', '@', 'ata', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'r@@', '<unk>', '@', 'ere', ',', 'e', '&apos;', 'una', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'sa', 'di', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:16:39,812 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:16:39,813 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:16:39,813 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a ,  una di<unk> @ segn<unk> @ ata di sc<unk> @ or<unk> @ r<unk> @ ere , e &apos; una sc<unk> @ or<unk> @ sa di 2<unk> @ 5 anni .
2025-05-27 20:16:43,174 - INFO - joeynmt.training - Epoch   9, Step:    69100, Batch Loss:     0.851346, Batch Acc: 0.727469, Tokens per Sec:    21414, Lr: 0.000300
2025-05-27 20:16:46,476 - INFO - joeynmt.training - Epoch   9, Step:    69200, Batch Loss:     0.949154, Batch Acc: 0.729226, Tokens per Sec:    24249, Lr: 0.000300
2025-05-27 20:16:49,791 - INFO - joeynmt.training - Epoch   9, Step:    69300, Batch Loss:     0.914277, Batch Acc: 0.725233, Tokens per Sec:    24249, Lr: 0.000300
2025-05-27 20:16:53,104 - INFO - joeynmt.training - Epoch   9, Step:    69400, Batch Loss:     0.977736, Batch Acc: 0.727470, Tokens per Sec:    23879, Lr: 0.000300
2025-05-27 20:16:56,436 - INFO - joeynmt.training - Epoch   9, Step:    69500, Batch Loss:     0.965108, Batch Acc: 0.726428, Tokens per Sec:    24306, Lr: 0.000300
2025-05-27 20:16:56,436 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:16:56,436 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:17:12,048 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 15.6029[sec], evaluation: 0.0000[sec]
2025-05-27 20:17:12,048 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:17:12,534 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/63000.ckpt
2025-05-27 20:17:12,553 - INFO - joeynmt.training - Example #0
2025-05-27 20:17:12,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:17:12,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:17:12,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'p@@', '<unk>', '@', 'op@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'i', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'le', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'per', 'i', 'qu@@', '<unk>', '@', 'elli', 'che', 'hanno', 'av@@', '<unk>', '@', 'uto', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:17:12,555 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:17:12,555 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:17:12,555 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due p<unk> @ op<unk> @ ol<unk> @ i per ri<unk> @ dur<unk> @ re le g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico che i g<unk> @ hi<unk> @ ac<unk> @ cio per i qu<unk> @ elli che hanno av<unk> @ uto tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % del 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:17:12,555 - INFO - joeynmt.training - Example #1
2025-05-27 20:17:12,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:17:12,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:17:12,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'azione', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ali', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ici', 'che', 'non', 'mostr@@', '<unk>', '@', 'a', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'da', '.', '</s>']
2025-05-27 20:17:12,556 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:17:12,556 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:17:12,556 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ azione di questo part<unk> @ icol<unk> @ are probl<unk> @ emi spe<unk> @ ci<unk> @ ali spe<unk> @ ci<unk> @ f<unk> @ ici che non mostr<unk> @ a il D<unk> @ ic<unk> @ e<unk> @ da .
2025-05-27 20:17:12,556 - INFO - joeynmt.training - Example #2
2025-05-27 20:17:12,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:17:12,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:17:12,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 't@@', '<unk>', '@', 'amente', ',', 'la', 'lin@@', '<unk>', '@', 'ea', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:17:12,557 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:17:12,557 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:17:12,557 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ t<unk> @ amente , la lin<unk> @ ea ar<unk> @ t<unk> @ ico  la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio del cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:17:12,557 - INFO - joeynmt.training - Example #3
2025-05-27 20:17:12,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:17:12,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:17:12,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:17:12,558 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:17:12,558 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:17:12,558 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si in<unk> @ ver<unk> @ no .
2025-05-27 20:17:12,558 - INFO - joeynmt.training - Example #4
2025-05-27 20:17:12,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:17:12,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:17:12,559 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'o', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'sc@@', '<unk>', '@', 'al@@', '<unk>', '@', 'a', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:17:12,559 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:17:12,559 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:17:12,559 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o che vi mostr<unk> @ o  una sc<unk> @ al<unk> @ a che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:17:15,909 - INFO - joeynmt.training - Epoch   9, Step:    69600, Batch Loss:     0.966279, Batch Acc: 0.732492, Tokens per Sec:    20330, Lr: 0.000300
2025-05-27 20:17:19,234 - INFO - joeynmt.training - Epoch   9, Step:    69700, Batch Loss:     0.962873, Batch Acc: 0.729508, Tokens per Sec:    23346, Lr: 0.000300
2025-05-27 20:17:22,582 - INFO - joeynmt.training - Epoch   9, Step:    69800, Batch Loss:     0.978434, Batch Acc: 0.729300, Tokens per Sec:    24284, Lr: 0.000300
2025-05-27 20:17:25,918 - INFO - joeynmt.training - Epoch   9, Step:    69900, Batch Loss:     0.983676, Batch Acc: 0.725484, Tokens per Sec:    23870, Lr: 0.000300
2025-05-27 20:17:29,248 - INFO - joeynmt.training - Epoch   9, Step:    70000, Batch Loss:     0.949489, Batch Acc: 0.730432, Tokens per Sec:    23867, Lr: 0.000300
2025-05-27 20:17:29,248 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:17:29,248 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:17:43,295 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 14.0339[sec], evaluation: 0.0000[sec]
2025-05-27 20:17:43,296 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:17:43,801 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/65000.ckpt
2025-05-27 20:17:43,825 - INFO - joeynmt.training - Example #0
2025-05-27 20:17:43,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:17:43,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:17:43,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'cose', ',', 'per', 'fare', 'per', 'fare', 'per', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ai', ',', 'per', 'i', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'volte', ',', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:17:43,827 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:17:43,827 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:17:43,827 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose , per fare per fare per con<unk> @ si<unk> @ der<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ai , per i con<unk> @ si<unk> @ der<unk> @ are i 4<unk> @ 8 milioni di volte , che ha av<unk> @ uto il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:17:43,827 - INFO - joeynmt.training - Example #1
2025-05-27 20:17:43,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:17:43,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:17:43,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'ter@@', '<unk>', '@', 'ra', 'di', 'tutto', 'questo', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', ',', 'perch', 'non', '', 'l&apos;', 'idea', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:17:43,828 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:17:43,828 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:17:43,828 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ ra di tutto questo spe<unk> @ ci<unk> @ f<unk> @ ico , perch non  l&apos; idea di questo part<unk> @ icol<unk> @ are spe<unk> @ ci<unk> @ ale .
2025-05-27 20:17:43,828 - INFO - joeynmt.training - Example #2
2025-05-27 20:17:43,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:17:43,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:17:43,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'lin@@', '<unk>', '@', 'ea', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'e', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', '.', '</s>']
2025-05-27 20:17:43,829 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:17:43,829 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:17:43,829 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ ea po<unk> @ ver<unk> @ a , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore c<unk> @ li<unk> @ m<unk> @ as<unk> @ e del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico .
2025-05-27 20:17:43,829 - INFO - joeynmt.training - Example #3
2025-05-27 20:17:43,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:17:43,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:17:43,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'in', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'e', 'si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', '.', '</s>']
2025-05-27 20:17:43,830 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:17:43,830 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:17:43,830 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in in<unk> @ ver<unk> @ no e si tr<unk> @ at<unk> @ ta .
2025-05-27 20:17:43,830 - INFO - joeynmt.training - Example #4
2025-05-27 20:17:43,830 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:17:43,830 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:17:43,830 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'volta', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'una', 'ser@@', '<unk>', '@', 'ie', 'di', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'che', 'vi', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:17:43,831 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:17:43,831 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:17:43,831 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o  una c<unk> @ ura di una ser<unk> @ ie di sc<unk> @ or<unk> @ so , che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:17:47,209 - INFO - joeynmt.training - Epoch   9, Step:    70100, Batch Loss:     0.883890, Batch Acc: 0.730245, Tokens per Sec:    20585, Lr: 0.000300
2025-05-27 20:17:50,543 - INFO - joeynmt.training - Epoch   9, Step:    70200, Batch Loss:     0.906340, Batch Acc: 0.726153, Tokens per Sec:    23662, Lr: 0.000300
2025-05-27 20:17:53,857 - INFO - joeynmt.training - Epoch   9, Step:    70300, Batch Loss:     1.011071, Batch Acc: 0.726810, Tokens per Sec:    23944, Lr: 0.000300
2025-05-27 20:17:57,187 - INFO - joeynmt.training - Epoch   9, Step:    70400, Batch Loss:     0.953250, Batch Acc: 0.730103, Tokens per Sec:    24047, Lr: 0.000300
2025-05-27 20:18:00,497 - INFO - joeynmt.training - Epoch   9, Step:    70500, Batch Loss:     0.940968, Batch Acc: 0.729158, Tokens per Sec:    23641, Lr: 0.000300
2025-05-27 20:18:00,497 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:18:00,497 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:18:14,102 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.61, acc:   0.72, generation: 13.5960[sec], evaluation: 0.0000[sec]
2025-05-27 20:18:14,102 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:18:14,588 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/67500.ckpt
2025-05-27 20:18:14,611 - INFO - joeynmt.training - Example #0
2025-05-27 20:18:14,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:18:14,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:18:14,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'la', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', ',', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'ore', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', '4@@', '<unk>', '@', '8', 'ore', 'di', '4@@', '<unk>', '@', '8', 'ore', ',', '4@@', '<unk>', '@', '8', 'ore', 'di', '4@@', '<unk>', '@', '8', 'ore', '.', '</s>']
2025-05-27 20:18:14,612 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:18:14,612 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:18:14,612 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ mostr<unk> @ a per ri<unk> @ dur<unk> @ re la g<unk> @ hi<unk> @ ac<unk> @ cio che , i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che aveva av<unk> @ uto 4<unk> @ 8 ore di tre milioni di anni , che aveva 4<unk> @ 8 ore di 4<unk> @ 8 ore , 4<unk> @ 8 ore di 4<unk> @ 8 ore .
2025-05-27 20:18:14,612 - INFO - joeynmt.training - Example #1
2025-05-27 20:18:14,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:18:14,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:18:14,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'che', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:18:14,613 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:18:14,613 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:18:14,613 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza che non  abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:18:14,613 - INFO - joeynmt.training - Example #2
2025-05-27 20:18:14,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:18:14,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:18:14,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:18:14,614 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:18:14,614 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:18:14,614 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa pi po<unk> @ ver<unk> @ a  il g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:18:14,614 - INFO - joeynmt.training - Example #3
2025-05-27 20:18:14,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:18:14,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:18:14,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', '', 'in', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'e', 'si', 'cres@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'u@@', '<unk>', '@', 'te', 'nel', 'v@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:18:14,615 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:18:14,615 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:18:14,615 - INFO - joeynmt.training - 	Hypothesis: S<unk> @  in in<unk> @ ver<unk> @ no e si cres<unk> @ ci<unk> @ u<unk> @ te nel v<unk> @ ento .
2025-05-27 20:18:14,615 - INFO - joeynmt.training - Example #4
2025-05-27 20:18:14,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:18:14,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:18:14,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:18:14,615 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:18:14,616 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:18:14,616 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a  una c<unk> @ ura di di<unk> @ seg<unk> @ na  una c<unk> @ ura di di<unk> @ seg<unk> @ na che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:18:17,854 - INFO - joeynmt.training - Epoch   9, Step:    70600, Batch Loss:     0.824759, Batch Acc: 0.728348, Tokens per Sec:    20832, Lr: 0.000300
2025-05-27 20:18:21,184 - INFO - joeynmt.training - Epoch   9, Step:    70700, Batch Loss:     0.892371, Batch Acc: 0.727699, Tokens per Sec:    23593, Lr: 0.000300
2025-05-27 20:18:24,492 - INFO - joeynmt.training - Epoch   9, Step:    70800, Batch Loss:     0.966860, Batch Acc: 0.727346, Tokens per Sec:    23731, Lr: 0.000300
2025-05-27 20:18:27,798 - INFO - joeynmt.training - Epoch   9, Step:    70900, Batch Loss:     0.927842, Batch Acc: 0.731212, Tokens per Sec:    23246, Lr: 0.000300
2025-05-27 20:18:29,588 - INFO - joeynmt.training - Epoch   9: total training loss 7297.46
2025-05-27 20:18:29,588 - INFO - joeynmt.training - EPOCH 10
2025-05-27 20:18:31,104 - INFO - joeynmt.training - Epoch  10, Step:    71000, Batch Loss:     0.973666, Batch Acc: 0.732212, Tokens per Sec:    22836, Lr: 0.000300
2025-05-27 20:18:31,105 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:18:31,105 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:18:46,855 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 15.7367[sec], evaluation: 0.0000[sec]
2025-05-27 20:18:47,286 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/69000.ckpt
2025-05-27 20:18:47,308 - INFO - joeynmt.training - Example #0
2025-05-27 20:18:47,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:18:47,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:18:47,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'rit@@', '<unk>', '@', 'ti', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ati', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'il', '4@@', '<unk>', '@', '8', 'stati', ',', 'per', 'c@@', '<unk>', '@', 'op@@', '<unk>', '@', 'p@@', '<unk>', '@', 'ure', ',', 'per', 'tre', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 20:18:47,309 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:18:47,309 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:18:47,309 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ rit<unk> @ ti per ri<unk> @ dur<unk> @ re i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per il 4<unk> @ 8 stati , per c<unk> @ op<unk> @ p<unk> @ ure , per tre milioni di anni .
2025-05-27 20:18:47,309 - INFO - joeynmt.training - Example #1
2025-05-27 20:18:47,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:18:47,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:18:47,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', ',', 'ma', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'da', '.', '</s>']
2025-05-27 20:18:47,310 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:18:47,310 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:18:47,310 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza , ma non  il D<unk> @ ic<unk> @ e non  il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio , non  il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ da .
2025-05-27 20:18:47,310 - INFO - joeynmt.training - Example #2
2025-05-27 20:18:47,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:18:47,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:18:47,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'il', 'sistema', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:18:47,311 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:18:47,311 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:18:47,311 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il sistema di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale .
2025-05-27 20:18:47,311 - INFO - joeynmt.training - Example #3
2025-05-27 20:18:47,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:18:47,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:18:47,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'nel', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 's@@', '<unk>', '@', 'v@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ano', '.', '</s>']
2025-05-27 20:18:47,312 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:18:47,312 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:18:47,312 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , nel v<unk> @ ento e si s<unk> @ v<unk> @ eg<unk> @ li<unk> @ ano .
2025-05-27 20:18:47,312 - INFO - joeynmt.training - Example #4
2025-05-27 20:18:47,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:18:47,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:18:47,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', '', 'una', 'st@@', '<unk>', '@', 'anza', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'ni', '', 'una', 'st@@', '<unk>', '@', 'anza', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'ni', ',', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:18:47,313 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:18:47,313 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:18:47,313 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a  una st<unk> @ anza di di<unk> @ seg<unk> @ ni  una st<unk> @ anza di di<unk> @ seg<unk> @ ni , che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:18:50,516 - INFO - joeynmt.training - Epoch  10, Step:    71100, Batch Loss:     0.916095, Batch Acc: 0.738323, Tokens per Sec:    21542, Lr: 0.000300
2025-05-27 20:18:53,709 - INFO - joeynmt.training - Epoch  10, Step:    71200, Batch Loss:     0.877577, Batch Acc: 0.737826, Tokens per Sec:    24659, Lr: 0.000300
2025-05-27 20:18:56,872 - INFO - joeynmt.training - Epoch  10, Step:    71300, Batch Loss:     0.848791, Batch Acc: 0.737042, Tokens per Sec:    24720, Lr: 0.000300
2025-05-27 20:19:00,075 - INFO - joeynmt.training - Epoch  10, Step:    71400, Batch Loss:     0.906458, Batch Acc: 0.736351, Tokens per Sec:    24995, Lr: 0.000300
2025-05-27 20:19:03,262 - INFO - joeynmt.training - Epoch  10, Step:    71500, Batch Loss:     0.957808, Batch Acc: 0.741761, Tokens per Sec:    25563, Lr: 0.000300
2025-05-27 20:19:03,262 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:19:03,262 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:19:16,757 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 13.4857[sec], evaluation: 0.0000[sec]
2025-05-27 20:19:17,067 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/71000.ckpt
2025-05-27 20:19:17,084 - INFO - joeynmt.training - Example #0
2025-05-27 20:19:17,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:19:17,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:19:17,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'i', 'di', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'i', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'i', '4@@', '<unk>', '@', '8', 'stati', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'stati', 'di', 'bas@@', '<unk>', '@', 'e', 'di', 'circa', '4@@', '<unk>', '@', '8', 'stati', ',', '4@@', '<unk>', '@', '8', 'stati', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'del', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:19:17,085 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:19:17,085 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:19:17,085 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due p<unk> @ ezz<unk> @ i di p<unk> @ ezz<unk> @ i di g<unk> @ hi<unk> @ ac<unk> @ cio , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i 4<unk> @ 8 stati , che aveva tre milioni di anni , il 4<unk> @ 8 stati di bas<unk> @ e di circa 4<unk> @ 8 stati , 4<unk> @ 8 stati , il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:19:17,085 - INFO - joeynmt.training - Example #1
2025-05-27 20:19:17,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:19:17,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:19:17,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'cre@@', '<unk>', '@', 'azione', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'non', 'c&apos;', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'a@@', '<unk>', '@', 'cia', '.', '</s>']
2025-05-27 20:19:17,086 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:19:17,086 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:19:17,086 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la cre<unk> @ azione di questo problema spe<unk> @ ci<unk> @ ale , non c&apos;  il D<unk> @ ic<unk> @ a<unk> @ cia .
2025-05-27 20:19:17,086 - INFO - joeynmt.training - Example #2
2025-05-27 20:19:17,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:19:17,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:19:17,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'il', 'cu@@', '<unk>', '@', 'ore', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , il cu<unk> @ ore  il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema glob<unk> @ ale .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - Example #3
2025-05-27 20:19:17,087 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:19:17,087 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:19:17,087 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', '<unk>', '@', 'c@@', '<unk>', '@', 'eva', 'in', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 's@@', '<unk>', '@', 'v@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ava', '.', '</s>']
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Hypothesis: Si cres<unk> @ c<unk> @ eva in v<unk> @ ento e si s<unk> @ v<unk> @ eg<unk> @ li<unk> @ ava .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - Example #4
2025-05-27 20:19:17,088 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:19:17,088 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:19:17,088 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'azione', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', ',', 'una', 'st@@', '<unk>', '@', 'azione', 'di', 'de@@', '<unk>', '@', 'fin@@', '<unk>', '@', 'i@@', '<unk>', '@', 'zione', 'di', 'quello', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:19:17,088 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:19:17,088 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:19:17,088 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ azione che vi mostr<unk> @ er<unk> @  , una st<unk> @ azione di de<unk> @ fin<unk> @ i<unk> @ zione di quello che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:19:20,360 - INFO - joeynmt.training - Epoch  10, Step:    71600, Batch Loss:     0.956945, Batch Acc: 0.733958, Tokens per Sec:    21864, Lr: 0.000300
2025-05-27 20:19:23,619 - INFO - joeynmt.training - Epoch  10, Step:    71700, Batch Loss:     0.965264, Batch Acc: 0.737450, Tokens per Sec:    24143, Lr: 0.000300
2025-05-27 20:19:26,921 - INFO - joeynmt.training - Epoch  10, Step:    71800, Batch Loss:     0.793962, Batch Acc: 0.737250, Tokens per Sec:    24064, Lr: 0.000300
2025-05-27 20:19:30,246 - INFO - joeynmt.training - Epoch  10, Step:    71900, Batch Loss:     0.866184, Batch Acc: 0.740242, Tokens per Sec:    24034, Lr: 0.000300
2025-05-27 20:19:33,589 - INFO - joeynmt.training - Epoch  10, Step:    72000, Batch Loss:     0.839245, Batch Acc: 0.738287, Tokens per Sec:    24086, Lr: 0.000300
2025-05-27 20:19:33,589 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:19:33,589 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:19:49,665 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 16.0619[sec], evaluation: 0.0000[sec]
2025-05-27 20:19:49,670 - INFO - joeynmt.training - Example #0
2025-05-27 20:19:49,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:19:49,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:19:49,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'ta', 'per', 'f@@', '<unk>', '@', 'ar', 's@@', '<unk>', '@', '', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'd@@', '<unk>', '@', 'enti', 'di', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'ore', 'di', 'tre', 'milioni', 'di', 'persone', 'che', 'aveva', '4@@', '<unk>', '@', '8', '%', 'di', 'tre', 'milioni', 'di', 'persone', ',', 'il', '4@@', '<unk>', '@', '8', 'ore', '.', '</s>']
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ta per f<unk> @ ar s<unk> @  che il g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ d<unk> @ enti di tre milioni di persone che hanno av<unk> @ uto 4<unk> @ 8 ore di tre milioni di persone che aveva 4<unk> @ 8 % di tre milioni di persone , il 4<unk> @ 8 ore .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - Example #1
2025-05-27 20:19:49,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:19:49,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:19:49,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'mente', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'ari', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ ar<unk> @ mente part<unk> @ icol<unk> @ ari , perch non  il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - Example #2
2025-05-27 20:19:49,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:19:49,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:19:49,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'cu@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'vo', 'del', 'cu@@', '<unk>', '@', 'ore', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio del cu<unk> @ ore c<unk> @ atti<unk> @ vo del cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - Example #3
2025-05-27 20:19:49,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:19:49,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:19:49,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'ap@@', '<unk>', '@', 'ete', ',', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'si', 'sp@@', '<unk>', '@', 'ost@@', '<unk>', '@', 'a', 'nel', 'sen@@', '<unk>', '@', 'so', 'di', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in est<unk> @ ate e si sp<unk> @ ost<unk> @ a nel sen<unk> @ so di est<unk> @ ate .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - Example #4
2025-05-27 20:19:49,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:19:49,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:19:49,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'c@@', '<unk>', '@', 'ura', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:19:49,673 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:19:49,673 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:19:49,673 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a cosa che vi mostr<unk> @ er<unk> @   una c<unk> @ ura di di<unk> @ seg<unk> @ na che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:19:53,013 - INFO - joeynmt.training - Epoch  10, Step:    72100, Batch Loss:     1.044492, Batch Acc: 0.732716, Tokens per Sec:    23376, Lr: 0.000300
2025-05-27 20:19:56,344 - INFO - joeynmt.training - Epoch  10, Step:    72200, Batch Loss:     0.860607, Batch Acc: 0.743710, Tokens per Sec:    23532, Lr: 0.000300
2025-05-27 20:19:59,660 - INFO - joeynmt.training - Epoch  10, Step:    72300, Batch Loss:     0.816292, Batch Acc: 0.734097, Tokens per Sec:    23468, Lr: 0.000300
2025-05-27 20:20:02,995 - INFO - joeynmt.training - Epoch  10, Step:    72400, Batch Loss:     0.866279, Batch Acc: 0.735663, Tokens per Sec:    23675, Lr: 0.000300
2025-05-27 20:20:06,332 - INFO - joeynmt.training - Epoch  10, Step:    72500, Batch Loss:     0.885982, Batch Acc: 0.732871, Tokens per Sec:    23640, Lr: 0.000300
2025-05-27 20:20:06,332 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:20:06,332 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:20:22,027 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.6808[sec], evaluation: 0.0000[sec]
2025-05-27 20:20:22,036 - INFO - joeynmt.training - Example #0
2025-05-27 20:20:22,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:20:22,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:20:22,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'cas@@', '<unk>', '@', 'i', 'per', 'fare', 'queste', 'due', 'cose', 'che', 'sono', 'st@@', '<unk>', '@', 'ate', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'ate', 'che', 'i', 'g@@', '<unk>', '@', 'ett@@', '<unk>', '@', 'ori', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'aveva', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', 'stati', ',', 'per', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', '.', '</s>']
2025-05-27 20:20:22,037 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:20:22,037 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:20:22,037 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due cas<unk> @ i per fare queste due cose che sono st<unk> @ ate di<unk> @ mostr<unk> @ ate che i g<unk> @ ett<unk> @ ori po<unk> @ ver<unk> @ i , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per la c<unk> @ aus<unk> @ a di tre milioni di anni , il 4<unk> @ 8 milioni di anni , aveva av<unk> @ uto 4<unk> @ 8 stati , per c<unk> @ aus<unk> @ a .
2025-05-27 20:20:22,037 - INFO - joeynmt.training - Example #1
2025-05-27 20:20:22,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:20:22,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:20:22,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'cre@@', '<unk>', '@', 'azione', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ali', ',', 'perch', 'non', 'ci', 'mostr@@', '<unk>', '@', 'a', 'il', 't@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'ca', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:20:22,037 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la cre<unk> @ azione di questo part<unk> @ icol<unk> @ are probl<unk> @ emi spe<unk> @ ci<unk> @ ali , perch non ci mostr<unk> @ a il t<unk> @ ic<unk> @ ca del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - Example #2
2025-05-27 20:20:22,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:20:22,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:20:22,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 't@@', '<unk>', '@', 'amente', ',', 'la', 'cosa', 'pi', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'a', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'della', 'nostra', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ t<unk> @ amente , la cosa pi po<unk> @ ver<unk> @ a c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio della nostra c<unk> @ atti<unk> @ va del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - Example #3
2025-05-27 20:20:22,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:20:22,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:20:22,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ri@@', '<unk>', '@', 'v@@', '<unk>', '@', 'ano', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:20:22,039 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:20:22,039 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:20:22,039 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ c<unk> @ ri<unk> @ v<unk> @ ano in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:20:22,039 - INFO - joeynmt.training - Example #4
2025-05-27 20:20:22,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:20:22,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:20:22,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 's@@', '<unk>', '@', 'li@@', '<unk>', '@', 'de', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:20:22,040 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:20:22,040 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:20:22,040 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ de che vi mostr<unk> @ er<unk> @  cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:20:25,201 - INFO - joeynmt.training - Epoch  10, Step:    72600, Batch Loss:     0.929835, Batch Acc: 0.729023, Tokens per Sec:    24402, Lr: 0.000300
2025-05-27 20:20:28,372 - INFO - joeynmt.training - Epoch  10, Step:    72700, Batch Loss:     0.887092, Batch Acc: 0.736869, Tokens per Sec:    25017, Lr: 0.000300
2025-05-27 20:20:31,545 - INFO - joeynmt.training - Epoch  10, Step:    72800, Batch Loss:     0.956872, Batch Acc: 0.737863, Tokens per Sec:    24952, Lr: 0.000300
2025-05-27 20:20:34,728 - INFO - joeynmt.training - Epoch  10, Step:    72900, Batch Loss:     0.821947, Batch Acc: 0.739159, Tokens per Sec:    25140, Lr: 0.000300
2025-05-27 20:20:37,895 - INFO - joeynmt.training - Epoch  10, Step:    73000, Batch Loss:     0.956521, Batch Acc: 0.735475, Tokens per Sec:    25076, Lr: 0.000300
2025-05-27 20:20:37,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:20:37,895 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:20:53,680 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 15.7714[sec], evaluation: 0.0000[sec]
2025-05-27 20:20:53,692 - INFO - joeynmt.training - Example #0
2025-05-27 20:20:53,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:20:53,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:20:53,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'per', 'ri@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'ir@@', '<unk>', '@', 'mi', ',', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'che', 'le', 'b@@', '<unk>', '@', 'arri@@', '<unk>', '@', 'ere', 'del', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'fatto', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:20:53,693 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:20:53,693 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:20:53,693 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so sc<unk> @ or<unk> @ so , per ri<unk> @ fer<unk> @ ir<unk> @ mi , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per con<unk> @ si<unk> @ der<unk> @ are che le b<unk> @ arri<unk> @ ere del 4<unk> @ 8 milioni di anni , che aveva fatto per il 4<unk> @ 0 % .
2025-05-27 20:20:53,693 - INFO - joeynmt.training - Example #1
2025-05-27 20:20:53,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:20:53,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:20:53,694 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ha@@', '<unk>', '@', 'i', 'un', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'f@@', '<unk>', '@', 'ico', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'ano', 'il', 'd@@', '<unk>', '@', 'ato', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:20:53,694 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:20:53,694 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:20:53,694 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ ha<unk> @ i un problema spe<unk> @ ci<unk> @ f<unk> @ ico , perch non  il D<unk> @ ic<unk> @ e<unk> @ ano il d<unk> @ ato di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:20:53,694 - INFO - joeynmt.training - Example #2
2025-05-27 20:20:53,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:20:53,695 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:20:53,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'cosa', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ica', '', 'la', 'p@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'gi@@', '<unk>', '@', 'ore', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:20:53,695 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:20:53,695 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:20:53,695 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la cosa ar<unk> @ t<unk> @ ica  la p<unk> @ eg<unk> @ gi<unk> @ ore del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico glob<unk> @ ale .
2025-05-27 20:20:53,695 - INFO - joeynmt.training - Example #3
2025-05-27 20:20:53,696 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:20:53,696 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:20:53,696 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:20:53,696 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:20:53,696 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:20:53,696 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e in<unk> @ ver<unk> @ no .
2025-05-27 20:20:53,696 - INFO - joeynmt.training - Example #4
2025-05-27 20:20:53,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:20:53,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:20:53,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 's@@', '<unk>', '@', 'li@@', '<unk>', '@', 'p', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', 'cosa', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:20:53,697 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:20:53,697 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:20:53,697 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ p che vi mostr<unk> @ er<unk> @  cosa  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:20:56,878 - INFO - joeynmt.training - Epoch  10, Step:    73100, Batch Loss:     0.950769, Batch Acc: 0.737087, Tokens per Sec:    24451, Lr: 0.000300
2025-05-27 20:21:00,034 - INFO - joeynmt.training - Epoch  10, Step:    73200, Batch Loss:     0.963544, Batch Acc: 0.736988, Tokens per Sec:    25051, Lr: 0.000300
2025-05-27 20:21:03,186 - INFO - joeynmt.training - Epoch  10, Step:    73300, Batch Loss:     0.796974, Batch Acc: 0.733416, Tokens per Sec:    25032, Lr: 0.000300
2025-05-27 20:21:06,353 - INFO - joeynmt.training - Epoch  10, Step:    73400, Batch Loss:     0.924487, Batch Acc: 0.731193, Tokens per Sec:    25535, Lr: 0.000300
2025-05-27 20:21:09,516 - INFO - joeynmt.training - Epoch  10, Step:    73500, Batch Loss:     0.872640, Batch Acc: 0.735069, Tokens per Sec:    24797, Lr: 0.000300
2025-05-27 20:21:09,517 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:21:09,517 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:21:24,332 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 14.8022[sec], evaluation: 0.0000[sec]
2025-05-27 20:21:24,762 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/68500.ckpt
2025-05-27 20:21:24,780 - INFO - joeynmt.training - Example #0
2025-05-27 20:21:24,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:21:24,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:21:24,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'due', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'ano', 'che', 'i', 'g@@', '<unk>', '@', 'over@@', '<unk>', '@', 'ni', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'po@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'i', ',', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', ',', 'il', '4@@', '<unk>', '@', '8', '%', 'del', '4@@', '<unk>', '@', '8', '%', '.', '</s>']
2025-05-27 20:21:24,782 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:21:24,782 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:21:24,782 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due due di<unk> @ mostr<unk> @ ano che i g<unk> @ over<unk> @ ni per ri<unk> @ dur<unk> @ re il g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i , che il g<unk> @ hi<unk> @ ac<unk> @ cio di tre milioni di anni , il 4<unk> @ 8 milioni di anni , il 4<unk> @ 8 , il 4<unk> @ 8 % del 4<unk> @ 8 % .
2025-05-27 20:21:24,782 - INFO - joeynmt.training - Example #1
2025-05-27 20:21:24,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:21:24,782 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:21:24,782 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', ',', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'di', 'questo', 'problema', '.', '</s>']
2025-05-27 20:21:24,783 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:21:24,783 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:21:24,783 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ co di questo problema .
2025-05-27 20:21:24,783 - INFO - joeynmt.training - Example #2
2025-05-27 20:21:24,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:21:24,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:21:24,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'il', 's@@', '<unk>', '@', 'ito', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'vo', '.', '</s>']
2025-05-27 20:21:24,784 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:21:24,784 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:21:24,784 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , il s<unk> @ ito di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico c<unk> @ atti<unk> @ vo .
2025-05-27 20:21:24,784 - INFO - joeynmt.training - Example #3
2025-05-27 20:21:24,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:21:24,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:21:24,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:21:24,785 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:21:24,785 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:21:24,785 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e in<unk> @ ver<unk> @ no .
2025-05-27 20:21:24,785 - INFO - joeynmt.training - Example #4
2025-05-27 20:21:24,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:21:24,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:21:24,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', '', 'un', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'no', 'di', 'quello', 'che', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:21:24,786 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:21:24,786 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:21:24,786 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a  un di<unk> @ seg<unk> @ no di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:21:27,969 - INFO - joeynmt.training - Epoch  10, Step:    73600, Batch Loss:     0.946310, Batch Acc: 0.737582, Tokens per Sec:    21713, Lr: 0.000300
2025-05-27 20:21:31,195 - INFO - joeynmt.training - Epoch  10, Step:    73700, Batch Loss:     0.985453, Batch Acc: 0.736713, Tokens per Sec:    24467, Lr: 0.000300
2025-05-27 20:21:34,548 - INFO - joeynmt.training - Epoch  10, Step:    73800, Batch Loss:     0.831221, Batch Acc: 0.736418, Tokens per Sec:    23894, Lr: 0.000300
2025-05-27 20:21:37,869 - INFO - joeynmt.training - Epoch  10, Step:    73900, Batch Loss:     0.908190, Batch Acc: 0.736467, Tokens per Sec:    23786, Lr: 0.000300
2025-05-27 20:21:41,324 - INFO - joeynmt.training - Epoch  10, Step:    74000, Batch Loss:     0.912961, Batch Acc: 0.731679, Tokens per Sec:    22428, Lr: 0.000300
2025-05-27 20:21:41,324 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:21:41,324 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:21:56,242 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.61, acc:   0.72, generation: 14.9048[sec], evaluation: 0.0000[sec]
2025-05-27 20:21:56,565 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/69500.ckpt
2025-05-27 20:21:56,587 - INFO - joeynmt.training - Example #0
2025-05-27 20:21:56,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:21:56,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:21:56,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'azioni', 'per', 'ri@@', '<unk>', '@', 'vel@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'gli', 'al@@', '<unk>', '@', 'im@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ari', ',', 'che', 'hanno', 'fatto', 'per', '4@@', '<unk>', '@', '8', 'ore', ',', '4@@', '<unk>', '@', '8', 'ore', ',', '4@@', '<unk>', '@', '8', 'ore', ',', '4@@', '<unk>', '@', '8', 'ore', 'di', '4@@', '<unk>', '@', '8', 'stati', ',', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:21:56,588 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:21:56,588 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:21:56,588 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ mostr<unk> @ azioni per ri<unk> @ vel<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che gli al<unk> @ im<unk> @ ent<unk> @ ari , che hanno fatto per 4<unk> @ 8 ore , 4<unk> @ 8 ore , 4<unk> @ 8 ore , 4<unk> @ 8 ore di 4<unk> @ 8 stati , per c<unk> @ ento .
2025-05-27 20:21:56,588 - INFO - joeynmt.training - Example #1
2025-05-27 20:21:56,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:21:56,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:21:56,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 20:21:56,589 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:21:56,589 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:21:56,589 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perch non  il D<unk> @ ic<unk> @ e<unk> @ o , perch non  il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 20:21:56,589 - INFO - joeynmt.training - Example #2
2025-05-27 20:21:56,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:21:56,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:21:56,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'il', 's@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'co', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:21:56,590 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:21:56,590 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:21:56,590 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , il s<unk> @ ac<unk> @ co di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale .
2025-05-27 20:21:56,590 - INFO - joeynmt.training - Example #3
2025-05-27 20:21:56,590 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:21:56,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:21:56,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pu', 'ri@@', '<unk>', '@', 'm@@', '<unk>', '@', 'pi@@', '<unk>', '@', 're', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Hypothesis: Si pu ri<unk> @ m<unk> @ pi<unk> @ re e in<unk> @ ver<unk> @ no .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - Example #4
2025-05-27 20:21:56,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:21:56,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:21:56,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'cosa', 'succ@@', '<unk>', '@', 'ede', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:21:59,806 - INFO - joeynmt.training - Epoch  10, Step:    74100, Batch Loss:     1.059531, Batch Acc: 0.731668, Tokens per Sec:    22029, Lr: 0.000300
2025-05-27 20:22:03,125 - INFO - joeynmt.training - Epoch  10, Step:    74200, Batch Loss:     1.105442, Batch Acc: 0.732392, Tokens per Sec:    23933, Lr: 0.000300
2025-05-27 20:22:06,446 - INFO - joeynmt.training - Epoch  10, Step:    74300, Batch Loss:     0.900091, Batch Acc: 0.733088, Tokens per Sec:    23716, Lr: 0.000300
2025-05-27 20:22:09,741 - INFO - joeynmt.training - Epoch  10, Step:    74400, Batch Loss:     0.909979, Batch Acc: 0.735851, Tokens per Sec:    23270, Lr: 0.000300
2025-05-27 20:22:13,081 - INFO - joeynmt.training - Epoch  10, Step:    74500, Batch Loss:     0.903672, Batch Acc: 0.734331, Tokens per Sec:    24209, Lr: 0.000300
2025-05-27 20:22:13,081 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:22:13,081 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:22:28,037 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 14.9432[sec], evaluation: 0.0000[sec]
2025-05-27 20:22:28,384 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/73500.ckpt
2025-05-27 20:22:28,407 - INFO - joeynmt.training - Example #0
2025-05-27 20:22:28,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:22:28,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:22:28,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'men@@', '<unk>', '@', 'si@@', '<unk>', '@', 'oni', 'per', 'ri@@', '<unk>', '@', 'dur@@', '<unk>', '@', 're', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '8', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', '.', '</s>']
2025-05-27 20:22:28,409 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:22:28,409 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:22:28,409 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ men<unk> @ si<unk> @ oni per ri<unk> @ dur<unk> @ re il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , il 4<unk> @ 8 milioni di anni , il 4<unk> @ 8 per il 4<unk> @ 8 milioni di anni .
2025-05-27 20:22:28,409 - INFO - joeynmt.training - Example #1
2025-05-27 20:22:28,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:22:28,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:22:28,409 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'mor@@', '<unk>', '@', 'al@@', '<unk>', '@', 'it', 'di', 'questo', 'problema', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ale', ',', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 20:22:28,410 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:22:28,410 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:22:28,410 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la mor<unk> @ al<unk> @ it di questo problema , perch non  il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ ent<unk> @ ale , non  il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:22:28,410 - INFO - joeynmt.training - Example #2
2025-05-27 20:22:28,410 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:22:28,410 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:22:28,410 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la c<unk> @ atti<unk> @ va  la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 20:22:28,411 - INFO - joeynmt.training - Example #3
2025-05-27 20:22:28,411 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:22:28,411 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:22:28,411 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'un', 'p@@', '<unk>', '@', 'ezz@@', '<unk>', '@', 'o', 'e', 'vi@@', '<unk>', '@', 'sta', '.', '</s>']
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:22:28,412 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e vi<unk> @ sta .
2025-05-27 20:22:28,412 - INFO - joeynmt.training - Example #4
2025-05-27 20:22:28,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:22:28,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:22:28,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'che', 'vi', '', 'succ@@', '<unk>', '@', 'esso', ',', '', 'una', 'sc@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ola', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:22:28,412 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:22:28,412 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:22:28,412 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a che vi  succ<unk> @ esso ,  una sc<unk> @ at<unk> @ ola di di<unk> @ seg<unk> @ na  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:22:31,638 - INFO - joeynmt.training - Epoch  10, Step:    74600, Batch Loss:     0.879014, Batch Acc: 0.733933, Tokens per Sec:    21920, Lr: 0.000300
2025-05-27 20:22:34,941 - INFO - joeynmt.training - Epoch  10, Step:    74700, Batch Loss:     0.912327, Batch Acc: 0.730641, Tokens per Sec:    22984, Lr: 0.000300
2025-05-27 20:22:38,245 - INFO - joeynmt.training - Epoch  10, Step:    74800, Batch Loss:     0.882666, Batch Acc: 0.734364, Tokens per Sec:    23875, Lr: 0.000300
2025-05-27 20:22:41,567 - INFO - joeynmt.training - Epoch  10, Step:    74900, Batch Loss:     0.843552, Batch Acc: 0.734258, Tokens per Sec:    23779, Lr: 0.000300
2025-05-27 20:22:44,899 - INFO - joeynmt.training - Epoch  10, Step:    75000, Batch Loss:     0.828934, Batch Acc: 0.735196, Tokens per Sec:    24370, Lr: 0.000300
2025-05-27 20:22:44,900 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:22:44,900 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:23:01,401 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 16.4878[sec], evaluation: 0.0000[sec]
2025-05-27 20:23:01,406 - INFO - joeynmt.training - Example #0
2025-05-27 20:23:01,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:23:01,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:23:01,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', ',', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'ta', 'per', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'do', 'a', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'anza', 'per', 'ri@@', '<unk>', '@', 'guar@@', '<unk>', '@', 'do', 'a', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'persone', ',', 'i', 'sol@@', '<unk>', '@', 'i', '4@@', '<unk>', '@', '8', 'ore', ',', 'il', '4@@', '<unk>', '@', '8', 'ore', 'ha', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due di<unk> @ ta per ri<unk> @ guar<unk> @ do a la di<unk> @ st<unk> @ anza per ri<unk> @ guar<unk> @ do a il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio che ha av<unk> @ uto il 4<unk> @ 8 milioni di persone , i sol<unk> @ i 4<unk> @ 8 ore , il 4<unk> @ 8 ore ha av<unk> @ uto il 4<unk> @ 0 % .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - Example #1
2025-05-27 20:23:01,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:23:01,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:23:01,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'qu@@', '<unk>', '@', 'in@@', '<unk>', '@', 'amento', ',', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ qu<unk> @ in<unk> @ amento , la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are , perch non  il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - Example #2
2025-05-27 20:23:01,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:23:01,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:23:01,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'della', 'c@@', '<unk>', '@', 'aus@@', '<unk>', '@', 'a', 'glob@@', '<unk>', '@', 'ale', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'as@@', '<unk>', '@', 'si@@', '<unk>', '@', 'mo', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la c<unk> @ aus<unk> @ a della c<unk> @ aus<unk> @ a della c<unk> @ aus<unk> @ a glob<unk> @ ale del nostro sistema c<unk> @ li<unk> @ m<unk> @ as<unk> @ si<unk> @ mo glob<unk> @ ale .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - Example #3
2025-05-27 20:23:01,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:23:01,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:23:01,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'una', 'v@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'i@@', '<unk>', '@', 'azione', 'e', 'sp@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ca', '.', '</s>']
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:23:01,409 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ar<unk> @ i<unk> @ azione e sp<unk> @ or<unk> @ ca .
2025-05-27 20:23:01,409 - INFO - joeynmt.training - Example #4
2025-05-27 20:23:01,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:23:01,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:23:01,409 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 's@@', '<unk>', '@', 'li@@', '<unk>', '@', 'de', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:23:01,409 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:23:01,409 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:23:01,409 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ de che vi mostr<unk> @ o  una di<unk> @ seg<unk> @ na che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:23:04,732 - INFO - joeynmt.training - Epoch  10, Step:    75100, Batch Loss:     0.964849, Batch Acc: 0.733259, Tokens per Sec:    23257, Lr: 0.000210
2025-05-27 20:23:08,039 - INFO - joeynmt.training - Epoch  10, Step:    75200, Batch Loss:     0.842434, Batch Acc: 0.736203, Tokens per Sec:    23222, Lr: 0.000210
2025-05-27 20:23:11,353 - INFO - joeynmt.training - Epoch  10, Step:    75300, Batch Loss:     0.976141, Batch Acc: 0.738136, Tokens per Sec:    24022, Lr: 0.000210
2025-05-27 20:23:14,647 - INFO - joeynmt.training - Epoch  10, Step:    75400, Batch Loss:     0.868657, Batch Acc: 0.738468, Tokens per Sec:    23429, Lr: 0.000210
2025-05-27 20:23:17,988 - INFO - joeynmt.training - Epoch  10, Step:    75500, Batch Loss:     0.897708, Batch Acc: 0.736889, Tokens per Sec:    23775, Lr: 0.000210
2025-05-27 20:23:17,989 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:23:17,989 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:23:34,134 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.95, ppl:   2.58, acc:   0.72, generation: 16.1317[sec], evaluation: 0.0000[sec]
2025-05-27 20:23:34,134 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:23:34,604 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/71500.ckpt
2025-05-27 20:23:34,629 - INFO - joeynmt.training - Example #0
2025-05-27 20:23:34,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:23:34,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:23:34,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 's@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ar@@', '<unk>', '@', 'ini', 'per', 'ri@@', '<unk>', '@', 'fer@@', '<unk>', '@', 'ir@@', '<unk>', '@', 'ci', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ano', 'per', 'i', 'ris@@', '<unk>', '@', 'ult@@', '<unk>', '@', 'ati', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ici', 'che', 'av@@', '<unk>', '@', 'evano', 'fatto', 'per', 'i', '4@@', '<unk>', '@', '8', 'stati', ',', 'per', 'la', 'qu@@', '<unk>', '@', 'ale', '', 'stato', 's@@', '<unk>', '@', 'otto', 'i', '4@@', '<unk>', '@', '8', 'stati', ',', 'per', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:23:34,631 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:23:34,631 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:23:34,631 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due s<unk> @ ott<unk> @ om<unk> @ ar<unk> @ ini per ri<unk> @ fer<unk> @ ir<unk> @ ci che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano per i ris<unk> @ ult<unk> @ ati ar<unk> @ t<unk> @ ici che av<unk> @ evano fatto per i 4<unk> @ 8 stati , per la qu<unk> @ ale  stato s<unk> @ otto i 4<unk> @ 8 stati , per il 4<unk> @ 0 % .
2025-05-27 20:23:34,631 - INFO - joeynmt.training - Example #1
2025-05-27 20:23:34,631 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:23:34,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:23:34,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'sost@@', '<unk>', '@', 'itu@@', '<unk>', '@', 'zione', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'co', 'del', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:23:34,632 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:23:34,632 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:23:34,632 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la sost<unk> @ itu<unk> @ zione di questo part<unk> @ icol<unk> @ are probl<unk> @ emi , perch non  il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:23:34,632 - INFO - joeynmt.training - Example #2
2025-05-27 20:23:34,632 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:23:34,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:23:34,632 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 's@@', '<unk>', '@', 'ett@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'vo', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:23:34,633 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:23:34,633 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:23:34,633 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so  la c<unk> @ atti<unk> @ va  la c<unk> @ atti<unk> @ va del nostro s<unk> @ ett<unk> @ ore c<unk> @ atti<unk> @ vo del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico glob<unk> @ ale .
2025-05-27 20:23:34,633 - INFO - joeynmt.training - Example #3
2025-05-27 20:23:34,633 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:23:34,633 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:23:34,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'it@@', '<unk>', '@', 'are', 'e', 'sp@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ca', 'nel', 'sen@@', '<unk>', '@', 'so', '.', '</s>']
2025-05-27 20:23:34,634 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:23:34,634 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:23:34,634 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ it<unk> @ are e sp<unk> @ or<unk> @ ca nel sen<unk> @ so .
2025-05-27 20:23:34,634 - INFO - joeynmt.training - Example #4
2025-05-27 20:23:34,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:23:34,634 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:23:34,634 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 's@@', '<unk>', '@', 'li@@', '<unk>', '@', 'de', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'ri@@', '<unk>', '@', 'pres@@', '<unk>', '@', 'a', 'di', 'una', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:23:34,635 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:23:34,635 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:23:34,635 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ de che vi mostr<unk> @ er<unk> @   una ri<unk> @ pres<unk> @ a di una di<unk> @ seg<unk> @ na che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:23:37,970 - INFO - joeynmt.training - Epoch  10, Step:    75600, Batch Loss:     0.874659, Batch Acc: 0.739633, Tokens per Sec:    20313, Lr: 0.000210
2025-05-27 20:23:41,290 - INFO - joeynmt.training - Epoch  10, Step:    75700, Batch Loss:     0.915896, Batch Acc: 0.738826, Tokens per Sec:    23996, Lr: 0.000210
2025-05-27 20:23:44,634 - INFO - joeynmt.training - Epoch  10, Step:    75800, Batch Loss:     0.881192, Batch Acc: 0.741301, Tokens per Sec:    24449, Lr: 0.000210
2025-05-27 20:23:47,934 - INFO - joeynmt.training - Epoch  10, Step:    75900, Batch Loss:     0.978765, Batch Acc: 0.737452, Tokens per Sec:    23705, Lr: 0.000210
2025-05-27 20:23:51,247 - INFO - joeynmt.training - Epoch  10, Step:    76000, Batch Loss:     0.975055, Batch Acc: 0.735602, Tokens per Sec:    23823, Lr: 0.000210
2025-05-27 20:23:51,248 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:23:51,248 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:24:06,228 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.57, acc:   0.73, generation: 14.9714[sec], evaluation: 0.0000[sec]
2025-05-27 20:24:06,228 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:24:06,709 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/70000.ckpt
2025-05-27 20:24:06,734 - INFO - joeynmt.training - Example #0
2025-05-27 20:24:06,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:24:06,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:24:06,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'anno', ',', 'questi', 'due', 'di@@', '<unk>', '@', 'f@@', '<unk>', '@', 'en@@', '<unk>', '@', 'om@@', '<unk>', '@', 'en@@', '<unk>', '@', 'i', 'per', 'ri@@', '<unk>', '@', 'vel@@', '<unk>', '@', 'are', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'i', 'cui', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ono', 'per', 'i', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '8', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', '', 'sp@@', '<unk>', '@', 'av@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ato', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:24:06,735 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:24:06,736 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:24:06,736 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , questi due di<unk> @ f<unk> @ en<unk> @ om<unk> @ en<unk> @ i per ri<unk> @ vel<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i cui i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 per c<unk> @ ento  sp<unk> @ av<unk> @ ent<unk> @ ato il 4<unk> @ 0 per c<unk> @ ento .
2025-05-27 20:24:06,736 - INFO - joeynmt.training - Example #1
2025-05-27 20:24:06,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:24:06,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:24:06,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'la', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ha@@', '<unk>', '@', 'i', 'un', 'problema', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'i@@', '<unk>', '@', 'ent@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:24:06,737 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:24:06,737 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:24:06,737 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ ha<unk> @ i un problema di questo part<unk> @ icol<unk> @ are spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ ent<unk> @ ale .
2025-05-27 20:24:06,737 - INFO - joeynmt.training - Example #2
2025-05-27 20:24:06,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:24:06,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:24:06,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'la', 's@@', '<unk>', '@', 'om@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'lia', '', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:24:06,738 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:24:06,738 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:24:06,738 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ om<unk> @ ig<unk> @ lia  il g<unk> @ hi<unk> @ ac<unk> @ cio del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:24:06,738 - INFO - joeynmt.training - Example #3
2025-05-27 20:24:06,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:24:06,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:24:06,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'e', 'si', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'nel', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:24:06,739 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:24:06,739 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:24:06,739 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di in<unk> @ ver<unk> @ no e si in<unk> @ ver<unk> @ no nel est<unk> @ ate .
2025-05-27 20:24:06,739 - INFO - joeynmt.training - Example #4
2025-05-27 20:24:06,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:24:06,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:24:06,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'cer@@', '<unk>', '@', 'ta', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'azione', 'di', 'cosa', 'acc@@', '<unk>', '@', 'a@@', '<unk>', '@', 'du@@', '<unk>', '@', 'to', 'in', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:24:06,740 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:24:06,740 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:24:06,740 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o  una cer<unk> @ ta di<unk> @ mostr<unk> @ azione di cosa acc<unk> @ a<unk> @ du<unk> @ to in 2<unk> @ 5 anni .
2025-05-27 20:24:10,080 - INFO - joeynmt.training - Epoch  10, Step:    76100, Batch Loss:     0.798196, Batch Acc: 0.741112, Tokens per Sec:    21055, Lr: 0.000210
2025-05-27 20:24:13,401 - INFO - joeynmt.training - Epoch  10, Step:    76200, Batch Loss:     1.055248, Batch Acc: 0.735542, Tokens per Sec:    24391, Lr: 0.000210
2025-05-27 20:24:16,694 - INFO - joeynmt.training - Epoch  10, Step:    76300, Batch Loss:     0.860439, Batch Acc: 0.739012, Tokens per Sec:    24135, Lr: 0.000210
2025-05-27 20:24:19,995 - INFO - joeynmt.training - Epoch  10, Step:    76400, Batch Loss:     0.973831, Batch Acc: 0.735579, Tokens per Sec:    24079, Lr: 0.000210
2025-05-27 20:24:23,318 - INFO - joeynmt.training - Epoch  10, Step:    76500, Batch Loss:     0.921327, Batch Acc: 0.737537, Tokens per Sec:    24341, Lr: 0.000210
2025-05-27 20:24:23,318 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:24:23,318 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:24:39,100 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.56, acc:   0.73, generation: 15.7686[sec], evaluation: 0.0000[sec]
2025-05-27 20:24:39,101 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:24:39,620 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/74500.ckpt
2025-05-27 20:24:39,645 - INFO - joeynmt.training - Example #0
2025-05-27 20:24:39,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:24:39,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:24:39,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'a', 'che', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ato', 'per', 'i', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'i', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ati', ',', 'che', 'gli', 'es@@', '<unk>', '@', 'c@@', '<unk>', '@', 'lu@@', '<unk>', '@', 'si@@', '<unk>', '@', 'oni', 'di', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '0', '%', 'dei', 'di@@', '<unk>', '@', 'st@@', '<unk>', '@', 'ati', ',', 'per', 's@@', '<unk>', '@', 'ott@@', '<unk>', '@', 'ol@@', '<unk>', '@', 'in@@', '<unk>', '@', 'e@@', '<unk>', '@', 'are', ',', 'il', '4@@', '<unk>', '@', '0', '%', '.', '</s>']
2025-05-27 20:24:39,646 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:24:39,646 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:24:39,646 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due di<unk> @ mostr<unk> @ a che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ato per i con<unk> @ si<unk> @ der<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati , che gli es<unk> @ c<unk> @ lu<unk> @ si<unk> @ oni di tre milioni di persone che hanno av<unk> @ uto il 4<unk> @ 0 % dei di<unk> @ st<unk> @ ati , per s<unk> @ ott<unk> @ ol<unk> @ in<unk> @ e<unk> @ are , il 4<unk> @ 0 % .
2025-05-27 20:24:39,647 - INFO - joeynmt.training - Example #1
2025-05-27 20:24:39,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:24:39,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:24:39,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'problema', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', 'si', 'mostr@@', '<unk>', '@', 'a', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'or@@', '<unk>', '@', 'io', '.', '</s>']
2025-05-27 20:24:39,647 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:24:39,648 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:24:39,648 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perch non si mostr<unk> @ a il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:24:39,648 - INFO - joeynmt.training - Example #2
2025-05-27 20:24:39,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:24:39,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:24:39,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'cu@@', '<unk>', '@', 'ore', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la cu<unk> @ ore  il cu<unk> @ ore di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - Example #3
2025-05-27 20:24:39,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:24:39,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:24:39,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'ento', 'e', 'si', 'sta', 'sp@@', '<unk>', '@', 'or@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ett@@', '<unk>', '@', 'ando', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si sta sp<unk> @ or<unk> @ g<unk> @ ett<unk> @ ando in est<unk> @ ate .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - Example #4
2025-05-27 20:24:39,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:24:39,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:24:39,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 's@@', '<unk>', '@', 'li@@', '<unk>', '@', 'de', 'che', 'vi', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'di@@', '<unk>', '@', 'vis@@', '<unk>', '@', 'a', 'di', 'quello', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:24:39,650 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:24:39,650 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:24:39,650 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ de che vi mostr<unk> @ er<unk> @   una di<unk> @ vis<unk> @ a di quello che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:24:42,970 - INFO - joeynmt.training - Epoch  10, Step:    76600, Batch Loss:     0.787117, Batch Acc: 0.743147, Tokens per Sec:    20537, Lr: 0.000210
2025-05-27 20:24:46,280 - INFO - joeynmt.training - Epoch  10, Step:    76700, Batch Loss:     1.033736, Batch Acc: 0.736549, Tokens per Sec:    23850, Lr: 0.000210
2025-05-27 20:24:49,602 - INFO - joeynmt.training - Epoch  10, Step:    76800, Batch Loss:     0.861462, Batch Acc: 0.741751, Tokens per Sec:    23849, Lr: 0.000210
2025-05-27 20:24:52,884 - INFO - joeynmt.training - Epoch  10, Step:    76900, Batch Loss:     0.916741, Batch Acc: 0.740548, Tokens per Sec:    24085, Lr: 0.000210
2025-05-27 20:24:56,186 - INFO - joeynmt.training - Epoch  10, Step:    77000, Batch Loss:     0.838196, Batch Acc: 0.737836, Tokens per Sec:    23612, Lr: 0.000210
2025-05-27 20:24:56,187 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:24:56,187 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:25:12,624 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.56, acc:   0.73, generation: 16.4241[sec], evaluation: 0.0000[sec]
2025-05-27 20:25:12,625 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:25:13,143 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/74000.ckpt
2025-05-27 20:25:13,176 - INFO - joeynmt.training - Example #0
2025-05-27 20:25:13,177 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:25:13,177 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:25:13,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'ta', 'per', 'ri@@', '<unk>', '@', 'vel@@', '<unk>', '@', 'are', 'i', 'due', 'di@@', '<unk>', '@', 'ta', 'per', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'are', 'che', 'l&apos;', 'or@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'che', 'ha', 'av@@', '<unk>', '@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '8', '%', ',', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', '4@@', '<unk>', '@', '8', '%', ',', 'per', 'c@@', '<unk>', '@', 'ento', '', 'stato', 'il', '4@@', '<unk>', '@', '0', '%', 'dei', 'con@@', '<unk>', '@', 'si@@', '<unk>', '@', 'der@@', '<unk>', '@', 'ati', '.', '</s>']
2025-05-27 20:25:13,178 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:25:13,178 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:25:13,178 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ta per ri<unk> @ vel<unk> @ are i due di<unk> @ ta per con<unk> @ si<unk> @ der<unk> @ are che l&apos; or<unk> @ t<unk> @ ico ar<unk> @ t<unk> @ ico che ha av<unk> @ uto per tre milioni di anni , che aveva av<unk> @ uto 4<unk> @ 8 % , per tre milioni di anni , che aveva 4<unk> @ 8 % , per c<unk> @ ento  stato il 4<unk> @ 0 % dei con<unk> @ si<unk> @ der<unk> @ ati .
2025-05-27 20:25:13,178 - INFO - joeynmt.training - Example #1
2025-05-27 20:25:13,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:25:13,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:25:13,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'st@@', '<unk>', '@', 'izi@@', '<unk>', '@', 'a', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'ano', '.', '</s>']
2025-05-27 20:25:13,179 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:25:13,179 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:25:13,179 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio , perch non  il D<unk> @ ic<unk> @ e<unk> @ ano .
2025-05-27 20:25:13,179 - INFO - joeynmt.training - Example #2
2025-05-27 20:25:13,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:25:13,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:25:13,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'in', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:25:13,180 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:25:13,180 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:25:13,180 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , in un cer<unk> @ to sen<unk> @ so  il cu<unk> @ ore di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale .
2025-05-27 20:25:13,180 - INFO - joeynmt.training - Example #3
2025-05-27 20:25:13,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:25:13,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:25:13,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ta', 'di', 'v@@', '<unk>', '@', 'est@@', '<unk>', '@', 'iti', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:25:13,181 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:25:13,181 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:25:13,181 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ est<unk> @ iti e in<unk> @ ver<unk> @ no .
2025-05-27 20:25:13,181 - INFO - joeynmt.training - Example #4
2025-05-27 20:25:13,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:25:13,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:25:13,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'c@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'at@@', '<unk>', '@', 'ric@@', '<unk>', '@', 'e', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:25:13,182 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:25:13,182 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:25:13,182 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o  una c<unk> @ ic<unk> @ at<unk> @ ric<unk> @ e che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:25:16,508 - INFO - joeynmt.training - Epoch  10, Step:    77100, Batch Loss:     0.860328, Batch Acc: 0.739088, Tokens per Sec:    20763, Lr: 0.000210
2025-05-27 20:25:19,809 - INFO - joeynmt.training - Epoch  10, Step:    77200, Batch Loss:     0.817546, Batch Acc: 0.738014, Tokens per Sec:    23693, Lr: 0.000210
2025-05-27 20:25:23,107 - INFO - joeynmt.training - Epoch  10, Step:    77300, Batch Loss:     0.978915, Batch Acc: 0.736929, Tokens per Sec:    24117, Lr: 0.000210
2025-05-27 20:25:26,436 - INFO - joeynmt.training - Epoch  10, Step:    77400, Batch Loss:     0.889588, Batch Acc: 0.738249, Tokens per Sec:    24295, Lr: 0.000210
2025-05-27 20:25:29,717 - INFO - joeynmt.training - Epoch  10, Step:    77500, Batch Loss:     1.023718, Batch Acc: 0.738344, Tokens per Sec:    23634, Lr: 0.000210
2025-05-27 20:25:29,717 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:25:29,718 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:25:45,471 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.55, acc:   0.73, generation: 15.7404[sec], evaluation: 0.0000[sec]
2025-05-27 20:25:45,472 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:25:45,956 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/70500.ckpt
2025-05-27 20:25:46,001 - INFO - joeynmt.training - Example #0
2025-05-27 20:25:46,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:25:46,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:25:46,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'queste', 'due', 'di@@', '<unk>', '@', 'ta', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'che', 'l&apos;', 'or@@', '<unk>', '@', 'ig@@', '<unk>', '@', 'ine', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'per', 'le', 'persone', 'che', 'hanno', 'av@@', '<unk>', '@', 'uto', 'il', '4@@', '<unk>', '@', '0', 'gra@@', '<unk>', '@', 'di', 'di', '.', '</s>']
2025-05-27 20:25:46,002 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:25:46,002 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:25:46,002 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ta per di<unk> @ mostr<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico che l&apos; or<unk> @ ig<unk> @ ine ar<unk> @ t<unk> @ ico per le persone che hanno av<unk> @ uto il 4<unk> @ 0 gra<unk> @ di di .
2025-05-27 20:25:46,003 - INFO - joeynmt.training - Example #1
2025-05-27 20:25:46,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:25:46,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:25:46,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'giu@@', '<unk>', '@', 'sta', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'i@@', '<unk>', '@', 'p@@', '<unk>', '@', 'are', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 20:25:46,003 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:25:46,004 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:25:46,004 - INFO - joeynmt.training - 	Hypothesis: Ma questo non  abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ sta , perch non  il D<unk> @ ic<unk> @ i<unk> @ p<unk> @ are il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 20:25:46,004 - INFO - joeynmt.training - Example #2
2025-05-27 20:25:46,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:25:46,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:25:46,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 'cu@@', '<unk>', '@', 'ore', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', '', 'il', 'cu@@', '<unk>', '@', 'ore', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'ma', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:25:46,005 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:25:46,005 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:25:46,005 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il cu<unk> @ ore  il cu<unk> @ ore ar<unk> @ t<unk> @ ico  il cu<unk> @ ore del nostro sistema c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:25:46,005 - INFO - joeynmt.training - Example #3
2025-05-27 20:25:46,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:25:46,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:25:46,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', '<unk>', '@', 'c@@', '<unk>', '@', 'eva', 'in', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', 'e', 'sp@@', '<unk>', '@', 'or@@', '<unk>', '@', 'g@@', '<unk>', '@', 'ere', 'in', 'est@@', '<unk>', '@', 'ate', '.', '</s>']
2025-05-27 20:25:46,005 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:25:46,006 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:25:46,006 - INFO - joeynmt.training - 	Hypothesis: Si cres<unk> @ c<unk> @ eva in in<unk> @ ver<unk> @ no e sp<unk> @ or<unk> @ g<unk> @ ere in est<unk> @ ate .
2025-05-27 20:25:46,006 - INFO - joeynmt.training - Example #4
2025-05-27 20:25:46,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:25:46,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:25:46,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'succ@@', '<unk>', '@', 'esso', 'una', 'cosa', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:25:46,006 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:25:46,007 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:25:46,007 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @   succ<unk> @ esso una cosa che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:25:49,311 - INFO - joeynmt.training - Epoch  10, Step:    77600, Batch Loss:     0.876878, Batch Acc: 0.739204, Tokens per Sec:    20182, Lr: 0.000210
2025-05-27 20:25:52,629 - INFO - joeynmt.training - Epoch  10, Step:    77700, Batch Loss:     0.927674, Batch Acc: 0.740964, Tokens per Sec:    23521, Lr: 0.000210
2025-05-27 20:25:55,958 - INFO - joeynmt.training - Epoch  10, Step:    77800, Batch Loss:     0.963026, Batch Acc: 0.738703, Tokens per Sec:    24012, Lr: 0.000210
2025-05-27 20:25:59,274 - INFO - joeynmt.training - Epoch  10, Step:    77900, Batch Loss:     0.930163, Batch Acc: 0.734404, Tokens per Sec:    23748, Lr: 0.000210
2025-05-27 20:26:02,580 - INFO - joeynmt.training - Epoch  10, Step:    78000, Batch Loss:     0.943340, Batch Acc: 0.736774, Tokens per Sec:    24020, Lr: 0.000210
2025-05-27 20:26:02,581 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:26:02,581 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:26:17,811 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.55, acc:   0.73, generation: 15.2163[sec], evaluation: 0.0000[sec]
2025-05-27 20:26:18,148 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/75500.ckpt
2025-05-27 20:26:18,166 - INFO - joeynmt.training - Example #0
2025-05-27 20:26:18,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:26:18,167 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:26:18,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'ti', 'per', 'fare', 'queste', 'due', 'di@@', '<unk>', '@', 'ta', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', ',', 'che', 'l&apos;', 'ho', 'av@@', '<unk>', '@', 'uto', '4@@', '<unk>', '@', '0', 'milioni', 'di', 'persone', 'che', 'aveva', 'fatto', 'per', 'tre', 'milioni', 'di', 'due', 'milioni', 'di', 'persone', ',', 'che', 'aveva', '4@@', '<unk>', '@', '0', '%', ',', 'il', '4@@', '<unk>', '@', '0', '%', 'di', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:26:18,168 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:26:18,168 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:26:18,168 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due di<unk> @ ti per fare queste due di<unk> @ ta per di<unk> @ mostr<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio , che l&apos; ho av<unk> @ uto 4<unk> @ 0 milioni di persone che aveva fatto per tre milioni di due milioni di persone , che aveva 4<unk> @ 0 % , il 4<unk> @ 0 % di c<unk> @ ento .
2025-05-27 20:26:18,168 - INFO - joeynmt.training - Example #1
2025-05-27 20:26:18,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:26:18,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:26:18,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'for@@', '<unk>', '@', 'te', 'la', 'ter@@', '<unk>', '@', 'n@@', '<unk>', '@', 'it', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'di', 'questo', 'part@@', '<unk>', '@', 'icol@@', '<unk>', '@', 'are', 'probl@@', '<unk>', '@', 'emi', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', '.', '</s>']
2025-05-27 20:26:18,169 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:26:18,169 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:26:18,169 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ n<unk> @ it di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:26:18,169 - INFO - joeynmt.training - Example #2
2025-05-27 20:26:18,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:26:18,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:26:18,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', '<unk>', '@', 'to', ',', 'il', 'sen@@', '<unk>', '@', 'so', '', 'il', 'sistema', 'di', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', ',', 'il', 'cu@@', '<unk>', '@', 'ore', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'vo', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'm@@', '<unk>', '@', 'ass@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:26:18,170 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:26:18,170 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:26:18,170 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il sen<unk> @ so  il sistema di g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico , il cu<unk> @ ore c<unk> @ atti<unk> @ vo del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico glob<unk> @ ale .
2025-05-27 20:26:18,170 - INFO - joeynmt.training - Example #3
2025-05-27 20:26:18,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:26:18,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:26:18,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pu', 'cres@@', '<unk>', '@', 'c@@', '<unk>', '@', 'ere', 'in', 'est@@', '<unk>', '@', 'ate', 'e', 'in@@', '<unk>', '@', 'ver@@', '<unk>', '@', 'no', '.', '</s>']
2025-05-27 20:26:18,171 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:26:18,171 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:26:18,171 - INFO - joeynmt.training - 	Hypothesis: Si pu cres<unk> @ c<unk> @ ere in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:26:18,171 - INFO - joeynmt.training - Example #4
2025-05-27 20:26:18,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:26:18,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:26:18,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'er@@', '<unk>', '@', '', '', 'una', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:26:18,171 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:26:18,172 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:26:18,172 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @   una di<unk> @ seg<unk> @ na di di<unk> @ seg<unk> @ na che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:26:21,474 - INFO - joeynmt.training - Epoch  10, Step:    78100, Batch Loss:     0.969628, Batch Acc: 0.736553, Tokens per Sec:    22033, Lr: 0.000210
2025-05-27 20:26:24,799 - INFO - joeynmt.training - Epoch  10, Step:    78200, Batch Loss:     0.910857, Batch Acc: 0.739438, Tokens per Sec:    24211, Lr: 0.000210
2025-05-27 20:26:28,055 - INFO - joeynmt.training - Epoch  10, Step:    78300, Batch Loss:     0.842467, Batch Acc: 0.740211, Tokens per Sec:    24720, Lr: 0.000210
2025-05-27 20:26:31,234 - INFO - joeynmt.training - Epoch  10, Step:    78400, Batch Loss:     0.938072, Batch Acc: 0.738290, Tokens per Sec:    24681, Lr: 0.000210
2025-05-27 20:26:34,524 - INFO - joeynmt.training - Epoch  10, Step:    78500, Batch Loss:     0.902632, Batch Acc: 0.736565, Tokens per Sec:    23764, Lr: 0.000210
2025-05-27 20:26:34,524 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:26:34,524 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:26:50,114 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.93, ppl:   2.54, acc:   0.73, generation: 15.5761[sec], evaluation: 0.0000[sec]
2025-05-27 20:26:50,115 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:26:50,630 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/76000.ckpt
2025-05-27 20:26:50,654 - INFO - joeynmt.training - Example #0
2025-05-27 20:26:50,654 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', '@@@', '@', 'etz@@', '@@@', '@', 't@@', '@@@', '@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', '@@@', '@', 'den', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ien', 'ge@@', '@@@', '@', 'zei@@', '@@@', '@', 'gt', ',', 'um', 'zu', 'ver@@', '@@@', '@', 'an@@', '@@@', '@', 'sch@@', '@@@', '@', 'au@@', '@@@', '@', 'lichen', ',', 'dass', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', ',', 'die', 'fr', 'ann@@', '@@@', '@', '@@', '@@@', '@', 'her@@', '@@@', '@', 'n@@', '@@@', '@', 'd', 'drei', 'Milli@@', '@@@', '@', 'onen', 'Jahre', 'die', 'Gr@@', '@@@', '@', '@@', '@@@', '@', 's@@', '@@@', '@', 'se', 'der', 'unter@@', '@@@', '@', 'en', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'a@@', '@@@', '@', 'aten', 'hatte', ',', 'um', '4@@', '@@@', '@', '0', 'Proz@@', '@@@', '@', 'ent', 'gesch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'ist', '.']
2025-05-27 20:26:50,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L&apos;', 'anno', 'sc@@', '@@@', '@', 'or@@', '@@@', '@', 'so', 'ho', 'mostr@@', '@@@', '@', 'ato', 'queste', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 've', 'per', 'di@@', '@@@', '@', 'mostr@@', '@@@', '@', 'are', 'che', 'la', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', ',', 'che', 'per', 'qu@@', '@@@', '@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', '@@@', '@', 'uto', 'le', 'di@@', '@@@', '@', 'men@@', '@@@', '@', 'si@@', '@@@', '@', 'oni', 'dei', '4@@', '@@@', '@', '8', 'St@@', '@@@', '@', 'ati', 'Un@@', '@@@', '@', 'iti', 'cont@@', '@@@', '@', 'in@@', '@@@', '@', 'ent@@', '@@@', '@', 'ali', ',', 'si', '', 'ri@@', '@@@', '@', 'str@@', '@@@', '@', 'et@@', '@@@', '@', 'ta', 'del', '4@@', '@@@', '@', '0', '%', '.']
2025-05-27 20:26:50,655 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L&apos;', 'anno', 'sc@@', '<unk>', '@', 'or@@', '<unk>', '@', 'so', 'ho', 'mostr@@', '<unk>', '@', 'ato', 'questi', 'due', 'di@@', '<unk>', '@', 'ti', 'per', 'di@@', '<unk>', '@', 'mostr@@', '<unk>', '@', 'are', 'che', 'il', 'g@@', '<unk>', '@', 'hi@@', '<unk>', '@', 'ac@@', '<unk>', '@', 'cio', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ico', 'che', 'gli', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 't@@', '<unk>', '@', 'av@@', '<unk>', '@', 'olo', 'per', 'tre', 'milioni', 'di', 'anni', ',', 'che', 'aveva', 'tre', 'milioni', 'di', 'anni', ',', 'per', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', ',', 'il', '4@@', '<unk>', '@', '0', 'per', 'c@@', '<unk>', '@', 'ento', '.', '</s>']
2025-05-27 20:26:50,655 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die fr ann@@ @@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ @@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:26:50,655 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si  ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:26:50,655 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due di<unk> @ ti per di<unk> @ mostr<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico che gli ar<unk> @ t<unk> @ t<unk> @ av<unk> @ olo per tre milioni di anni , che aveva tre milioni di anni , per il 4<unk> @ 0 per c<unk> @ ento di tre milioni di anni , il 4<unk> @ 0 per c<unk> @ ento .
2025-05-27 20:26:50,655 - INFO - joeynmt.training - Example #1
2025-05-27 20:26:50,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', '@@@', '@', 'c@@', '@@@', '@', 'kt', 'nicht', 'star@@', '@@@', '@', 'k', 'gen@@', '@@@', '@', 'u@@', '@@@', '@', 'g', 'die', 'Er@@', '@@@', '@', 'n@@', '@@@', '@', 'st@@', '@@@', '@', 'ha@@', '@@@', '@', 'f@@', '@@@', '@', 'tig@@', '@@@', '@', 'keit', 'dieses', 'spe@@', '@@@', '@', 'zi@@', '@@@', '@', 'ellen', 'Probl@@', '@@@', '@', 'em@@', '@@@', '@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'D@@', '@@@', '@', 'ic@@', '@@@', '@', 'ke', 'des', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'es', 'zei@@', '@@@', '@', 'gt', '.']
2025-05-27 20:26:50,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', '@@@', '@', 'utt@@', '@@@', '@', 'a@@', '@@@', '@', 'via', 'questo', 's@@', '@@@', '@', 'ott@@', '@@@', '@', 'ov@@', '@@@', '@', 'al@@', '@@@', '@', 'ut@@', '@@@', '@', 'a', 'la', 'gr@@', '@@@', '@', 'av@@', '@@@', '@', 'it', 'del', 'problema', 'perch', 'non', 'mostr@@', '@@@', '@', 'a', 'lo', 'sp@@', '@@@', '@', 'ess@@', '@@@', '@', 'ore', 'del', 'g@@', '@@@', '@', 'hi@@', '@@@', '@', 'ac@@', '@@@', '@', 'cio', '.']
2025-05-27 20:26:50,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', '', 'abb@@', '<unk>', '@', 'ast@@', '<unk>', '@', 'anza', 'in@@', '<unk>', '@', 'tel@@', '<unk>', '@', 'li@@', '<unk>', '@', 'gente', 'di', 'questo', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', 'spe@@', '<unk>', '@', 'ci@@', '<unk>', '@', 'ale', ',', 'perch', 'non', '', 'il', 'D@@', '<unk>', '@', 'ic@@', '<unk>', '@', 'e@@', '<unk>', '@', 'an@@', '<unk>', '@', 'o', '.', '</s>']
2025-05-27 20:26:50,656 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ c@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:26:50,656 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ it del problema perch non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:26:50,656 - INFO - joeynmt.training - 	Hypothesis: Ma non  abb<unk> @ ast<unk> @ anza in<unk> @ tel<unk> @ li<unk> @ gente di questo spe<unk> @ ci<unk> @ ale spe<unk> @ ci<unk> @ ale , perch non  il D<unk> @ ic<unk> @ e<unk> @ an<unk> @ o .
2025-05-27 20:26:50,657 - INFO - joeynmt.training - Example #2
2025-05-27 20:26:50,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', '@@@', '@', 'wis@@', '@@@', '@', 's@@', '@@@', '@', 'em', 'S@@', '@@@', '@', 'in@@', '@@@', '@', 'ne', 'ist', 'die', 'ar@@', '@@@', '@', 'kt@@', '@@@', '@', 'ische', 'E@@', '@@@', '@', 'is@@', '@@@', '@', 'k@@', '@@@', '@', 'app@@', '@@@', '@', 'e', 'das', 'schl@@', '@@@', '@', 'ag@@', '@@@', '@', 'ende', 'Her@@', '@@@', '@', 'z', 'unser@@', '@@@', '@', 'es', 'glob@@', '@@@', '@', 'alen', 'K@@', '@@@', '@', 'li@@', '@@@', '@', 'm@@', '@@@', '@', 'as@@', '@@@', '@', 'yst@@', '@@@', '@', 'em@@', '@@@', '@', 's', '.']
2025-05-27 20:26:50,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', '@@@', '@', 'ot@@', '@@@', '@', 'ta', 'gl@@', '@@@', '@', 'a@@', '@@@', '@', 'ci@@', '@@@', '@', 'ale', 'ar@@', '@@@', '@', 't@@', '@@@', '@', 'ica', '', ',', 'in', 'un', 'cer@@', '@@@', '@', 'to', 'sen@@', '@@@', '@', 'so', ',', 'il', 'cu@@', '@@@', '@', 'ore', 'p@@', '@@@', '@', 'ul@@', '@@@', '@', 's@@', '@@@', '@', 'ante', 'del', 'sistema', 'c@@', '@@@', '@', 'li@@', '@@@', '@', 'mat@@', '@@@', '@', 'ico', 'glob@@', '@@@', '@', 'ale', '.']
2025-05-27 20:26:50,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', '<unk>', '@', 'to', 'sen@@', '<unk>', '@', 'so', ',', 'la', 'f@@', '<unk>', '@', 'att@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ia', 'ar@@', '<unk>', '@', 't@@', '<unk>', '@', 'ica', '', 'la', 'c@@', '<unk>', '@', 'atti@@', '<unk>', '@', 'va', 'del', 'nostro', 'sistema', 'c@@', '<unk>', '@', 'li@@', '<unk>', '@', 'mat@@', '<unk>', '@', 'ico', 'glob@@', '<unk>', '@', 'ale', '.', '</s>']
2025-05-27 20:26:50,657 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:26:50,657 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica  , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:26:50,657 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la f<unk> @ att<unk> @ or<unk> @ ia ar<unk> @ t<unk> @ ica  la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:26:50,658 - INFO - joeynmt.training - Example #3
2025-05-27 20:26:50,658 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', '@@@', '@', 'ch@@', '@@@', '@', 'st', 'im', 'W@@', '@@@', '@', 'in@@', '@@@', '@', 'ter', 'und', 'sch@@', '@@@', '@', 'r@@', '@@@', '@', 'um@@', '@@@', '@', 'p@@', '@@@', '@', 'ft', 'im', 'S@@', '@@@', '@', 'om@@', '@@@', '@', 'mer', '.']
2025-05-27 20:26:50,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', '@@@', '@', 'p@@', '@@@', '@', 'an@@', '@@@', '@', 'de', 'd&apos;', 'in@@', '@@@', '@', 'ver@@', '@@@', '@', 'no', 'e', 'si', 'rit@@', '@@@', '@', 'ir@@', '@@@', '@', 'a', 'd&apos;', 'est@@', '@@@', '@', 'ate', '.']
2025-05-27 20:26:50,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', '<unk>', '@', 'al@@', '<unk>', '@', 'a', 's@@', '<unk>', '@', 'v@@', '<unk>', '@', 'eg@@', '<unk>', '@', 'li@@', '<unk>', '@', 'are', 'nel', 'v@@', '<unk>', '@', 'ento', 'e', 'sp@@', '<unk>', '@', 'or@@', '<unk>', '@', 'ti@@', '<unk>', '@', 'vo', '.', '</s>']
2025-05-27 20:26:50,658 - INFO - joeynmt.training - 	Source:     Sie w@@ ch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:26:50,658 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:26:50,658 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ al<unk> @ a s<unk> @ v<unk> @ eg<unk> @ li<unk> @ are nel v<unk> @ ento e sp<unk> @ or<unk> @ ti<unk> @ vo .
2025-05-27 20:26:50,658 - INFO - joeynmt.training - Example #4
2025-05-27 20:26:50,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nch@@', '@@@', '@', 'ste', 'F@@', '@@@', '@', 'ol@@', '@@@', '@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', '@@@', '@', 'ge', ',', 'ist', 'eine', 'Z@@', '@@@', '@', 'ei@@', '@@@', '@', 'tra@@', '@@@', '@', 'ff@@', '@@@', '@', 'er@@', '@@@', '@', 'auf@@', '@@@', '@', 'nah@@', '@@@', '@', 'me', 'was', 'in', 'den', 'letz@@', '@@@', '@', 'ten', '2@@', '@@@', '@', '5', 'Jahren', 'passiert', 'ist', '.']
2025-05-27 20:26:50,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', '@@@', '@', 'si@@', '@@@', '@', 'ma', 'di@@', '@@@', '@', 'apos@@', '@@@', '@', 'iti@@', '@@@', '@', 'va', 'sar@@', '@@@', '@', '', 'una', 'rap@@', '@@@', '@', 'i@@', '@@@', '@', 'da', 'car@@', '@@@', '@', 'r@@', '@@@', '@', 'ell@@', '@@@', '@', 'ata', 'su@@', '@@@', '@', 'gli', 'av@@', '@@@', '@', 'ven@@', '@@@', '@', 'im@@', '@@@', '@', 'enti', 'degli', 'ulti@@', '@@@', '@', 'mi', '2@@', '@@@', '@', '5', 'anni', '.']
2025-05-27 20:26:50,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', '<unk>', '@', 'si@@', '<unk>', '@', 'ma', 'di@@', '<unk>', '@', 'apos@@', '<unk>', '@', 'iti@@', '<unk>', '@', 'va', 'che', 'vi', 'mostr@@', '<unk>', '@', 'o', '', 'una', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'di', 'di@@', '<unk>', '@', 'seg@@', '<unk>', '@', 'na', 'che', '', 'succ@@', '<unk>', '@', 'esso', 'negli', 'ulti@@', '<unk>', '@', 'mi', '2@@', '<unk>', '@', '5', 'anni', '.', '</s>']
2025-05-27 20:26:50,659 - INFO - joeynmt.training - 	Source:     Die nch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:26:50,659 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@  una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:26:50,659 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ apos<unk> @ iti<unk> @ va che vi mostr<unk> @ o  una di<unk> @ seg<unk> @ na di di<unk> @ seg<unk> @ na che  succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:26:54,002 - INFO - joeynmt.training - Epoch  10, Step:    78600, Batch Loss:     0.870978, Batch Acc: 0.738446, Tokens per Sec:    20338, Lr: 0.000210
2025-05-27 20:26:57,363 - INFO - joeynmt.training - Epoch  10, Step:    78700, Batch Loss:     0.962496, Batch Acc: 0.740699, Tokens per Sec:    23842, Lr: 0.000210
2025-05-27 20:27:00,701 - INFO - joeynmt.training - Epoch  10, Step:    78800, Batch Loss:     0.971170, Batch Acc: 0.741172, Tokens per Sec:    23694, Lr: 0.000210
2025-05-27 20:27:02,515 - INFO - joeynmt.training - Epoch  10: total training loss 7099.63
2025-05-27 20:27:02,515 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-27 20:27:02,515 - INFO - joeynmt.training - Best validation result (greedy) at step    78500:   2.54 ppl.
2025-05-27 20:27:02,535 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-27 20:27:02,579 - INFO - joeynmt.model - Enc-dec model built.
2025-05-27 20:27:02,664 - INFO - joeynmt.helpers - Load model from /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/78500.ckpt.
2025-05-27 20:27:02,680 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	loss_function=None)
2025-05-27 20:27:02,689 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-27 20:27:02,689 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:27:02,689 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:27:28,217 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 25.5199[sec], evaluation: 0.0000[sec]
2025-05-27 20:27:28,221 - INFO - joeynmt.prediction - Translations saved to: /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/00078500.hyps.dev.
2025-05-27 20:27:28,221 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-27 20:27:28,221 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:27:28,221 - INFO - joeynmt.prediction - Predicting 1567 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-27 20:27:59,024 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 30.7910[sec], evaluation: 0.0000[sec]
2025-05-27 20:27:59,030 - INFO - joeynmt.prediction - Translations saved to: /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/00078500.hyps.test.
