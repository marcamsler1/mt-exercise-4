2025-05-29 21:36:25,617 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-29 21:36:25,617 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_de_it
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                     cfg.data.train : data/unprocessed/train.de-it
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                       cfg.data.dev : data/unprocessed/dev-de-it
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                      cfg.data.test : data/unprocessed/test.de-it
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-29 21:36:25,618 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_de_it
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-29 21:36:25,619 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-29 21:36:25,756 - INFO - joeynmt.data - Building tokenizer...
2025-05-29 21:36:25,767 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 21:36:25,767 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 21:36:25,767 - INFO - joeynmt.data - Loading train set...
2025-05-29 21:36:26,176 - INFO - joeynmt.data - Building vocabulary...
2025-05-29 21:36:26,209 - INFO - joeynmt.data - Loading dev set...
2025-05-29 21:38:55,035 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_de_it
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                     cfg.data.train : data/unprocessed/train.de-it
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                       cfg.data.dev : data/unprocessed/dev.de-it
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                      cfg.data.test : data/unprocessed/test.de-it
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-29 21:38:55,036 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_de_it
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-29 21:38:55,037 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-29 21:38:55,171 - INFO - joeynmt.data - Building tokenizer...
2025-05-29 21:38:55,181 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 21:38:55,181 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 21:38:55,181 - INFO - joeynmt.data - Loading train set...
2025-05-29 21:38:55,495 - INFO - joeynmt.data - Building vocabulary...
2025-05-29 21:38:55,529 - INFO - joeynmt.data - Loading dev set...
2025-05-29 21:38:55,535 - INFO - joeynmt.data - Loading test set...
2025-05-29 21:38:55,541 - INFO - joeynmt.data - Data loaded.
2025-05-29 21:38:55,541 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=208858, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-29 21:38:55,542 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=923, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-29 21:38:55,542 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1567, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-29 21:38:55,542 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ or@@ e@@ : Die Ab@@ wen@@ dung der K@@ li@@ ma@@ k@@ at@@ a@@ str@@ op@@ he
	[TRG] A@@ l G@@ or@@ e@@ : ar@@ rest@@ iamo il ris@@ cal@@ d@@ amento glob@@ ale
2025-05-29 21:38:55,542 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ! (5) # (6) $ (7) % (8) &#9@@ (9) &@@
2025-05-29 21:38:55,543 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ! (5) # (6) $ (7) % (8) &#9@@ (9) &@@
2025-05-29 21:38:55,543 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2000
2025-05-29 21:38:55,543 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2000
2025-05-29 21:38:55,553 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 21:38:55,636 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 21:38:55,647 - INFO - joeynmt.model - Total params: 3411200
2025-05-29 21:38:55,649 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2025-05-29 21:38:55,649 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-29 21:38:59,402 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-29 21:38:59,403 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-29 21:38:59,403 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-29 21:38:59,403 - INFO - joeynmt.training - EPOCH 1
2025-05-29 21:39:03,762 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.871879, Batch Acc: 0.038890, Tokens per Sec:    16125, Lr: 0.000300
2025-05-29 21:39:07,464 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.840584, Batch Acc: 0.063333, Tokens per Sec:    19138, Lr: 0.000300
2025-05-29 21:39:11,128 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.678377, Batch Acc: 0.077478, Tokens per Sec:    19100, Lr: 0.000300
2025-05-29 21:39:14,778 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.563287, Batch Acc: 0.092825, Tokens per Sec:    19384, Lr: 0.000300
2025-05-29 21:39:18,420 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.603869, Batch Acc: 0.102001, Tokens per Sec:    19528, Lr: 0.000300
2025-05-29 21:39:18,421 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:39:18,421 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:39:30,747 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.51, ppl:  33.38, acc:   0.10, generation: 12.2982[sec], evaluation: 0.0000[sec]
2025-05-29 21:39:30,748 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:39:31,286 - INFO - joeynmt.training - Example #0
2025-05-29 21:39:31,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:39:31,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:39:31,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che']
2025-05-29 21:39:31,288 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:39:31,288 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:39:31,288 - INFO - joeynmt.training - 	Hypothesis: E che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che
2025-05-29 21:39:31,288 - INFO - joeynmt.training - Example #1
2025-05-29 21:39:31,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:39:31,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:39:31,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che']
2025-05-29 21:39:31,289 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:39:31,289 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:39:31,290 - INFO - joeynmt.training - 	Hypothesis: E un un un un un un un un un un un un un un un un un un che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che
2025-05-29 21:39:31,290 - INFO - joeynmt.training - Example #2
2025-05-29 21:39:31,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:39:31,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:39:31,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che']
2025-05-29 21:39:31,290 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:39:31,290 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:39:31,291 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che
2025-05-29 21:39:31,291 - INFO - joeynmt.training - Example #3
2025-05-29 21:39:31,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:39:31,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:39:31,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che']
2025-05-29 21:39:31,291 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:39:31,291 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:39:31,292 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che
2025-05-29 21:39:31,292 - INFO - joeynmt.training - Example #4
2025-05-29 21:39:31,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:39:31,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:39:31,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che']
2025-05-29 21:39:31,292 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:39:31,292 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:39:31,293 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che
2025-05-29 21:39:34,951 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.528926, Batch Acc: 0.106350, Tokens per Sec:    16962, Lr: 0.000300
2025-05-29 21:39:38,825 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.444692, Batch Acc: 0.107692, Tokens per Sec:    18391, Lr: 0.000300
2025-05-29 21:39:42,391 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.502784, Batch Acc: 0.109774, Tokens per Sec:    19349, Lr: 0.000300
2025-05-29 21:39:45,972 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.346793, Batch Acc: 0.111256, Tokens per Sec:    20284, Lr: 0.000300
2025-05-29 21:39:49,575 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.381377, Batch Acc: 0.112003, Tokens per Sec:    20139, Lr: 0.000300
2025-05-29 21:39:49,575 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:39:49,575 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:40:00,480 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.39, ppl:  29.63, acc:   0.12, generation: 10.8898[sec], evaluation: 0.0000[sec]
2025-05-29 21:40:00,481 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:40:01,000 - INFO - joeynmt.training - Example #0
2025-05-29 21:40:01,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:40:01,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:40:01,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'o@@', '.', '</s>']
2025-05-29 21:40:01,002 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:40:01,002 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:40:01,002 - INFO - joeynmt.training - 	Hypothesis: E un po di un po di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un pare di un po.
2025-05-29 21:40:01,002 - INFO - joeynmt.training - Example #1
2025-05-29 21:40:01,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:40:01,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:40:01,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'un', 'p@@', 'are', 'di', 'un', 'f@@', 'are', 'di', 'un', 'p@@', 'o@@', '.', '</s>']
2025-05-29 21:40:01,003 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:40:01,003 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:40:01,003 - INFO - joeynmt.training - 	Hypothesis: E che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che un pare di un fare di un po.
2025-05-29 21:40:01,003 - INFO - joeynmt.training - Example #2
2025-05-29 21:40:01,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:40:01,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:40:01,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'o@@', '.', '</s>']
2025-05-29 21:40:01,004 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:40:01,004 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:40:01,004 - INFO - joeynmt.training - 	Hypothesis: E un po di un po di un pare di un pare di un pare di un pare di un pare di un po.
2025-05-29 21:40:01,004 - INFO - joeynmt.training - Example #3
2025-05-29 21:40:01,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:40:01,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:40:01,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'di', 'un', 'f@@', 'o', 'di', 'un', 'f@@', 'o', 'di', 'un', 'f@@', 'o', 'di', 'un', 'f@@', 'o@@', '.', '</s>']
2025-05-29 21:40:01,005 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:40:01,005 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:40:01,005 - INFO - joeynmt.training - 	Hypothesis: E di un fo di un fo di un fo di un fo.
2025-05-29 21:40:01,005 - INFO - joeynmt.training - Example #4
2025-05-29 21:40:01,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:40:01,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:40:01,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'are', 'di', 'un', 'p@@', 'o@@', '.', '</s>']
2025-05-29 21:40:01,006 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:40:01,006 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:40:01,006 - INFO - joeynmt.training - 	Hypothesis: E che un po di un po di un pare di un pare di un pare di un pare di un pare di un po.
2025-05-29 21:40:04,583 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.355963, Batch Acc: 0.115850, Tokens per Sec:    17018, Lr: 0.000300
2025-05-29 21:40:08,143 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.510516, Batch Acc: 0.123737, Tokens per Sec:    19403, Lr: 0.000300
2025-05-29 21:40:11,721 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.365259, Batch Acc: 0.124434, Tokens per Sec:    20189, Lr: 0.000300
2025-05-29 21:40:15,294 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.280413, Batch Acc: 0.135580, Tokens per Sec:    20247, Lr: 0.000300
2025-05-29 21:40:18,867 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.261175, Batch Acc: 0.142642, Tokens per Sec:    20458, Lr: 0.000300
2025-05-29 21:40:18,869 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:40:18,869 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:40:30,263 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.21, ppl:  24.85, acc:   0.15, generation: 11.3789[sec], evaluation: 0.0000[sec]
2025-05-29 21:40:30,264 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:40:30,768 - INFO - joeynmt.training - Example #0
2025-05-29 21:40:30,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:40:30,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:40:30,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'p@@', 'et@@', 'e@@', ',', 'che', 'è', 'un', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'i@@', '.', '</s>']
2025-05-29 21:40:30,770 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:40:30,770 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:40:30,770 - INFO - joeynmt.training - 	Hypothesis: Il pete, che è un pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la pete, e la peti.
2025-05-29 21:40:30,770 - INFO - joeynmt.training - Example #1
2025-05-29 21:40:30,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:40:30,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:40:30,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'un', 'p@@', 'et@@', 'e@@', ',', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-29 21:40:30,771 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:40:30,771 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:40:30,771 - INFO - joeynmt.training - 	Hypothesis: Ma è è è è è è è è è è è è un pete, non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-29 21:40:30,771 - INFO - joeynmt.training - Example #2
2025-05-29 21:40:30,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:40:30,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:40:30,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mio', 'pi@@', 'amo', 'che', 'è', 'un', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'e', 'e', 'la', 'p@@', 'et@@', 'e@@', '.', '</s>']
2025-05-29 21:40:30,772 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:40:30,772 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:40:30,772 - INFO - joeynmt.training - 	Hypothesis: Il mio piamo che è un pete, e la pete, e la pete, e la pete, e e e la pete.
2025-05-29 21:40:30,772 - INFO - joeynmt.training - Example #3
2025-05-29 21:40:30,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:40:30,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:40:30,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mio', 'mio', 'mio', 'mio', 'p@@', 'o@@', ',', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'la', 'p@@', 'et@@', 'e@@', '.', '</s>']
2025-05-29 21:40:30,773 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:40:30,773 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:40:30,773 - INFO - joeynmt.training - 	Hypothesis: Il mio mio mio mio po, e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e la pete.
2025-05-29 21:40:30,773 - INFO - joeynmt.training - Example #4
2025-05-29 21:40:30,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:40:30,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:40:30,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'p@@', 'et@@', 'e@@', ',', 'è', 'è', 'è', 'è', 'è', 'è', 'un', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', ',', 'e', 'la', 'p@@', 'et@@', 'e@@', '.', '</s>']
2025-05-29 21:40:30,774 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:40:30,774 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:40:30,774 - INFO - joeynmt.training - 	Hypothesis: Il pete, è è è è è è un pete, e la pete, e la pete, e la pete.
2025-05-29 21:40:34,256 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.094585, Batch Acc: 0.153473, Tokens per Sec:    17964, Lr: 0.000300
2025-05-29 21:40:37,825 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.208847, Batch Acc: 0.159362, Tokens per Sec:    19594, Lr: 0.000300
2025-05-29 21:40:41,357 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.130093, Batch Acc: 0.165744, Tokens per Sec:    19498, Lr: 0.000300
2025-05-29 21:40:44,893 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.066176, Batch Acc: 0.172791, Tokens per Sec:    20129, Lr: 0.000300
2025-05-29 21:40:48,458 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.021369, Batch Acc: 0.176322, Tokens per Sec:    19701, Lr: 0.000300
2025-05-29 21:40:48,459 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:40:48,460 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:41:00,303 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.97, ppl:  19.43, acc:   0.19, generation: 11.8323[sec], evaluation: 0.0000[sec]
2025-05-29 21:41:00,304 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:41:00,780 - INFO - joeynmt.training - Example #0
2025-05-29 21:41:00,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:41:00,782 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:41:00,782 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'gente', 'che', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 's@@', 'otto', 'la', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'di', 'un', 'p@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@', 'azi@@']
2025-05-29 21:41:00,782 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:41:00,782 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:41:00,783 - INFO - joeynmt.training - 	Hypothesis: La gente che si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si sotto la loro loro loro loro loro loro loro di un paziaziaziaziaziaziaziaziaziaziaziazi
2025-05-29 21:41:00,783 - INFO - joeynmt.training - Example #1
2025-05-29 21:41:00,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:41:00,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:41:00,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', '<unk>', '<unk>', 'è', 'un', 'po@@', '<unk>', '<unk>', 'è', 'un', 'po@@', '<unk>', '<unk>', 'è', 'un', 'po@@', '<unk>', '<unk>', 'è', 'un', 'po@@', '<unk>', '<unk>', '<unk>', 'è', 'un', 'po@@', '<unk>', '<unk>', '<unk>', '<unk>', 'è', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:41:00,784 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:41:00,784 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:41:00,784 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> <unk> <unk> è un po<unk> <unk> è un po<unk> <unk> è un po<unk> <unk> è un po<unk> <unk> <unk> è un po<unk> <unk> <unk> <unk> è un po<unk> .
2025-05-29 21:41:00,784 - INFO - joeynmt.training - Example #2
2025-05-29 21:41:00,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:41:00,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:41:00,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'è', 'un', 'p@@', 'op@@', 'ol@@', 'i', 'di', 'un', 'p@@', 'op@@', 'ol@@', 'i', 'di', 'un', 'p@@', 'es@@', 'c@@', '<unk>', 'è', 'un', 'b@@', 'o', 'di', 'un', 'p@@', 'op@@', 'ol@@', 'i', 'di', 'un', 'p@@', 'op@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 21:41:00,785 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:41:00,785 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:41:00,785 - INFO - joeynmt.training - 	Hypothesis: La cosa è un popoli di un popoli di un pesc<unk> è un bo di un popoli di un popola.
2025-05-29 21:41:00,785 - INFO - joeynmt.training - Example #3
2025-05-29 21:41:00,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:41:00,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:41:00,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', '<unk>', 'è', 'un', 'p@@', 'op@@', 'ol@@', 'ol@@', 'ol@@', 'ol@@', 'i', 'di', 'un', 'p@@', 'op@@', 'ol@@', 'ol@@', 'ol@@', 'ol@@', 'ol@@', 'ol@@', 'ol@@', 'ol@@', 'e@@', '.', '</s>']
2025-05-29 21:41:00,786 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:41:00,786 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:41:00,786 - INFO - joeynmt.training - 	Hypothesis: C<unk> è un popololololi di un popolololololololole.
2025-05-29 21:41:00,786 - INFO - joeynmt.training - Example #4
2025-05-29 21:41:00,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:41:00,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:41:00,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è']
2025-05-29 21:41:00,787 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:41:00,787 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:41:00,787 - INFO - joeynmt.training - 	Hypothesis: La cosa è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è
2025-05-29 21:41:04,367 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.948035, Batch Acc: 0.189349, Tokens per Sec:    17283, Lr: 0.000300
2025-05-29 21:41:07,923 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.922971, Batch Acc: 0.192624, Tokens per Sec:    20346, Lr: 0.000300
2025-05-29 21:41:11,505 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.894875, Batch Acc: 0.197824, Tokens per Sec:    19479, Lr: 0.000300
2025-05-29 21:41:15,059 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.775446, Batch Acc: 0.203554, Tokens per Sec:    19972, Lr: 0.000300
2025-05-29 21:41:18,565 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.775058, Batch Acc: 0.204052, Tokens per Sec:    19672, Lr: 0.000300
2025-05-29 21:41:18,565 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:41:18,566 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:41:30,017 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.81, ppl:  16.55, acc:   0.21, generation: 11.4392[sec], evaluation: 0.0000[sec]
2025-05-29 21:41:30,018 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:41:30,532 - INFO - joeynmt.training - Example #0
2025-05-29 21:41:30,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:41:30,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:41:30,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 're@@', 'do', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'modo', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'modo', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'modo', 'di', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'di', 'di', 'un', 'altro', 'che', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'di', 'un', 'modo', 'di', 'un', 'con@@', 'ten@@', 'ere', 'la', 'mia', 'm@@', 'ezz@@', 'o', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'di', 'di', 'di', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'di', 'cui', 'la', 'mia', 'm@@', 'ett@@', 'o@@', ',', 'e', 'la', 'm@@', 'ett@@', 'ore', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di']
2025-05-29 21:41:30,533 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:41:30,534 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:41:30,534 - INFO - joeynmt.training - 	Hypothesis: Credo di un modo di un modo di un mezzo di un modo di un mezzo di un mezzo di un mezzo di un modo di un mezzo di un mezzo di un modo di di un modo di un modo di un modo di un modo di di di un altro che si si si si si si si di un modo di un contenere la mia mezzo di un modo di un modo di un modo di di di di di un modo di un modo di di cui la mia metto, e la mettore di un modo di un modo di
2025-05-29 21:41:30,534 - INFO - joeynmt.training - Example #1
2025-05-29 21:41:30,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:41:30,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:41:30,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:41:30,535 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:41:30,535 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:41:30,535 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di un po<unk> di di un po<unk> di un po<unk> .
2025-05-29 21:41:30,535 - INFO - joeynmt.training - Example #2
2025-05-29 21:41:30,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:41:30,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:41:30,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'è', 'un', 'altro', 'che', 'è', 'un', 'po@@', '<unk>', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'cer@@', 'to', 'che', 'la', 'nostra', 'm@@', 'ezz@@', 'o', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'b@@', 'ell@@', '<unk>', 'in@@', 'segn@@', 'ato', 'a', 'a', 'di', 'c@@', 'ult@@', 'ura', 'di', 'un', 'altro', 'che', 'è', 'un', 'm@@', 'ezz@@', 'o', 'di', 'un', 'b@@', 'b@@', 'b@@', 'o', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'b@@', 'o', 'di', 'di', 'c@@', 'ento', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'c@@', 'ento', 'di', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'si', 'ri@@', 'man@@', 'c@@', 'entr@@', 'o', 'di', 'c@@', 'ult@@']
2025-05-29 21:41:30,536 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:41:30,536 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:41:30,536 - INFO - joeynmt.training - 	Hypothesis: La cosa è un altro che è un po<unk> di un mezzo di un mezzo di un mezzo di mezzo di un mezzo di un mezzo di un mezzo di un certo che la nostra mezzo di un mezzo di un bell<unk> insegnato a a di cultura di un altro che è un mezzo di un bbbo di un modo di un modo di un bo di di cento di un mezzo di cento di un modo che è un modo che si rimancentro di cult
2025-05-29 21:41:30,536 - INFO - joeynmt.training - Example #3
2025-05-29 21:41:30,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:41:30,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:41:30,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 're@@', 'do', 'di', 'un', 'm@@', 'ett@@', 'ore', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e']
2025-05-29 21:41:30,537 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:41:30,537 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:41:30,537 - INFO - joeynmt.training - 	Hypothesis: Credo di un mettore e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e
2025-05-29 21:41:30,537 - INFO - joeynmt.training - Example #4
2025-05-29 21:41:30,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:41:30,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:41:30,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'è', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:41:30,538 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:41:30,538 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:41:30,538 - INFO - joeynmt.training - 	Hypothesis: La cosa è un po<unk> .
2025-05-29 21:41:34,119 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.718654, Batch Acc: 0.209548, Tokens per Sec:    17299, Lr: 0.000300
2025-05-29 21:41:37,650 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.790651, Batch Acc: 0.217431, Tokens per Sec:    19886, Lr: 0.000300
2025-05-29 21:41:41,170 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.725393, Batch Acc: 0.221495, Tokens per Sec:    21319, Lr: 0.000300
2025-05-29 21:41:44,962 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.663798, Batch Acc: 0.225202, Tokens per Sec:    17944, Lr: 0.000300
2025-05-29 21:41:48,486 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.677439, Batch Acc: 0.228560, Tokens per Sec:    19931, Lr: 0.000300
2025-05-29 21:41:48,486 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:41:48,486 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:41:59,838 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.71, ppl:  15.04, acc:   0.23, generation: 11.3391[sec], evaluation: 0.0000[sec]
2025-05-29 21:41:59,839 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:42:00,389 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/500.ckpt
2025-05-29 21:42:00,409 - INFO - joeynmt.training - Example #0
2025-05-29 21:42:00,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:42:00,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:42:00,410 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'prima', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'il', 'mondo', 'che', 'si', 'è', 'la', 'nostra', 'c@@', 'enza', 'di', 'cui', 'si', 'ri@@', 'vol@@', 't@@', 'a@@', ',', 'e', 'la', 'gente', 'che', 'è', 'che', 'è', 'che', 'si', 'può', 'essere', 'un', 'ar@@', 'g@@', 'ent@@', 'e@@', ',', 'e', 'la', 'gente', 'che', 'si', 'può', 'essere', 'un', 'ar@@', 'g@@', 'ent@@', 'e@@', ',', 'e', 'la', 'gente', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'la', 'nostra', 'c@@', 'ur@@', 'g@@', 'g@@', 'g@@', 'ere', 'che', 'è', 'che', 'è', 'che', 'si', 'può', 'essere', 'un', 'modo', 'che', 'si', 'trov@@', 'are', 'il', 'mondo', 'che', 'si', 'trov@@', 'are', 'la', 'gente', 'che', 'si', 'può', 'essere', 'un', 'modo', 'che', 'si', 'ri@@', 'v@@', 'ono', 'che', 'si', 'è', 'che', 'è', 'che']
2025-05-29 21:42:00,410 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:42:00,410 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:42:00,410 - INFO - joeynmt.training - 	Hypothesis: E la prima che è che è che è che è che è che è che è il mondo che si è la nostra cenza di cui si rivolta, e la gente che è che è che si può essere un argente, e la gente che si può essere un argente, e la gente che si è che si è che è che è che è che la nostra curgggere che è che è che si può essere un modo che si trovare il mondo che si trovare la gente che si può essere un modo che si rivono che si è che è che
2025-05-29 21:42:00,410 - INFO - joeynmt.training - Example #1
2025-05-29 21:42:00,411 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:42:00,411 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:42:00,411 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'la', 'nostra', 's@@', 'otto', 'il', 'mondo', 'non', 'è', 'che', 'non', 'è', 'la', 'nostra', 's@@', 'ott@@', 'ot@@', 'ale', 'che', 'non', 'è', 'la', 'nostra', 's@@', 'ott@@', 'ot@@', 'a', 'a', 'a', 'a', 'a', 'che', 'non', 'è', 'la', 'nostra', 's@@', 'ott@@', 'ot@@', 'ti@@', '.', '</s>']
2025-05-29 21:42:00,411 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:42:00,411 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:42:00,411 - INFO - joeynmt.training - 	Hypothesis: Ma non è che è che è che è che è che è che è che non è la nostra sotto il mondo non è che non è la nostra sottotale che non è la nostra sottota a a a a che non è la nostra sottotti.
2025-05-29 21:42:00,412 - INFO - joeynmt.training - Example #2
2025-05-29 21:42:00,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:42:00,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:42:00,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'è', 'una', 'b@@', 'ell@@', 'a@@', ',', 'è', 'la', 'nostra', 's@@', 'ott@@', 'ott@@', 'ot@@', 'ale', 'è', 'la', 'nostra', 's@@', 'ott@@', 'ott@@', 'o@@', ',', 'e', 'la', 'nostra', 'nostra', 'nostra', 'c@@', 'enza', 'di', 'una', 'b@@', 'ell@@', 'a@@', '.', '</s>']
2025-05-29 21:42:00,412 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:42:00,412 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:42:00,412 - INFO - joeynmt.training - 	Hypothesis: In questo è una bella, è la nostra sottottotale è la nostra sottotto, e la nostra nostra nostra cenza di una bella.
2025-05-29 21:42:00,413 - INFO - joeynmt.training - Example #3
2025-05-29 21:42:00,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:42:00,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:42:00,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Non', 'è', 'la', 'mia', 'v@@', 'it@@', 'a@@', ',', 'e', 'sono', 'i', 'sono', 'i', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 's@@', 'ec@@', 'c@@', 'a@@', '.', '</s>']
2025-05-29 21:42:00,413 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:42:00,413 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:42:00,413 - INFO - joeynmt.training - 	Hypothesis: Non è la mia vita, e sono i sono i e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e secca.
2025-05-29 21:42:00,413 - INFO - joeynmt.training - Example #4
2025-05-29 21:42:00,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:42:00,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:42:00,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mio', 'mio', 'p@@', 'ad@@', 're', 'il', 'mondo', 'è', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'una', 'b@@', 'ell@@', '<unk>', 'ar@@', 'g@@', 'g@@', 'o', 'di', 'un', 'po@@', '<unk>', 'di', 'una', 'b@@', 'ell@@', '<unk>', 'in@@', 'cre@@', 'di@@', 'bil@@', 'mente', 'è', 'un', 'po@@', '<unk>', 'di', 'una', 's@@', 'ott@@', 'a@@', '.', '</s>']
2025-05-29 21:42:00,414 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:42:00,414 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:42:00,414 - INFO - joeynmt.training - 	Hypothesis: Il mio mio padre il mondo è un po<unk> di un po<unk> di una bell<unk> arggo di un po<unk> di una bell<unk> incredibilmente è un po<unk> di una sotta.
2025-05-29 21:42:03,968 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.763814, Batch Acc: 0.228312, Tokens per Sec:    17305, Lr: 0.000300
2025-05-29 21:42:07,505 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.723915, Batch Acc: 0.235433, Tokens per Sec:    20291, Lr: 0.000300
2025-05-29 21:42:11,035 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.798038, Batch Acc: 0.233895, Tokens per Sec:    20504, Lr: 0.000300
2025-05-29 21:42:14,572 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.641459, Batch Acc: 0.239726, Tokens per Sec:    20132, Lr: 0.000300
2025-05-29 21:42:18,101 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.615885, Batch Acc: 0.239120, Tokens per Sec:    20461, Lr: 0.000300
2025-05-29 21:42:18,102 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:42:18,102 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:42:29,655 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.63, ppl:  13.88, acc:   0.25, generation: 11.5352[sec], evaluation: 0.0000[sec]
2025-05-29 21:42:29,656 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:42:30,192 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/1000.ckpt
2025-05-29 21:42:30,216 - INFO - joeynmt.training - Example #0
2025-05-29 21:42:30,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:42:30,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:42:30,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'se', 'non', 'av@@', 'ete', 'che', 'av@@', 'ete', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'di', 'c@@', 'ri@@', 'es@@', 'ist@@', 'ono', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'di', 'di', 'di', 'un', 'po@@', '<unk>', 'di', 'di', 'di', 'di', 'di', 'c@@', 'entr@@', 'are', 'il', 'mon@@', 'd@@', 'o@@', '.', '</s>']
2025-05-29 21:42:30,218 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:42:30,218 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:42:30,218 - INFO - joeynmt.training - 	Hypothesis: E se non avete che avete un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di di un po<unk> di un po<unk> di un po<unk> di un po<unk> di di criesistono di un po<unk> di un po<unk> di un po<unk> di di di di un po<unk> di di di di di centrare il mondo.
2025-05-29 21:42:30,218 - INFO - joeynmt.training - Example #1
2025-05-29 21:42:30,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:42:30,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:42:30,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'cui', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'cui', 'non', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'cui', 'non', 'è', 'la', 'gente', 'che', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'cui', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'cui', 'non', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'cui', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'cui', 'non', 'è', 'il', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:42:30,219 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:42:30,219 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:42:30,219 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di cui non è un po<unk> di cui non è stato un po<unk> di cui non è la gente che non è un po<unk> di cui non è un po<unk> di cui non è stato un po<unk> di cui non è un po<unk> di cui non è il nostro nostro nostro nostro nostro problema.
2025-05-29 21:42:30,219 - INFO - joeynmt.training - Example #2
2025-05-29 21:42:30,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:42:30,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:42:30,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'è', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'b@@', 'ag@@', 'li@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 21:42:30,220 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:42:30,220 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:42:30,220 - INFO - joeynmt.training - 	Hypothesis: La prima volta che è un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di sbagliato.
2025-05-29 21:42:30,220 - INFO - joeynmt.training - Example #3
2025-05-29 21:42:30,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:42:30,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:42:30,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'poi', 'abbiamo', 'fatto', 'che', 'av@@', 'uto', 'una', 'b@@', 'ag@@', 'li@@', 'at@@', 'a@@', '.', '</s>']
2025-05-29 21:42:30,221 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:42:30,221 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:42:30,221 - INFO - joeynmt.training - 	Hypothesis: E poi abbiamo fatto che avuto una bagliata.
2025-05-29 21:42:30,221 - INFO - joeynmt.training - Example #4
2025-05-29 21:42:30,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:42:30,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:42:30,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'è', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:42:30,222 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:42:30,222 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:42:30,222 - INFO - joeynmt.training - 	Hypothesis: La prima volta che è un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di un po<unk> di di un po<unk> .
2025-05-29 21:42:33,779 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.600540, Batch Acc: 0.240949, Tokens per Sec:    17199, Lr: 0.000300
2025-05-29 21:42:37,301 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.577228, Batch Acc: 0.245261, Tokens per Sec:    20229, Lr: 0.000300
2025-05-29 21:42:40,806 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.548728, Batch Acc: 0.244707, Tokens per Sec:    20596, Lr: 0.000300
2025-05-29 21:42:44,299 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.643934, Batch Acc: 0.253180, Tokens per Sec:    20629, Lr: 0.000300
2025-05-29 21:42:47,782 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.505774, Batch Acc: 0.253725, Tokens per Sec:    19964, Lr: 0.000300
2025-05-29 21:42:47,783 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:42:47,783 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:42:57,746 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.58, ppl:  13.18, acc:   0.26, generation: 9.9501[sec], evaluation: 0.0000[sec]
2025-05-29 21:42:57,747 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:42:58,281 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/1500.ckpt
2025-05-29 21:42:58,306 - INFO - joeynmt.training - Example #0
2025-05-29 21:42:58,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:42:58,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:42:58,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'gente', 'non', 'è', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mon@@', 'd@@', 'o@@', ',', 'e', 'la', 'gente', 'per', 'la', 'nostra', 's@@', 'etti@@', 'man@@', 'a@@', '.', '</s>']
2025-05-29 21:42:58,308 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:42:58,308 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:42:58,308 - INFO - joeynmt.training - 	Hypothesis: E la gente non è il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo per il mondo, e la gente per la nostra settimana.
2025-05-29 21:42:58,308 - INFO - joeynmt.training - Example #1
2025-05-29 21:42:58,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:42:58,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:42:58,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'mondo', 'è', 'che', 'non', 'è', 'il', 'mondo', 'non', 'è', 'il', 'mondo', 'è', 'che', 'non', 'è', 'il', 'mondo', 'non', 'è', 'il', 'mondo', 'non', 'è', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'per', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'per', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'per', 'il', 'mondo', 'per', 'il', 'mondo', 'che', 'non', 'è', 'il', 'mondo', 'non', 'è', 'il', 'mondo', 'in', 'modo', 'in', 'cui', 'non', 'si', 'può', 'essere', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'di', 'di', 'persone', 'che', 'non', 'è']
2025-05-29 21:42:58,309 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:42:58,309 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:42:58,309 - INFO - joeynmt.training - 	Hypothesis: Ma non è il mondo è che non è il mondo non è il mondo è che non è il mondo non è il mondo non è il mondo che non è il mondo che non è il mondo per il mondo che non è il mondo che non è il mondo che non è il mondo per il mondo che non è il mondo che non è il mondo che non è il mondo per il mondo per il mondo che non è il mondo non è il mondo in modo in cui non si può essere più più più più più più più più più più più più più più più più più più più più più più più di di persone che non è
2025-05-29 21:42:58,309 - INFO - joeynmt.training - Example #2
2025-05-29 21:42:58,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:42:58,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:42:58,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'di', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'cui', 'si', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il', 'mondo', 'è', 'il']
2025-05-29 21:42:58,310 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:42:58,310 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:42:58,310 - INFO - joeynmt.training - 	Hypothesis: In questo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo di cento di cento di cento di cento di cui si è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il mondo è il
2025-05-29 21:42:58,310 - INFO - joeynmt.training - Example #3
2025-05-29 21:42:58,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:42:58,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:42:58,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Non', 'è', 'il', 'm@@', 'om@@', 'ent@@', 'o@@', ',', 'e', 'la', 'm@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 21:42:58,311 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:42:58,311 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:42:58,311 - INFO - joeynmt.training - 	Hypothesis: Non è il momento, e la momento.
2025-05-29 21:42:58,311 - INFO - joeynmt.training - Example #4
2025-05-29 21:42:58,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:42:58,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:42:58,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'è', 'una', 'storia', 'di', 'una', 'storia', 'di', 'una', 'storia', 'di', 'una', 'pers@@', 'ona', 'di', 'una', 'pers@@', 'ona', 'di', 'una', 's@@', 'ec@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 21:42:58,312 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:42:58,312 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:42:58,312 - INFO - joeynmt.training - 	Hypothesis: La prima volta che è una storia di una storia di una storia di una persona di una persona di una secola.
2025-05-29 21:43:01,870 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.531313, Batch Acc: 0.255737, Tokens per Sec:    17483, Lr: 0.000300
2025-05-29 21:43:05,389 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.708178, Batch Acc: 0.257799, Tokens per Sec:    20375, Lr: 0.000300
2025-05-29 21:43:08,883 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     2.497022, Batch Acc: 0.260017, Tokens per Sec:    19970, Lr: 0.000300
2025-05-29 21:43:12,387 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     2.536008, Batch Acc: 0.260864, Tokens per Sec:    20245, Lr: 0.000300
2025-05-29 21:43:15,900 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     2.634121, Batch Acc: 0.265700, Tokens per Sec:    20627, Lr: 0.000300
2025-05-29 21:43:15,901 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:43:15,901 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:43:25,721 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.52, ppl:  12.48, acc:   0.27, generation: 9.8063[sec], evaluation: 0.0000[sec]
2025-05-29 21:43:25,722 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:43:26,241 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/2000.ckpt
2025-05-29 21:43:26,260 - INFO - joeynmt.training - Example #0
2025-05-29 21:43:26,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:43:26,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:43:26,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', 'è', 'un', 'pa@@', 'io', 'di', 'un', 'pa@@', 'io', 'di', 'c@@', 'arb@@', 'on@@', 'ica', 'di', 'un', 'pa@@', 'es@@', 'e@@', ',', 'e', 'la', 'gente', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'pa@@', 'io', 'di', 'c@@', 'entr@@', 'o', 'di', 'un', 'pa@@', 'ese', 'di', 'doll@@', 'ari', 'e', 'la', 'c@@', 'ult@@', 'ura', 'di', 'c@@', 'entr@@', 'are', 'la', 'c@@', 'aus@@', 'a', 'di', 'un', 'pa@@', 'ese', 'e', 'di', 'c@@', 'aus@@', 'a', 'di', 'un', 'pa@@', 'es@@', 'e@@', '.', '</s>']
2025-05-29 21:43:26,261 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:43:26,262 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:43:26,262 - INFO - joeynmt.training - 	Hypothesis: E questo è un paio di un paio di carbonica di un paese, e la gente che si tratta di un paio di centro di un paese di dollari e la cultura di centrare la causa di un paese e di causa di un paese.
2025-05-29 21:43:26,262 - INFO - joeynmt.training - Example #1
2025-05-29 21:43:26,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:43:26,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:43:26,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'gente', 'non', 'è', 'la', 'nostra', 'c@@', 'ult@@', 'ura', 'di', 'un', 'po@@', '<unk>', 'di', 'in@@', 'forma@@', 'zione', 'di', 'un', 'po@@', '<unk>', 'di', 'in@@', 'forma@@', 'zione', 'di', 'un', 'po@@', '<unk>', 'di', 'di', 'c@@', 'l@@', '<unk>', 'in@@', 'cre@@', 'di@@', 'bil@@', 'mente', 'non', 'è', 'la', 'nostra', 'c@@', 'ult@@', 'ura', 'di', 'un', 'po@@', '<unk>', 'di', 'di', 'c@@', 'aus@@', 'a', 'di', 'un', 'po@@', '<unk>', 'di', 'in@@', 'forma@@', 'zione', 'di', 'un', 'po@@', '<unk>', 'di', 'c@@', 'entr@@', 'o', 'di', 'un', 'po@@', '<unk>', 'di', 'in@@', 'cre@@', 'di@@', 'bil@@', 'mente', 'non', 'è', 'stato', 'un', 'p@@', 'es@@', 'o', 'di', 'in@@', 'ten@@', 'ere', 'di', 'in@@', 'segn@@', 'are', 'la', 'nostra', 'c@@', 'ult@@', 'ura', 'di', 'c@@', 'ult@@', 'ura', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:43:26,263 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:43:26,263 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:43:26,263 - INFO - joeynmt.training - 	Hypothesis: Ma non è la gente non è la nostra cultura di un po<unk> di informazione di un po<unk> di informazione di un po<unk> di di cl<unk> incredibilmente non è la nostra cultura di un po<unk> di di causa di un po<unk> di informazione di un po<unk> di centro di un po<unk> di incredibilmente non è stato un peso di intenere di insegnare la nostra cultura di cultura di un po<unk> .
2025-05-29 21:43:26,263 - INFO - joeynmt.training - Example #2
2025-05-29 21:43:26,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:43:26,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:43:26,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'è', 'un', 'p@@', 'ad@@', 'r@@', 'ato', 'di', 'un', 'p@@', 'es@@', 'perim@@', 'ento', 'di', 'un', 'p@@', 'es@@', 'c@@', 'ento', 'di', 'un', 'p@@', 'es@@', 'c@@', 'e@@', '.', '</s>']
2025-05-29 21:43:26,264 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:43:26,264 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:43:26,264 - INFO - joeynmt.training - 	Hypothesis: In questo è un padrato di un pesperimento di un pescento di un pesce.
2025-05-29 21:43:26,264 - INFO - joeynmt.training - Example #3
2025-05-29 21:43:26,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:43:26,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:43:26,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 're@@', 'do', 'e', 'la', 'p@@', 'es@@', 'c@@', 'e@@', ',', 'e', 'la', 'p@@', 'es@@', 'c@@', 'e@@', '.', '</s>']
2025-05-29 21:43:26,265 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:43:26,265 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:43:26,265 - INFO - joeynmt.training - 	Hypothesis: Credo e la pesce, e la pesce.
2025-05-29 21:43:26,265 - INFO - joeynmt.training - Example #4
2025-05-29 21:43:26,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:43:26,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:43:26,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'stato', 'un', 'm@@', 'oti@@', 'vo', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'una', 'cosa', 'che', 'è', 'stato', 'un', 's@@', 'ec@@', 'ol@@', 'o@@', ',', 'e', 'la', 'gente', 'che', 'è', 'una', 'cosa', 'che', 'è', 'stato', 'un', 'm@@', 'oti@@', 'vo', 'è', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'un', 'm@@', 'oti@@', 'vo', 'è', 'stato']
2025-05-29 21:43:26,266 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:43:26,266 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:43:26,266 - INFO - joeynmt.training - 	Hypothesis: E questo è una cosa che è una cosa che è una cosa che è una cosa che è una cosa che è una cosa che è stato un po<unk> di una cosa che è una cosa che è stato un motivo è una cosa che è una cosa che è una cosa che è una cosa che è una cosa che è una cosa che è una cosa che è stato un po<unk> di una cosa che è stato un secolo, e la gente che è una cosa che è stato un motivo è che è una cosa che è una cosa che è stato stato stato stato stato stato un motivo è stato
2025-05-29 21:43:29,830 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:     2.590721, Batch Acc: 0.266047, Tokens per Sec:    17555, Lr: 0.000300
2025-05-29 21:43:33,352 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:     2.475997, Batch Acc: 0.270408, Tokens per Sec:    20782, Lr: 0.000300
2025-05-29 21:43:36,876 - INFO - joeynmt.training - Epoch   1, Step:     4800, Batch Loss:     2.602565, Batch Acc: 0.267443, Tokens per Sec:    20403, Lr: 0.000300
2025-05-29 21:43:40,375 - INFO - joeynmt.training - Epoch   1, Step:     4900, Batch Loss:     2.554309, Batch Acc: 0.275162, Tokens per Sec:    20242, Lr: 0.000300
2025-05-29 21:43:43,893 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:     2.521240, Batch Acc: 0.271166, Tokens per Sec:    20163, Lr: 0.000300
2025-05-29 21:43:43,894 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:43:43,894 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:43:55,366 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.49, ppl:  12.07, acc:   0.28, generation: 11.4557[sec], evaluation: 0.0000[sec]
2025-05-29 21:43:55,367 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:43:55,896 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/2500.ckpt
2025-05-29 21:43:55,951 - INFO - joeynmt.training - Example #0
2025-05-29 21:43:55,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:43:55,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:43:55,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', 'è', 'stato', 'un', 'mili@@', 'ar@@', 'di', 'di', 'di', 'persone', 'che', 'si', 'può', 'essere', 'un', 'mili@@', 'ar@@', 'di', 'di', 'di', 'doll@@', 'ar@@', 'i@@', ',', 'e', 'il', '2@@', '5', 'an@@', 'ni@@', ',', 'e', 'la', 'gente', 'di', '1@@', '5', 'an@@', 'ni@@', ',', 'e', 'la', 'gente', 'di', '1@@', '5', 'an@@', 'ni@@', ',', 'e', 'il', '2@@', '5', 'anni', 'fa@@', ',', 'e', 'il', '2@@', '5', 'an@@', 'ni@@', ',', 'e', 'la', 'gente', 'di', '1@@', '5', 'anni', 'fa@@', ',', 'e', 'il', '2@@', '5', 'milioni', 'di', 'persone', 'che', 'hanno', 'sc@@', 'rit@@', 'to', 'per', 'il', '2@@', '5', 'anni', 'per', 'c@@', 'ento', 'di', '1@@', '0@@', '%', 'di', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', ',', 'e', 'per', 'il', 'mili@@', 'ar@@', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'persone', 'che', 'si']
2025-05-29 21:43:55,953 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:43:55,953 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:43:55,953 - INFO - joeynmt.training - 	Hypothesis: E questo è stato un miliardi di di persone che si può essere un miliardi di di dollari, e il 25 anni, e la gente di 15 anni, e la gente di 15 anni, e il 25 anni fa, e il 25 anni, e la gente di 15 anni fa, e il 25 milioni di persone che hanno scritto per il 25 anni per cento di 10% di 1000000000000, e per il miliardi di di di di di di persone che si
2025-05-29 21:43:55,953 - INFO - joeynmt.training - Example #1
2025-05-29 21:43:55,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:43:55,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:43:55,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'gente', 'non', 'è', 'la', 'nostra', 'nostra', 'nostra', 's@@', 'per@@', 'anz@@', 'a@@', ',', 'non', 'è', 'la', 'nostra', 's@@', 'per@@', 'anz@@', 'a@@', ',', 'non', 'è', 'la', 'nostra', 's@@', 'per@@', 'anz@@', 'a@@', '.', '</s>']
2025-05-29 21:43:55,954 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:43:55,954 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:43:55,954 - INFO - joeynmt.training - 	Hypothesis: Ma non è la gente non è la nostra nostra nostra speranza, non è la nostra speranza, non è la nostra speranza.
2025-05-29 21:43:55,954 - INFO - joeynmt.training - Example #2
2025-05-29 21:43:55,955 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:43:55,955 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:43:55,955 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'mo@@', 'dello', 'di', 'cui', 'è', 'la', 'nostra', 'nostra', 'nostra', 'soci@@', 'età', 'di', 'cui', 'è', 'la', 'nostra', 'nostra', 'c@@', 'ult@@', 'ur@@', 'ale', 'è', 'la', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'c@@', 'ult@@', 'ur@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:43:55,955 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:43:55,955 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:43:55,955 - INFO - joeynmt.training - 	Hypothesis: In questo modello di cui è la nostra nostra nostra società di cui è la nostra nostra culturale è la nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra culturale.
2025-05-29 21:43:55,955 - INFO - joeynmt.training - Example #3
2025-05-29 21:43:55,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:43:55,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:43:55,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'em@@', 'br@@', 'a', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'e', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'e', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'e', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'e', 'e', 'e', 'l@@', '<unk>', 'in@@', 'f@@', 'am@@', 'ig@@', 'li@@', '.', '</s>']
2025-05-29 21:43:55,956 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:43:55,956 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:43:55,956 - INFO - joeynmt.training - 	Hypothesis: Sembra e e l<unk> influenza e e l<unk> influenza e e e l<unk> influenza e e e l<unk> influenza e e l<unk> influenza e e l<unk> influenza e e e l<unk> influenza e e l<unk> influenza e e e l<unk> infamigli.
2025-05-29 21:43:55,956 - INFO - joeynmt.training - Example #4
2025-05-29 21:43:55,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:43:55,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:43:55,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', 'è', 'una', 'cosa', 'che', 'è', 'la', 'cosa', 'che', 'è', 'la', 'cosa', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'una', 'cosa', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'una', 'cosa', 'che', 'è', 'la', 'cosa', 'che', 'ho', 'fatto', 'che', 'ho', 'visto', 'che', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'è', 'una', 'cosa', 'che', 'è', 'la', 'gente', 'che', 'è', 'la', 'cosa', 'che', 'ho', 'fatto', 'che', 'la', 'gente', 'che', 'è', 'la', 'gente', 'che', 'ho', 'det@@', 't@@', 'o@@', ',', 'e', 'la', 'gente', 'che', 'è', 'una', 'cosa', 'che', 'è', 'la', 'gente', 'che', 'è']
2025-05-29 21:43:55,957 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:43:55,957 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:43:55,957 - INFO - joeynmt.training - 	Hypothesis: E questo è una cosa che è la cosa che è la cosa che è la gente che è la gente che è la gente che è la gente che è la gente che è la gente che è la gente che è la gente che è una cosa che è la gente che è la gente che è la gente che è la gente che è una cosa che è la cosa che ho fatto che ho visto che la gente che è la gente che è una cosa che è la gente che è la cosa che ho fatto che la gente che è la gente che ho detto, e la gente che è una cosa che è la gente che è
2025-05-29 21:43:59,527 - INFO - joeynmt.training - Epoch   1, Step:     5100, Batch Loss:     2.354725, Batch Acc: 0.276652, Tokens per Sec:    17091, Lr: 0.000300
2025-05-29 21:44:03,041 - INFO - joeynmt.training - Epoch   1, Step:     5200, Batch Loss:     2.676089, Batch Acc: 0.276818, Tokens per Sec:    19902, Lr: 0.000300
2025-05-29 21:44:06,534 - INFO - joeynmt.training - Epoch   1, Step:     5300, Batch Loss:     2.560021, Batch Acc: 0.278955, Tokens per Sec:    20484, Lr: 0.000300
2025-05-29 21:44:10,015 - INFO - joeynmt.training - Epoch   1, Step:     5400, Batch Loss:     2.508651, Batch Acc: 0.282156, Tokens per Sec:    20112, Lr: 0.000300
2025-05-29 21:44:13,518 - INFO - joeynmt.training - Epoch   1, Step:     5500, Batch Loss:     2.631936, Batch Acc: 0.280683, Tokens per Sec:    19589, Lr: 0.000300
2025-05-29 21:44:13,518 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:44:13,518 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:44:24,897 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.46, ppl:  11.66, acc:   0.29, generation: 11.3651[sec], evaluation: 0.0000[sec]
2025-05-29 21:44:24,898 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:44:25,448 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/3000.ckpt
2025-05-29 21:44:25,472 - INFO - joeynmt.training - Example #0
2025-05-29 21:44:25,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:44:25,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:44:25,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', '1@@', '5@@', '%', 'di', 'questi', 'sono', 'sono', 'i', 'm@@', 'ezz@@', 'i', 'di', 'un', 'mili@@', 'ar@@', 'di', 'di', 'di', 'di', 'doll@@', 'ar@@', 'i@@', ',', 'e', 'i', 'sono', 'i', 'm@@', 'ezz@@', 'i', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'fa@@', ',', 'e', 'l@@', '<unk>', 'inter@@', 'a', 'di', 'un', 'mili@@', 'ar@@', 'di', 'di', 'di', 'di', 'di', 'di', 'doll@@', 'ar@@', 'i@@', '.', '</s>']
2025-05-29 21:44:25,474 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:44:25,474 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:44:25,474 - INFO - joeynmt.training - 	Hypothesis: E il 15% di questi sono sono i mezzi di un miliardi di di di dollari, e i sono i mezzi di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni di 15 anni fa, e l<unk> intera di un miliardi di di di di di dollari.
2025-05-29 21:44:25,474 - INFO - joeynmt.training - Example #1
2025-05-29 21:44:25,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:44:25,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:44:25,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'modo', 'in', 'cui', 'la', 'nostra', 's@@', 'per@@', 'o', 'che', 'la', 'nostra', 's@@', 'per@@', 'o', 'che', 'si', 'può', 'essere', 'un', 'modo', 'di', 'cui', 'non', 'è', 'che', 'non', 'è', 'la', 'nostra', 's@@', 'per@@', 'at@@', 'ura', 'non', 'è', 'la', 'nostra', 's@@', 'per@@', 'at@@', 'a@@', '.', '</s>']
2025-05-29 21:44:25,475 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:44:25,475 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:44:25,475 - INFO - joeynmt.training - 	Hypothesis: Ma non è un modo in cui la nostra spero che la nostra spero che si può essere un modo di cui non è che non è la nostra speratura non è la nostra sperata.
2025-05-29 21:44:25,475 - INFO - joeynmt.training - Example #2
2025-05-29 21:44:25,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:44:25,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:44:25,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'mo@@', 'd@@', 'o@@', ',', 'il', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 's@@', 'an@@', 'it@@', 'o@@', ',', 'e', 'la', 'nostra', 's@@', 'itu@@', 'azione', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'l@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'ale', 'di', 'l@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:44:25,476 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:44:25,476 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:44:25,476 - INFO - joeynmt.training - 	Hypothesis: In questo modo, il nostro nostro nostro nostro nostro sanito, e la nostra situazione di un certo senso di l<unk> industriale di l<unk> industriale.
2025-05-29 21:44:25,476 - INFO - joeynmt.training - Example #3
2025-05-29 21:44:25,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:44:25,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:44:25,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'e', 'l@@', '<unk>', 'idea', 'di', 'un', 'b@@', 'an@@', 'om@@', 'a', 'e', 'e', 'e', 'l@@', '<unk>', 'in@@', 't@@', 'om@@', 'o@@', '.', '</s>']
2025-05-29 21:44:25,477 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:44:25,477 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:44:25,477 - INFO - joeynmt.training - 	Hypothesis: Lo e l<unk> idea di un banoma e e e l<unk> intomo.
2025-05-29 21:44:25,477 - INFO - joeynmt.training - Example #4
2025-05-29 21:44:25,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:44:25,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:44:25,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'che', 'mi', 'ha', 'detto', 'che', 'mi', 'sono', 'un', 'p@@', 'oco', 'di', 'un', 'p@@', 'oco', 'di', 'un', 'p@@', 'oco', 'di', 'un', 'p@@', 'oco', 'che', 'è', 'che', 'è', 'che', 'la', 'prima', 'volta', 'che', 'è', 'che', 'è', 'che', 'la', 'cosa', 'che', 'è', 'che', 'è', 'un', 's@@', 'ac@@', 'co', 'di', 'qu@@', 'at@@', 'tro', 'di', 'un', 'p@@', 'oco', 'di', 'p@@', 'op@@', 'ol@@', 'o@@', ',', 'e', 'mi', 'sono', 'stati', 'in', 'un', 'altro', 'altro', 'che', 'mi', 'ha', 'detto', 'che', 'mi', 'pi@@', 'ac@@', 'er@@', 'o@@', ',', 'e', 'ho', 'fatto', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'p@@', 'oco', 'di', 'di@@', 'mostr@@', 'are', 'un', 'po@@', '<unk>', 'di', 'p@@', 'op@@', 'ol@@', 'o@@', ',', 'e', 'mi', 'sono', 'un', 'po@@', '<unk>', 'di', 'di@@', 'st@@', 'anza', 'di', 'p@@', 'oco', 'di', 'vi@@', 'sta', 'di', 'un', 'p@@', 'oco', 'di', 'di@@', 're@@']
2025-05-29 21:44:25,478 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:44:25,478 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:44:25,478 - INFO - joeynmt.training - 	Hypothesis: La cosa che mi ha detto che mi sono un poco di un poco di un poco di un poco che è che è che la prima volta che è che è che la cosa che è che è un sacco di quattro di un poco di popolo, e mi sono stati in un altro altro che mi ha detto che mi piacero, e ho fatto che vi mostrerò un poco di dimostrare un po<unk> di popolo, e mi sono un po<unk> di distanza di poco di vista di un poco di dire
2025-05-29 21:44:29,017 - INFO - joeynmt.training - Epoch   1, Step:     5600, Batch Loss:     2.406860, Batch Acc: 0.282540, Tokens per Sec:    17538, Lr: 0.000300
2025-05-29 21:44:32,492 - INFO - joeynmt.training - Epoch   1, Step:     5700, Batch Loss:     2.574897, Batch Acc: 0.284907, Tokens per Sec:    20068, Lr: 0.000300
2025-05-29 21:44:35,947 - INFO - joeynmt.training - Epoch   1, Step:     5800, Batch Loss:     2.285330, Batch Acc: 0.288493, Tokens per Sec:    19573, Lr: 0.000300
2025-05-29 21:44:39,430 - INFO - joeynmt.training - Epoch   1, Step:     5900, Batch Loss:     2.437846, Batch Acc: 0.287849, Tokens per Sec:    20009, Lr: 0.000300
2025-05-29 21:44:42,905 - INFO - joeynmt.training - Epoch   1, Step:     6000, Batch Loss:     2.369055, Batch Acc: 0.286647, Tokens per Sec:    20414, Lr: 0.000300
2025-05-29 21:44:42,905 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:44:42,905 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:44:53,800 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.41, ppl:  11.19, acc:   0.29, generation: 10.8814[sec], evaluation: 0.0000[sec]
2025-05-29 21:44:53,802 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:44:54,367 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/3500.ckpt
2025-05-29 21:44:54,393 - INFO - joeynmt.training - Example #0
2025-05-29 21:44:54,394 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:44:54,394 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:44:54,394 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', 'è', 'stato', 'un', 'mili@@', 'ar@@', 'di', 'di', 'di', 'persone', 'che', 'hanno', 'fatto', 'che', 'il', 'mondo', 'che', 'il', 'mondo', 'che', 'il', 'mondo', 'che', 'il', '1@@', '0@@', '%', 'dei', 'bambini', 'che', 'hanno', 'fatto', 'per', 'la', 'c@@', 'ult@@', 'ura', 'di', '1@@', '00', 'mili@@', 'ar@@', 'di', 'di', 'di', 'di', 'doll@@', 'ari', 'di', '1@@', '00', 'mili@@', 'ar@@', 'di', 'di', 'di', 'doll@@', 'ari', 'per', 'il', 'mili@@', 'ar@@', 'di', 'di', 'di', 'di', 'persone', 'che', 'hanno', 'fatto', 'che', 'il', 'mili@@', 'ar@@', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'persone', 'che', 'si', 'è', 'stato', 'un', 'mili@@', 'ar@@', 'di', 'di', 'di', 'di', 'di', 'di', 'persone', 'che', 'si', 'è', 'stato', 'più', 'di', 'persone', 'che', 'si', 'può', 'essere', 'più', 'di', 'persone', 'che', 'si', 'è', 'stato', 'più', 'più', 'di', 'persone', 'che', 'il', 'mili@@', 'ar@@', 'di', 'di', 'di', 'persone']
2025-05-29 21:44:54,395 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:44:54,395 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:44:54,395 - INFO - joeynmt.training - 	Hypothesis: E questo è stato un miliardi di di persone che hanno fatto che il mondo che il mondo che il mondo che il 10% dei bambini che hanno fatto per la cultura di 100 miliardi di di di dollari di 100 miliardi di di dollari per il miliardi di di di persone che hanno fatto che il miliardi di di di di di di persone che si è stato un miliardi di di di di di persone che si è stato più di persone che si può essere più di persone che si è stato più più di persone che il miliardi di di persone
2025-05-29 21:44:54,395 - INFO - joeynmt.training - Example #1
2025-05-29 21:44:54,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:44:54,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:44:54,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'nostro', 'sistema', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'ma', 'non', 'è', 'il', 'nostro', 'sistema', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'nostro', 'sistema', 'di', 'questo', 'non', 'è', 'il', 'nostro', 'sistema', 'di', 'un', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:44:54,396 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:44:54,396 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:44:54,396 - INFO - joeynmt.training - 	Hypothesis: Ma non è il nostro sistema di questo problema, ma non è il nostro sistema di questo problema, non è il nostro sistema di questo non è il nostro sistema di un problema.
2025-05-29 21:44:54,396 - INFO - joeynmt.training - Example #2
2025-05-29 21:44:54,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:44:54,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:44:54,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'mo@@', 'd@@', 'o@@', ',', 'il', 'nostro', 'sistema', 'di', 'b@@', 'ag@@', 'li@@', 'ato', 'e', 'la', 'nostra', 'c@@', 'ult@@', 'ura', 'è', 'la', 'nostra', 'c@@', 'ult@@', 'ura', 'del', 'nostro', 'sistema', 'di', 'c@@', 'entr@@', 'are', 'la', 'nostra', 'es@@', 'ist@@', 'enza', 'del', 'nostro', 'sistema', 'di', 'di@@', 'st@@', 'in@@', 'i@@', 'o@@', '.', '</s>']
2025-05-29 21:44:54,397 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:44:54,397 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:44:54,397 - INFO - joeynmt.training - 	Hypothesis: In questo modo, il nostro sistema di bagliato e la nostra cultura è la nostra cultura del nostro sistema di centrare la nostra esistenza del nostro sistema di distinio.
2025-05-29 21:44:54,397 - INFO - joeynmt.training - Example #3
2025-05-29 21:44:54,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:44:54,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:44:54,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'et@@', 'ta', 'e', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'e', 'e', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'e', 'e', 'la', 'p@@', 'op@@', 'ol@@', 'it@@', 'a@@', '.', '</s>']
2025-05-29 21:44:54,398 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:44:54,398 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:44:54,398 - INFO - joeynmt.training - 	Hypothesis: Sapetta e la popolazione e e la popolazione e e la popolita.
2025-05-29 21:44:54,398 - INFO - joeynmt.training - Example #4
2025-05-29 21:44:54,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:44:54,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:44:54,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', 'o', 'è', 'che', 'vi', 'ho', 'fatto', 'che', 'vi', 'ho', 'fatto', 'un', 'po@@', '<unk>', 'di', 'più', 'di', 'più', 'di', 'più', 'di', 'più', 'di', 'più', 'di', 'più', 'di', '1@@', '00', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:44:54,399 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:44:54,399 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:44:54,399 - INFO - joeynmt.training - 	Hypothesis: Il primo è che vi ho fatto che vi ho fatto un po<unk> di più di più di più di più di più di più di 100 anni fa.
2025-05-29 21:44:57,916 - INFO - joeynmt.training - Epoch   1, Step:     6100, Batch Loss:     2.502487, Batch Acc: 0.292144, Tokens per Sec:    17153, Lr: 0.000300
2025-05-29 21:45:01,400 - INFO - joeynmt.training - Epoch   1, Step:     6200, Batch Loss:     2.419184, Batch Acc: 0.293773, Tokens per Sec:    20163, Lr: 0.000300
2025-05-29 21:45:04,849 - INFO - joeynmt.training - Epoch   1, Step:     6300, Batch Loss:     2.507244, Batch Acc: 0.296100, Tokens per Sec:    19410, Lr: 0.000300
2025-05-29 21:45:08,325 - INFO - joeynmt.training - Epoch   1, Step:     6400, Batch Loss:     2.304121, Batch Acc: 0.297358, Tokens per Sec:    20833, Lr: 0.000300
2025-05-29 21:45:11,775 - INFO - joeynmt.training - Epoch   1, Step:     6500, Batch Loss:     2.346305, Batch Acc: 0.300114, Tokens per Sec:    20331, Lr: 0.000300
2025-05-29 21:45:11,776 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:45:11,776 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:45:21,043 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.38, ppl:  10.86, acc:   0.30, generation: 9.2548[sec], evaluation: 0.0000[sec]
2025-05-29 21:45:21,044 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:45:21,626 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/4000.ckpt
2025-05-29 21:45:21,653 - INFO - joeynmt.training - Example #0
2025-05-29 21:45:21,654 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:45:21,654 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:45:21,654 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', 'è', 'un', 'mili@@', 'ar@@', 'di', 'di', 'di', 'di', 'di', 'doll@@', 'ar@@', 'i@@', ',', 'per', 'esem@@', 'pi@@', 'o@@', ',', 'e', 'il', 'p@@', 'es@@', 'o', 'di', 'c@@', 'aus@@', 'a', 'di', 'p@@', 'es@@', 'o', 'per', 'il', 'mon@@', 'd@@', 'o@@', ',', 'e', 'il', 'p@@', 'es@@', 'o', 'di', '1@@', '00', 'milioni', 'di', 'doll@@', 'ar@@', 'i@@', ',', 'e', 'il', 'p@@', 'es@@', 'o', 'di', '1@@', '00', 'milioni', 'di', 'doll@@', 'ar@@', 'i@@', '.', '</s>']
2025-05-29 21:45:21,655 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:45:21,655 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:45:21,655 - INFO - joeynmt.training - 	Hypothesis: E questo è un miliardi di di di di dollari, per esempio, e il peso di causa di peso per il mondo, e il peso di 100 milioni di dollari, e il peso di 100 milioni di dollari.
2025-05-29 21:45:21,655 - INFO - joeynmt.training - Example #1
2025-05-29 21:45:21,655 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:45:21,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:45:21,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', ',', 'è', 'che', 'la', 'ris@@', 'post@@', 'a', 'è', 'che', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:45:21,656 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:45:21,656 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:45:21,656 - INFO - joeynmt.training - 	Hypothesis: Ma non è il problema, non è il problema, è che la risposta è che non è il problema.
2025-05-29 21:45:21,656 - INFO - joeynmt.training - Example #2
2025-05-29 21:45:21,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:45:21,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:45:21,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'mo@@', 'd@@', 'o@@', ',', 'la', 'nostra', 'soci@@', 'età', 'di', 'cui', 'la', 'nostra', 'soci@@', 'età', 'di', 'l@@', '<unk>', 'ar@@', 'ea', 'del', 'nostro', 'sistema', 'di', 'c@@', 'entr@@', 'are', 'la', 'nostra', 'soci@@', 'età', 'di', 'c@@', 'aus@@', 'a', 'di', 'c@@', 'aus@@', 'a', 'di', 'c@@', 'aus@@', 'a', 'di', 'l@@', '<unk>', 'ar@@', 'ea', 'di', 'cui', 'la', 'nostra', 'soci@@', 'età', 'di', 'c@@', 'aus@@', 'a', 'di', 'l@@', '<unk>', 'ar@@', 'ch@@', 'e@@', '.', '</s>']
2025-05-29 21:45:21,657 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:45:21,657 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:45:21,657 - INFO - joeynmt.training - 	Hypothesis: In questo modo, la nostra società di cui la nostra società di l<unk> area del nostro sistema di centrare la nostra società di causa di causa di causa di l<unk> area di cui la nostra società di causa di l<unk> arche.
2025-05-29 21:45:21,657 - INFO - joeynmt.training - Example #3
2025-05-29 21:45:21,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:45:21,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:45:21,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Non', 'si', 'è', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'li@@', 'a@@', '.', '</s>']
2025-05-29 21:45:21,658 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:45:21,658 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:45:21,658 - INFO - joeynmt.training - 	Hypothesis: Non si è la sua famiglia e e la sua famiglia.
2025-05-29 21:45:21,658 - INFO - joeynmt.training - Example #4
2025-05-29 21:45:21,658 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:45:21,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:45:21,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'ar@@', 'g@@', 'o', 'un', 'ar@@', 'g@@', 'o', 'di', 'un', 'ar@@', 'g@@', 'omento', 'che', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'è', 'che', 'la', 'prima', 'volta', 'che', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'è', 'che', 'la', 'prima', 'volta', 'che', 'ho', 'fatto', 'che', 'la', 'prima', 'volta', 'che', 'ho', 'fatto', 'un', 'altro', 'giorno', 'in', 'cui', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'ar@@', 'g@@', 'over@@', 'no', 'è', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'a', 'questo', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'è', 'il', 'mio', 'p@@', 'ad@@', 're', 'di', 'm@@', 'e@@', '.', '</s>']
2025-05-29 21:45:21,659 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:45:21,659 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:45:21,659 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostrerò un argo un argo di un argomento che è una cosa che è successo è che la prima volta che è una cosa che è successo è che la prima volta che ho fatto che la prima volta che ho fatto un altro giorno in cui vi mostro che vi mostra che vi mostrerò che vi mostrerò un argoverno è una cosa che vi mostra questo è una cosa che è successo è il mio padre di me.
2025-05-29 21:45:25,196 - INFO - joeynmt.training - Epoch   1, Step:     6600, Batch Loss:     2.434537, Batch Acc: 0.299556, Tokens per Sec:    16978, Lr: 0.000300
2025-05-29 21:45:28,672 - INFO - joeynmt.training - Epoch   1, Step:     6700, Batch Loss:     2.485802, Batch Acc: 0.302615, Tokens per Sec:    19992, Lr: 0.000300
2025-05-29 21:45:32,120 - INFO - joeynmt.training - Epoch   1, Step:     6800, Batch Loss:     2.325810, Batch Acc: 0.304419, Tokens per Sec:    19902, Lr: 0.000300
2025-05-29 21:45:35,617 - INFO - joeynmt.training - Epoch   1, Step:     6900, Batch Loss:     2.338169, Batch Acc: 0.300627, Tokens per Sec:    20617, Lr: 0.000300
2025-05-29 21:45:39,030 - INFO - joeynmt.training - Epoch   1, Step:     7000, Batch Loss:     2.491939, Batch Acc: 0.302331, Tokens per Sec:    20456, Lr: 0.000300
2025-05-29 21:45:39,030 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:45:39,030 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:45:48,421 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.36, ppl:  10.55, acc:   0.31, generation: 9.3782[sec], evaluation: 0.0000[sec]
2025-05-29 21:45:48,421 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:45:48,982 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/4500.ckpt
2025-05-29 21:45:49,009 - INFO - joeynmt.training - Example #0
2025-05-29 21:45:49,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:45:49,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:45:49,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'fatto', 'che', 'ho', 'inizi@@', 'ato', 'a', 'pensare', 'a', 'questa', 's@@', 'fi@@', 'da', 'per', 'creare', 'un', 'po@@', '<unk>', 'di', 'p@@', 'oco', 'di', 'p@@', 'oco', 'di', 'c@@', 'arb@@', 'on@@', 'i@@', ',', 'che', 'sono', 'più', 'di', '1@@', '5', 'milioni', 'di', 'doll@@', 'ari', 'per', 'c@@', 'ento', 'di', 'più', 'di', '1@@', '5', 'milioni', 'di', 'doll@@', 'ari', 'di', 'anni', 'fa@@', ',', 'per', 'il', 'mon@@', 'd@@', 'o@@', ',', 'e', 'che', 'è', 'stato', 'un', 'mili@@', 'one', 'di', 'doll@@', 'ar@@', 'i@@', '.', '</s>']
2025-05-29 21:45:49,010 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:45:49,010 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:45:49,010 - INFO - joeynmt.training - 	Hypothesis: E ho fatto che ho iniziato a pensare a questa sfida per creare un po<unk> di poco di poco di carboni, che sono più di 15 milioni di dollari per cento di più di 15 milioni di dollari di anni fa, per il mondo, e che è stato un milione di dollari.
2025-05-29 21:45:49,010 - INFO - joeynmt.training - Example #1
2025-05-29 21:45:49,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:45:49,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:45:49,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'problema', 'non', 'è', 'stato', 'un', 'problema', 'non', 'è', 'stato', 'un', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'il', 'problema', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:45:49,011 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:45:49,011 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:45:49,011 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema non è stato un problema non è stato un problema di problema, il problema non è il problema.
2025-05-29 21:45:49,011 - INFO - joeynmt.training - Example #2
2025-05-29 21:45:49,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:45:49,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:45:49,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o@@', ',', 'la', 'nostra', 'es@@', 'peri@@', 'enza', 'è', 'la', 'nostra', 'es@@', 'peri@@', 'enza', 'di', 'un', 'sistema', 'di', 'p@@', 'es@@', 'c@@', 'en@@', 'z@@', 'a@@', '.', '</s>']
2025-05-29 21:45:49,012 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:45:49,012 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:45:49,012 - INFO - joeynmt.training - 	Hypothesis: In questo caso, la nostra esperienza è la nostra esperienza di un sistema di pescenza.
2025-05-29 21:45:49,012 - INFO - joeynmt.training - Example #3
2025-05-29 21:45:49,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:45:49,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:45:49,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'poi', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'p@@', 'oco', 'di', 'p@@', 'oco', 'di', 'p@@', 'oco', 'di', 'p@@', 'op@@', 'ol@@', 'ar@@', 'e@@', '.', '</s>']
2025-05-29 21:45:49,013 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:45:49,013 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:45:49,013 - INFO - joeynmt.training - 	Hypothesis: E poi si tratta di un poco di poco di poco di popolare.
2025-05-29 21:45:49,013 - INFO - joeynmt.training - Example #4
2025-05-29 21:45:49,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:45:49,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:45:49,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'storia', 'di', 'questa', 'cosa', 'che', 'ho', 'fatto', 'che', 'vi', 'ho', 'fatto', 'un', 'po@@', '<unk>', 'di', 'anni', 'fa@@', ',', 'e', 'ho', 'fatto', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', 'più', 'grande', 'grande', 'grande', 'grande', 'grande', 'grande', 'grande', 'grande', 'grande', 'grande', 'grande', 's@@', 'ott@@', 'o@@', '.', '</s>']
2025-05-29 21:45:49,014 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:45:49,014 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:45:49,014 - INFO - joeynmt.training - 	Hypothesis: La mia storia di questa cosa che ho fatto che vi ho fatto un po<unk> di anni fa, e ho fatto che è stato un po<unk> più grande grande grande grande grande grande grande grande grande grande grande sotto.
2025-05-29 21:45:52,503 - INFO - joeynmt.training - Epoch   1, Step:     7100, Batch Loss:     2.445152, Batch Acc: 0.307911, Tokens per Sec:    17336, Lr: 0.000300
2025-05-29 21:45:55,992 - INFO - joeynmt.training - Epoch   1, Step:     7200, Batch Loss:     2.381419, Batch Acc: 0.310815, Tokens per Sec:    20257, Lr: 0.000300
2025-05-29 21:45:59,496 - INFO - joeynmt.training - Epoch   1, Step:     7300, Batch Loss:     2.347739, Batch Acc: 0.308909, Tokens per Sec:    21181, Lr: 0.000300
2025-05-29 21:46:02,956 - INFO - joeynmt.training - Epoch   1, Step:     7400, Batch Loss:     2.368051, Batch Acc: 0.310786, Tokens per Sec:    20405, Lr: 0.000300
2025-05-29 21:46:06,823 - INFO - joeynmt.training - Epoch   1, Step:     7500, Batch Loss:     2.295664, Batch Acc: 0.310848, Tokens per Sec:    17855, Lr: 0.000300
2025-05-29 21:46:06,823 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:46:06,823 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:46:15,661 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.33, ppl:  10.31, acc:   0.32, generation: 8.8266[sec], evaluation: 0.0000[sec]
2025-05-29 21:46:15,662 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:46:16,180 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/5000.ckpt
2025-05-29 21:46:16,200 - INFO - joeynmt.training - Example #0
2025-05-29 21:46:16,200 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:46:16,200 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:46:16,200 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'dopo', '1@@', '5', 'anni', 'ho', 'inizi@@', 'ato', 'a', '4@@', '0', 'an@@', 'ni@@', ',', 'e', 'ho', 'fatto', 'che', 'la', 'c@@', 'aus@@', 'a', 'di', 'l@@', '<unk>', 'es@@', 'peri@@', 'enza', 'di', 'c@@', 'arb@@', 'on@@', 'i@@', ',', 'che', 'la', 'c@@', 'ris@@', 'i', 'di', '1@@', '00', 'milioni', 'di', 'anni', 'di', 'anni', 'fa@@', ',', 'per', 'la', 'prima', 'volta', 'che', 'il', '2@@', '5@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', ',', 'per', 'il', '2@@', '5@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '.', '</s>']
2025-05-29 21:46:16,201 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:46:16,201 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:46:16,201 - INFO - joeynmt.training - 	Hypothesis: E dopo 15 anni ho iniziato a 40 anni, e ho fatto che la causa di l<unk> esperienza di carboni, che la crisi di 100 milioni di anni di anni fa, per la prima volta che il 250000000000000000, per il 250000000000000000000000000.
2025-05-29 21:46:16,201 - INFO - joeynmt.training - Example #1
2025-05-29 21:46:16,201 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:46:16,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:46:16,201 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'nostra', 's@@', 'per@@', 'anza', 'che', 'non', 'è', 'la', 's@@', 'itu@@', 'azione', 'di', 'un', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 's@@', 'itu@@', 'azione', 'di', 'un', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:46:16,202 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:46:16,202 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:46:16,202 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema, non è la nostra speranza che non è la situazione di un problema, non è la situazione di un problema.
2025-05-29 21:46:16,202 - INFO - joeynmt.training - Example #2
2025-05-29 21:46:16,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:46:16,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:46:16,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'è', 'la', 'nostra', 'c@@', 'ris@@', 'i', 'del', 'nostro', 'cor@@', 'so', 'è', 'la', 'sua', 'f@@', 'ig@@', 'lia', 'della', 'nostra', 'soci@@', 'età', 'di', 'l@@', '<unk>', 'in@@', 'forma@@', 'zione', 'della', 'nostra', 'nat@@', 'ur@@', 'a@@', '.', '</s>']
2025-05-29 21:46:16,203 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:46:16,203 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:46:16,203 - INFO - joeynmt.training - 	Hypothesis: In realtà è la nostra crisi del nostro corso è la sua figlia della nostra società di l<unk> informazione della nostra natura.
2025-05-29 21:46:16,203 - INFO - joeynmt.training - Example #3
2025-05-29 21:46:16,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:46:16,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:46:16,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'sua', 'v@@', 'it@@', 'a@@', ',', 'e', 'la', 'sua', 'f@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'ig@@', 'lia', 'e', 'il', 'p@@', 'al@@', 'og@@', 'o', 'di', 'un', 'f@@', 'ig@@', 'li@@', '.', '</s>']
2025-05-29 21:46:16,204 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:46:16,204 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:46:16,204 - INFO - joeynmt.training - 	Hypothesis: E la sua vita, e la sua figlia e la sua figlia e il palogo di un figli.
2025-05-29 21:46:16,204 - INFO - joeynmt.training - Example #4
2025-05-29 21:46:16,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:46:16,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:46:16,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'ho', 'fatto', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'ho', 'fatto', 'una', 'cosa', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'qu@@', 'asi', 'cosa', 'succ@@', 'e@@', '<unk>', 'è', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', '1@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:46:16,204 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:46:16,204 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:46:16,204 - INFO - joeynmt.training - 	Hypothesis: La prima volta che ho fatto che vi mostro che vi ho fatto una cosa che è stato un po<unk> di quasi cosa succe<unk> è che è stato un po<unk> di 15 anni fa.
2025-05-29 21:46:19,689 - INFO - joeynmt.training - Epoch   1, Step:     7600, Batch Loss:     2.392332, Batch Acc: 0.314277, Tokens per Sec:    18059, Lr: 0.000300
2025-05-29 21:46:23,128 - INFO - joeynmt.training - Epoch   1, Step:     7700, Batch Loss:     2.393897, Batch Acc: 0.312146, Tokens per Sec:    20355, Lr: 0.000300
2025-05-29 21:46:26,582 - INFO - joeynmt.training - Epoch   1, Step:     7800, Batch Loss:     2.288767, Batch Acc: 0.314180, Tokens per Sec:    20984, Lr: 0.000300
2025-05-29 21:46:30,028 - INFO - joeynmt.training - Epoch   1, Step:     7900, Batch Loss:     2.273712, Batch Acc: 0.313912, Tokens per Sec:    20815, Lr: 0.000300
2025-05-29 21:46:33,466 - INFO - joeynmt.training - Epoch   1, Step:     8000, Batch Loss:     2.156587, Batch Acc: 0.321639, Tokens per Sec:    20158, Lr: 0.000300
2025-05-29 21:46:33,467 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:46:33,467 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:46:43,280 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.31, ppl:  10.04, acc:   0.33, generation: 9.8009[sec], evaluation: 0.0000[sec]
2025-05-29 21:46:43,281 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:46:43,854 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/5500.ckpt
2025-05-29 21:46:43,891 - INFO - joeynmt.training - Example #0
2025-05-29 21:46:43,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:46:43,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:46:43,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'questo', 'è', 'un', 'anno', 'anno', 'di', 'm@@', 'e@@', ',', 'e', 'ho', 'inizi@@', 'ato', 'a', 'fare', 'per', 'cerc@@', 'are', 'di', 'ri@@', 'fl@@', 'it@@', 't@@', 'o@@', ',', 'che', 'la', 'c@@', 'aus@@', 'a', 'di', 'c@@', 'a@@', 'er@@', 'e@@', ',', 'per', 'la', 'prima', 'volta', 'che', 'hanno', 'fatto', 'è', 'il', 'prim@@', 'o', 'di', '1@@', '00', 'anni', 'di', 'anni', 'fa@@', ',', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'di', '4@@', '0', 'e', 'di', '4@@', '0', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:46:43,892 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:46:43,892 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:46:43,892 - INFO - joeynmt.training - 	Hypothesis: E questo è un anno anno di me, e ho iniziato a fare per cercare di riflitto, che la causa di caere, per la prima volta che hanno fatto è il primo di 100 anni di anni fa, per il 40 per cento di 40 anni di 40 e di 40 anni.
2025-05-29 21:46:43,892 - INFO - joeynmt.training - Example #1
2025-05-29 21:46:43,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:46:43,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:46:43,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'problema', 'non', 'è', 'stato', 'il', 'problema', 'di', 'in@@', 'forma@@', 'zione', 'di', 'un', 'problema', 'di', 'in@@', 'forma@@', 'zione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'che', 'non', 'è', 'il', 'problema', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'di', 'essere', 'um@@', 'an@@', 'o@@', '.', '</s>']
2025-05-29 21:46:43,893 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:46:43,893 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:46:43,893 - INFO - joeynmt.training - 	Hypothesis: Ma non è il problema non è stato il problema di informazione di un problema di informazione di questo problema, che non è il problema di carbonio di di essere umano.
2025-05-29 21:46:43,894 - INFO - joeynmt.training - Example #2
2025-05-29 21:46:43,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:46:43,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:46:43,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o@@', ',', 'il', 'nostro', 'sistema', 'di', 'c@@', 'a@@', 'str@@', 'a', 'di', 'un', 'po@@', '<unk>', 'di', 'in@@', 'forma@@', 'zione', 'di', 'un', 'cer@@', 'to', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'c@@', 'a@@', 'er@@', 'e@@', '.', '</s>']
2025-05-29 21:46:43,894 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:46:43,894 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:46:43,894 - INFO - joeynmt.training - 	Hypothesis: In questo caso, il nostro sistema di castra di un po<unk> di informazione di un certo di carbonio di carbonio di carbonio di carbonio di carbonio di caere.
2025-05-29 21:46:43,895 - INFO - joeynmt.training - Example #3
2025-05-29 21:46:43,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:46:43,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:46:43,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'chiam@@', 'a', 'un', 'po@@', '<unk>', 'di', 'b@@', 'om@@', 'b@@', 'o', 'e', 'l@@', '<unk>', 'in@@', 'forma@@', 'zione', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'de@@', 'fin@@', 'i@@', 'zione', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:46:43,895 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:46:43,895 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:46:43,895 - INFO - joeynmt.training - 	Hypothesis: Si chiama un po<unk> di bombo e l<unk> informazione e la sua famiglia e la definizione di un po<unk> .
2025-05-29 21:46:43,895 - INFO - joeynmt.training - Example #4
2025-05-29 21:46:43,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:46:43,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:46:43,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'ho', 'fatto', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'po@@', '<unk>', 'di', 'anni', 'fa@@', ',', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', ',', 'e', 'questo', 'è', 'stato', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:46:43,896 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:46:43,896 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:46:43,896 - INFO - joeynmt.training - 	Hypothesis: La prima volta che ho fatto che vi mostrerò che vi mostrerò un po<unk> di anni fa, che è stato un po<unk> , e questo è stato un po<unk> .
2025-05-29 21:46:47,404 - INFO - joeynmt.training - Epoch   1, Step:     8100, Batch Loss:     2.301574, Batch Acc: 0.319095, Tokens per Sec:    17513, Lr: 0.000300
2025-05-29 21:46:50,879 - INFO - joeynmt.training - Epoch   1, Step:     8200, Batch Loss:     2.299048, Batch Acc: 0.320740, Tokens per Sec:    20679, Lr: 0.000300
2025-05-29 21:46:54,337 - INFO - joeynmt.training - Epoch   1, Step:     8300, Batch Loss:     2.236707, Batch Acc: 0.323278, Tokens per Sec:    20887, Lr: 0.000300
2025-05-29 21:46:57,776 - INFO - joeynmt.training - Epoch   1, Step:     8400, Batch Loss:     2.260719, Batch Acc: 0.322505, Tokens per Sec:    20581, Lr: 0.000300
2025-05-29 21:47:01,223 - INFO - joeynmt.training - Epoch   1, Step:     8500, Batch Loss:     2.349523, Batch Acc: 0.324096, Tokens per Sec:    20338, Lr: 0.000300
2025-05-29 21:47:01,223 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:47:01,223 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:47:09,492 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.77, acc:   0.33, generation: 8.2611[sec], evaluation: 0.0000[sec]
2025-05-29 21:47:09,492 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:47:09,988 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/6000.ckpt
2025-05-29 21:47:10,010 - INFO - joeynmt.training - Example #0
2025-05-29 21:47:10,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:47:10,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:47:10,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questi', 'anni', 'di', 'questi', 'anni', 'per', 'fare', 'per', 'fare', 'per', 'fare', 'il', 'm@@', 'ezz@@', 'o', 'di', 'm@@', 'e@@', ',', 'che', 'la', 'maggi@@', 'or', 'parte', 'della', 'nostra', 'es@@', 'peri@@', 'enza', 'di', 'due', 'mili@@', 'ar@@', 'di', 'di', 'di', 'doll@@', 'ari', 'per', 'la', 'prima', 'volta', 'che', 'ha', 'fatto', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:47:10,012 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:47:10,012 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:47:10,012 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questi anni di questi anni per fare per fare per fare il mezzo di me, che la maggior parte della nostra esperienza di due miliardi di di dollari per la prima volta che ha fatto 40 anni per cento di 40 anni per cento di 40 anni per cento di 40 anni per cento di 40 per cento di 40 anni per cento di 40 per cento di 40 anni per cento di 40 anni fa.
2025-05-29 21:47:10,012 - INFO - joeynmt.training - Example #1
2025-05-29 21:47:10,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:47:10,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:47:10,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'problema', 'non', 'è', 'stato', 'un', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'un', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:47:10,013 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:47:10,013 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:47:10,013 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema non è stato un problema di problema, e non è un problema, non è il problema.
2025-05-29 21:47:10,013 - INFO - joeynmt.training - Example #2
2025-05-29 21:47:10,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:47:10,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:47:10,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'm@@', 'ezz@@', 'o', 'di', 'm@@', 'ezz@@', 'o', 'di', 'm@@', 'ezz@@', 'o', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'm@@', 'ezz@@', 'o', 'di', 'c@@', 'entr@@', 'ale', 'della', 'c@@', 'entr@@', 'ale', 'e', 'la', 'nostra', 'es@@', 'peri@@', 'enza', 'di', 'un', 'sistema', 'di', 'b@@', 'ell@@', 'issi@@', 'mo@@', '.', '</s>']
2025-05-29 21:47:10,014 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:47:10,014 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:47:10,014 - INFO - joeynmt.training - 	Hypothesis: In questo mezzo di mezzo di mezzo di un certo senso di mezzo di centrale della centrale e la nostra esperienza di un sistema di bellissimo.
2025-05-29 21:47:10,014 - INFO - joeynmt.training - Example #3
2025-05-29 21:47:10,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:47:10,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:47:10,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'modo', 'in', 'cui', 'la', 'sua', 'f@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'ig@@', 'lia', 'e', 'il', 'suo', 'n@@', 'om@@', 'e', 'e', 'di', 'pi@@', 'ù@@', '.', '</s>']
2025-05-29 21:47:10,014 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:47:10,014 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:47:10,014 - INFO - joeynmt.training - 	Hypothesis: E in modo in cui la sua figlia e la sua figlia e il suo nome e di più.
2025-05-29 21:47:10,014 - INFO - joeynmt.training - Example #4
2025-05-29 21:47:10,015 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:47:10,015 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:47:10,015 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'po@@', '<unk>', 'di', '1@@', '5', 'anni', 'fa@@', ',', 'è', 'che', 'è', 'succ@@', 'esso', 'a', '1@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:47:10,015 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:47:10,015 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:47:10,015 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostrerò che vi mostrerò un po<unk> di 15 anni fa, è che è successo a 15 anni fa.
2025-05-29 21:47:13,467 - INFO - joeynmt.training - Epoch   1, Step:     8600, Batch Loss:     2.322526, Batch Acc: 0.323707, Tokens per Sec:    18207, Lr: 0.000300
2025-05-29 21:47:16,934 - INFO - joeynmt.training - Epoch   1, Step:     8700, Batch Loss:     2.304739, Batch Acc: 0.324877, Tokens per Sec:    20529, Lr: 0.000300
2025-05-29 21:47:20,372 - INFO - joeynmt.training - Epoch   1, Step:     8800, Batch Loss:     2.253634, Batch Acc: 0.333221, Tokens per Sec:    20684, Lr: 0.000300
2025-05-29 21:47:23,804 - INFO - joeynmt.training - Epoch   1, Step:     8900, Batch Loss:     2.413224, Batch Acc: 0.328914, Tokens per Sec:    20246, Lr: 0.000300
2025-05-29 21:47:27,220 - INFO - joeynmt.training - Epoch   1, Step:     9000, Batch Loss:     2.300927, Batch Acc: 0.331415, Tokens per Sec:    20151, Lr: 0.000300
2025-05-29 21:47:27,220 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:47:27,220 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:47:38,062 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.47, acc:   0.34, generation: 10.8298[sec], evaluation: 0.0000[sec]
2025-05-29 21:47:38,063 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:47:38,617 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/6500.ckpt
2025-05-29 21:47:38,642 - INFO - joeynmt.training - Example #0
2025-05-29 21:47:38,642 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:47:38,642 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:47:38,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'in', 'questo', 'cas@@', 'o', 'per', 'fare', 'il', 'mio', 'p@@', 'ad@@', 're', 'per', 'il', 'nostro', 'pian@@', 'eta', 'che', 'si', 'è', 'l@@', '<unk>', 'un@@', 'ica', 'che', 'il', 'mio', 's@@', 'ito', 'per', 'tre', 'anni', 'fa@@', ',', 'per', 'tre', 'anni', 'di', 'tre', 'anni', 'di', 'tre', 'an@@', 'ni@@', ',', 'per', 'tre', 'anni', 'di', '1@@', '5', 'an@@', 'ni@@', ',', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:47:38,643 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:47:38,643 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:47:38,643 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno in questo caso per fare il mio padre per il nostro pianeta che si è l<unk> unica che il mio sito per tre anni fa, per tre anni di tre anni di tre anni, per tre anni di 15 anni, per il 40 per cento di 40 anni.
2025-05-29 21:47:38,643 - INFO - joeynmt.training - Example #1
2025-05-29 21:47:38,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:47:38,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:47:38,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 's@@', 'b@@', 'ag@@', 'li@@', 'at@@', 'o@@', ',', 'e', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:47:38,644 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:47:38,644 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:47:38,644 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di sbagliato, e non è il problema, non è il problema.
2025-05-29 21:47:38,644 - INFO - joeynmt.training - Example #2
2025-05-29 21:47:38,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:47:38,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:47:38,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'mio', 'p@@', 'ad@@', 're', 'il', 'nostro', 'sistema', 'di', 's@@', 'an@@', 'gu@@', 'e', 'il', 'nostro', 'sistema', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'un', 'sistema', 'di', 'g@@', 'over@@', 'no', 'del', 'nostro', 'sistema', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'un', 'sistema', 'di', 'g@@', 'ar@@', 'g@@', 'o', 'di', 's@@', 'an@@', 'gu@@', 'e', 'di', 'l@@', '<unk>', 'in@@', 'tel@@', 'li@@', 'gen@@', 'za', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'un', 'sistema', 'di', 'g@@', 'ar@@', 'g@@', 'omento', 'di', 'in@@', 'segn@@', 'are', 'il', 'nostro', 'sistema', 'di', 'in@@', 'segn@@', 'are', 'il', 'nostro', 'sistema', 'di', 's@@', 'an@@', 'gu@@', 'e', 'di', 's@@', 'é', 'il', 'nostro', 'sistema', 'di', 's@@', 'an@@', 'gu@@', 'e', 'il', 'nostro', 'sistema', 'di', 's@@', 'an@@', 'gu@@', 'ag@@', 'li@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 21:47:38,645 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:47:38,645 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:47:38,645 - INFO - joeynmt.training - 	Hypothesis: Nel mio padre il nostro sistema di sangue il nostro sistema di carbonio di un sistema di governo del nostro sistema di carbonio di un sistema di gargo di sangue di l<unk> intelligenza di carbonio di un sistema di gargomento di insegnare il nostro sistema di insegnare il nostro sistema di sangue di sé il nostro sistema di sangue il nostro sistema di sanguagliato.
2025-05-29 21:47:38,645 - INFO - joeynmt.training - Example #3
2025-05-29 21:47:38,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:47:38,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:47:38,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'ho', 'fatto', 'il', 'suo', 's@@', 'ito', 'e', 'il', 'suo', 's@@', 'ac@@', 'co', 'di', 's@@', 'om@@', 'ma@@', '.', '</s>']
2025-05-29 21:47:38,646 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:47:38,646 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:47:38,646 - INFO - joeynmt.training - 	Hypothesis: L<unk> ho fatto il suo sito e il suo sacco di somma.
2025-05-29 21:47:38,646 - INFO - joeynmt.training - Example #4
2025-05-29 21:47:38,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:47:38,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:47:38,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'po@@', '<unk>', 'di', 's@@', 'om@@', 'ig@@', 'li@@', ',', 'e', 'il', '1@@', '1@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:47:38,647 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:47:38,647 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:47:38,647 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostro che vi vi mostrerò un po<unk> di somigli, e il 115 anni.
2025-05-29 21:47:42,146 - INFO - joeynmt.training - Epoch   1, Step:     9100, Batch Loss:     2.360475, Batch Acc: 0.327310, Tokens per Sec:    17552, Lr: 0.000300
2025-05-29 21:47:45,600 - INFO - joeynmt.training - Epoch   1, Step:     9200, Batch Loss:     2.268062, Batch Acc: 0.331135, Tokens per Sec:    20423, Lr: 0.000300
2025-05-29 21:47:49,039 - INFO - joeynmt.training - Epoch   1, Step:     9300, Batch Loss:     2.205280, Batch Acc: 0.341785, Tokens per Sec:    20698, Lr: 0.000300
2025-05-29 21:47:52,502 - INFO - joeynmt.training - Epoch   1, Step:     9400, Batch Loss:     2.273545, Batch Acc: 0.331695, Tokens per Sec:    20631, Lr: 0.000300
2025-05-29 21:47:55,951 - INFO - joeynmt.training - Epoch   1, Step:     9500, Batch Loss:     2.319104, Batch Acc: 0.332635, Tokens per Sec:    20758, Lr: 0.000300
2025-05-29 21:47:55,952 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:47:55,952 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:48:06,529 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.26, acc:   0.35, generation: 10.5640[sec], evaluation: 0.0000[sec]
2025-05-29 21:48:06,529 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:48:07,051 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/7000.ckpt
2025-05-29 21:48:07,077 - INFO - joeynmt.training - Example #0
2025-05-29 21:48:07,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:48:07,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:48:07,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'ho', 'inizi@@', 'ato', 'a', 'questo', 'ann@@', 'o@@', ',', 'ho', 'inizi@@', 'ato', 'per', 'per', 'creare', 'un', 'pa@@', 'es@@', 'aggio', 'per', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'un', 'pa@@', 'ese', 'che', 'la', 'c@@', 'aus@@', 'a', 'di', 'tre', 'anni', 'di', 'tre', 'anni', 'di', 'tre', 'anni', 'di', 'tre', 'anni', 'di', '4@@', '0', 'anni', 'di', '4@@', '0', 'anni', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'pa@@', 'es@@', 'e@@', '.', '</s>']
2025-05-29 21:48:07,078 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:48:07,078 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:48:07,078 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno ho iniziato a questo anno, ho iniziato per per creare un paesaggio per la popolazione di un paese che la causa di tre anni di tre anni di tre anni di tre anni di 40 anni di 40 anni di 40 anni per cento di 40 per cento di 40 per cento di 40 per cento di 40 per cento di 40 per cento per cento per il 40 per cento di un paese.
2025-05-29 21:48:07,078 - INFO - joeynmt.training - Example #1
2025-05-29 21:48:07,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:48:07,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:48:07,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'si', 'tr@@', 'at@@', 'ta', 'di', 'questo', 'non', 'è', 'il', 'problema', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'problema', 'di', 'cui', 'non', 'è', 'il', 'problema', 'del', 'mon@@', 'd@@', 'o@@', '.', '</s>']
2025-05-29 21:48:07,079 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:48:07,079 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:48:07,079 - INFO - joeynmt.training - 	Hypothesis: Ma non si tratta di questo non è il problema di questo problema, non è il problema di problema, non è il problema di cui non è il problema del mondo.
2025-05-29 21:48:07,079 - INFO - joeynmt.training - Example #2
2025-05-29 21:48:07,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:48:07,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:48:07,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'è', 'una', 'c@@', 'aus@@', 'a', 'di', 'c@@', 'l@@', 'ass@@', 'ic@@', 'ur@@', 'a@@', ',', 'la', 'nostra', 'c@@', 'aus@@', 'a', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'c@@', 'arb@@', 'on@@', 'i@@', 'o@@', '.', '</s>']
2025-05-29 21:48:07,080 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:48:07,080 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:48:07,080 - INFO - joeynmt.training - 	Hypothesis: In realtà è una causa di classicura, la nostra causa di un certo senso di carbonio.
2025-05-29 21:48:07,080 - INFO - joeynmt.training - Example #3
2025-05-29 21:48:07,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:48:07,081 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:48:07,081 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ig@@', 'li@@', 'a@@', '.', '</s>']
2025-05-29 21:48:07,081 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:48:07,081 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:48:07,081 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un po<unk> di somma di somma di somma di somma di somiglia.
2025-05-29 21:48:07,081 - INFO - joeynmt.training - Example #4
2025-05-29 21:48:07,081 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:48:07,081 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:48:07,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'a', 'che', 'cosa', 'succ@@', 'e@@', 'de@@', 'va', 'in', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'è', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'vi', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'a', 'che', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'a', 'che', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'e@@', 'de@@', 'va', 'in', 'un', 'modo', 'di', 'far@@', 'e@@', '.', '</s>']
2025-05-29 21:48:07,082 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:48:07,082 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:48:07,082 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostra che vi vi mostrerò che vi mostra che cosa succedeva in una cosa che è successo in una cosa che è successo in una cosa che è successo è che è successo in cui vi mostrerò che la prima volta che vi mostra che vi vi vi mostrerò che vi mostra che la prima volta che vi mostra che la prima volta che vi mostra cosa succedeva in un modo di fare.
2025-05-29 21:48:10,538 - INFO - joeynmt.training - Epoch   1, Step:     9600, Batch Loss:     2.217276, Batch Acc: 0.337139, Tokens per Sec:    17223, Lr: 0.000300
2025-05-29 21:48:13,988 - INFO - joeynmt.training - Epoch   1, Step:     9700, Batch Loss:     2.146796, Batch Acc: 0.335671, Tokens per Sec:    20706, Lr: 0.000300
2025-05-29 21:48:17,420 - INFO - joeynmt.training - Epoch   1, Step:     9800, Batch Loss:     2.150216, Batch Acc: 0.341872, Tokens per Sec:    20483, Lr: 0.000300
2025-05-29 21:48:20,861 - INFO - joeynmt.training - Epoch   1, Step:     9900, Batch Loss:     2.381231, Batch Acc: 0.339521, Tokens per Sec:    20650, Lr: 0.000300
2025-05-29 21:48:24,296 - INFO - joeynmt.training - Epoch   1, Step:    10000, Batch Loss:     2.446911, Batch Acc: 0.344739, Tokens per Sec:    21065, Lr: 0.000300
2025-05-29 21:48:24,297 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:48:24,297 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:48:34,578 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.04, acc:   0.36, generation: 10.2684[sec], evaluation: 0.0000[sec]
2025-05-29 21:48:34,579 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:48:35,112 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/7500.ckpt
2025-05-29 21:48:35,138 - INFO - joeynmt.training - Example #0
2025-05-29 21:48:35,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:48:35,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:48:35,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'ho', 'visto', 'questo', 'è', 'il', 'ann@@', 'o@@', ',', 'che', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'un', 'anno', 'di', 'b@@', 'an@@', 'c@@', 'a@@', ',', 'che', 'la', 'c@@', 'ura', 'di', 'un', 'pa@@', 'io', 'di', 'di', '1@@', '00', 'milioni', 'di', 'anni', 'per', 'tre', 'anni', 'per', 'tre', 'anni', 'di', 'tre', 'anni', 'di', '1@@', '00', 'anni', 'per', 'tre', 'anni', 'per', 'tre', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'c@@', 'ento', 'di', 'un', 'anno', 'per', 'il', '9@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '.', '</s>']
2025-05-29 21:48:35,139 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:48:35,140 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:48:35,140 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno ho visto questo è il anno, che la popolazione di un anno di banca, che la cura di un paio di di 100 milioni di anni per tre anni per tre anni di tre anni di 100 anni per tre anni per tre anni per il 40 per cento per il 40 per cento per il 40 per cento per il 40 per cento di 40 per cento per cento di un anno per il 9000000000.
2025-05-29 21:48:35,140 - INFO - joeynmt.training - Example #1
2025-05-29 21:48:35,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:48:35,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:48:35,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'problema', 'non', 'è', 'un', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'il', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'D@@', 'ic@@', 'ic@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 21:48:35,140 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:48:35,140 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:48:35,141 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema non è un problema di problema, il problema, non è il problema, non è il Dicicico.
2025-05-29 21:48:35,141 - INFO - joeynmt.training - Example #2
2025-05-29 21:48:35,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:48:35,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:48:35,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'è', 'il', 'nostro', 'sistema', 'di', 'S@@', 'in@@', 'e@@', ',', 'il', 'nostro', 'sistema', 'di', 'E@@', 'b@@', 're@@', 've', 'il', 'nostro', 'sistema', 'di', 'al@@', 'ber@@', 'i', 'del', 'nostro', 'sistema', 'di', 'al@@', 'im@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 21:48:35,141 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:48:35,141 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:48:35,141 - INFO - joeynmt.training - 	Hypothesis: In realtà è il nostro sistema di Sine, il nostro sistema di Ebreve il nostro sistema di alberi del nostro sistema di alimento.
2025-05-29 21:48:35,142 - INFO - joeynmt.training - Example #3
2025-05-29 21:48:35,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:48:35,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:48:35,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'che', 'è', 'stato', 'un', 'p@@', 'ò', 'di', 'pi@@', 'ù@@', '.', '</s>']
2025-05-29 21:48:35,142 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:48:35,142 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:48:35,142 - INFO - joeynmt.training - 	Hypothesis: E la cosa che è stato un pò di più.
2025-05-29 21:48:35,142 - INFO - joeynmt.training - Example #4
2025-05-29 21:48:35,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:48:35,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:48:35,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'ho', 'fatto', 'che', 'vi', 'mostr@@', 'a', 'un', 'po@@', '<unk>', 'di', '1@@', '5', 'anni', 'fa', 'è', 'un', 'po@@', '<unk>', 'più', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'di', '1@@', '5', 'anni', 'fa', 'in', '1@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:48:35,143 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:48:35,143 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:48:35,143 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che ho fatto che vi mostra un po<unk> di 15 anni fa è un po<unk> più di 15 anni di 15 anni di 15 anni fa in 15 anni fa.
2025-05-29 21:48:38,604 - INFO - joeynmt.training - Epoch   1, Step:    10100, Batch Loss:     2.220913, Batch Acc: 0.347931, Tokens per Sec:    17678, Lr: 0.000300
2025-05-29 21:48:42,055 - INFO - joeynmt.training - Epoch   1, Step:    10200, Batch Loss:     2.238421, Batch Acc: 0.345803, Tokens per Sec:    20531, Lr: 0.000300
2025-05-29 21:48:45,514 - INFO - joeynmt.training - Epoch   1, Step:    10300, Batch Loss:     2.242135, Batch Acc: 0.344486, Tokens per Sec:    20411, Lr: 0.000300
2025-05-29 21:48:48,933 - INFO - joeynmt.training - Epoch   1, Step:    10400, Batch Loss:     2.129186, Batch Acc: 0.350040, Tokens per Sec:    20731, Lr: 0.000300
2025-05-29 21:48:52,348 - INFO - joeynmt.training - Epoch   1, Step:    10500, Batch Loss:     2.264490, Batch Acc: 0.343730, Tokens per Sec:    20295, Lr: 0.000300
2025-05-29 21:48:52,348 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:48:52,348 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:49:02,248 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.87, acc:   0.36, generation: 9.8914[sec], evaluation: 0.0000[sec]
2025-05-29 21:49:02,248 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:49:02,718 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/8000.ckpt
2025-05-29 21:49:02,739 - INFO - joeynmt.training - Example #0
2025-05-29 21:49:02,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:49:02,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:49:02,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'ho', 'visto', 'queste', 'cose', 'che', 'ho', 'sc@@', 'oper@@', 'to', 'che', 'la', 'gente', 'per', 'ri@@', 'fer@@', 'im@@', 'ento', 'per', 'ri@@', 'dur@@', 're', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'un', 'm@@', 'ezz@@', 'o', 'di', 'm@@', 'ezz@@', 'o', 'di', 'tre', 'anni', 'fa@@', ',', 'le', 'tre', 'anni', 'fa@@', ',', 'le', 'tre', 'anni', 'fa@@', ',', 'e', 'l@@', '<unk>', '8@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'milioni', 'di', 'persone', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'per', 'l@@', '<unk>', 'un@@', 'ica', 'di', 'l@@', '<unk>', 'in@@', 'segn@@', 'amento', 'per', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'per', 'la', 'l@@', 'et@@', 'ta', 'di', 'c@@', 'ur@@', 'a@@', '.', '</s>']
2025-05-29 21:49:02,740 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:49:02,740 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:49:02,740 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno ho visto queste cose che ho scoperto che la gente per riferimento per ridurre la popolazione di un mezzo di mezzo di tre anni fa, le tre anni fa, le tre anni fa, e l<unk> 80 anni per cento di 40 anni per cento di 40 milioni di persone per cento di 40 anni per cento di 40 anni per cento per l<unk> unica di l<unk> insegnamento per la popolazione per la letta di cura.
2025-05-29 21:49:02,740 - INFO - joeynmt.training - Example #1
2025-05-29 21:49:02,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:49:02,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:49:02,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'cosa', 'che', 'non', 'è', 'la', 'ri@@', 'vol@@', 't@@', 'a@@', ',', 'non', 'è', 'la', 'maggi@@', 'or', 'parte', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'di', 'E@@', 'g@@', 'h@@', 'ic@@', 'k@@', '.', '</s>']
2025-05-29 21:49:02,741 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:49:02,741 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:49:02,741 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa che non è la rivolta, non è la maggior parte di questo problema, non è la squadra di Eghick.
2025-05-29 21:49:02,741 - INFO - joeynmt.training - Example #2
2025-05-29 21:49:02,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:49:02,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:49:02,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'è', 'la', 'stessa', 'cos@@', 'a@@', ',', 'la', 'maggi@@', 'or', 'parte', 'del', 'nostro', 'cor@@', 'po', 'di', 'un', 'sistema', 'di', 'c@@', 'arb@@', 'on@@', 'io', 'di', 'l@@', '<unk>', 'es@@', 'peri@@', 'enza', 'della', 'nostra', 'nat@@', 'ur@@', 'a@@', '.', '</s>']
2025-05-29 21:49:02,742 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:49:02,742 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:49:02,742 - INFO - joeynmt.training - 	Hypothesis: In realtà è la stessa cosa, la maggior parte del nostro corpo di un sistema di carbonio di l<unk> esperienza della nostra natura.
2025-05-29 21:49:02,742 - INFO - joeynmt.training - Example #3
2025-05-29 21:49:02,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:49:02,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:49:02,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 're@@', 'do', 'che', 'la', 's@@', 'itu@@', 'azione', 'è', 'la', 'sua', 'v@@', 'it@@', 'a@@', '.', '</s>']
2025-05-29 21:49:02,743 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:49:02,743 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:49:02,743 - INFO - joeynmt.training - 	Hypothesis: Credo che la situazione è la sua vita.
2025-05-29 21:49:02,743 - INFO - joeynmt.training - Example #4
2025-05-29 21:49:02,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:49:02,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:49:02,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'ede', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'vi', 'è', 'succ@@', 'esso', 'in', 'cui', 'vi', 'mostr@@', 'a', 'che', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'e@@', 'de@@', 'va', 'in', 'cui', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'ede', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'ede', 'in', 'cui', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'e@@', 'de@@', 'va', 'in', 'cui', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'e@@', 'de@@', 'va', 'in', 'cui', 'vi', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'vi', 'sono', 'più']
2025-05-29 21:49:02,744 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:49:02,744 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:49:02,744 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostra che vi vi mostra che vi mostra cosa succede è una cosa che è successo in cui è successo in cui è successo in cui è successo in cui vi è successo in cui vi mostra che la prima volta che vi mostra che vi mostra cosa succedeva in cui vi mostra che vi mostra che vi mostra cosa succede che vi mostra cosa succede in cui vi mostra cosa succedeva in cui vi mostra cosa succedeva in cui vi è una cosa che è successo in cui vi sono più
2025-05-29 21:49:06,163 - INFO - joeynmt.training - Epoch   1, Step:    10600, Batch Loss:     2.199151, Batch Acc: 0.352230, Tokens per Sec:    18773, Lr: 0.000300
2025-05-29 21:49:09,562 - INFO - joeynmt.training - Epoch   1, Step:    10700, Batch Loss:     2.148453, Batch Acc: 0.348024, Tokens per Sec:    21345, Lr: 0.000300
2025-05-29 21:49:09,845 - INFO - joeynmt.training - Epoch   1: total training loss 28119.11
2025-05-29 21:49:09,845 - INFO - joeynmt.training - EPOCH 2
2025-05-29 21:49:12,893 - INFO - joeynmt.training - Epoch   2, Step:    10800, Batch Loss:     2.236220, Batch Acc: 0.360570, Tokens per Sec:    21343, Lr: 0.000300
2025-05-29 21:49:16,181 - INFO - joeynmt.training - Epoch   2, Step:    10900, Batch Loss:     2.206486, Batch Acc: 0.357980, Tokens per Sec:    21532, Lr: 0.000300
2025-05-29 21:49:19,471 - INFO - joeynmt.training - Epoch   2, Step:    11000, Batch Loss:     2.137371, Batch Acc: 0.359041, Tokens per Sec:    21481, Lr: 0.000300
2025-05-29 21:49:19,471 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:49:19,471 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:49:28,997 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.16, ppl:   8.70, acc:   0.36, generation: 9.5148[sec], evaluation: 0.0000[sec]
2025-05-29 21:49:28,998 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:49:29,469 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/8500.ckpt
2025-05-29 21:49:29,493 - INFO - joeynmt.training - Example #0
2025-05-29 21:49:29,493 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:49:29,493 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:49:29,493 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questa', 's@@', 'qu@@', 'ad@@', 'ra', 'di', 'queste', 'par@@', 'ole', 'per', 'lavor@@', 'are', 'per', 'lavor@@', 'are', 'in', 'un', 'pa@@', 'io', 'di', 'c@@', 'r@@', 'ar@@', 'e@@', ',', 'che', 'la', 'ri@@', 'vol@@', 't@@', 'a@@', ',', 'per', 'tre', 'anni', 'di', 'tre', 'anni', 'di', 'tre', 'anni', 'di', '1@@', '8@@', '0', 'e', 'c@@', 'ento', 'di', '4@@', '0', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:49:29,494 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:49:29,494 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:49:29,494 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questa squadra di queste parole per lavorare per lavorare in un paio di crare, che la rivolta, per tre anni di tre anni di tre anni di 180 e cento di 40 anni.
2025-05-29 21:49:29,494 - INFO - joeynmt.training - Example #1
2025-05-29 21:49:29,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:49:29,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:49:29,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'n@@', 'ec@@', 'ess@@', 'ar@@', 'i@@', 'amente', 'la', 's@@', 'itu@@', 'azione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'di@@', 'stri@@', 'bu@@', 'zione', 'di', 'un', 'problema', 'di', 's@@', 'ac@@', 'ri@@', 'm@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 21:49:29,495 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:49:29,495 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:49:29,495 - INFO - joeynmt.training - 	Hypothesis: Ma non è necessariamente la situazione di questo problema, non è la distribuzione di un problema di sacrimico.
2025-05-29 21:49:29,495 - INFO - joeynmt.training - Example #2
2025-05-29 21:49:29,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:49:29,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:49:29,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'di', 's@@', 'an@@', 'gu@@', 'e', 'è', 'la', 's@@', 'itu@@', 'azione', 'di', 'un', 'sistema', 'di', 'in@@', 'segn@@', 'are', 'la', 'nostra', 'con@@', 'fer@@', 'enza', 'del', 'nostro', 'sistema', 'di', 'sistema', 'di', 'in@@', 'segn@@', 'are', 'il', 'sistema', 'di', 'al@@', 'im@@', 'ent@@', 'ar@@', 'e@@', '.', '</s>']
2025-05-29 21:49:29,496 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:49:29,496 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:49:29,496 - INFO - joeynmt.training - 	Hypothesis: In questo caso di sangue è la situazione di un sistema di insegnare la nostra conferenza del nostro sistema di sistema di insegnare il sistema di alimentare.
2025-05-29 21:49:29,496 - INFO - joeynmt.training - Example #3
2025-05-29 21:49:29,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:49:29,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:49:29,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'os@@', 'siamo', 'in@@', 'tr@@', 'o@@', 'vi@@', 'amo', 'in', 'gi@@', 'ro', 'e', 'il', 'suo', 'n@@', 'om@@', 'e', 'e', 'in', 'gi@@', 'ro', 'e', 'il', 'suo', 's@@', 'om@@', 'ig@@', 'li@@', 'o@@', '.', '</s>']
2025-05-29 21:49:29,497 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:49:29,497 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:49:29,497 - INFO - joeynmt.training - 	Hypothesis: Possiamo introviamo in giro e il suo nome e in giro e il suo somiglio.
2025-05-29 21:49:29,497 - INFO - joeynmt.training - Example #4
2025-05-29 21:49:29,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:49:29,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:49:29,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'ede', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'si', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'gra@@', 'do', 'di', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:49:29,497 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:49:29,497 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:49:29,497 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostrerò che vi mostrerò una cosa che vi mostra cosa succede in cui è successo in cui si è successo in cui è successo in grado di anni fa.
2025-05-29 21:49:32,856 - INFO - joeynmt.training - Epoch   2, Step:    11100, Batch Loss:     2.329686, Batch Acc: 0.356881, Tokens per Sec:    18187, Lr: 0.000300
2025-05-29 21:49:36,190 - INFO - joeynmt.training - Epoch   2, Step:    11200, Batch Loss:     2.074558, Batch Acc: 0.355361, Tokens per Sec:    21654, Lr: 0.000300
2025-05-29 21:49:39,489 - INFO - joeynmt.training - Epoch   2, Step:    11300, Batch Loss:     2.197963, Batch Acc: 0.364316, Tokens per Sec:    22100, Lr: 0.000300
2025-05-29 21:49:42,780 - INFO - joeynmt.training - Epoch   2, Step:    11400, Batch Loss:     2.148227, Batch Acc: 0.360350, Tokens per Sec:    20747, Lr: 0.000300
2025-05-29 21:49:46,078 - INFO - joeynmt.training - Epoch   2, Step:    11500, Batch Loss:     2.072215, Batch Acc: 0.357853, Tokens per Sec:    21475, Lr: 0.000300
2025-05-29 21:49:46,078 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:49:46,078 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:49:54,629 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.14, ppl:   8.53, acc:   0.37, generation: 8.5423[sec], evaluation: 0.0000[sec]
2025-05-29 21:49:54,629 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:49:55,116 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/9000.ckpt
2025-05-29 21:49:55,140 - INFO - joeynmt.training - Example #0
2025-05-29 21:49:55,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:49:55,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:49:55,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'ho', 'sc@@', 'oper@@', 'to', 'questo', 'ann@@', 'o@@', ',', 'ho', 'sc@@', 'oper@@', 'to', 'che', 'la', 'gente', 'ha', 'fatto', 'che', 'la', 'gente', 'che', 'la', 'gente', 'che', 'la', 'maggi@@', 'or', 'parte', 'di', 'un', 'pa@@', 'io', 'di', 'mili@@', 'ar@@', 'di', 'di', 'di', 'anni', 'e', 'tre', 'mili@@', 'ar@@', 'di', 'di', 'anni', 'e', 'l@@', '<unk>', '8@@', '0', 'mili@@', 'on@@', 'i@@', '.', '</s>']
2025-05-29 21:49:55,141 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:49:55,141 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:49:55,141 - INFO - joeynmt.training - 	Hypothesis: L<unk> ho scoperto questo anno, ho scoperto che la gente ha fatto che la gente che la gente che la maggior parte di un paio di miliardi di di anni e tre miliardi di anni e l<unk> 80 milioni.
2025-05-29 21:49:55,141 - INFO - joeynmt.training - Example #1
2025-05-29 21:49:55,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:49:55,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:49:55,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'più', 'grande', 's@@', 'par@@', 'it@@', 'a@@', ',', 'non', 'è', 'la', 'ver@@', 'sione', 'del', 'D@@', 'ic@@', 'o@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'azione', 'del', 'D@@', 'E@@', ',', 'non', 'la', 's@@', 'itu@@', 'azione', 'del', 'D@@', 'E@@', 'g@@', '.', '</s>']
2025-05-29 21:49:55,142 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:49:55,142 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:49:55,142 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> più grande sparita, non è la versione del Dico, non è la dimostrazione del DE, non la situazione del DEg.
2025-05-29 21:49:55,142 - INFO - joeynmt.training - Example #2
2025-05-29 21:49:55,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:49:55,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:49:55,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'altre', 'par@@', 'ole', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'un', 'sistema', 'di', 'in@@', 'forma@@', 'zione', 'di', 'un', 'sistema', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'del', 'nostro', 'sistema', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'del', 'nostro', 'sistema', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'un', 'sistema', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'un', 'sistema', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'un', 'sistema', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'in@@', 'segn@@', 'are', 'il', 'nostro', 'sistema', 'di', 'in@@', 's@@', 'an@@', 'it@@', 'ar@@', 'i@@', 'o@@', ',', 'e', 'la', 'nostra', 'c@@', 'aus@@', 'a', 'di', 'un', 'sistema', 'di', 'in@@', 'segn@@', 'are', 'il', 'nostro', 'sistema', 'di', 'in@@', 's@@', 'etti@@', 'man@@', 'e', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'in@@', 's@@', 'etti@@', 'man@@', 'e', 'di', 'in@@', 'segn@@', 'are', 'il', 'nostro', 'sistema', 'di', 'in@@']
2025-05-29 21:49:55,143 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:49:55,143 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:49:55,143 - INFO - joeynmt.training - 	Hypothesis: In altre parole è la causa di un sistema di informazione di un sistema di influenza del nostro sistema di influenza del nostro sistema di influenza di un sistema di influenza di un sistema di influenza di influenza di un sistema di influenza di insegnare il nostro sistema di insanitario, e la nostra causa di un sistema di insegnare il nostro sistema di insettimane di influenza di insettimane di insegnare il nostro sistema di in
2025-05-29 21:49:55,143 - INFO - joeynmt.training - Example #3
2025-05-29 21:49:55,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:49:55,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:49:55,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E@@', '<unk>', 'la', 'cosa', 'più', 'al@@', 'to', 'e', 'la', 'sua', 'f@@', 'am@@', 'ma', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:49:55,143 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:49:55,143 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:49:55,143 - INFO - joeynmt.training - 	Hypothesis: E<unk> la cosa più alto e la sua famma di un po<unk> .
2025-05-29 21:49:55,144 - INFO - joeynmt.training - Example #4
2025-05-29 21:49:55,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:49:55,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:49:55,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', 'o', 'prim@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'po@@', '<unk>', 'di', 'più', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'fa', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'vi', 'mostr@@', 'a', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:49:55,144 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:49:55,144 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:49:55,144 - INFO - joeynmt.training - 	Hypothesis: Il primo primo che vi mostro che vi mostrerò un po<unk> di più di quello che è successo in cui è successo in 25 anni fa in cui è successo in cui vi mostra 25 anni fa.
2025-05-29 21:49:58,518 - INFO - joeynmt.training - Epoch   2, Step:    11600, Batch Loss:     2.297654, Batch Acc: 0.359169, Tokens per Sec:    18660, Lr: 0.000300
2025-05-29 21:50:01,878 - INFO - joeynmt.training - Epoch   2, Step:    11700, Batch Loss:     2.231109, Batch Acc: 0.362599, Tokens per Sec:    21079, Lr: 0.000300
2025-05-29 21:50:05,218 - INFO - joeynmt.training - Epoch   2, Step:    11800, Batch Loss:     2.152530, Batch Acc: 0.367004, Tokens per Sec:    21027, Lr: 0.000300
2025-05-29 21:50:08,574 - INFO - joeynmt.training - Epoch   2, Step:    11900, Batch Loss:     2.311926, Batch Acc: 0.366814, Tokens per Sec:    21406, Lr: 0.000300
2025-05-29 21:50:11,929 - INFO - joeynmt.training - Epoch   2, Step:    12000, Batch Loss:     2.112128, Batch Acc: 0.365936, Tokens per Sec:    21186, Lr: 0.000300
2025-05-29 21:50:11,929 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:50:11,929 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:50:21,911 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.13, ppl:   8.39, acc:   0.38, generation: 9.9684[sec], evaluation: 0.0000[sec]
2025-05-29 21:50:21,912 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:50:22,421 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/9500.ckpt
2025-05-29 21:50:22,440 - INFO - joeynmt.training - Example #0
2025-05-29 21:50:22,441 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:50:22,441 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:50:22,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'in', 'questa', 'st@@', 'anza', 'di', 'ri@@', 'pres@@', 'e', 'per', 'fare', 'un', 'pa@@', 'io', 'di', 'di', 's@@', 'é', 'che', 'la', 'gente', 'è', 'che', 'la', 'c@@', 'aus@@', 'a', 'di', 'questi', 'tre', 'anni', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'e', 'di', 'anni', 'e', 'due', 'milioni', 'di', 'anni', 'e', 'di', '4@@', '0', 'anni', 'e', 'hanno', '4@@', '0', 'anni', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 21:50:22,441 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:50:22,441 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:50:22,441 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno in questa stanza di riprese per fare un paio di di sé che la gente è che la causa di questi tre anni per i tre milioni di anni e di anni e due milioni di anni e di 40 anni e hanno 40 anni per cento.
2025-05-29 21:50:22,441 - INFO - joeynmt.training - Example #1
2025-05-29 21:50:22,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:50:22,442 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:50:22,442 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'problema', 'di', 'in@@', 'segn@@', 'anti', 'di', 's@@', 'é', 'la', 's@@', 'itu@@', 'azione', 'di', 'questa', 's@@', 'itu@@', 'azione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'l@@', 'et@@', 'ter@@', 'a', 'di', 'E@@', 'g@@', 'n@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 21:50:22,442 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:50:22,442 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:50:22,442 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema di insegnanti di sé la situazione di questa situazione di questo problema, non è la lettera di Egnica.
2025-05-29 21:50:22,442 - INFO - joeynmt.training - Example #2
2025-05-29 21:50:22,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:50:22,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:50:22,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'non', 'lo', 'sap@@', 'pi@@', 'amo', 'è', 'la', 'ri@@', 'pres@@', 'a', 'la', 'ri@@', 'vol@@', 't@@', 'a@@', ',', 'il', 'nostro', 'sistema', 'di', 'des@@', 'ig@@', 'n', 'del', 'nostro', 'sistema', 'di', 'mat@@', 'em@@', 'at@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 21:50:22,443 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:50:22,443 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:50:22,443 - INFO - joeynmt.training - 	Hypothesis: In realtà non lo sappiamo è la ripresa la rivolta, il nostro sistema di design del nostro sistema di matematico.
2025-05-29 21:50:22,443 - INFO - joeynmt.training - Example #3
2025-05-29 21:50:22,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:50:22,444 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:50:22,444 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma', 'di', 'una', 'b@@', 'om@@', 'b@@', 'a', 'e', 'la', 'm@@', 'om@@', 'ent@@', 'a@@', '.', '</s>']
2025-05-29 21:50:22,444 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:50:22,444 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:50:22,444 - INFO - joeynmt.training - 	Hypothesis: Lo somma di somma di una bomba e la momenta.
2025-05-29 21:50:22,444 - INFO - joeynmt.training - Example #4
2025-05-29 21:50:22,444 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:50:22,444 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:50:22,445 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'questo', 'cas@@', 'o', 'è', 'succ@@', 'esso', 'in', 'questo', 'cas@@', 'o', 'è', 'succ@@', 'esso', 'in', 'questo', 'cas@@', 'o', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'un', 'modo', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'la', 'prima', 'cosa', 'è', 'succ@@', 'esso', 'in', 'cui', 'la', 'cosa', 'più', 'fa@@', 'ci@@', 'le', 'è', 'che', 'è', 'succ@@', 'esso', 'in', 'un', 'modo', 'di', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'la', 'cosa', 'che', 'è', 'succ@@', 'essi@@', 'v@@', 'amente', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'tutto', 'il', 'mon@@', 'd@@', 'o@@', '.', '</s>']
2025-05-29 21:50:22,445 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:50:22,445 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:50:22,445 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostro che vi è una cosa che è una cosa che è successo in questo caso è successo in questo caso è successo in questo caso è successo in cui è successo in un modo in cui è successo in cui è la prima cosa è successo in cui la cosa più facile è che è successo in un modo di cui è successo in cui la cosa che è successivamente una cosa che è successo in tutto il mondo.
2025-05-29 21:50:25,844 - INFO - joeynmt.training - Epoch   2, Step:    12100, Batch Loss:     2.177496, Batch Acc: 0.370446, Tokens per Sec:    18118, Lr: 0.000300
2025-05-29 21:50:29,230 - INFO - joeynmt.training - Epoch   2, Step:    12200, Batch Loss:     2.118106, Batch Acc: 0.364016, Tokens per Sec:    20804, Lr: 0.000300
2025-05-29 21:50:32,594 - INFO - joeynmt.training - Epoch   2, Step:    12300, Batch Loss:     2.090364, Batch Acc: 0.368688, Tokens per Sec:    21505, Lr: 0.000300
2025-05-29 21:50:35,957 - INFO - joeynmt.training - Epoch   2, Step:    12400, Batch Loss:     2.024854, Batch Acc: 0.365873, Tokens per Sec:    21037, Lr: 0.000300
2025-05-29 21:50:39,302 - INFO - joeynmt.training - Epoch   2, Step:    12500, Batch Loss:     2.148469, Batch Acc: 0.369976, Tokens per Sec:    21174, Lr: 0.000300
2025-05-29 21:50:39,302 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:50:39,302 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:50:49,264 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.10, ppl:   8.16, acc:   0.38, generation: 9.9451[sec], evaluation: 0.0000[sec]
2025-05-29 21:50:49,265 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:50:49,854 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/10000.ckpt
2025-05-29 21:50:49,879 - INFO - joeynmt.training - Example #0
2025-05-29 21:50:49,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:50:49,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:50:49,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'ho', 'fatto', 'questa', 'è', 'la', 'qu@@', 'ant@@', 'ità', 'di', 'ri@@', 'guar@@', 'da', 'un', 'altro', 'pa@@', 'io', 'di', 's@@', 'ett@@', 'or@@', 'e@@', ',', 'che', 'la', 'maggi@@', 'or', 'parte', 'di', 'un', 'po@@', '<unk>', 'di', 'tre', 'mili@@', 'ar@@', 'di', 'di', 'di', 'anni', 'di', '4@@', '8', 'an@@', 'ni@@', ',', 'che', 'hanno', '4@@', '8', 'milioni', 'di', 'anni', 'di', '4@@', '8', 'an@@', 'ni@@', ',', 'e', '4@@', '0', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:50:49,880 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:50:49,880 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:50:49,880 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno ho fatto questa è la quantità di riguarda un altro paio di settore, che la maggior parte di un po<unk> di tre miliardi di di anni di 48 anni, che hanno 48 milioni di anni di 48 anni, e 40 anni.
2025-05-29 21:50:49,880 - INFO - joeynmt.training - Example #1
2025-05-29 21:50:49,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:50:49,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:50:49,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'altro', 'che', 'non', 'è', 'un', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'è', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'a', 'non', 'è', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'a@@', '.', '</s>']
2025-05-29 21:50:49,881 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:50:49,881 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:50:49,881 - INFO - joeynmt.training - 	Hypothesis: Ma non è un altro che non è un problema di problema, non è la dimostra che non è la democrazia non è la democrazia.
2025-05-29 21:50:49,881 - INFO - joeynmt.training - Example #2
2025-05-29 21:50:49,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:50:49,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:50:49,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'è', 'la', 's@@', 'itu@@', 'azione', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'un', 'sistema', 'di', 'in@@', 'segn@@', 'al@@', 'e@@', ',', 'il', 'nostro', 'sistema', 'di', 'des@@', 'ig@@', 'n', 'del', 'nostro', 'sistema', 'di', 'sist@@', 'em@@', 'at@@', 'or@@', 'i@@', '.', '</s>']
2025-05-29 21:50:49,882 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:50:49,882 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:50:49,882 - INFO - joeynmt.training - 	Hypothesis: In realtà è la situazione è la causa di un sistema di insegnale, il nostro sistema di design del nostro sistema di sistematori.
2025-05-29 21:50:49,882 - INFO - joeynmt.training - Example #3
2025-05-29 21:50:49,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:50:49,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:50:49,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'in', 'cui', 'si', 'è', 'ri@@', 'p@@', 'et@@', 'r@@', 'ol@@', 'i@@', '.', '</s>']
2025-05-29 21:50:49,883 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:50:49,883 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:50:49,883 - INFO - joeynmt.training - 	Hypothesis: E si è rimasta in cui si è ripetroli.
2025-05-29 21:50:49,883 - INFO - joeynmt.training - Example #4
2025-05-29 21:50:49,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:50:49,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:50:49,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'è', 'succ@@', 'esso', 'a', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:50:49,884 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:50:49,884 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:50:49,884 - INFO - joeynmt.training - 	Hypothesis: La prossima che vi mostrerò una cosa che vi mostrerò una cosa che è successo in cui è successo in cui è successo è successo a 25 anni fa.
2025-05-29 21:50:53,251 - INFO - joeynmt.training - Epoch   2, Step:    12600, Batch Loss:     2.055939, Batch Acc: 0.371522, Tokens per Sec:    17791, Lr: 0.000300
2025-05-29 21:50:56,596 - INFO - joeynmt.training - Epoch   2, Step:    12700, Batch Loss:     2.084970, Batch Acc: 0.369350, Tokens per Sec:    21212, Lr: 0.000300
2025-05-29 21:50:59,944 - INFO - joeynmt.training - Epoch   2, Step:    12800, Batch Loss:     2.116713, Batch Acc: 0.373404, Tokens per Sec:    21454, Lr: 0.000300
2025-05-29 21:51:03,280 - INFO - joeynmt.training - Epoch   2, Step:    12900, Batch Loss:     2.058502, Batch Acc: 0.374213, Tokens per Sec:    21133, Lr: 0.000300
2025-05-29 21:51:06,612 - INFO - joeynmt.training - Epoch   2, Step:    13000, Batch Loss:     1.997620, Batch Acc: 0.370169, Tokens per Sec:    20875, Lr: 0.000300
2025-05-29 21:51:06,613 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:51:06,613 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:51:16,186 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.09, ppl:   8.08, acc:   0.39, generation: 9.5605[sec], evaluation: 0.0000[sec]
2025-05-29 21:51:16,186 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:51:16,703 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/10500.ckpt
2025-05-29 21:51:16,728 - INFO - joeynmt.training - Example #0
2025-05-29 21:51:16,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:51:16,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:51:16,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'ho', 'fatto', 'questa', 'fot@@', 'o', 'di', 'queste', 'due', 'f@@', 'ig@@', 'li@@', ',', 'per', 'per', 'fare', 'il', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'la', 'gente', 'che', 'la', 'maggi@@', 'or', 'parte', 'di', 'un', 'm@@', 'ic@@', 'l@@', 'aggio', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '0', 'e', 'm@@', 'ezz@@', 'o', 'di', '4@@', '0', 'an@@', 'ni@@', ',', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'p@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 21:51:16,730 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:51:16,730 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:51:16,730 - INFO - joeynmt.training - 	Hypothesis: L<unk> ho fatto questa foto di queste due figli, per per fare il motivo per cui la gente che la maggior parte di un miclaggio di tre milioni di anni di anni di tre milioni di anni di anni di 40 e mezzo di 40 anni, per il 40 per cento di 40 per cento di 40 per cento di pato.
2025-05-29 21:51:16,730 - INFO - joeynmt.training - Example #1
2025-05-29 21:51:16,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:51:16,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:51:16,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'cosa', 'che', 'non', 'è', 'la', 'ris@@', 'post@@', 'a', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'on@@', 'e@@', ',', 'non', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'a', 'non', 'è', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'a', 'di', 'essere', 'l@@', '<unk>', 'al@@', 'te@@', 'or@@', 'i@@', 'a@@', '.', '</s>']
2025-05-29 21:51:16,731 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:51:16,731 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:51:16,731 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa che non è la risposta di questo problema, non è la democrazione, non la democrazia non è la democrazia di essere l<unk> alteoria.
2025-05-29 21:51:16,731 - INFO - joeynmt.training - Example #2
2025-05-29 21:51:16,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:51:16,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:51:16,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'non', 'lo', 'sap@@', 'pi@@', 'amo', 'che', 'la', 'c@@', 'av@@', 'e', 'la', 'm@@', 'app@@', 'a', 'di', 'un', 'sistema', 'di', 'in@@', 'tel@@', 'li@@', 'gen@@', 'za', 'di', 'm@@', 'ass@@', 'a', 'del', 'sistema', 'di', 'c@@', 'li@@', 'm@@', 'b@@', 'ol@@', 'i@@', 'o@@', '.', '</s>']
2025-05-29 21:51:16,732 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:51:16,732 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:51:16,732 - INFO - joeynmt.training - 	Hypothesis: In realtà non lo sappiamo che la cave la mappa di un sistema di intelligenza di massa del sistema di climbolio.
2025-05-29 21:51:16,732 - INFO - joeynmt.training - Example #3
2025-05-29 21:51:16,733 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:51:16,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:51:16,733 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', '<unk>', 'è', 'un', 'p@@', 'ò', 'di', 'b@@', 'or@@', 'do', 'e', 'la', 'p@@', 'om@@', 'b@@', 'a', 'e', 'l@@', '<unk>', 'or@@', 'a@@', '.', '</s>']
2025-05-29 21:51:16,733 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:51:16,733 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:51:16,733 - INFO - joeynmt.training - 	Hypothesis: C<unk> è un pò di bordo e la pomba e l<unk> ora.
2025-05-29 21:51:16,733 - INFO - joeynmt.training - Example #4
2025-05-29 21:51:16,733 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:51:16,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:51:16,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'volta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'a', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'a', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'la', 'mia', 'm@@', 'og@@', 'l@@', 'ie', 'di', 'tutto', 'il', 'mon@@', 'd@@', 'o@@', '.', '</s>']
2025-05-29 21:51:16,734 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:51:16,734 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:51:16,734 - INFO - joeynmt.training - 	Hypothesis: La prossima volta che vi mostrerò una cosa che vi mostra una cosa che è una cosa che è successo in cui la prima volta che la prima volta che la prima volta che la prima volta che la prima volta che vi mostra una cosa che è successo in cui la mia moglie di tutto il mondo.
2025-05-29 21:51:20,119 - INFO - joeynmt.training - Epoch   2, Step:    13100, Batch Loss:     2.170592, Batch Acc: 0.369046, Tokens per Sec:    17865, Lr: 0.000300
2025-05-29 21:51:23,488 - INFO - joeynmt.training - Epoch   2, Step:    13200, Batch Loss:     2.074244, Batch Acc: 0.376526, Tokens per Sec:    21570, Lr: 0.000300
2025-05-29 21:51:26,834 - INFO - joeynmt.training - Epoch   2, Step:    13300, Batch Loss:     2.007083, Batch Acc: 0.377479, Tokens per Sec:    20996, Lr: 0.000300
2025-05-29 21:51:30,147 - INFO - joeynmt.training - Epoch   2, Step:    13400, Batch Loss:     2.118116, Batch Acc: 0.372487, Tokens per Sec:    21154, Lr: 0.000300
2025-05-29 21:51:33,492 - INFO - joeynmt.training - Epoch   2, Step:    13500, Batch Loss:     2.322828, Batch Acc: 0.377257, Tokens per Sec:    21691, Lr: 0.000300
2025-05-29 21:51:33,492 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:51:33,492 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:51:42,688 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.07, ppl:   7.92, acc:   0.39, generation: 9.1828[sec], evaluation: 0.0000[sec]
2025-05-29 21:51:42,689 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:51:43,233 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/11000.ckpt
2025-05-29 21:51:43,253 - INFO - joeynmt.training - Example #0
2025-05-29 21:51:43,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:51:43,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:51:43,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'che', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'ri@@', 'guar@@', 'do', 'che', 'la', 'sc@@', 'el@@', 'ta', 'di', 'un', 'el@@', 'em@@', 'ento', 'di', 's@@', 'for@@', 'z@@', 'o', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'i', 'prim@@', 'i', 'anni', 'di', '4@@', '0', 'e', 'm@@', 'ezz@@', 'o', 'di', '4@@', '0', 'an@@', 'ni@@', ',', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'di', '4@@', '0', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:51:43,254 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:51:43,254 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:51:43,254 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato che la popolazione di riguardo che la scelta di un elemento di sforzo di tre milioni di anni per i primi anni di 40 e mezzo di 40 anni, per il 40 per cento di 40 ore di 40 anni per cento di 40 per cento di 40 anni.
2025-05-29 21:51:43,254 - INFO - joeynmt.training - Example #1
2025-05-29 21:51:43,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:51:43,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:51:43,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 's@@', 'itu@@', 'azione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'che', 'non', 'è', 'il', 'problema', 'del', 'problema', 'del', 'D@@', 'ic@@', 'e@@', ',', 'non', 'è', 'il', 'D@@', 'ic@@', 'e@@', '.', '</s>']
2025-05-29 21:51:43,255 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:51:43,255 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:51:43,255 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di situazione di questo problema, che non è il problema del problema del Dice, non è il Dice.
2025-05-29 21:51:43,255 - INFO - joeynmt.training - Example #2
2025-05-29 21:51:43,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:51:43,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:51:43,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o@@', ',', 'la', 's@@', 'itu@@', 'azione', 'è', 'la', 's@@', 'itu@@', 'azione', 'di', 'una', 's@@', 'itu@@', 'azione', 'di', 'c@@', 'aus@@', 'a', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 21:51:43,256 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:51:43,256 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:51:43,256 - INFO - joeynmt.training - 	Hypothesis: In questo caso, la situazione è la situazione di una situazione di causa del nostro sistema di climatico.
2025-05-29 21:51:43,256 - INFO - joeynmt.training - Example #3
2025-05-29 21:51:43,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:51:43,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:51:43,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', 'at@@', 'ta', 'di', 'una', 's@@', 'itu@@', 'azione', 'di', 'p@@', 'om@@', 'p@@', 'e', 'di', 'l@@', 'or@@', 'o@@', '.', '</s>']
2025-05-29 21:51:43,257 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:51:43,257 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:51:43,257 - INFO - joeynmt.training - 	Hypothesis: Si tratta di una situazione di pompe di loro.
2025-05-29 21:51:43,257 - INFO - joeynmt.training - Example #4
2025-05-29 21:51:43,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:51:43,257 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:51:43,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'cosa', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'a', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:51:43,258 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:51:43,258 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:51:43,258 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostro che vi mostro è una cosa che vi mostra una cosa che è successo in cui è successo in 25 anni.
2025-05-29 21:51:46,599 - INFO - joeynmt.training - Epoch   2, Step:    13600, Batch Loss:     1.981573, Batch Acc: 0.378927, Tokens per Sec:    17863, Lr: 0.000300
2025-05-29 21:51:49,921 - INFO - joeynmt.training - Epoch   2, Step:    13700, Batch Loss:     2.117573, Batch Acc: 0.379178, Tokens per Sec:    21203, Lr: 0.000300
2025-05-29 21:51:53,266 - INFO - joeynmt.training - Epoch   2, Step:    13800, Batch Loss:     2.085494, Batch Acc: 0.379598, Tokens per Sec:    21545, Lr: 0.000300
2025-05-29 21:51:56,592 - INFO - joeynmt.training - Epoch   2, Step:    13900, Batch Loss:     2.046196, Batch Acc: 0.381039, Tokens per Sec:    21497, Lr: 0.000300
2025-05-29 21:51:59,937 - INFO - joeynmt.training - Epoch   2, Step:    14000, Batch Loss:     2.062300, Batch Acc: 0.381092, Tokens per Sec:    21773, Lr: 0.000300
2025-05-29 21:51:59,938 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:51:59,938 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:52:09,273 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.84, acc:   0.40, generation: 9.3233[sec], evaluation: 0.0000[sec]
2025-05-29 21:52:09,274 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:52:09,842 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/11500.ckpt
2025-05-29 21:52:09,869 - INFO - joeynmt.training - Example #0
2025-05-29 21:52:09,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:52:09,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:52:09,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'questo', 'p@@', 'al@@', 'co', 'di', 'fare', 'questo', 'p@@', 'es@@', 'c@@', 'lu@@', 'si@@', 'on@@', 'e@@', ',', 'che', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'un', 'in@@', 't@@', 'as@@', 'so', 'di', 'tre', 'mili@@', 'ar@@', 'di', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:52:09,870 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:52:09,870 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:52:09,870 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno questo palco di fare questo pesclusione, che la popolazione di un intasso di tre miliardi di anni di persone che hanno fatto tre milioni di anni di persone che hanno fatto per il 48 per cento di 40 anni.
2025-05-29 21:52:09,870 - INFO - joeynmt.training - Example #1
2025-05-29 21:52:09,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:52:09,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:52:09,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'm@@', 'ano', 'di', 'un', 'problema', 'di', 'probl@@', 'emi', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'D@@', 'ic@@', 'e', 'non', 'è', 'il', 'D@@', 'ic@@', 'e', 'non', 'è', 'il', 'D@@', 'ic@@', 'e', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'e', 'che', 'è', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:52:09,871 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:52:09,871 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:52:09,871 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di mano di un problema di problemi di questo problema, non è il Dice non è il Dice non è il Dice che non è il Dice che è un po<unk> .
2025-05-29 21:52:09,871 - INFO - joeynmt.training - Example #2
2025-05-29 21:52:09,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:52:09,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:52:09,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'non', 'sap@@', 'pi@@', 'amo', 'che', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'un', 'in@@', 'tel@@', 'li@@', 'gen@@', 'za', 'del', 'nostro', 'sistema', 'di', 'c@@', 'l@@', 'ass@@', 'e@@', '.', '</s>']
2025-05-29 21:52:09,872 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:52:09,872 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:52:09,872 - INFO - joeynmt.training - 	Hypothesis: In realtà non sappiamo che è la causa di un intelligenza del nostro sistema di classe.
2025-05-29 21:52:09,872 - INFO - joeynmt.training - Example #3
2025-05-29 21:52:09,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:52:09,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:52:09,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'i', 'far@@', 'anno', 'in', 'modo', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'p@@', 'an@@', 'co', 'di', 'm@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 21:52:09,873 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:52:09,873 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:52:09,873 - INFO - joeynmt.training - 	Hypothesis: Vi faranno in modo che si tratta di un panco di momento.
2025-05-29 21:52:09,873 - INFO - joeynmt.training - Example #4
2025-05-29 21:52:09,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:52:09,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:52:09,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'po@@', '<unk>', 'di', 'm@@', 'e@@', ',', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:52:09,874 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:52:09,874 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:52:09,874 - INFO - joeynmt.training - 	Hypothesis: La prossima che vi mostro che vi mostrerò un po<unk> di me, una cosa che è successo in 25 anni.
2025-05-29 21:52:13,254 - INFO - joeynmt.training - Epoch   2, Step:    14100, Batch Loss:     2.198543, Batch Acc: 0.380256, Tokens per Sec:    17564, Lr: 0.000300
2025-05-29 21:52:16,586 - INFO - joeynmt.training - Epoch   2, Step:    14200, Batch Loss:     2.129679, Batch Acc: 0.380866, Tokens per Sec:    20768, Lr: 0.000300
2025-05-29 21:52:19,929 - INFO - joeynmt.training - Epoch   2, Step:    14300, Batch Loss:     1.940478, Batch Acc: 0.382209, Tokens per Sec:    21343, Lr: 0.000300
2025-05-29 21:52:23,252 - INFO - joeynmt.training - Epoch   2, Step:    14400, Batch Loss:     2.145283, Batch Acc: 0.377514, Tokens per Sec:    20562, Lr: 0.000300
2025-05-29 21:52:26,584 - INFO - joeynmt.training - Epoch   2, Step:    14500, Batch Loss:     2.176336, Batch Acc: 0.382654, Tokens per Sec:    21548, Lr: 0.000300
2025-05-29 21:52:26,584 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:52:26,584 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:52:35,766 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.73, acc:   0.40, generation: 9.1702[sec], evaluation: 0.0000[sec]
2025-05-29 21:52:35,767 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:52:36,276 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/12000.ckpt
2025-05-29 21:52:36,298 - INFO - joeynmt.training - Example #0
2025-05-29 21:52:36,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:52:36,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:52:36,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'in', 'questa', 'fot@@', 'o', 'di', 'f@@', 'ar', 's@@', 'ì', 'che', 'la', 'gente', 'che', 'la', 'maggi@@', 'or', 'parte', 'di', 'qu@@', 'elli', 'che', 'hanno', 'fatto', 'è', 'che', 'la', 'sua', 'in@@', 'f@@', 'lu@@', 'en@@', 'z@@', 'a@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '2@@', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'St@@', 'ati', 'Un@@', 'iti@@', '.', '</s>']
2025-05-29 21:52:36,299 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:52:36,299 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:52:36,299 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno in questa foto di far sì che la gente che la maggior parte di quelli che hanno fatto è che la sua influenza, per tre milioni di anni di anni di 40 per cento di 240 ore per cento di 40 ore per cento di 40 ore per cento di 40 per cento di Stati Uniti.
2025-05-29 21:52:36,299 - INFO - joeynmt.training - Example #1
2025-05-29 21:52:36,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:52:36,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:52:36,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'un', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'il', 'D@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 21:52:36,300 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:52:36,300 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:52:36,300 - INFO - joeynmt.training - 	Hypothesis: Ma non si tratta di un problema di problema, non è un problema di problema, non è la dimostra che non è la dimostra che il Dico.
2025-05-29 21:52:36,300 - INFO - joeynmt.training - Example #2
2025-05-29 21:52:36,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:52:36,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:52:36,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'ur@@', 'a@@', ',', 'la', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'li@@', 'ma', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 21:52:36,301 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:52:36,301 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:52:36,301 - INFO - joeynmt.training - 	Hypothesis: In questo caso è la causa della nostra cura, la causa della nostra clima di climatica.
2025-05-29 21:52:36,301 - INFO - joeynmt.training - Example #3
2025-05-29 21:52:36,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:52:36,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:52:36,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'e@@', 'dete', 'in', 'un', 'modo', 'di', 'essere', 'in', 'cui', 'la', 'sua', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma', 'e', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'an@@', 'it@@', 'à@@', ',', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'a', 'un', 'p@@', 'om@@', 'b@@', 'a', 'e', 'la', 'sua', 'v@@', 'it@@', 'a@@', ',', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'per']
2025-05-29 21:52:36,302 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:52:36,302 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:52:36,302 - INFO - joeynmt.training - 	Hypothesis: Vedete in un modo di essere in cui la sua somma di somma di somma di somma di somma e di un po<unk> di sanità, e la sua famiglia e la sua famiglia e la sua famiglia e la sua famiglia e la sua famiglia a un pomba e la sua vita, e la sua famiglia e la sua famiglia e la sua famiglia e la sua famiglia e la sua famiglia e per
2025-05-29 21:52:36,302 - INFO - joeynmt.training - Example #4
2025-05-29 21:52:36,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:52:36,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:52:36,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'i', 'che', 'vi', 'mostr@@', 'i', 'che', 'sono', 'st@@', 'ate', 'in', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:52:36,302 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:52:36,303 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:52:36,303 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostrerò che vi mostri che vi mostri che sono state in 25 anni.
2025-05-29 21:52:39,627 - INFO - joeynmt.training - Epoch   2, Step:    14600, Batch Loss:     1.978256, Batch Acc: 0.386277, Tokens per Sec:    18639, Lr: 0.000300
2025-05-29 21:52:42,958 - INFO - joeynmt.training - Epoch   2, Step:    14700, Batch Loss:     2.107165, Batch Acc: 0.384518, Tokens per Sec:    21659, Lr: 0.000300
2025-05-29 21:52:46,280 - INFO - joeynmt.training - Epoch   2, Step:    14800, Batch Loss:     2.174899, Batch Acc: 0.385209, Tokens per Sec:    21660, Lr: 0.000300
2025-05-29 21:52:49,608 - INFO - joeynmt.training - Epoch   2, Step:    14900, Batch Loss:     2.152491, Batch Acc: 0.388210, Tokens per Sec:    21078, Lr: 0.000300
2025-05-29 21:52:52,935 - INFO - joeynmt.training - Epoch   2, Step:    15000, Batch Loss:     2.056882, Batch Acc: 0.391724, Tokens per Sec:    21309, Lr: 0.000300
2025-05-29 21:52:52,935 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:52:52,935 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:53:01,953 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.03, ppl:   7.58, acc:   0.40, generation: 9.0103[sec], evaluation: 0.0000[sec]
2025-05-29 21:53:01,953 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:53:02,421 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/12500.ckpt
2025-05-29 21:53:02,444 - INFO - joeynmt.training - Example #0
2025-05-29 21:53:02,445 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:53:02,445 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:53:02,445 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'mostr@@', 'azioni', 'che', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'o', 'di', 'fare', 'il', '4@@', '0@@', '%', 'di', 'un', 'el@@', 'et@@', 'tr@@', 'ic@@', 'e', 'che', 'la', 'c@@', 'aus@@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'hanno', '4@@', '0', 'milioni', 'di', 'anni', 'per', 'la', 'maggi@@', 'or', 'parte', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', 'circa', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', 'st@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 21:53:02,445 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:53:02,445 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:53:02,445 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due dimostrazioni che ho mostrato questa foto di fare il 40% di un elettrice che la causa di tre milioni di anni di persone che hanno hanno 40 milioni di anni per la maggior parte di 40 ore per cento di circa 40 ore per cento di stato.
2025-05-29 21:53:02,446 - INFO - joeynmt.training - Example #1
2025-05-29 21:53:02,446 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:53:02,446 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:53:02,446 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'un', 'probl@@', 'em@@', 'a@@', ',', 'che', 'non', 'è', 'il', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'D@@', 'ic@@', 'o@@', ',', 'non', 'è', 'la', 'de@@', 'b@@', 'a', 'di', 'E@@', 'g@@', 'it@@', 't@@', '.', '</s>']
2025-05-29 21:53:02,446 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:53:02,446 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:53:02,446 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema, non è un problema, che non è il problema, non è il Dico, non è la deba di Egitt.
2025-05-29 21:53:02,447 - INFO - joeynmt.training - Example #2
2025-05-29 21:53:02,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:53:02,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:53:02,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'è', 'la', 's@@', 'an@@', 'ità', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 's@@', 'an@@', 'gu@@', 'e', 'di', 'f@@', 'ar', 's@@', 'ì', 'che', 'il', 'nostro', 'sistema', 'di', 's@@', 'an@@', 'gu@@', 'e', 'del', 'sistema', 'di', 's@@', 'an@@', 'gu@@', 'e@@', '.', '</s>']
2025-05-29 21:53:02,447 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:53:02,447 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:53:02,447 - INFO - joeynmt.training - 	Hypothesis: In questo caso è la sanità è la causa di sangue di far sì che il nostro sistema di sangue del sistema di sangue.
2025-05-29 21:53:02,447 - INFO - joeynmt.training - Example #3
2025-05-29 21:53:02,448 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:53:02,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:53:02,448 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ei', 'è', 'il', 'p@@', 'al@@', 'to', 'in', 'b@@', 'ell@@', 'issi@@', 'mo', 'e', 'la', 'sua', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma@@', '.', '</s>']
2025-05-29 21:53:02,448 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:53:02,448 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:53:02,448 - INFO - joeynmt.training - 	Hypothesis: Lei è il palto in bellissimo e la sua somma di somma.
2025-05-29 21:53:02,448 - INFO - joeynmt.training - Example #4
2025-05-29 21:53:02,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:53:02,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:53:02,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'la', 'mia', 'f@@', 're@@', 'qu@@', 'enza', 'di', 'ciò', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:53:02,449 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:53:02,449 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:53:02,449 - INFO - joeynmt.training - 	Hypothesis: Il prossimo è che vi mostrerò la mia frequenza di ciò che è successo in 25 anni fa.
2025-05-29 21:53:05,731 - INFO - joeynmt.training - Epoch   2, Step:    15100, Batch Loss:     2.105871, Batch Acc: 0.386355, Tokens per Sec:    17871, Lr: 0.000300
2025-05-29 21:53:09,008 - INFO - joeynmt.training - Epoch   2, Step:    15200, Batch Loss:     1.932836, Batch Acc: 0.384277, Tokens per Sec:    21792, Lr: 0.000300
2025-05-29 21:53:12,276 - INFO - joeynmt.training - Epoch   2, Step:    15300, Batch Loss:     2.043548, Batch Acc: 0.387579, Tokens per Sec:    21887, Lr: 0.000300
2025-05-29 21:53:15,568 - INFO - joeynmt.training - Epoch   2, Step:    15400, Batch Loss:     1.955824, Batch Acc: 0.387510, Tokens per Sec:    21149, Lr: 0.000300
2025-05-29 21:53:18,809 - INFO - joeynmt.training - Epoch   2, Step:    15500, Batch Loss:     2.329391, Batch Acc: 0.388559, Tokens per Sec:    21453, Lr: 0.000300
2025-05-29 21:53:18,809 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:53:18,809 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:53:27,470 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.01, ppl:   7.50, acc:   0.41, generation: 8.6485[sec], evaluation: 0.0000[sec]
2025-05-29 21:53:27,470 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:53:27,979 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/13000.ckpt
2025-05-29 21:53:28,004 - INFO - joeynmt.training - Example #0
2025-05-29 21:53:28,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:53:28,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:53:28,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'è', 'questa', 'fot@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'cosa', 'che', 'la', 'gente', 'è', 'che', 'la', 's@@', 'itu@@', 'azione', 'di', 'un', 'el@@', 'em@@', 'ento', 'che', 'la', 'c@@', 'ur@@', 'g@@', 'azione', 'di', 'un', 'el@@', 'et@@', 'tr@@', 'ic@@', 'e', 'di', 'un', 'pa@@', 'io', 'di', '4@@', '0', 'ore', 'di', 'St@@', 'a@@', 'for@@', 'd', 'A@@', 'h@@', ',', 'per', 'il', '4@@', '0', 'ore', 'di', 'St@@', 'a@@', 'for@@', 'd', 'per', 'il', '4@@', '0', 'ore', 'di', 'St@@', 'a@@', 'f@@', 'u', 'di', 'St@@', 'a@@', 'ci@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 21:53:28,006 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:53:28,006 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:53:28,006 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso è questa foto, ho mostrato questa cosa che la gente è che la situazione di un elemento che la curgazione di un elettrice di un paio di 40 ore di Staford Ah, per il 40 ore di Staford per il 40 ore di Stafu di Staciate.
2025-05-29 21:53:28,006 - INFO - joeynmt.training - Example #1
2025-05-29 21:53:28,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:53:28,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:53:28,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'molto', 'diff@@', 'ic@@', 'ile', 'da', 'un', 'problema', 'di', 'in@@', 'segn@@', 'are', 'il', 'ter@@', 'ren@@', 'o', 'di', 'questo', 'mo@@', 'd@@', 'o@@', ',', 'non', 'è', 'il', 'D@@', 'ic@@', 'o@@', ',', 'non', 'è', 'la', 'de@@', 'b@@', 'b@@', 'b@@', 'a', 'di', 'D@@', 'ic@@', 'is@@', '.', '</s>']
2025-05-29 21:53:28,007 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:53:28,007 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:53:28,007 - INFO - joeynmt.training - 	Hypothesis: Ma non è molto difficile da un problema di insegnare il terreno di questo modo, non è il Dico, non è la debbba di Dicis.
2025-05-29 21:53:28,007 - INFO - joeynmt.training - Example #2
2025-05-29 21:53:28,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:53:28,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:53:28,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'è', 'il', 'sistema', 'di', 's@@', 'an@@', 'gu@@', 'e', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'soci@@', 'età', 'di', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'soci@@', 'età', 'soci@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:53:28,008 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:53:28,008 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:53:28,008 - INFO - joeynmt.training - 	Hypothesis: In questo caso è il sistema di sangue è la causa della nostra società di causa della nostra società sociale.
2025-05-29 21:53:28,008 - INFO - joeynmt.training - Example #3
2025-05-29 21:53:28,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:53:28,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:53:28,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'c@@', 'entr@@', 'o', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 's@@', 'om@@', 'mer@@', 'i@@', 'di@@', '.', '</s>']
2025-05-29 21:53:28,009 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:53:28,009 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:53:28,009 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un centro in un certo senso di sommeridi.
2025-05-29 21:53:28,009 - INFO - joeynmt.training - Example #4
2025-05-29 21:53:28,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:53:28,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:53:28,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'sc@@', 'el@@', 'ta', 'di', 'una', 'sc@@', 'el@@', 'ta', 'di', 'cosa', 'succ@@', 'ede', 'in', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:53:28,010 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:53:28,010 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:53:28,010 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostrerò una scelta di una scelta di cosa succede in 25 anni fa.
2025-05-29 21:53:31,363 - INFO - joeynmt.training - Epoch   2, Step:    15600, Batch Loss:     2.044035, Batch Acc: 0.390052, Tokens per Sec:    17950, Lr: 0.000300
2025-05-29 21:53:34,702 - INFO - joeynmt.training - Epoch   2, Step:    15700, Batch Loss:     2.077245, Batch Acc: 0.390361, Tokens per Sec:    21432, Lr: 0.000300
2025-05-29 21:53:38,021 - INFO - joeynmt.training - Epoch   2, Step:    15800, Batch Loss:     1.819604, Batch Acc: 0.394247, Tokens per Sec:    21396, Lr: 0.000300
2025-05-29 21:53:41,341 - INFO - joeynmt.training - Epoch   2, Step:    15900, Batch Loss:     2.182459, Batch Acc: 0.390911, Tokens per Sec:    21390, Lr: 0.000300
2025-05-29 21:53:44,647 - INFO - joeynmt.training - Epoch   2, Step:    16000, Batch Loss:     2.086628, Batch Acc: 0.391151, Tokens per Sec:    21198, Lr: 0.000300
2025-05-29 21:53:44,648 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:53:44,648 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:53:52,485 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.41, acc:   0.41, generation: 7.8252[sec], evaluation: 0.0000[sec]
2025-05-29 21:53:52,485 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:53:52,978 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/13500.ckpt
2025-05-29 21:53:53,004 - INFO - joeynmt.training - Example #0
2025-05-29 21:53:53,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:53:53,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:53:53,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'in', 'questo', 'cas@@', 'o', 'di', 'in@@', 'segn@@', 'are', 'a', 'fare', 'per', 'fare', 'la', 'p@@', 'ell@@', 'e@@', ',', 'che', 'i', 'li@@', 'br@@', 'i', 'di', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'è', 'il', '4@@', '0', 'or@@', 'e@@', '.', '</s>']
2025-05-29 21:53:53,005 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:53:53,006 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:53:53,006 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno in questo caso di insegnare a fare per fare la pelle, che i libri di artici, per i tre milioni di anni di anni di persone che hanno fatto è il 40 ore.
2025-05-29 21:53:53,006 - INFO - joeynmt.training - Example #1
2025-05-29 21:53:53,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:53:53,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:53:53,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'molto', 'più', 'a', 'questo', 'tipo', 'di', 'in@@', 'segn@@', 'are', 'la', 'T@@', 'erra', 'è', 'il', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'il', 'D@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 21:53:53,006 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:53:53,007 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:53:53,007 - INFO - joeynmt.training - 	Hypothesis: Ma non è molto più a questo tipo di insegnare la Terra è il problema, non è la dimostra che non è la dimostra che il Dico.
2025-05-29 21:53:53,007 - INFO - joeynmt.training - Example #2
2025-05-29 21:53:53,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:53:53,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:53:53,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'è', 'la', 's@@', 'itu@@', 'azione', 'di', 'el@@', 'et@@', 'tr@@', 'ic@@', 'e', 'che', 'è', 'la', 'nostra', 'c@@', 'aus@@', 'a', 'del', 'nostro', 'sistema', 'soci@@', 'ale', 'del', 'nostro', 'sistema', 'soci@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:53:53,008 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:53:53,008 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:53:53,008 - INFO - joeynmt.training - 	Hypothesis: In questo caso è la situazione di elettrice che è la nostra causa del nostro sistema sociale del nostro sistema sociale.
2025-05-29 21:53:53,008 - INFO - joeynmt.training - Example #3
2025-05-29 21:53:53,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:53:53,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:53:53,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'ri@@', 'p@@', 'et@@', 'ere', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 21:53:53,008 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:53:53,008 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:53:53,009 - INFO - joeynmt.training - 	Hypothesis: Prima di ripetere in un certo senso.
2025-05-29 21:53:53,009 - INFO - joeynmt.training - Example #4
2025-05-29 21:53:53,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:53:53,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:53:53,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'volta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'in', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:53:53,009 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:53:53,009 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:53:53,009 - INFO - joeynmt.training - 	Hypothesis: La prossima volta che vi mostrerò che vi mostrerò una causa di quello che è successo in 25 anni in 25 anni.
2025-05-29 21:53:56,343 - INFO - joeynmt.training - Epoch   2, Step:    16100, Batch Loss:     1.849222, Batch Acc: 0.397567, Tokens per Sec:    18239, Lr: 0.000300
2025-05-29 21:53:59,658 - INFO - joeynmt.training - Epoch   2, Step:    16200, Batch Loss:     1.958147, Batch Acc: 0.392808, Tokens per Sec:    21199, Lr: 0.000300
2025-05-29 21:54:02,941 - INFO - joeynmt.training - Epoch   2, Step:    16300, Batch Loss:     2.042387, Batch Acc: 0.390553, Tokens per Sec:    20809, Lr: 0.000300
2025-05-29 21:54:06,344 - INFO - joeynmt.training - Epoch   2, Step:    16400, Batch Loss:     1.892212, Batch Acc: 0.397428, Tokens per Sec:    21531, Lr: 0.000300
2025-05-29 21:54:09,632 - INFO - joeynmt.training - Epoch   2, Step:    16500, Batch Loss:     2.061549, Batch Acc: 0.394077, Tokens per Sec:    21428, Lr: 0.000300
2025-05-29 21:54:09,632 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:54:09,633 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:54:19,335 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.32, acc:   0.41, generation: 9.6900[sec], evaluation: 0.0000[sec]
2025-05-29 21:54:19,335 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:54:19,870 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/14000.ckpt
2025-05-29 21:54:19,897 - INFO - joeynmt.training - Example #0
2025-05-29 21:54:19,897 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:54:19,897 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:54:19,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'par@@', 'ec@@', 'chi@@', ',', 'per', 'far@@', 'l@@', 'o@@', ',', 'per', 'far@@', 'l@@', 'o@@', ',', 'che', 'la', 'la', 'sc@@', 'el@@', 'ta', 'che', 'la', 'sc@@', 'el@@', 'ta', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '1@@', '8', 'ore', 'di', 'St@@', 'ato', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '0', 'ore', 'di', 'cui', 'il', '4@@', '0', 'ore', 'di', '1@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', 'di', '1@@', '8', 'ore', 'di', '1@@', '0@@', '%', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:54:19,898 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:54:19,898 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:54:19,898 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due parecchi, per farlo, per farlo, che la la scelta che la scelta di tre milioni di anni di anni di tre milioni di anni di anni di 18 ore di Stato che ha avuto il 40 ore di cui il 40 ore di 18 ore per cento di un po<unk> di 18 ore di 10% di un po<unk> .
2025-05-29 21:54:19,898 - INFO - joeynmt.training - Example #1
2025-05-29 21:54:19,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:54:19,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:54:19,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'più', 'diff@@', 'ic@@', 'il@@', 'e@@', ',', 'la', 'T@@', 'er@@', 'ra@@', ',', 'non', 'è', 'il', 'ris@@', 'ult@@', 'ato', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'ris@@', 'ol@@', 'u@@', 'zione', 'di', 'E@@', 'is@@', 'mo@@', '.', '</s>']
2025-05-29 21:54:19,899 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:54:19,899 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:54:19,899 - INFO - joeynmt.training - 	Hypothesis: Ma non è più difficile, la Terra, non è il risultato di questo problema, non è la risoluzione di Eismo.
2025-05-29 21:54:19,899 - INFO - joeynmt.training - Example #2
2025-05-29 21:54:19,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:54:19,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:54:19,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'è', 'la', 'nostra', 'str@@', 'utt@@', 'ura', 'di', 'el@@', 'em@@', 'ento', 'della', 'nostra', 'for@@', 'za', 'della', 'nostra', 'c@@', 'las@@', 'si@@', 'fic@@', 'azione', 'glob@@', 'ale', 'della', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'for@@', 'ma', 'di', 'sist@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:54:19,900 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:54:19,900 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:54:19,900 - INFO - joeynmt.training - 	Hypothesis: In questo caso è la nostra struttura di elemento della nostra forza della nostra classificazione globale della causa della nostra forma di sistema.
2025-05-29 21:54:19,900 - INFO - joeynmt.training - Example #3
2025-05-29 21:54:19,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:54:19,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:54:19,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'om@@', 'ma', 'in', 'un', 's@@', 'om@@', 'ma', 'di', 's@@', 'om@@', 'ma@@', '.', '</s>']
2025-05-29 21:54:19,901 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:54:19,901 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:54:19,901 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un po<unk> di somma in un somma di somma.
2025-05-29 21:54:19,901 - INFO - joeynmt.training - Example #4
2025-05-29 21:54:19,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:54:19,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:54:19,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'è', 'una', 'c@@', 'l@@', 'ass@@', 'a', 'di', 'ciò', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'il', 'pros@@', 'si@@', 'mo', 'è', 'succ@@', 'ess@@', 'o@@', '.', '</s>']
2025-05-29 21:54:19,902 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:54:19,902 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:54:19,902 - INFO - joeynmt.training - 	Hypothesis: Il prossimo è che vi mostrerò che vi mostrerò che vi è una classa di ciò che è successo in cui è successo in cui è successo in cui è successo in cui il prossimo è successo.
2025-05-29 21:54:23,234 - INFO - joeynmt.training - Epoch   2, Step:    16600, Batch Loss:     1.898584, Batch Acc: 0.398978, Tokens per Sec:    18074, Lr: 0.000300
2025-05-29 21:54:26,560 - INFO - joeynmt.training - Epoch   2, Step:    16700, Batch Loss:     1.930021, Batch Acc: 0.400892, Tokens per Sec:    21771, Lr: 0.000300
2025-05-29 21:54:29,870 - INFO - joeynmt.training - Epoch   2, Step:    16800, Batch Loss:     2.039463, Batch Acc: 0.394439, Tokens per Sec:    21010, Lr: 0.000300
2025-05-29 21:54:33,184 - INFO - joeynmt.training - Epoch   2, Step:    16900, Batch Loss:     1.995679, Batch Acc: 0.394963, Tokens per Sec:    20925, Lr: 0.000300
2025-05-29 21:54:36,480 - INFO - joeynmt.training - Epoch   2, Step:    17000, Batch Loss:     1.954259, Batch Acc: 0.397646, Tokens per Sec:    21168, Lr: 0.000300
2025-05-29 21:54:36,481 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:54:36,481 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:54:46,645 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.27, acc:   0.42, generation: 10.1547[sec], evaluation: 0.0000[sec]
2025-05-29 21:54:46,645 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:54:47,148 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/14500.ckpt
2025-05-29 21:54:47,170 - INFO - joeynmt.training - Example #0
2025-05-29 21:54:47,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:54:47,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:54:47,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'sc@@', 'or@@', 'sa', 'di', 'un', 'li@@', 'br@@', 'o', 'di', 'un', 'el@@', 'et@@', 'tr@@', 'ic@@', 'e', 'di', 'un', 'el@@', 'et@@', 'tr@@', 'ic@@', 'e', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'per', 'il', '4@@', '8', 'ore', 'di', '4@@', '8', 'ore', 'di', 'St@@', 'at@@', 'e@@', ',', 'per', 'il', '4@@', '8', 'ore', 'di', '4@@', '8', 'ore', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', 'di', '4@@', '8', 'ore', 'di', 'St@@', 'ati', 'Un@@', 'iti@@', ',', 'e', 'il', '4@@', '8', 'ore', 'di', 'un', 'po@@', '<unk>', 'di', 'c@@', 'las@@', 'si@@', 'fic@@', 'azione', 'di', 'un', 'po@@', '<unk>', 'di', 'più', 'di', '4@@', '8', 'st@@', 'a@@', 'si@@', ',', 'e', 'il', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'sono', 'stati', 'più']
2025-05-29 21:54:47,171 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:54:47,171 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:54:47,171 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questa scorsa di un libro di un elettrice di un elettrice di tre milioni di anni di persone che hanno fatto per il 48 ore di 48 ore di State, per il 48 ore di 48 ore di 48 ore per cento di un po<unk> di 48 ore di Stati Uniti, e il 48 ore di un po<unk> di classificazione di un po<unk> di più di 48 stasi, e il motivo per cui sono stati più
2025-05-29 21:54:47,171 - INFO - joeynmt.training - Example #1
2025-05-29 21:54:47,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:54:47,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:54:47,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'più', 'diff@@', 'ic@@', 'ile', 'da', 'questo', 'problema', 'è', 'il', 'problema', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'il', 'D@@', 'ic@@', 'e', 'non', 'è', 'la', 'de@@', 'fin@@', 'i@@', 'zione', 'del', 'D@@', 'ic@@', 'e', 'del', 'D@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 21:54:47,172 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:54:47,172 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:54:47,172 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di più difficile da questo problema è il problema di questo problema, non è il Dice non è la definizione del Dice del Dico.
2025-05-29 21:54:47,172 - INFO - joeynmt.training - Example #2
2025-05-29 21:54:47,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:54:47,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:54:47,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'di', 's@@', 'an@@', 'gu@@', 'e', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'un', 'sistema', 'di', 'c@@', 'aus@@', 'a', 'del', 'nostro', 'sistema', 'soci@@', 'ale', 'del', 'nostro', 'sistema', 'soci@@', 'ale', 'del', 'nostro', 'sistema', 'soci@@', 'ale', 'del', 'sistema', 'di', 'el@@', 'em@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 21:54:47,173 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:54:47,173 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:54:47,173 - INFO - joeynmt.training - 	Hypothesis: In questo caso di sangue è la causa di un sistema di causa del nostro sistema sociale del nostro sistema sociale del nostro sistema sociale del sistema di elemento.
2025-05-29 21:54:47,173 - INFO - joeynmt.training - Example #3
2025-05-29 21:54:47,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:54:47,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:54:47,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E@@', '<unk>', 'stato', 'un', 'po@@', '<unk>', 'di', 'c@@', 'att@@', 'ur@@', 'a@@', ',', 'e', 'il', 'suo', 's@@', 'om@@', 'ma', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:54:47,174 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:54:47,174 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:54:47,174 - INFO - joeynmt.training - 	Hypothesis: E<unk> stato un po<unk> di cattura, e il suo somma di un po<unk> .
2025-05-29 21:54:47,174 - INFO - joeynmt.training - Example #4
2025-05-29 21:54:47,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:54:47,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:54:47,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'f@@', 'att@@', 'o@@', ',', 'è', 'una', 'c@@', 'at@@', 'ura', 'di', 'quello', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'ede', 'in', 'quello', 'che', 'succ@@', 'ede', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:54:47,174 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:54:47,175 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:54:47,175 - INFO - joeynmt.training - 	Hypothesis: Il prossimo fatto, è una catura di quello che vi mostra cosa succede in quello che succede nel 25 anni.
2025-05-29 21:54:50,456 - INFO - joeynmt.training - Epoch   2, Step:    17100, Batch Loss:     2.049829, Batch Acc: 0.397795, Tokens per Sec:    18189, Lr: 0.000300
2025-05-29 21:54:53,763 - INFO - joeynmt.training - Epoch   2, Step:    17200, Batch Loss:     2.111928, Batch Acc: 0.401020, Tokens per Sec:    21409, Lr: 0.000300
2025-05-29 21:54:57,057 - INFO - joeynmt.training - Epoch   2, Step:    17300, Batch Loss:     1.984836, Batch Acc: 0.400945, Tokens per Sec:    21266, Lr: 0.000300
2025-05-29 21:55:00,357 - INFO - joeynmt.training - Epoch   2, Step:    17400, Batch Loss:     1.925081, Batch Acc: 0.403050, Tokens per Sec:    21408, Lr: 0.000300
2025-05-29 21:55:03,673 - INFO - joeynmt.training - Epoch   2, Step:    17500, Batch Loss:     2.037601, Batch Acc: 0.398852, Tokens per Sec:    21446, Lr: 0.000300
2025-05-29 21:55:03,673 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:55:03,674 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:55:12,821 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.14, acc:   0.42, generation: 9.1344[sec], evaluation: 0.0000[sec]
2025-05-29 21:55:12,821 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:55:13,321 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/15000.ckpt
2025-05-29 21:55:13,343 - INFO - joeynmt.training - Example #0
2025-05-29 21:55:13,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:55:13,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:55:13,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'o', 'per', 'fare', 'questo', 'f@@', 'ut@@', 'uro', 'di', 'un', 'el@@', 'em@@', 'ent@@', 'o@@', ',', 'che', 'la', 'c@@', 'ur@@', 'a@@', ',', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'ore', 'di', 'anni', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:55:13,345 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:55:13,345 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:55:13,345 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questa foto per fare questo futuro di un elemento, che la cura, per i tre milioni di anni per i tre milioni di anni di anni di 48 ore di anni di 48 ore per cento di 40 ore per cento di 40 ore per cento di 40 anni.
2025-05-29 21:55:13,345 - INFO - joeynmt.training - Example #1
2025-05-29 21:55:13,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:55:13,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:55:13,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'problema', 'non', 'è', 'un', 'problema', 'di', 'in@@', 'segn@@', 'ante', 'la', 'ter@@', 'ra@@', ',', 'che', 'non', 'è', 'la', 'de@@', 'fin@@', 'i@@', 'zione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 21:55:13,346 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:55:13,346 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:55:13,346 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema non è un problema di insegnante la terra, che non è la definizione di questo problema.
2025-05-29 21:55:13,346 - INFO - joeynmt.training - Example #2
2025-05-29 21:55:13,346 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:55:13,346 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:55:13,346 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 'for@@', 'za', 'del', 'nostro', 'sistema', 'sistema', 'di', 'in@@', 'tel@@', 'li@@', 'gen@@', 'za', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'della', 'nostra', 'soci@@', 'età', 'soci@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:55:13,347 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:55:13,347 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:55:13,347 - INFO - joeynmt.training - 	Hypothesis: In effetti, la settimana è la forza del nostro sistema sistema di intelligenza del nostro sistema globale della nostra società sociale.
2025-05-29 21:55:13,347 - INFO - joeynmt.training - Example #3
2025-05-29 21:55:13,347 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:55:13,347 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:55:13,347 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'gra@@', 'do', 'di', 'ri@@', 'man@@', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 21:55:13,348 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:55:13,348 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:55:13,348 - INFO - joeynmt.training - 	Hypothesis: Si può essere in grado di rimane in un certo senso.
2025-05-29 21:55:13,348 - INFO - joeynmt.training - Example #4
2025-05-29 21:55:13,348 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:55:13,348 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:55:13,348 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'ura', 'di', 'quello', 'che', 'succ@@', 'ede', 'è', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'succ@@', 'ede', 'in', 'un', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:55:13,349 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:55:13,349 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:55:13,349 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostrerò una cura di quello che succede è una causa di quello che succede in un 25 anni.
2025-05-29 21:55:16,676 - INFO - joeynmt.training - Epoch   2, Step:    17600, Batch Loss:     2.151389, Batch Acc: 0.403488, Tokens per Sec:    18385, Lr: 0.000300
2025-05-29 21:55:19,992 - INFO - joeynmt.training - Epoch   2, Step:    17700, Batch Loss:     2.076207, Batch Acc: 0.394838, Tokens per Sec:    21902, Lr: 0.000300
2025-05-29 21:55:23,290 - INFO - joeynmt.training - Epoch   2, Step:    17800, Batch Loss:     2.185614, Batch Acc: 0.404503, Tokens per Sec:    22022, Lr: 0.000300
2025-05-29 21:55:26,589 - INFO - joeynmt.training - Epoch   2, Step:    17900, Batch Loss:     2.120980, Batch Acc: 0.402329, Tokens per Sec:    21639, Lr: 0.000300
2025-05-29 21:55:29,898 - INFO - joeynmt.training - Epoch   2, Step:    18000, Batch Loss:     1.899606, Batch Acc: 0.405689, Tokens per Sec:    21511, Lr: 0.000300
2025-05-29 21:55:29,898 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:55:29,898 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:55:38,311 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.04, acc:   0.42, generation: 8.4050[sec], evaluation: 0.0000[sec]
2025-05-29 21:55:38,311 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:55:38,795 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/15500.ckpt
2025-05-29 21:55:38,819 - INFO - joeynmt.training - Example #0
2025-05-29 21:55:38,819 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:55:38,819 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:55:38,819 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'o', 'che', 'la', 'cosa', 'che', 'la', 'maggi@@', 'or', 'parte', 'di', 'questo', 'è', 'che', 'la', 'maggi@@', 'or', 'parte', 'di', 'questi', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'qu@@', 'elli', 'di', 'qu@@', 'elli', 'di', 'qu@@', 'at@@', 'tro', 'di', '4@@', '8', 'ore', 'di', 'anni', 'di', '4@@', '0', 'ore', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', 'un', 'pa@@', 'io', 'di', 'anni', 'di', 'l@@', 'or@@', 'o@@', '.', '</s>']
2025-05-29 21:55:38,820 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:55:38,820 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:55:38,820 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questa foto che la cosa che la maggior parte di questo è che la maggior parte di questi tre milioni di anni di anni di quelli di quelli di quattro di 48 ore di anni di 40 ore di 40 ore per cento di 40 ore per cento di 40 ore per cento di 40 ore per cento di 40 ore per cento di un paio di anni di loro.
2025-05-29 21:55:38,820 - INFO - joeynmt.training - Example #1
2025-05-29 21:55:38,820 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:55:38,820 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:55:38,820 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'p@@', 'au@@', 'ra', 'che', 'il', 'ter@@', 'ren@@', 'o', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'e@@', 'is@@', 'mo', 'del', 'D@@', 'ic@@', 'e@@', 'is@@', 'mo', 'del', 'D@@', 'ic@@', 'e@@', 'en@@', '.', '</s>']
2025-05-29 21:55:38,821 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:55:38,821 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:55:38,821 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un po<unk> di paura che il terreno di questo problema, non è la dimostra il Diceismo del Diceismo del Diceen.
2025-05-29 21:55:38,821 - INFO - joeynmt.training - Example #2
2025-05-29 21:55:38,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:55:38,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:55:38,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 'c@@', 'aus@@', 'a', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:55:38,822 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:55:38,822 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:55:38,822 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la settimana è la causa del nostro sistema globale del nostro sistema globale del nostro sistema globale.
2025-05-29 21:55:38,822 - INFO - joeynmt.training - Example #3
2025-05-29 21:55:38,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:55:38,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:55:38,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'un', 'b@@', 'el', 'm@@', 'ezz@@', 'o', 'di', 's@@', 'om@@', 'ma', 'del', 's@@', 'ett@@', 'ore', 'e', 'il', 'c@@', 'li@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 21:55:38,822 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:55:38,822 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:55:38,823 - INFO - joeynmt.training - 	Hypothesis: Prima di un bel mezzo di somma del settore e il cliento.
2025-05-29 21:55:38,823 - INFO - joeynmt.training - Example #4
2025-05-29 21:55:38,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:55:38,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:55:38,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'la', 'mia', 'f@@', 'e@@', 'qu@@', 'i@@', ',', 'è', 'una', 'cell@@', 'u@@', 'la', 'in', 'cui', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:55:38,823 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:55:38,823 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:55:38,823 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostrerò la mia fequi, è una cellula in cui è successo nel 25 anni fa.
2025-05-29 21:55:42,141 - INFO - joeynmt.training - Epoch   2, Step:    18100, Batch Loss:     2.096076, Batch Acc: 0.404622, Tokens per Sec:    19005, Lr: 0.000300
2025-05-29 21:55:45,321 - INFO - joeynmt.training - Epoch   2, Step:    18200, Batch Loss:     2.082474, Batch Acc: 0.401934, Tokens per Sec:    21991, Lr: 0.000300
2025-05-29 21:55:48,452 - INFO - joeynmt.training - Epoch   2, Step:    18300, Batch Loss:     1.875368, Batch Acc: 0.404062, Tokens per Sec:    22091, Lr: 0.000300
2025-05-29 21:55:51,582 - INFO - joeynmt.training - Epoch   2, Step:    18400, Batch Loss:     2.072365, Batch Acc: 0.402246, Tokens per Sec:    22657, Lr: 0.000300
2025-05-29 21:55:54,716 - INFO - joeynmt.training - Epoch   2, Step:    18500, Batch Loss:     1.996892, Batch Acc: 0.408247, Tokens per Sec:    22454, Lr: 0.000300
2025-05-29 21:55:54,716 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:55:54,716 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:56:04,696 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.04, acc:   0.42, generation: 9.9660[sec], evaluation: 0.0000[sec]
2025-05-29 21:56:05,086 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/16000.ckpt
2025-05-29 21:56:05,114 - INFO - joeynmt.training - Example #0
2025-05-29 21:56:05,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:56:05,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:56:05,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'o', 'di', 'un', 'pa@@', 'io', 'di', 'di', 's@@', 'é', 'che', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'la', 'c@@', 'at@@', 'ric@@', 'e', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'per', 'i', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'un', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:56:05,115 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:56:05,115 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:56:05,115 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questa foto di un paio di di sé che la prima volta che la prima volta che la catrice di tre milioni di anni di anni di anni di anni di tre milioni di anni di anni per i 48 ore per cento di anni per il 40 per cento di 48 ore per cento di un 40 per cento di anni.
2025-05-29 21:56:05,115 - INFO - joeynmt.training - Example #1
2025-05-29 21:56:05,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:56:05,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:56:05,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'i@@', ',', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'di', 'E@@', 'is@@', '.', '</s>']
2025-05-29 21:56:05,116 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:56:05,116 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:56:05,116 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un po<unk> di popolazione di questo tipo di problemi, non è il Dicke non è il Dicke di Eis.
2025-05-29 21:56:05,116 - INFO - joeynmt.training - Example #2
2025-05-29 21:56:05,116 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:56:05,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:56:05,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 's@@', 'é', 'la', 'c@@', 'ur@@', 'a@@', ',', 'la', 'c@@', 'at@@', 'tr@@', 'ezz@@', 'a@@', ',', 'il', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', 'mo', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:56:05,117 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:56:05,117 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:56:05,117 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di sé la cura, la cattrezza, il climassimo del nostro sistema globale.
2025-05-29 21:56:05,117 - INFO - joeynmt.training - Example #3
2025-05-29 21:56:05,117 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:56:05,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:56:05,117 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'in', 'un', 'cer@@', 'to', 'punto', 'in', 'cui', 'il', 'suo', 's@@', 'om@@', 'mer@@', 'c@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 21:56:05,118 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:56:05,118 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:56:05,118 - INFO - joeynmt.training - 	Hypothesis: E in un certo senso, e in un certo punto in cui il suo sommercato.
2025-05-29 21:56:05,118 - INFO - joeynmt.training - Example #4
2025-05-29 21:56:05,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:56:05,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:56:05,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'c@@', 'at@@', 'en@@', 'a', 'di', 'cosa', 'succ@@', 'ede', 'in', 'gra@@', 'do', 'di', 'di', 'di', 'in@@', 'segn@@', 'are', 'a', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:56:05,118 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:56:05,118 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:56:05,119 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostro che vi mostro è una catena di cosa succede in grado di di di insegnare a 25 anni fa.
2025-05-29 21:56:08,462 - INFO - joeynmt.training - Epoch   2, Step:    18600, Batch Loss:     1.895931, Batch Acc: 0.404283, Tokens per Sec:    18728, Lr: 0.000300
2025-05-29 21:56:11,771 - INFO - joeynmt.training - Epoch   2, Step:    18700, Batch Loss:     1.872808, Batch Acc: 0.404866, Tokens per Sec:    22015, Lr: 0.000300
2025-05-29 21:56:15,088 - INFO - joeynmt.training - Epoch   2, Step:    18800, Batch Loss:     2.023094, Batch Acc: 0.406398, Tokens per Sec:    21149, Lr: 0.000300
2025-05-29 21:56:18,390 - INFO - joeynmt.training - Epoch   2, Step:    18900, Batch Loss:     1.891350, Batch Acc: 0.408397, Tokens per Sec:    21443, Lr: 0.000300
2025-05-29 21:56:21,684 - INFO - joeynmt.training - Epoch   2, Step:    19000, Batch Loss:     1.958574, Batch Acc: 0.407192, Tokens per Sec:    21296, Lr: 0.000300
2025-05-29 21:56:21,685 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:56:21,685 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:56:30,350 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.99, acc:   0.43, generation: 8.6540[sec], evaluation: 0.0000[sec]
2025-05-29 21:56:30,351 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:56:30,842 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/16500.ckpt
2025-05-29 21:56:30,867 - INFO - joeynmt.training - Example #0
2025-05-29 21:56:30,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:56:30,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:56:30,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'è', 'che', 'la', 'f@@', 'am@@', 'ig@@', 'lia', 'per', 'essere', 'un', 'po@@', '<unk>', 'di', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'un', 'el@@', 'et@@', 'tr@@', 'ic@@', 'e', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 21:56:30,868 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:56:30,868 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:56:30,868 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso è che la famiglia per essere un po<unk> di popolazione di un elettrice per il 40 per cento di tre milioni di anni di anni di persone che hanno fatto per tre milioni di anni di persone che hanno fatto il 40 per cento di 40 per cento di 40 per cento di un po<unk> .
2025-05-29 21:56:30,869 - INFO - joeynmt.training - Example #1
2025-05-29 21:56:30,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:56:30,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:56:30,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'ver@@', 'amente', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'en@@', 'z@@', 'a@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'la', 'de@@', 'b@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 21:56:30,869 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:56:30,869 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:56:30,869 - INFO - joeynmt.training - 	Hypothesis: Ma non è veramente l<unk> influenza, non è la dimostra questo problema, non è la dimostra la debola.
2025-05-29 21:56:30,869 - INFO - joeynmt.training - Example #2
2025-05-29 21:56:30,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:56:30,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:56:30,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'la', 's@@', 'etti@@', ',', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'è', 'la', 's@@', 'fi@@', 'da', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'della', 'nostra', 'soci@@', 'et@@', 'à@@', '.', '</s>']
2025-05-29 21:56:30,870 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:56:30,870 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:56:30,870 - INFO - joeynmt.training - 	Hypothesis: In effetti, la setti, la climatica è la sfida del nostro sistema globale della nostra società.
2025-05-29 21:56:30,870 - INFO - joeynmt.training - Example #3
2025-05-29 21:56:30,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:56:30,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:56:30,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Pot@@', 'ete', 'vedere', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'la', 'v@@', 'it@@', 'a@@', '.', '</s>']
2025-05-29 21:56:30,871 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:56:30,871 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:56:30,871 - INFO - joeynmt.training - 	Hypothesis: Potete vedere in un certo senso, e la vita.
2025-05-29 21:56:30,871 - INFO - joeynmt.training - Example #4
2025-05-29 21:56:30,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:56:30,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:56:30,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'la', 'mia', 'f@@', 'e@@', 'zion@@', 'e@@', ',', 'è', 'una', 'di', 'queste', 'cos@@', 'e@@', ',', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'questo', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:56:30,872 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:56:30,872 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:56:30,872 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostrerò la mia fezione, è una di queste cose, che è successo in cui è successo in cui è successo in questo 25 anni fa.
2025-05-29 21:56:34,405 - INFO - joeynmt.training - Epoch   2, Step:    19100, Batch Loss:     2.096031, Batch Acc: 0.403618, Tokens per Sec:    17455, Lr: 0.000300
2025-05-29 21:56:38,101 - INFO - joeynmt.training - Epoch   2, Step:    19200, Batch Loss:     1.761616, Batch Acc: 0.403869, Tokens per Sec:    18762, Lr: 0.000300
2025-05-29 21:56:41,513 - INFO - joeynmt.training - Epoch   2, Step:    19300, Batch Loss:     1.988957, Batch Acc: 0.408032, Tokens per Sec:    20677, Lr: 0.000300
2025-05-29 21:56:44,919 - INFO - joeynmt.training - Epoch   2, Step:    19400, Batch Loss:     2.146533, Batch Acc: 0.409522, Tokens per Sec:    20755, Lr: 0.000300
2025-05-29 21:56:48,235 - INFO - joeynmt.training - Epoch   2, Step:    19500, Batch Loss:     2.103738, Batch Acc: 0.405974, Tokens per Sec:    20793, Lr: 0.000300
2025-05-29 21:56:48,236 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:56:48,236 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:56:57,269 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.94, acc:   0.43, generation: 9.0208[sec], evaluation: 0.0000[sec]
2025-05-29 21:56:57,270 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:56:57,727 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/17000.ckpt
2025-05-29 21:56:57,746 - INFO - joeynmt.training - Example #0
2025-05-29 21:56:57,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:56:57,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:56:57,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'par@@', 'ti', 'di', 'sc@@', 'al@@', 'are', 'che', 'le', 'persone', 'che', 'hanno', 'fatto', 'la', 'sc@@', 'al@@', 'a', 'che', 'le', 'persone', 'che', 'hanno', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'ore', 'di', 'anni', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'an@@', 'gu@@', 'e', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'l@@', 'or@@', 'o@@', '.', '</s>']
2025-05-29 21:56:57,747 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:56:57,747 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:56:57,747 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due parti di scalare che le persone che hanno fatto la scala che le persone che hanno fatto per tre milioni di anni di anni di tre milioni di anni di anni di 48 ore di anni di 48 ore per cento di 40 ore per cento di 40 ore per cento di 40 per cento di sangue per il 40 per cento di loro.
2025-05-29 21:56:57,747 - INFO - joeynmt.training - Example #1
2025-05-29 21:56:57,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:56:57,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:56:57,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'un', 'problema', 'non', 'è', 'stato', 'un', 'problema', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'che', 'non', 'è', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'on@@', 'e@@', '.', '</s>']
2025-05-29 21:56:57,748 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:56:57,748 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:56:57,748 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un problema non è stato un problema di questo tipo di problema, che non è la democrazione.
2025-05-29 21:56:57,748 - INFO - joeynmt.training - Example #2
2025-05-29 21:56:57,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:56:57,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:56:57,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'la', 's@@', 'etti@@', ',', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 21:56:57,749 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:56:57,749 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:56:57,749 - INFO - joeynmt.training - 	Hypothesis: In effetti, la setti, è la settimana è la squadra di climatica.
2025-05-29 21:56:57,749 - INFO - joeynmt.training - Example #3
2025-05-29 21:56:57,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:56:57,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:56:57,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'or@@', 'n@@', 'am@@', 'ent@@', 'e@@', ',', 'e', 'la', 'sc@@', 'u@@', 'ola', 'di', 's@@', 'abbi@@', 'a', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 21:56:57,750 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:56:57,750 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:56:57,750 - INFO - joeynmt.training - 	Hypothesis: Sornamente, e la scuola di sabbia in un certo senso.
2025-05-29 21:56:57,750 - INFO - joeynmt.training - Example #4
2025-05-29 21:56:57,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:56:57,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:56:57,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'sc@@', 'el@@', 'ta', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'la', 'prima', 'volta', 'che', 'è', 'succ@@', 'esso', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'la', 'gente', 'è', 'succ@@', 'ess@@', 'o@@', '.', '</s>']
2025-05-29 21:56:57,750 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:56:57,751 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:56:57,751 - INFO - joeynmt.training - 	Hypothesis: Il prossimo è che vi mostrerò che vi mostrerò una scelta di quello che è successo in cui la prima volta che è successo è successo in cui è successo in cui è successo in cui la gente è successo.
2025-05-29 21:57:01,106 - INFO - joeynmt.training - Epoch   2, Step:    19600, Batch Loss:     2.065135, Batch Acc: 0.411609, Tokens per Sec:    18884, Lr: 0.000300
2025-05-29 21:57:04,444 - INFO - joeynmt.training - Epoch   2, Step:    19700, Batch Loss:     1.792935, Batch Acc: 0.410063, Tokens per Sec:    21449, Lr: 0.000300
2025-05-29 21:57:07,770 - INFO - joeynmt.training - Epoch   2, Step:    19800, Batch Loss:     1.941977, Batch Acc: 0.415387, Tokens per Sec:    21483, Lr: 0.000300
2025-05-29 21:57:11,101 - INFO - joeynmt.training - Epoch   2, Step:    19900, Batch Loss:     2.177310, Batch Acc: 0.410934, Tokens per Sec:    21557, Lr: 0.000300
2025-05-29 21:57:14,408 - INFO - joeynmt.training - Epoch   2, Step:    20000, Batch Loss:     2.044296, Batch Acc: 0.408645, Tokens per Sec:    21420, Lr: 0.000300
2025-05-29 21:57:14,408 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:57:14,408 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:57:24,166 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.83, acc:   0.43, generation: 9.7441[sec], evaluation: 0.0000[sec]
2025-05-29 21:57:24,167 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:57:24,681 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/17500.ckpt
2025-05-29 21:57:24,706 - INFO - joeynmt.training - Example #0
2025-05-29 21:57:24,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:57:24,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:57:24,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'la', 'gente', 'ha', 'mostr@@', 'ato', 'che', 'la', 'gente', 'ha', 'mostr@@', 'ato', 'che', 'la', 'sc@@', 'u@@', 'ola', 'che', 'la', 'sc@@', 'an@@', 'c@@', 'a@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '0', 'e', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'guar@@', 'do', 'il', '4@@', '0@@', '%', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 'sc@@', 'or@@', 'so', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'an@@', 'gu@@', 'e', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'an@@', 'gu@@', 'e', 'di', 'un', 'pa@@', 'io', 'di', 'anni', 'di', 'sc@@']
2025-05-29 21:57:24,708 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:57:24,708 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:57:24,708 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso che la gente ha mostrato che la gente ha mostrato che la scuola che la scanca, per tre milioni di anni di tre milioni di anni di anni di 40 e i 40 per cento di 40 per cento di 40 per cento di 40 per cento di 40 per cento di riguardo il 40% di un sacco di scorso di un sacco di sangue di un sacco di sangue di un paio di anni di sc
2025-05-29 21:57:24,708 - INFO - joeynmt.training - Example #1
2025-05-29 21:57:24,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:57:24,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:57:24,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 's@@', 'an@@', 'gu@@', 'e', 'che', 'non', 'è', 'la', 'ris@@', 'ol@@', 'u@@', 'zione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'è', 'la', 'd@@', 'ell@@', '<unk>', 'E@@', 'is@@', 'es', 'che', 'ci', 'mostr@@', 'a', 'che', 'il', 'D@@', 'ic@@', 'e', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'l@@', '<unk>', 'e@@', 'qu@@', 'i@@', 'li@@', 'bri@@', 'o@@', '.', '</s>']
2025-05-29 21:57:24,709 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:57:24,709 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:57:24,709 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di sangue che non è la risoluzione di questo problema, non è la dimostra che non è la dell<unk> Eises che ci mostra che il Dice che si tratta di l<unk> equilibrio.
2025-05-29 21:57:24,709 - INFO - joeynmt.training - Example #2
2025-05-29 21:57:24,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:57:24,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:57:24,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti', 'che', 'si', 's@@', 'ov@@', 'in@@', 'iamo', 'la', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'soci@@', 'età', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'della', 'c@@', 'li@@', 'mat@@', 'em@@', 'at@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 21:57:24,710 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:57:24,710 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:57:24,710 - INFO - joeynmt.training - 	Hypothesis: In effetti che si soviniamo la causa della nostra causa della nostra società del nostro sistema globale della climatematica.
2025-05-29 21:57:24,710 - INFO - joeynmt.training - Example #3
2025-05-29 21:57:24,710 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:57:24,710 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:57:24,710 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'oi', 'si', 'può', 'essere', 'in', 'gra@@', 'do', 'di', 'sc@@', 'ar@@', 'p@@', 'e', 'di', 'sc@@', 'ar@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 21:57:24,710 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:57:24,711 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:57:24,711 - INFO - joeynmt.training - 	Hypothesis: Poi si può essere in grado di scarpe di scarica.
2025-05-29 21:57:24,711 - INFO - joeynmt.training - Example #4
2025-05-29 21:57:24,711 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:57:24,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:57:24,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'not@@', 'a', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'i', 'una', 'c@@', 'aus@@', 'a', 'di', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'anni', 'di', '2@@', '5', 'anni', 'di', '2@@', '5', 'anni', 'di', 'qu@@', 'ell@@', '<unk>', 'ulti@@', 'ma', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:57:24,711 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:57:24,711 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:57:24,712 - INFO - joeynmt.training - 	Hypothesis: La prossima nota che vi mostro che vi mostri una causa di cosa che è successo in cui è successo nel 25 anni di 25 anni di 25 anni di quell<unk> ultima anni.
2025-05-29 21:57:28,023 - INFO - joeynmt.training - Epoch   2, Step:    20100, Batch Loss:     2.071069, Batch Acc: 0.415092, Tokens per Sec:    18452, Lr: 0.000300
2025-05-29 21:57:31,410 - INFO - joeynmt.training - Epoch   2, Step:    20200, Batch Loss:     1.796927, Batch Acc: 0.416185, Tokens per Sec:    20556, Lr: 0.000300
2025-05-29 21:57:34,784 - INFO - joeynmt.training - Epoch   2, Step:    20300, Batch Loss:     1.865422, Batch Acc: 0.411281, Tokens per Sec:    20855, Lr: 0.000300
2025-05-29 21:57:38,152 - INFO - joeynmt.training - Epoch   2, Step:    20400, Batch Loss:     1.923374, Batch Acc: 0.408680, Tokens per Sec:    20923, Lr: 0.000300
2025-05-29 21:57:41,528 - INFO - joeynmt.training - Epoch   2, Step:    20500, Batch Loss:     2.101566, Batch Acc: 0.414121, Tokens per Sec:    21516, Lr: 0.000300
2025-05-29 21:57:41,529 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:57:41,529 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:57:50,637 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.75, acc:   0.44, generation: 9.0949[sec], evaluation: 0.0000[sec]
2025-05-29 21:57:50,638 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:57:51,335 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/18500.ckpt
2025-05-29 21:57:51,362 - INFO - joeynmt.training - Example #0
2025-05-29 21:57:51,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:57:51,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:57:51,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'fare', 'questo', 'per', 'fare', 'per', 'fare', 'questo', 'per', 'fare', 'un', 'el@@', 'et@@', 'tr@@', 'ic@@', 'o@@', ',', 'che', 'la', 'maggi@@', 'or', 'parte', 'di', 'un', 'el@@', 'em@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'è', 'stato', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'c@@', 'entr@@', 'o', 'di', 's@@', 'ott@@', 'ol@@', 'in@@', 'e@@', '.', '</s>']
2025-05-29 21:57:51,363 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:57:51,363 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:57:51,363 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di fare questo per fare per fare questo per fare un elettrico, che la maggior parte di un elemento di tre milioni di anni di persone che hanno fatto per tre milioni di anni di persone che hanno fatto è stato il 40 per cento di 40 per cento di 40 per cento di un centro di sottoline.
2025-05-29 21:57:51,363 - INFO - joeynmt.training - Example #1
2025-05-29 21:57:51,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:57:51,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:57:51,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'ris@@', 'ol@@', 'ver@@', 'e@@', ',', 'non', 'è', 'il', 'ris@@', 'ol@@', 'to', 'di', 'questo', 'non', 'è', 'il', 'd@@', 'ot@@', 'tor@@', 'e@@', '.', '</s>']
2025-05-29 21:57:51,364 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:57:51,364 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:57:51,365 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di popolazione di questo risolvere, non è il risolto di questo non è il dottore.
2025-05-29 21:57:51,365 - INFO - joeynmt.training - Example #2
2025-05-29 21:57:51,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:57:51,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:57:51,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'di', 'un', 'sistema', 'glob@@', 'ale', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 21:57:51,365 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:57:51,365 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:57:51,366 - INFO - joeynmt.training - 	Hypothesis: In questo caso è la settimana è la squadra di un sistema globale di climatica.
2025-05-29 21:57:51,366 - INFO - joeynmt.training - Example #3
2025-05-29 21:57:51,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:57:51,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:57:51,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'gra@@', 'do', 'di', 's@@', 'abbi@@', 'a', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 21:57:51,366 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:57:51,366 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:57:51,366 - INFO - joeynmt.training - 	Hypothesis: Si può essere in grado di sabbia in un certo senso.
2025-05-29 21:57:51,366 - INFO - joeynmt.training - Example #4
2025-05-29 21:57:51,367 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:57:51,367 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:57:51,367 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'ura', 'di', 'queste', 'è', 'una', 'c@@', 'at@@', 'en@@', 'a', 'di', 'cosa', 'succ@@', 'ede', 'in', 'questo', 'peri@@', 'o@@', 'do', 'di', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:57:51,367 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:57:51,367 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:57:51,367 - INFO - joeynmt.training - 	Hypothesis: La prossima cosa che vi mostrerò una cura di queste è una catena di cosa succede in questo periodo di 25 anni.
2025-05-29 21:57:54,761 - INFO - joeynmt.training - Epoch   2, Step:    20600, Batch Loss:     1.844209, Batch Acc: 0.412544, Tokens per Sec:    17681, Lr: 0.000300
2025-05-29 21:57:57,557 - INFO - joeynmt.training - Epoch   2, Step:    20700, Batch Loss:     1.835577, Batch Acc: 0.416463, Tokens per Sec:    25432, Lr: 0.000300
2025-05-29 21:57:59,404 - INFO - joeynmt.training - Epoch   2, Step:    20800, Batch Loss:     2.040800, Batch Acc: 0.416456, Tokens per Sec:    38487, Lr: 0.000300
2025-05-29 21:58:01,326 - INFO - joeynmt.training - Epoch   2, Step:    20900, Batch Loss:     2.187608, Batch Acc: 0.418104, Tokens per Sec:    36424, Lr: 0.000300
2025-05-29 21:58:04,714 - INFO - joeynmt.training - Epoch   2, Step:    21000, Batch Loss:     1.789362, Batch Acc: 0.414999, Tokens per Sec:    21127, Lr: 0.000300
2025-05-29 21:58:04,715 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:58:04,715 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:58:13,117 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.68, acc:   0.44, generation: 8.3909[sec], evaluation: 0.0000[sec]
2025-05-29 21:58:13,118 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:58:13,686 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/18000.ckpt
2025-05-29 21:58:13,716 - INFO - joeynmt.training - Example #0
2025-05-29 21:58:13,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:58:13,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:58:13,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'par@@', 'ole', 'per', 'creare', 'queste', 'cose', 'che', 'hanno', 'mostr@@', 'ato', 'che', 'la', 'gente', 'è', 'la', 'm@@', 'ano', 'di', 'un', 'e@@', 'is@@', 'c@@', 'e@@', 'zion@@', 'e@@', ',', 'per', 'il', '4@@', '0', 'mili@@', 'ar@@', 'di', 'di', 'di', 'anni', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'proc@@', 'esso', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', 'di', 'p@@', 'om@@', 'er@@', 'ig@@', 'gi@@', 'o', 'di', 'un', 'po@@', '<unk>', 'di', 'p@@', 'om@@', 'er@@', 'ig@@', 'gi@@', 'o', 'di', 'un', 'po@@', '<unk>', 'di', 'p@@', 'om@@', 'er@@', 'ig@@', 'gi@@', 'o', 'di', 'un', 'pa@@', 'io', 'di', 'di', 'di', 'di', 'migli@@']
2025-05-29 21:58:13,717 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:58:13,717 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:58:13,717 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due parole per creare queste cose che hanno mostrato che la gente è la mano di un eiscezione, per il 40 miliardi di di anni di 48 ore per cento di 40 per cento di 40 per cento di 40 per cento di un processo di 40 per cento di un po<unk> di pomeriggio di un po<unk> di pomeriggio di un po<unk> di pomeriggio di un paio di di di di migli
2025-05-29 21:58:13,717 - INFO - joeynmt.training - Example #1
2025-05-29 21:58:13,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:58:13,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:58:13,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'n@@', 'ec@@', 'ess@@', 'ario', 'che', 'non', 'è', 'n@@', 'ec@@', 'ess@@', 'ario', 'che', 'non', 'è', 'n@@', 'ec@@', 'ess@@', 'ario', 'non', 'è', 'la', 'de@@', 'b@@', 'b@@', 'a', 'non', 'è', 'la', 'de@@', 'b@@', 'b@@', 'a', 'che', 'non', 'è', 'la', 'de@@', 'b@@', 'b@@', 'a', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'ci@@', 'b@@', 'o', 'di', 'p@@', 'op@@', 'ol@@', 'ar@@', 'e@@', '.', '</s>']
2025-05-29 21:58:13,718 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:58:13,718 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:58:13,718 - INFO - joeynmt.training - 	Hypothesis: Ma non è necessario che non è necessario che non è necessario non è la debba non è la debba che non è la debba di un pezzo di cibo di popolare.
2025-05-29 21:58:13,718 - INFO - joeynmt.training - Example #2
2025-05-29 21:58:13,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:58:13,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:58:13,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'il', 'S@@', 'in@@', 'ne', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 's@@', 'itu@@', 'azione', 'della', 'nostra', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:58:13,719 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:58:13,719 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:58:13,719 - INFO - joeynmt.training - 	Hypothesis: In effetti, il Sinne è la settimana è la situazione della nostra climassa del nostro sistema globale.
2025-05-29 21:58:13,719 - INFO - joeynmt.training - Example #3
2025-05-29 21:58:13,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:58:13,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:58:13,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'che', 'è', 'n@@', 'ell@@', '<unk>', 'in@@', 'ten@@', 'zion@@', 'e@@', '.', '</s>']
2025-05-29 21:58:13,720 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:58:13,720 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:58:13,720 - INFO - joeynmt.training - 	Hypothesis: E la cosa che è nell<unk> intenzione.
2025-05-29 21:58:13,720 - INFO - joeynmt.training - Example #4
2025-05-29 21:58:13,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:58:13,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:58:13,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'ura', 'di', 'queste', 'è', 'una', 'c@@', 'ura', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:58:13,721 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:58:13,721 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:58:13,721 - INFO - joeynmt.training - 	Hypothesis: La prossima cosa che vi mostrerò una cura di queste è una cura di quello che è successo in cui è successo nel 25 anni.
2025-05-29 21:58:17,122 - INFO - joeynmt.training - Epoch   2, Step:    21100, Batch Loss:     1.941145, Batch Acc: 0.413878, Tokens per Sec:    17980, Lr: 0.000300
2025-05-29 21:58:20,484 - INFO - joeynmt.training - Epoch   2, Step:    21200, Batch Loss:     1.948873, Batch Acc: 0.414841, Tokens per Sec:    21574, Lr: 0.000300
2025-05-29 21:58:22,637 - INFO - joeynmt.training - Epoch   2, Step:    21300, Batch Loss:     1.854207, Batch Acc: 0.416721, Tokens per Sec:    32316, Lr: 0.000300
2025-05-29 21:58:25,808 - INFO - joeynmt.training - Epoch   2, Step:    21400, Batch Loss:     1.830006, Batch Acc: 0.420752, Tokens per Sec:    21918, Lr: 0.000300
2025-05-29 21:58:26,807 - INFO - joeynmt.training - Epoch   2: total training loss 22120.80
2025-05-29 21:58:26,807 - INFO - joeynmt.training - EPOCH 3
2025-05-29 21:58:29,215 - INFO - joeynmt.training - Epoch   3, Step:    21500, Batch Loss:     2.150301, Batch Acc: 0.425980, Tokens per Sec:    21163, Lr: 0.000300
2025-05-29 21:58:29,216 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:58:29,216 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:58:37,779 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.61, acc:   0.44, generation: 8.5473[sec], evaluation: 0.0000[sec]
2025-05-29 21:58:37,780 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:58:38,343 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/19000.ckpt
2025-05-29 21:58:38,370 - INFO - joeynmt.training - Example #0
2025-05-29 21:58:38,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:58:38,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:58:38,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'ri@@', 'man@@', 'ere', 'questa', 'fot@@', 'o', 'che', 'i', 'gi@@', 'ar@@', 't@@', 'icol@@', 'i', 'che', 'i', 'gi@@', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'i', 'gi@@', 'ar@@', 't@@', 'icol@@', 'i', 'che', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 's@@', 'ott@@', 'om@@', 'ar@@', 'ini', 'di', 'qu@@', 'at@@', 'tro', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 21:58:38,371 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:58:38,371 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:58:38,371 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di rimanere questa foto che i giarticoli che i giartici, che i giarticoli che sono stati in grado di sottomarini di quattro stati.
2025-05-29 21:58:38,371 - INFO - joeynmt.training - Example #1
2025-05-29 21:58:38,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:58:38,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:58:38,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'm@@', 'ezz@@', 'o', 'di', 's@@', 'é', 'la', 'ter@@', 'ra@@', ',', 'e', 'non', 'è', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'on@@', 'e@@', ',', 'non', 'è', 'la', 'de@@', 'b@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 21:58:38,372 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:58:38,372 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:58:38,372 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di mezzo di sé la terra, e non è la democrazione, non è la debola.
2025-05-29 21:58:38,372 - INFO - joeynmt.training - Example #2
2025-05-29 21:58:38,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:58:38,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:58:38,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'in', 'realtà', 'è', 'la', 'str@@', 'utt@@', 'ura', 'della', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'ult@@', 'ura', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:58:38,373 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:58:38,373 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:58:38,373 - INFO - joeynmt.training - 	Hypothesis: In effetti, in realtà è la struttura della causa della nostra causa della nostra cultura del nostro sistema globale.
2025-05-29 21:58:38,373 - INFO - joeynmt.training - Example #3
2025-05-29 21:58:38,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:58:38,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:58:38,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'più', 'diff@@', 'ic@@', 'ile', 'da', 'un', 'b@@', 'att@@', 'ito', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:58:38,374 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:58:38,374 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:58:38,374 - INFO - joeynmt.training - 	Hypothesis: E la cosa più difficile da un battito in un sacco di sommergiale.
2025-05-29 21:58:38,374 - INFO - joeynmt.training - Example #4
2025-05-29 21:58:38,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:58:38,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:58:38,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cell@@', 'u@@', 'la', 'di', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 21:58:38,375 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:58:38,375 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:58:38,375 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostrerò che vi mostrerò una cellula di cosa che è successo in cui è successo in 25 anni fa.
2025-05-29 21:58:41,781 - INFO - joeynmt.training - Epoch   3, Step:    21600, Batch Loss:     1.882967, Batch Acc: 0.428081, Tokens per Sec:    17538, Lr: 0.000300
2025-05-29 21:58:45,164 - INFO - joeynmt.training - Epoch   3, Step:    21700, Batch Loss:     1.856416, Batch Acc: 0.425084, Tokens per Sec:    21177, Lr: 0.000300
2025-05-29 21:58:48,535 - INFO - joeynmt.training - Epoch   3, Step:    21800, Batch Loss:     1.765004, Batch Acc: 0.427220, Tokens per Sec:    21231, Lr: 0.000300
2025-05-29 21:58:51,908 - INFO - joeynmt.training - Epoch   3, Step:    21900, Batch Loss:     1.864963, Batch Acc: 0.422116, Tokens per Sec:    21546, Lr: 0.000300
2025-05-29 21:58:55,251 - INFO - joeynmt.training - Epoch   3, Step:    22000, Batch Loss:     1.792696, Batch Acc: 0.425205, Tokens per Sec:    20939, Lr: 0.000300
2025-05-29 21:58:55,252 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:58:55,252 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:59:05,803 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.64, acc:   0.44, generation: 10.5367[sec], evaluation: 0.0000[sec]
2025-05-29 21:59:06,161 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/19500.ckpt
2025-05-29 21:59:06,187 - INFO - joeynmt.training - Example #0
2025-05-29 21:59:06,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:59:06,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:59:06,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'abbiamo', 'fatto', 'queste', 'due', 'di@@', 'mostr@@', 'azioni', 'che', 'sono', 'le', 'due', 'di@@', 'mostr@@', 'ano', 'che', 'la', 'f@@', 'ig@@', 'ura', 'del', 'mon@@', 'd@@', 'o@@', ',', 'che', 'la', 'gente', 'è', 'il', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'le', 'persone', 'hanno', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'il', '4@@', '0@@', '%', 'di', 'persone', 'che', 'hanno', 'fatto', 'il', '4@@', '0@@', '%', 'di', 'persone', 'che', 'hanno', 'fatto', 'il', '4@@', '0@@', '%', 'di', 'un', 'pa@@', 'io', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'chi@@', 'est@@', 'o@@', '.', '</s>']
2025-05-29 21:59:06,189 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:59:06,189 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:59:06,189 - INFO - joeynmt.training - 	Hypothesis: Lo abbiamo fatto queste due dimostrazioni che sono le due dimostrano che la figura del mondo, che la gente è il motivo per cui le persone hanno fatto per tre milioni di anni di anni di tre milioni di anni di anni di persone che hanno fatto il 40% di persone che hanno fatto il 40% di persone che hanno fatto il 40% di un paio di anni di 40 per cento di richiesto.
2025-05-29 21:59:06,189 - INFO - joeynmt.training - Example #1
2025-05-29 21:59:06,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:59:06,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:59:06,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'più', 'in@@', 'tel@@', 'li@@', 'gente', 'di', 'un', 'problema', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'il', 'd@@', 'ot@@', 'tor@@', 'e@@', ',', 'ma', 'non', 'è', 'il', 'd@@', 'ic@@', 'lo', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'E@@', 'is@@', 'es', 'e', 'il', 'di@@', 'seg@@', 'no', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'em@@', 'er@@', 'gen@@', 'z@@', 'a@@', '.', '</s>']
2025-05-29 21:59:06,190 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:59:06,190 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:59:06,190 - INFO - joeynmt.training - 	Hypothesis: Ma non è più intelligente di un problema di questo tipo di problema, e non è il dottore, ma non è il diclo del ghiaccio di Eises e il disegno del ghiaccio di emergenza.
2025-05-29 21:59:06,190 - INFO - joeynmt.training - Example #2
2025-05-29 21:59:06,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:59:06,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:59:06,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti', 'in@@', 'segn@@', 'ano', 'il', 'S@@', 'in@@', 'ne', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 21:59:06,191 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:59:06,191 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:59:06,191 - INFO - joeynmt.training - 	Hypothesis: In effetti insegnano il Sinne è la settimana del nostro climatico del nostro climatico del nostro sistema globale.
2025-05-29 21:59:06,191 - INFO - joeynmt.training - Example #3
2025-05-29 21:59:06,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:59:06,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:59:06,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'em@@', 'br@@', 'a', 'in', 'modo', 'che', 'si', 'trov@@', 'ano', 'in', 'un', 'cer@@', 'to', 'in', 's@@', 'otto', 'il', 's@@', 'ac@@', 'co', 'di', 's@@', 'abbi@@', 'a', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'ott@@', 'om@@', 'ar@@', 'ino', 'e', 'il', 'suo', 'inter@@', 'o', 's@@', 'ott@@', 'om@@', 'ar@@', 'ino', 'e', 'il', 'suo', 'inter@@', 'v@@', 'ento', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é', 'e', 'che', 'si', 'trov@@', 'ano', 'il', 'suo', 'inter@@', 'o', 's@@', 'ott@@', 'om@@', 'ar@@', 'ino', 'e', 'il', 'suo', 's@@', 'ac@@', 'co', 'di', 'in@@', 'd@@', 'os@@', 's@@', 'are', 'e', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é', 'e', 'che', 'si', 'trov@@', 'ano', 'in', 'modo', 'che', 'si', 'trov@@', 'ano', 'in', 'modo', 'che', 'si', 'trov@@', 'ano', 'il', 'suo', 's@@', 'ac@@', 'co', 'di', 'in@@', 'tel@@', 'li@@', 'g@@', 'ent@@', 'e@@', ',', 'e', 'la', 'ri@@', 'chi@@', 'est@@']
2025-05-29 21:59:06,191 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:59:06,191 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:59:06,192 - INFO - joeynmt.training - 	Hypothesis: Sembra in modo che si trovano in un certo in sotto il sacco di sabbia un sacco di sottomarino e il suo intero sottomarino e il suo intervento di un po<unk> di sé e che si trovano il suo intero sottomarino e il suo sacco di indossare e di un po<unk> di sé e che si trovano in modo che si trovano in modo che si trovano il suo sacco di intelligente, e la richiest
2025-05-29 21:59:06,192 - INFO - joeynmt.training - Example #4
2025-05-29 21:59:06,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:59:06,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:59:06,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'la', 'pros@@', 'si@@', 'ma', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cell@@', 'u@@', 'la', 'di', 'cosa', 'che', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:59:06,192 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:59:06,192 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:59:06,192 - INFO - joeynmt.training - 	Hypothesis: La prossima è la prossima che vi mostrerò una cellula di cosa che è successo nel 25 anni.
2025-05-29 21:59:09,573 - INFO - joeynmt.training - Epoch   3, Step:    22100, Batch Loss:     1.925566, Batch Acc: 0.425565, Tokens per Sec:    19610, Lr: 0.000300
2025-05-29 21:59:12,924 - INFO - joeynmt.training - Epoch   3, Step:    22200, Batch Loss:     1.915220, Batch Acc: 0.428238, Tokens per Sec:    21111, Lr: 0.000300
2025-05-29 21:59:16,309 - INFO - joeynmt.training - Epoch   3, Step:    22300, Batch Loss:     2.037173, Batch Acc: 0.429030, Tokens per Sec:    21540, Lr: 0.000300
2025-05-29 21:59:19,686 - INFO - joeynmt.training - Epoch   3, Step:    22400, Batch Loss:     1.842342, Batch Acc: 0.425719, Tokens per Sec:    20965, Lr: 0.000300
2025-05-29 21:59:23,074 - INFO - joeynmt.training - Epoch   3, Step:    22500, Batch Loss:     1.896537, Batch Acc: 0.431865, Tokens per Sec:    20757, Lr: 0.000300
2025-05-29 21:59:23,075 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:59:23,075 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:59:31,242 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.44, generation: 8.1559[sec], evaluation: 0.0000[sec]
2025-05-29 21:59:31,243 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:59:31,983 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/20000.ckpt
2025-05-29 21:59:32,009 - INFO - joeynmt.training - Example #0
2025-05-29 21:59:32,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:59:32,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:59:32,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'ogra@@', 'f@@', 'ia', 'per', 'fare', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'che', 'l@@', '<unk>', 'e@@', '<unk>', ',', 'che', 'la', 'gente', 'ha', 'mostr@@', 'ato', 'che', 'la', 'ri@@', 'chi@@', 'ede', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'circa', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'chi@@', 'ede', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'otto', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'chi@@', 'est@@', 'a', 'per', 'c@@', 'ri@@', 'min@@', 'ar@@', 'e@@', '.', '</s>']
2025-05-29 21:59:32,011 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:59:32,011 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:59:32,011 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questa fotografia per fare il 40 per cento che l<unk> e<unk> , che la gente ha mostrato che la richiede per tre milioni di anni di anni di tre milioni di anni di anni per il 40 per cento di 40 per cento di circa 40 per cento di 40 per cento di richiede di un sacco di sotto il 40 per cento di richiesta per criminare.
2025-05-29 21:59:32,011 - INFO - joeynmt.training - Example #1
2025-05-29 21:59:32,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:59:32,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:59:32,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'è', 'un', 'probl@@', 'em@@', 'a@@', ',', 'e', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'on@@', 'e@@', ',', 'non', 'è', 'il', 'd@@', 'ic@@', 'chi@@', 'o@@', '.', '</s>']
2025-05-29 21:59:32,012 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:59:32,012 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:59:32,012 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un po<unk> di popolazione di questo è un problema, e la democrazione, non è il dicchio.
2025-05-29 21:59:32,012 - INFO - joeynmt.training - Example #2
2025-05-29 21:59:32,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:59:32,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:59:32,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'in', 'S@@', 'in@@', 'ne', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 'str@@', 'utt@@', 'ura', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'di', 'ri@@', 'chi@@', 'est@@', 'o@@', '.', '</s>']
2025-05-29 21:59:32,013 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:59:32,013 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:59:32,013 - INFO - joeynmt.training - 	Hypothesis: In effetti, in Sinne è la settimana è la struttura globale del nostro sistema globale del nostro sistema globale del nostro sistema globale del sistema globale del sistema globale del sistema globale del sistema globale del sistema globale del sistema di richiesto.
2025-05-29 21:59:32,013 - INFO - joeynmt.training - Example #3
2025-05-29 21:59:32,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:59:32,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:59:32,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'c@@', 'ri@@', 've', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 21:59:32,014 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:59:32,014 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:59:32,014 - INFO - joeynmt.training - 	Hypothesis: Scrive in un certo senso.
2025-05-29 21:59:32,014 - INFO - joeynmt.training - Example #4
2025-05-29 21:59:32,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:59:32,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:59:32,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'la', 'pros@@', 'si@@', 'ma', 'è', 'una', 'cell@@', 'u@@', 'la', 'di', 'cosa', 'che', 'è', 'stato', 'in', 'gra@@', 'do', 'di', 'fare', 'il', 'più', 'di', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 21:59:32,014 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:59:32,014 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:59:32,015 - INFO - joeynmt.training - 	Hypothesis: La prossima è la prossima è una cellula di cosa che è stato in grado di fare il più di 25 anni.
2025-05-29 21:59:35,417 - INFO - joeynmt.training - Epoch   3, Step:    22600, Batch Loss:     1.952868, Batch Acc: 0.423500, Tokens per Sec:    16643, Lr: 0.000300
2025-05-29 21:59:38,795 - INFO - joeynmt.training - Epoch   3, Step:    22700, Batch Loss:     2.117713, Batch Acc: 0.424714, Tokens per Sec:    20298, Lr: 0.000300
2025-05-29 21:59:42,178 - INFO - joeynmt.training - Epoch   3, Step:    22800, Batch Loss:     1.998790, Batch Acc: 0.423152, Tokens per Sec:    21043, Lr: 0.000300
2025-05-29 21:59:45,550 - INFO - joeynmt.training - Epoch   3, Step:    22900, Batch Loss:     1.986617, Batch Acc: 0.426025, Tokens per Sec:    21287, Lr: 0.000300
2025-05-29 21:59:48,921 - INFO - joeynmt.training - Epoch   3, Step:    23000, Batch Loss:     1.930363, Batch Acc: 0.429056, Tokens per Sec:    21442, Lr: 0.000300
2025-05-29 21:59:48,921 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:59:48,921 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:59:57,927 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.44, generation: 8.9940[sec], evaluation: 0.0000[sec]
2025-05-29 21:59:57,928 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:59:58,445 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/20500.ckpt
2025-05-29 21:59:58,471 - INFO - joeynmt.training - Example #0
2025-05-29 21:59:58,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 21:59:58,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:59:58,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'f@@', 'ig@@', 'li@@', ',', 'per', 'creare', 'queste', 'due', 'f@@', 'ig@@', 'li@@', ',', 'che', 'la', 's@@', 'itu@@', 'azione', 'di', 'l@@', '<unk>', 'E@@', 'is@@', 'k@@', 'e@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 's@@', 'ott@@', 'op@@', 'ost@@', 'e', 'per', 'la', 'prima', 'volta', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'per', 'la', 'prima', 'volta', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'è', 'la', 'di@@', 'st@@', 'in@@', 'a@@', '.', '</s>']
2025-05-29 21:59:58,472 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:59:58,472 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:59:58,472 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due figli, per creare queste due figli, che la situazione di l<unk> Eiske, per tre milioni di anni di anni di sottoposte per la prima volta la squadra per la prima volta la squadra è la distina.
2025-05-29 21:59:58,472 - INFO - joeynmt.training - Example #1
2025-05-29 21:59:58,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 21:59:58,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 21:59:58,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'in@@', 't@@', 'eg@@', 'r@@', 'ato', 'la', 'T@@', 'er@@', 'ra@@', ',', 'la', 'T@@', 'er@@', 'ra@@', ',', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'è', 'la', 'd@@', 'ell@@', '<unk>', 'E@@', 'is@@', 'es@@', 'e@@', '.', '</s>']
2025-05-29 21:59:58,473 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:59:58,473 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:59:58,473 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato integrato la Terra, la Terra, non è la dimostra che non è la dell<unk> Eisese.
2025-05-29 21:59:58,473 - INFO - joeynmt.training - Example #2
2025-05-29 21:59:58,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 21:59:58,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 21:59:58,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 'di@@', 'st@@', 'in@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', 'mo', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', '.', '</s>']
2025-05-29 21:59:58,474 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:59:58,474 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:59:58,474 - INFO - joeynmt.training - 	Hypothesis: In effetti, la settimana è la distina, il cuore del nostro climassimo del nostro climassi.
2025-05-29 21:59:58,474 - INFO - joeynmt.training - Example #3
2025-05-29 21:59:58,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:59:58,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 21:59:58,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'prima', 'volta', 'che', 'si', 'è', 'ri@@', 'vel@@', 'a', 'e', 'la', 'ri@@', 'vi@@', 'sta', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 21:59:58,475 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:59:58,475 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:59:58,475 - INFO - joeynmt.training - 	Hypothesis: E la prima volta che si è rivela e la rivista in un certo senso.
2025-05-29 21:59:58,475 - INFO - joeynmt.training - Example #4
2025-05-29 21:59:58,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 21:59:58,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 21:59:58,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cap@@', 'ac@@', 'ità', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'at@@', 'en@@', 'a', 'di', 'cosa', 'succ@@', 'ede', 'nel', '200@@', '9@@', ',', 'è', 'che', 'è', 'succ@@', 'esso', 'nel', '200@@', '9@@', '.', '</s>']
2025-05-29 21:59:58,476 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:59:58,476 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:59:58,476 - INFO - joeynmt.training - 	Hypothesis: La prossima capacità che vi mostrerò una catena di cosa succede nel 2009, è che è successo nel 2009.
2025-05-29 22:00:01,854 - INFO - joeynmt.training - Epoch   3, Step:    23100, Batch Loss:     1.953481, Batch Acc: 0.426273, Tokens per Sec:    18520, Lr: 0.000300
2025-05-29 22:00:05,167 - INFO - joeynmt.training - Epoch   3, Step:    23200, Batch Loss:     1.938632, Batch Acc: 0.424372, Tokens per Sec:    21438, Lr: 0.000300
2025-05-29 22:00:08,478 - INFO - joeynmt.training - Epoch   3, Step:    23300, Batch Loss:     1.909553, Batch Acc: 0.424341, Tokens per Sec:    20932, Lr: 0.000300
2025-05-29 22:00:11,751 - INFO - joeynmt.training - Epoch   3, Step:    23400, Batch Loss:     1.848973, Batch Acc: 0.421519, Tokens per Sec:    21231, Lr: 0.000300
2025-05-29 22:00:15,025 - INFO - joeynmt.training - Epoch   3, Step:    23500, Batch Loss:     2.165184, Batch Acc: 0.427215, Tokens per Sec:    22109, Lr: 0.000300
2025-05-29 22:00:15,025 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:00:15,026 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:00:22,170 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.49, acc:   0.45, generation: 7.1335[sec], evaluation: 0.0000[sec]
2025-05-29 22:00:22,170 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:00:22,662 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/21000.ckpt
2025-05-29 22:00:22,688 - INFO - joeynmt.training - Example #0
2025-05-29 22:00:22,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:00:22,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:00:22,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'f@@', 'ig@@', 'li@@', ',', 'per', 'ri@@', 'dur@@', 're', 'il', '4@@', '0@@', '%', 'di', 'un', 'e@@', 'qu@@', 'i@@', 'li@@', 'bri@@', 'o', 'che', 'la', 'maggi@@', 'or', 'parte', 'di', 'questi', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'questi', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'fl@@', 'essi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:00:22,689 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:00:22,689 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:00:22,689 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di queste due figli, per ridurre il 40% di un equilibrio che la maggior parte di questi tre milioni di anni di anni di questi tre milioni di anni di anni di 48 per cento di anni di 48 per cento di 40 per cento di 40 per cento di riflessibile.
2025-05-29 22:00:22,689 - INFO - joeynmt.training - Example #1
2025-05-29 22:00:22,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:00:22,690 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:00:22,690 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'che', 'non', 'è', 'un', 'problema', 'di', 'ris@@', 'ol@@', 'vere', 'il', 'pot@@', 'ere', 'di', 'questo', 'non', 'è', 'il', 'd@@', 'ott@@', 'ic@@', 'olo', 'di', 'p@@', 'oco', 'd@@', 'ell@@', '<unk>', 'E@@', 'is@@', 'es@@', 'e@@', '.', '</s>']
2025-05-29 22:00:22,690 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:00:22,690 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:00:22,690 - INFO - joeynmt.training - 	Hypothesis: Ma non è un certo senso, che non è un problema di risolvere il potere di questo non è il dotticolo di poco dell<unk> Eisese.
2025-05-29 22:00:22,690 - INFO - joeynmt.training - Example #2
2025-05-29 22:00:22,690 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:00:22,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:00:22,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'la', 'S@@', 'in@@', 'ne', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a@@', ',', 'la', 's@@', 'fi@@', 'da', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:00:22,691 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:00:22,691 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:00:22,691 - INFO - joeynmt.training - 	Hypothesis: In realtà la Sinne è la settimana, la sfida globale del nostro climatico del nostro climatico del nostro sistema globale.
2025-05-29 22:00:22,691 - INFO - joeynmt.training - Example #3
2025-05-29 22:00:22,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:00:22,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:00:22,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'ete', 'in', 'm@@', 'ezz@@', 'o', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'ott@@', 'o@@', '.', '</s>']
2025-05-29 22:00:22,692 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:00:22,692 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:00:22,692 - INFO - joeynmt.training - 	Hypothesis: Sapete in mezzo di un sacco di sotto.
2025-05-29 22:00:22,692 - INFO - joeynmt.training - Example #4
2025-05-29 22:00:22,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:00:22,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:00:22,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cap@@', 'is@@', 'co', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cell@@', 'u@@', 'la', 'prima', 'cosa', 'che', 'è', 'succ@@', 'esso', 'nel', '200@@', '5@@', '.', '</s>']
2025-05-29 22:00:22,693 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:00:22,693 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:00:22,693 - INFO - joeynmt.training - 	Hypothesis: La prossima capisco che vi mostrerò una cellula prima cosa che è successo nel 2005.
2025-05-29 22:00:26,077 - INFO - joeynmt.training - Epoch   3, Step:    23600, Batch Loss:     1.926504, Batch Acc: 0.431966, Tokens per Sec:    18102, Lr: 0.000300
2025-05-29 22:00:29,457 - INFO - joeynmt.training - Epoch   3, Step:    23700, Batch Loss:     1.950220, Batch Acc: 0.430115, Tokens per Sec:    21033, Lr: 0.000300
2025-05-29 22:00:32,841 - INFO - joeynmt.training - Epoch   3, Step:    23800, Batch Loss:     2.045244, Batch Acc: 0.426874, Tokens per Sec:    21236, Lr: 0.000300
2025-05-29 22:00:36,200 - INFO - joeynmt.training - Epoch   3, Step:    23900, Batch Loss:     1.924865, Batch Acc: 0.429854, Tokens per Sec:    20804, Lr: 0.000300
2025-05-29 22:00:39,553 - INFO - joeynmt.training - Epoch   3, Step:    24000, Batch Loss:     1.874992, Batch Acc: 0.429908, Tokens per Sec:    20407, Lr: 0.000300
2025-05-29 22:00:39,553 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:00:39,553 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:00:49,519 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.46, acc:   0.45, generation: 9.9533[sec], evaluation: 0.0000[sec]
2025-05-29 22:00:49,520 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:00:50,086 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/22000.ckpt
2025-05-29 22:00:50,113 - INFO - joeynmt.training - Example #0
2025-05-29 22:00:50,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:00:50,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:00:50,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'che', 'la', 'gente', 'che', 'ha', 'mostr@@', 'ato', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'che', 'l@@', '<unk>', 'E@@', 'is@@', 'k@@', 'el@@', 'e@@', ',', 'per', 'la', 'prima', 'volta', 'che', 'i', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'fl@@', 'ett@@', 'ur@@', 'e@@', '.', '</s>']
2025-05-29 22:00:50,114 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:00:50,114 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:00:50,114 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato che la gente che ha mostrato che la ghiaccio è che l<unk> Eiskele, per la prima volta che i tre milioni di anni di anni di tre milioni di anni di anni di 48 ore per cento di 40 per cento di 40 per cento di 40 per cento di 40 per cento di rifletture.
2025-05-29 22:00:50,114 - INFO - joeynmt.training - Example #1
2025-05-29 22:00:50,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:00:50,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:00:50,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'problema', 'non', 'è', 'un', 'problema', 'di', 'ris@@', 'ol@@', 'vere', 'il', 'problema', 'di', 'questo', 'probl@@', 'em@@', 'i@@', ',', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'E@@', 'is@@', 'es', 'che', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'del', 'E@@', 'is@@', 'es', 'che', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'k@@', '.', '</s>']
2025-05-29 22:00:50,115 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:00:50,115 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:00:50,115 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema non è un problema di risolvere il problema di questo problemi, non è il Dicke non è la Dicke del Eises che mostra il Dicke del Eises che mostra il Dick.
2025-05-29 22:00:50,115 - INFO - joeynmt.training - Example #2
2025-05-29 22:00:50,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:00:50,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:00:50,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'è', 'l@@', '<unk>', 'E@@', 'is@@', 'k@@', 'd@@', ',', 'la', 'sig@@', 'nor@@', 'i@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:00:50,116 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:00:50,116 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:00:50,116 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è l<unk> Eiskd, la signori, il cuore globale.
2025-05-29 22:00:50,116 - INFO - joeynmt.training - Example #3
2025-05-29 22:00:50,116 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:00:50,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:00:50,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'po@@', '<unk>', 'di', 'in@@', 'forma@@', 'zione', 'in', 'un', 'f@@', 'ut@@', 'uro', 'in', 'un', 'f@@', 'ut@@', 'ur@@', 'o@@', '.', '</s>']
2025-05-29 22:00:50,117 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:00:50,117 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:00:50,117 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un po<unk> di informazione in un futuro in un futuro.
2025-05-29 22:00:50,117 - INFO - joeynmt.training - Example #4
2025-05-29 22:00:50,117 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:00:50,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:00:50,117 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'che', 'vi', 'mostr@@', 'o', 'la', 'pros@@', 'si@@', 'ma', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'succ@@', 'ede', 'nel', 'prim@@', 'o', 'anno', 'sc@@', 'or@@', 'so', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', '200@@', '.', '</s>']
2025-05-29 22:00:50,118 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:00:50,118 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:00:50,118 - INFO - joeynmt.training - 	Hypothesis: La prossima che vi mostro la prossima che vi mostro è una causa di quello che succede nel primo anno scorso di quello che è successo nel 200.
2025-05-29 22:00:53,532 - INFO - joeynmt.training - Epoch   3, Step:    24100, Batch Loss:     1.944398, Batch Acc: 0.433502, Tokens per Sec:    18320, Lr: 0.000300
2025-05-29 22:00:56,899 - INFO - joeynmt.training - Epoch   3, Step:    24200, Batch Loss:     1.884649, Batch Acc: 0.429560, Tokens per Sec:    20516, Lr: 0.000300
2025-05-29 22:01:00,277 - INFO - joeynmt.training - Epoch   3, Step:    24300, Batch Loss:     2.048484, Batch Acc: 0.424204, Tokens per Sec:    21020, Lr: 0.000300
2025-05-29 22:01:03,590 - INFO - joeynmt.training - Epoch   3, Step:    24400, Batch Loss:     1.865915, Batch Acc: 0.430623, Tokens per Sec:    21144, Lr: 0.000300
2025-05-29 22:01:06,916 - INFO - joeynmt.training - Epoch   3, Step:    24500, Batch Loss:     1.893870, Batch Acc: 0.425616, Tokens per Sec:    19967, Lr: 0.000300
2025-05-29 22:01:06,916 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:01:06,916 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:01:16,035 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.41, acc:   0.45, generation: 9.1060[sec], evaluation: 0.0000[sec]
2025-05-29 22:01:16,036 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:01:16,538 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/21500.ckpt
2025-05-29 22:01:16,555 - INFO - joeynmt.training - Example #0
2025-05-29 22:01:16,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:01:16,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:01:16,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'o', 'per', 'fare', 'per', 'ri@@', 'dur@@', 're', 'che', 'la', 'm@@', 'app@@', 'a', 'che', 'la', 'm@@', 'app@@', 'a', 'che', 'la', 'sc@@', 'al@@', 'a', 'che', 'la', 'sc@@', 'ann@@', 'er@@', 'ia', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'm@@', 'esso', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'persone', 'che', 'sono', 'st@@', 'ate', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:01:16,556 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:01:16,556 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:01:16,556 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questa foto per fare per ridurre che la mappa che la mappa che la scala che la scanneria di tre milioni di anni di persone che hanno messo di tre milioni di anni di anni di persone che sono state per il 48 per cento di anni per cento di anni.
2025-05-29 22:01:16,556 - INFO - joeynmt.training - Example #1
2025-05-29 22:01:16,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:01:16,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:01:16,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'un', 'problema', 'di', 'ris@@', 'ol@@', 'vere', 'il', 'ris@@', 'ult@@', 'ato', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'for@@', 'za', 'del', 'p@@', 'op@@', 'ol@@', 'o@@', ',', 'non', 'è', 'la', 'for@@', 'za', 'del', 'p@@', 'op@@', 'ol@@', 'o@@', '.', '</s>']
2025-05-29 22:01:16,557 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:01:16,557 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:01:16,557 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un problema di risolvere il risultato di questo tipo di problema, non è la forza del popolo, non è la forza del popolo.
2025-05-29 22:01:16,557 - INFO - joeynmt.training - Example #2
2025-05-29 22:01:16,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:01:16,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:01:16,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'S@@', 'in@@', 'ne', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'di', 'un', 'sistema', 'glob@@', 'ale', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'em@@', 'at@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:01:16,558 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:01:16,558 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:01:16,558 - INFO - joeynmt.training - 	Hypothesis: In Sinne è la settimana è la squadra di un sistema globale globale del nostro climatematico.
2025-05-29 22:01:16,558 - INFO - joeynmt.training - Example #3
2025-05-29 22:01:16,559 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:01:16,559 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:01:16,559 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E@@', '<unk>', 'un', 'po@@', '<unk>', 'di', 'in@@', 'ten@@', 'zione', 'a', 'm@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:01:16,559 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:01:16,559 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:01:16,559 - INFO - joeynmt.training - 	Hypothesis: E<unk> un po<unk> di intenzione a momento.
2025-05-29 22:01:16,559 - INFO - joeynmt.training - Example #4
2025-05-29 22:01:16,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:01:16,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:01:16,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'col@@', 'i@@', 'o@@', ',', 'la', 'pros@@', 'si@@', 'ma', 'volta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', 'questo', 'peri@@', 'o@@', 'do', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'è', 'succ@@', 'esso', 'in', 'questo', 'm@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:01:16,560 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:01:16,560 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:01:16,560 - INFO - joeynmt.training - 	Hypothesis: Il prossimo colio, la prossima volta che vi mostrerò una causa di quello che è successo in questo periodo di quello che è successo è successo in questo momento.
2025-05-29 22:01:19,884 - INFO - joeynmt.training - Epoch   3, Step:    24600, Batch Loss:     2.049145, Batch Acc: 0.427655, Tokens per Sec:    18996, Lr: 0.000300
2025-05-29 22:01:23,204 - INFO - joeynmt.training - Epoch   3, Step:    24700, Batch Loss:     1.873697, Batch Acc: 0.433892, Tokens per Sec:    22308, Lr: 0.000300
2025-05-29 22:01:26,565 - INFO - joeynmt.training - Epoch   3, Step:    24800, Batch Loss:     1.846507, Batch Acc: 0.428671, Tokens per Sec:    20525, Lr: 0.000300
2025-05-29 22:01:29,952 - INFO - joeynmt.training - Epoch   3, Step:    24900, Batch Loss:     1.912636, Batch Acc: 0.432309, Tokens per Sec:    21074, Lr: 0.000300
2025-05-29 22:01:33,323 - INFO - joeynmt.training - Epoch   3, Step:    25000, Batch Loss:     1.903989, Batch Acc: 0.429609, Tokens per Sec:    20836, Lr: 0.000300
2025-05-29 22:01:33,324 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:01:33,324 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:01:42,835 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.36, acc:   0.45, generation: 9.4988[sec], evaluation: 0.0000[sec]
2025-05-29 22:01:42,836 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:01:43,398 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/22500.ckpt
2025-05-29 22:01:43,420 - INFO - joeynmt.training - Example #0
2025-05-29 22:01:43,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:01:43,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:01:43,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'cose', 'che', 'sono', 'st@@', 'ate', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'l@@', '<unk>', 'e@@', 'du@@', 'c@@', 'azione', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'su@@', 'oi', 'di@@', 'sp@@', 'os@@', 'i@@', ',', 'i', '4@@', '8', 'st@@', 'ati@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'pa@@', 'io', 'di', 'p@@', 'ezz@@', 'o', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'pa@@', 'io', 'di', 'ri@@', 'l@@', 'ev@@', 'amento', 'di', 'un', 'po@@', '<unk>', 'di', 'più', 'di', 'un', 'po@@', '<unk>', 'di', 'p@@', 'op@@', 'ol@@', 'are', 'di', 'un', 'pa@@', 'io', 'di', 'di', 'di', 's@@']
2025-05-29 22:01:43,422 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:01:43,422 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:01:43,422 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste cose che sono state per ridurre il ghiaccio che l<unk> educazione di un ghiaccio, che i suoi disposi, i 48 stati, il 40 per cento di 40 per cento di 40 per cento di 40 per cento di un paio di pezzo di 40 per cento di un paio di rilevamento di un po<unk> di più di un po<unk> di popolare di un paio di di di s
2025-05-29 22:01:43,422 - INFO - joeynmt.training - Example #1
2025-05-29 22:01:43,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:01:43,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:01:43,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'un', 'probl@@', 'em@@', 'a@@', ',', 'la', 'T@@', 'erra', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'non', 'è', 'la', 'de@@', 'fin@@', 'i@@', 'zione', 'di', 'un', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ott@@', 'ic@@', 'chi@@', 'o@@', '.', '</s>']
2025-05-29 22:01:43,423 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:01:43,423 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:01:43,423 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è un problema, la Terra è una cosa che è una cosa che non è la definizione di un problema, perché non è il dotticchio.
2025-05-29 22:01:43,423 - INFO - joeynmt.training - Example #2
2025-05-29 22:01:43,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:01:43,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:01:43,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'di', 'S@@', 'in@@', 'ne', 'è', 'la', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 's@@', 'itu@@', 'azione', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:01:43,424 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:01:43,424 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:01:43,424 - INFO - joeynmt.training - 	Hypothesis: In certo senso di Sinne è la settimana è la situazione globale.
2025-05-29 22:01:43,424 - INFO - joeynmt.training - Example #3
2025-05-29 22:01:43,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:01:43,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:01:43,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'un', 'm@@', 'ezz@@', 'o', 'di', 'in@@', 'ten@@', 'zione', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'é', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:01:43,425 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:01:43,425 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:01:43,425 - INFO - joeynmt.training - 	Hypothesis: E in un mezzo di intenzione in un sacco di sé di un po<unk> .
2025-05-29 22:01:43,425 - INFO - joeynmt.training - Example #4
2025-05-29 22:01:43,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:01:43,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:01:43,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'li@@', 'vello', 'di', 'di@@', 'mostr@@', 'are', 'è', 'una', 'c@@', 'at@@', 'tr@@', 'ezz@@', 'at@@', 'ura', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:01:43,426 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:01:43,426 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:01:43,426 - INFO - joeynmt.training - 	Hypothesis: Il prossimo livello di dimostrare è una cattrezzatura che è successo in cui è successo in cui è successo nel 25 anni.
2025-05-29 22:01:46,829 - INFO - joeynmt.training - Epoch   3, Step:    25100, Batch Loss:     1.925331, Batch Acc: 0.426456, Tokens per Sec:    18111, Lr: 0.000300
2025-05-29 22:01:50,210 - INFO - joeynmt.training - Epoch   3, Step:    25200, Batch Loss:     2.137608, Batch Acc: 0.428392, Tokens per Sec:    21189, Lr: 0.000300
2025-05-29 22:01:53,561 - INFO - joeynmt.training - Epoch   3, Step:    25300, Batch Loss:     1.840698, Batch Acc: 0.432790, Tokens per Sec:    20737, Lr: 0.000300
2025-05-29 22:01:56,919 - INFO - joeynmt.training - Epoch   3, Step:    25400, Batch Loss:     1.811463, Batch Acc: 0.435475, Tokens per Sec:    20831, Lr: 0.000300
2025-05-29 22:02:00,278 - INFO - joeynmt.training - Epoch   3, Step:    25500, Batch Loss:     1.892944, Batch Acc: 0.428753, Tokens per Sec:    21126, Lr: 0.000300
2025-05-29 22:02:00,278 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:02:00,278 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:02:08,462 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.31, acc:   0.45, generation: 8.1722[sec], evaluation: 0.0000[sec]
2025-05-29 22:02:08,462 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:02:08,966 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/23000.ckpt
2025-05-29 22:02:08,991 - INFO - joeynmt.training - Example #0
2025-05-29 22:02:08,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:02:08,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:02:08,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questa', 'di@@', 'mostr@@', 'a', 'queste', 'due', 'di@@', 'ec@@', 'i', 'di', 'ri@@', 'l@@', 'ev@@', 'it@@', 'are', 'che', 'la', 'gente', 'è', 'che', 'la', 'prima', 'di', 'che', 'la', 'm@@', 'ano', 'di', 'l@@', '<unk>', 'e@@', 'is@@', 'c@@', 'e@@', ',', 'che', 'la', 'gente', 'per', 'la', 'prima', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'è', 'stato', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', '.', '</s>']
2025-05-29 22:02:08,992 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:02:08,993 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:02:08,993 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questa dimostra queste due dieci di rilevitare che la gente è che la prima di che la mano di l<unk> eisce, che la gente per la prima di tre milioni di anni di anni di tre milioni di anni di anni di anni di persone che hanno fatto è stato il 40 per cento di l<unk> anno scorso.
2025-05-29 22:02:08,993 - INFO - joeynmt.training - Example #1
2025-05-29 22:02:08,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:02:08,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:02:08,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'un', 'problema', 'di', 'ris@@', 'ol@@', 'vere', 'il', 'fatto', 'che', 'la', 'prima', 'volta', 'che', 'non', 'è', 'un', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'de@@', 'b@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 22:02:08,994 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:02:08,994 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:02:08,994 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è un problema di risolvere il fatto che la prima volta che non è un problema di problema, non è la debola.
2025-05-29 22:02:08,994 - INFO - joeynmt.training - Example #2
2025-05-29 22:02:08,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:02:08,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:02:08,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'il', 'sen@@', 'so', 'è', 'la', 'str@@', 'utt@@', 'ura', 'bi@@', 'an@@', 'ca', 'di', 'c@@', 'atti@@', 'v@@', 'ità', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:02:08,994 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:02:08,995 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:02:08,995 - INFO - joeynmt.training - 	Hypothesis: In effetti, il senso è la struttura bianca di cattività globale.
2025-05-29 22:02:08,995 - INFO - joeynmt.training - Example #3
2025-05-29 22:02:08,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:02:08,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:02:08,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'on@@', 'si@@', 'ete', 'in', 'v@@', 'it@@', 'a@@', ',', 'e', 'il', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'f@@', 'am@@', 'ig@@', 'li@@', 'a@@', '.', '</s>']
2025-05-29 22:02:08,995 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:02:08,995 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:02:08,996 - INFO - joeynmt.training - 	Hypothesis: Consiete in vita, e il motivo per cui si tratta di un famiglia.
2025-05-29 22:02:08,996 - INFO - joeynmt.training - Example #4
2025-05-29 22:02:08,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:02:08,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:02:08,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'li@@', 'vello', 'di', 'col@@', 'i@@', ',', 'è', 'una', 'c@@', 'aus@@', 'a', 'di', 'cosa', 'succ@@', 'ede', 'nel', 'm@@', 'ezz@@', 'o', 'di', 'cosa', 'succ@@', 'ede', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:02:08,996 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:02:08,996 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:02:08,996 - INFO - joeynmt.training - 	Hypothesis: Il prossimo livello di coli, è una causa di cosa succede nel mezzo di cosa succede nel 25 anni.
2025-05-29 22:02:12,345 - INFO - joeynmt.training - Epoch   3, Step:    25600, Batch Loss:     2.003698, Batch Acc: 0.431198, Tokens per Sec:    18168, Lr: 0.000300
2025-05-29 22:02:15,669 - INFO - joeynmt.training - Epoch   3, Step:    25700, Batch Loss:     1.860521, Batch Acc: 0.431338, Tokens per Sec:    21031, Lr: 0.000300
2025-05-29 22:02:18,995 - INFO - joeynmt.training - Epoch   3, Step:    25800, Batch Loss:     2.015342, Batch Acc: 0.432084, Tokens per Sec:    21562, Lr: 0.000300
2025-05-29 22:02:22,327 - INFO - joeynmt.training - Epoch   3, Step:    25900, Batch Loss:     1.866560, Batch Acc: 0.437065, Tokens per Sec:    22012, Lr: 0.000300
2025-05-29 22:02:25,660 - INFO - joeynmt.training - Epoch   3, Step:    26000, Batch Loss:     1.839735, Batch Acc: 0.430956, Tokens per Sec:    21597, Lr: 0.000300
2025-05-29 22:02:25,660 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:02:25,660 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:02:33,913 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.27, acc:   0.46, generation: 8.2406[sec], evaluation: 0.0000[sec]
2025-05-29 22:02:33,913 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:02:34,408 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/23500.ckpt
2025-05-29 22:02:34,427 - INFO - joeynmt.training - Example #0
2025-05-29 22:02:34,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:02:34,427 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:02:34,427 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questi', 'due', 'vol@@', 'i', 'f@@', 'att@@', 'ori', 'per', 'ri@@', 'vel@@', 'are', 'che', 'la', 'gente', 'che', 'ha', 'di@@', 'mostr@@', 'ato', 'che', 'la', 'gente', 'che', 'ha', 'fatto', 'la', 'prima', 'volta', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'per', 'i', 'loro', 'l@@', '<unk>', 'ap@@', 'er@@', 't@@', 'ura', 'di', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'an@@', 'gu@@', 'e', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:02:34,428 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:02:34,428 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:02:34,428 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questi due voli fattori per rivelare che la gente che ha dimostrato che la gente che ha fatto la prima volta che i ghiacciati per i loro l<unk> apertura di milioni di anni di anni di persone che hanno 40 per cento di 40 per cento di 40 per cento di 40 per cento di sangue per cento di un po<unk> .
2025-05-29 22:02:34,428 - INFO - joeynmt.training - Example #1
2025-05-29 22:02:34,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:02:34,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:02:34,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'un', 'grande', 'grande', 'ris@@', 'ol@@', 'vere', 'il', 'ris@@', 'ult@@', 'ato', 'di', 'questo', 'spe@@', 'ci@@', 'fic@@', 'o@@', ',', 'non', 'è', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'a', 'del', 'E@@', 'is@@', 'es', 'che', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'del', 'E@@', 'is@@', 'es', '</s>']
2025-05-29 22:02:34,429 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:02:34,429 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:02:34,429 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un grande grande risolvere il risultato di questo specifico, non è la democrazia del Eises che mostra il Dicke del Eises
2025-05-29 22:02:34,429 - INFO - joeynmt.training - Example #2
2025-05-29 22:02:34,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:02:34,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:02:34,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti', 'non', 'sap@@', 'pi@@', 'amo', 'che', 'la', 'c@@', 'aus@@', 'a', 'della', 's@@', 'edi@@', 'a', 'della', 'nostra', 'c@@', 'ur@@', 'a@@', '.', '</s>']
2025-05-29 22:02:34,430 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:02:34,430 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:02:34,430 - INFO - joeynmt.training - 	Hypothesis: In effetti non sappiamo che la causa della sedia della nostra cura.
2025-05-29 22:02:34,430 - INFO - joeynmt.training - Example #3
2025-05-29 22:02:34,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:02:34,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:02:34,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'realtà', 'è', 'stato', 'il', 'p@@', 'ò', 'in', 'un', 'f@@', 'ut@@', 'uro', 'in', 'un', 'f@@', 'ut@@', 'uro', 'in', 'un', 'f@@', 'ut@@', 'ur@@', 'o@@', '.', '</s>']
2025-05-29 22:02:34,430 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:02:34,430 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:02:34,431 - INFO - joeynmt.training - 	Hypothesis: E in realtà è stato il pò in un futuro in un futuro in un futuro.
2025-05-29 22:02:34,431 - INFO - joeynmt.training - Example #4
2025-05-29 22:02:34,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:02:34,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:02:34,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'succ@@', 'essi@@', 'vo', 'è', 'una', 'c@@', 'at@@', 'en@@', 'a', 'è', 'una', 'c@@', 'at@@', 'en@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:02:34,431 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:02:34,431 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:02:34,431 - INFO - joeynmt.training - 	Hypothesis: Il prossimo successivo è una catena è una catena di quello che è successo negli ultimi 25 anni.
2025-05-29 22:02:37,779 - INFO - joeynmt.training - Epoch   3, Step:    26100, Batch Loss:     1.823565, Batch Acc: 0.434142, Tokens per Sec:    18794, Lr: 0.000300
2025-05-29 22:02:41,097 - INFO - joeynmt.training - Epoch   3, Step:    26200, Batch Loss:     1.907687, Batch Acc: 0.433693, Tokens per Sec:    20768, Lr: 0.000300
2025-05-29 22:02:44,428 - INFO - joeynmt.training - Epoch   3, Step:    26300, Batch Loss:     1.758285, Batch Acc: 0.431414, Tokens per Sec:    21325, Lr: 0.000300
2025-05-29 22:02:47,751 - INFO - joeynmt.training - Epoch   3, Step:    26400, Batch Loss:     1.898740, Batch Acc: 0.432647, Tokens per Sec:    22240, Lr: 0.000300
2025-05-29 22:02:51,068 - INFO - joeynmt.training - Epoch   3, Step:    26500, Batch Loss:     2.143824, Batch Acc: 0.433110, Tokens per Sec:    21160, Lr: 0.000300
2025-05-29 22:02:51,069 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:02:51,069 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:02:58,917 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.27, acc:   0.45, generation: 7.8375[sec], evaluation: 0.0000[sec]
2025-05-29 22:02:58,918 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:02:59,411 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/24000.ckpt
2025-05-29 22:02:59,435 - INFO - joeynmt.training - Example #0
2025-05-29 22:02:59,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:02:59,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:02:59,436 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'di@@', 'mostr@@', 'a', 'che', 'la', 'gente', 'che', 'la', 'gente', 'che', 'la', 'gente', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ato', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'di', 's@@', 'ott@@', 'op@@', 'ost@@', 'o', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'l@@', 'ev@@', 'are', 'il', '4@@', '0@@', '%', 'di', 'queste', 'cos@@', 'e@@', '.', '</s>']
2025-05-29 22:02:59,436 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:02:59,437 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:02:59,437 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questa dimostra che la gente che la gente che la gente è stato un po<unk> di ghiaccio di ghiacciato per il 48% di questi sono stati in grado di di sottoposto 48 ore per cento di 48 ore per cento di 40 per cento di rilevare il 40% di queste cose.
2025-05-29 22:02:59,437 - INFO - joeynmt.training - Example #1
2025-05-29 22:02:59,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:02:59,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:02:59,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'lo', 'fac@@', 'ci@@', 'am@@', 'o@@', ',', 'non', 'è', 'un', 'grande', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'un', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'm@@', 'ic@@', 'l@@', 'a@@', '.', '</s>']
2025-05-29 22:02:59,437 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:02:59,438 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:02:59,438 - INFO - joeynmt.training - 	Hypothesis: Ma non lo facciamo, non è un grande problema, e non è un problema, perché non c<unk> è la micla.
2025-05-29 22:02:59,438 - INFO - joeynmt.training - Example #2
2025-05-29 22:02:59,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:02:59,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:02:59,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'cas@@', 'o', 'di', 's@@', 'etti@@', 'man@@', 'a', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'at@@', 'en@@', 'a', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'un', 'sistema', 'di', 'm@@', 'ass@@', 'a', 'di', 'un', 'sistema', 'di', 'c@@', 'op@@', 'pi@@', 'r@@', 'on@@', 'e@@', ',', 'e', 'la', 'c@@', 'aus@@', 'a', 'di', 'un', 'sistema', 'di', 'c@@', 'aus@@', 'a', 'di', 's@@', 'é', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'sistema', 'di', 'm@@', 'ass@@', 'a', 'di', 'c@@', 'aus@@', 'a', 'di', 'l@@', 'or@@', 'o@@', '.', '</s>']
2025-05-29 22:02:59,438 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:02:59,438 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:02:59,439 - INFO - joeynmt.training - 	Hypothesis: In questo caso di settimana è la causa della nostra causa della nostra catena del nostro climatico del climatico del climatico di climatico di climatico di un sistema di massa di un sistema di coppirone, e la causa di un sistema di causa di sé che si tratta di un sistema di massa di causa di loro.
2025-05-29 22:02:59,439 - INFO - joeynmt.training - Example #3
2025-05-29 22:02:59,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:02:59,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:02:59,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'p@@', 'ò', 'in', 'm@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:02:59,439 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:02:59,439 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:02:59,439 - INFO - joeynmt.training - 	Hypothesis: E la cosa che si tratta di un pò in momento.
2025-05-29 22:02:59,439 - INFO - joeynmt.training - Example #4
2025-05-29 22:02:59,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:02:59,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:02:59,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'delle', 'col@@', 'i@@', 'e@@', ',', 'la', 'pros@@', 'si@@', 'ma', 'delle', 'persone', 'che', 'sono', 'st@@', 'ate', 'fac@@', 'endo', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'succ@@', 'ede', 'nel', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 22:02:59,440 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:02:59,440 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:02:59,440 - INFO - joeynmt.training - 	Hypothesis: La prossima delle colie, la prossima delle persone che sono state facendo una causa di quello che succede nel 25 anni fa.
2025-05-29 22:03:02,788 - INFO - joeynmt.training - Epoch   3, Step:    26600, Batch Loss:     1.955072, Batch Acc: 0.433706, Tokens per Sec:    17913, Lr: 0.000300
2025-05-29 22:03:06,138 - INFO - joeynmt.training - Epoch   3, Step:    26700, Batch Loss:     1.778507, Batch Acc: 0.437514, Tokens per Sec:    20611, Lr: 0.000300
2025-05-29 22:03:09,464 - INFO - joeynmt.training - Epoch   3, Step:    26800, Batch Loss:     2.038563, Batch Acc: 0.431486, Tokens per Sec:    20739, Lr: 0.000300
2025-05-29 22:03:12,825 - INFO - joeynmt.training - Epoch   3, Step:    26900, Batch Loss:     1.912134, Batch Acc: 0.431739, Tokens per Sec:    21136, Lr: 0.000300
2025-05-29 22:03:16,185 - INFO - joeynmt.training - Epoch   3, Step:    27000, Batch Loss:     1.966024, Batch Acc: 0.437151, Tokens per Sec:    20900, Lr: 0.000300
2025-05-29 22:03:16,185 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:03:16,186 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:03:25,384 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.26, acc:   0.46, generation: 9.1869[sec], evaluation: 0.0000[sec]
2025-05-29 22:03:25,385 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:03:25,943 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/24500.ckpt
2025-05-29 22:03:25,969 - INFO - joeynmt.training - Example #0
2025-05-29 22:03:25,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:03:25,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:03:25,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questi', 'due', 'di@@', 'sp@@', 'on@@', 'i@@', 'bili', 'per', 'di@@', 're@@', ',', 'per', 'di@@', 'mostr@@', 'ar@@', 'vi', 'che', 'la', 'c@@', 'aus@@', 'a', 'di', 'p@@', 'op@@', 'ol@@', 'ar@@', 'e@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'il', '4@@', '8@@', ',', 'che', 'è', 'stato', 'il', '4@@', '8', 'mili@@', 'on@@', 'i@@', ',', 'per', 'il', '4@@', '8@@', ',', 'per', 'il', '4@@', '8@@', ',', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'guar@@', 'do', 'a', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'guar@@', 'do', 'a', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:03:25,970 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:03:25,970 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:03:25,970 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questi due disponibili per dire, per dimostrarvi che la causa di popolare, che i ghiacciano il 48, che è stato il 48 milioni, per il 48, per il 48, per il 40 per cento di 40 per cento di 40 per cento di riguardo a 40 per cento di riguardo a 40 per cento di un po<unk> .
2025-05-29 22:03:25,970 - INFO - joeynmt.training - Example #1
2025-05-29 22:03:25,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:03:25,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:03:25,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'ris@@', 'ol@@', 't@@', 'o@@', ',', 'la', 'ter@@', 'ra@@', ',', 'che', 'non', 'c@@', '<unk>', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 22:03:25,971 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:03:25,971 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:03:25,971 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di risolto, la terra, che non c<unk> è la causa di questo tipo di problema.
2025-05-29 22:03:25,971 - INFO - joeynmt.training - Example #2
2025-05-29 22:03:25,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:03:25,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:03:25,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'sen@@', 'so', 'di', 's@@', 'é', 'la', 'c@@', 'aus@@', 'a', 'di', 'p@@', 'op@@', 'ol@@', 'azione', 'della', 'c@@', 'at@@', 'en@@', 'a', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'e', 'il', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'e', 'il', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'e', 'il', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'ic@@', 'l@@', 'oc@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:03:25,972 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:03:25,972 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:03:25,972 - INFO - joeynmt.training - 	Hypothesis: In questo senso di sé la causa di popolazione della catena del nostro climatico e il nostro climatico e il nostro climatico e il climatico di ciclocale.
2025-05-29 22:03:25,972 - INFO - joeynmt.training - Example #3
2025-05-29 22:03:25,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:03:25,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:03:25,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'li@@', '.', '</s>']
2025-05-29 22:03:25,973 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:03:25,973 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:03:25,973 - INFO - joeynmt.training - 	Hypothesis: E la cosa che è stato un po<unk> di sommergibili.
2025-05-29 22:03:25,973 - INFO - joeynmt.training - Example #4
2025-05-29 22:03:25,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:03:25,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:03:25,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'delle', 'cose', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'la', 'di@@', 'mostr@@', 'a', 'è', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:03:25,974 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:03:25,974 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:03:25,974 - INFO - joeynmt.training - 	Hypothesis: La prossima delle cose che vi mostrerò la dimostra è una causa di quello che è successo nel 25 anni.
2025-05-29 22:03:29,377 - INFO - joeynmt.training - Epoch   3, Step:    27100, Batch Loss:     1.919241, Batch Acc: 0.433684, Tokens per Sec:    17680, Lr: 0.000300
2025-05-29 22:03:32,763 - INFO - joeynmt.training - Epoch   3, Step:    27200, Batch Loss:     1.824318, Batch Acc: 0.432112, Tokens per Sec:    20806, Lr: 0.000300
2025-05-29 22:03:36,135 - INFO - joeynmt.training - Epoch   3, Step:    27300, Batch Loss:     1.836525, Batch Acc: 0.438404, Tokens per Sec:    20973, Lr: 0.000300
2025-05-29 22:03:39,524 - INFO - joeynmt.training - Epoch   3, Step:    27400, Batch Loss:     1.741406, Batch Acc: 0.434285, Tokens per Sec:    21294, Lr: 0.000300
2025-05-29 22:03:42,906 - INFO - joeynmt.training - Epoch   3, Step:    27500, Batch Loss:     1.877917, Batch Acc: 0.431964, Tokens per Sec:    21143, Lr: 0.000300
2025-05-29 22:03:42,907 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:03:42,907 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:03:52,698 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.21, acc:   0.46, generation: 9.7781[sec], evaluation: 0.0000[sec]
2025-05-29 22:03:52,699 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:03:53,247 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/25000.ckpt
2025-05-29 22:03:53,275 - INFO - joeynmt.training - Example #0
2025-05-29 22:03:53,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:03:53,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:03:53,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'seg@@', 'ni', 'di', 'di@@', 're@@', ',', 'che', 'l@@', '<unk>', 'e@@', 'qu@@', 'i@@', ',', 'che', 'l@@', '<unk>', 'e@@', 'qu@@', 'i@@', 'p@@', 'aggi@@', 'amento', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'qu@@', 'elli', 'di', 'questi', 'sono', 'stati', 'in', '4@@', '8', 'st@@', 'ati@@', ',', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:03:53,276 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:03:53,276 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:03:53,277 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questi due disegni di dire, che l<unk> equi, che l<unk> equipaggiamento di un ghiaccio di quelli di questi sono stati in 48 stati, per 40 per cento di 40 per cento di 40 per cento di 40 per cento di anni.
2025-05-29 22:03:53,277 - INFO - joeynmt.training - Example #1
2025-05-29 22:03:53,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:03:53,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:03:53,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 'problema', 'di', 'n@@', 'as@@', 'c@@', 'ere', 'di', 'questo', 'spe@@', 'ci@@', 'fic@@', 'o@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'de@@', 'st@@', 'in@@', 'azione', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:03:53,277 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:03:53,277 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:03:53,278 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è un certo senso di un problema di nascere di questo specifico, perché non c<unk> è la destinazione del ghiaccio.
2025-05-29 22:03:53,278 - INFO - joeynmt.training - Example #2
2025-05-29 22:03:53,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:03:53,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:03:53,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'sen@@', 'so', 'di', 'S@@', 'in@@', 'ne', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'c@@', 'att@@', 'ur@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:03:53,278 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:03:53,278 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:03:53,279 - INFO - joeynmt.training - 	Hypothesis: In questo senso di Sinne è la causa della cattura, il cuore globale del nostro climatico del nostro climatico del nostro climatico di climatico di climatico.
2025-05-29 22:03:53,279 - INFO - joeynmt.training - Example #3
2025-05-29 22:03:53,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:03:53,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:03:53,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'più', 'b@@', 'ell@@', 'issi@@', 'mo', 'in', 'b@@', 're@@', 've', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 'f@@', 'ut@@', 'uro', 'di', 'un', 'f@@', 'ut@@', 'uro', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:03:53,279 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:03:53,279 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:03:53,279 - INFO - joeynmt.training - 	Hypothesis: E la cosa più bellissimo in breve in un certo senso di un futuro di un futuro di un po<unk> .
2025-05-29 22:03:53,280 - INFO - joeynmt.training - Example #4
2025-05-29 22:03:53,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:03:53,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:03:53,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cap@@', 'it@@', 'ale', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'succ@@', 'ede', 'nel', 'cor@@', 'so', 'di', 'quello', 'che', 'succ@@', 'ede', 'nel', 'cor@@', 'so', 'di', 'questa', 'sc@@', 'or@@', 'sa', 'di', 'tutto', 'ci@@', 'ò@@', ',', 'e', 'la', 'pros@@', 'si@@', 'ma', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:03:53,280 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:03:53,280 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:03:53,280 - INFO - joeynmt.training - 	Hypothesis: La prossima capitale che vi mostrerò una causa di quello che succede nel corso di quello che succede nel corso di questa scorsa di tutto ciò, e la prossima anni.
2025-05-29 22:03:56,684 - INFO - joeynmt.training - Epoch   3, Step:    27600, Batch Loss:     1.832346, Batch Acc: 0.429684, Tokens per Sec:    17633, Lr: 0.000300
2025-05-29 22:04:00,081 - INFO - joeynmt.training - Epoch   3, Step:    27700, Batch Loss:     1.742112, Batch Acc: 0.437590, Tokens per Sec:    20919, Lr: 0.000300
2025-05-29 22:04:03,451 - INFO - joeynmt.training - Epoch   3, Step:    27800, Batch Loss:     1.851468, Batch Acc: 0.437160, Tokens per Sec:    20886, Lr: 0.000300
2025-05-29 22:04:06,844 - INFO - joeynmt.training - Epoch   3, Step:    27900, Batch Loss:     1.738448, Batch Acc: 0.433680, Tokens per Sec:    21721, Lr: 0.000300
2025-05-29 22:04:10,216 - INFO - joeynmt.training - Epoch   3, Step:    28000, Batch Loss:     1.953690, Batch Acc: 0.434835, Tokens per Sec:    20862, Lr: 0.000300
2025-05-29 22:04:10,216 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:04:10,216 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:04:19,649 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.20, acc:   0.46, generation: 9.4206[sec], evaluation: 0.0000[sec]
2025-05-29 22:04:19,649 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:04:20,185 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/25500.ckpt
2025-05-29 22:04:20,211 - INFO - joeynmt.training - Example #0
2025-05-29 22:04:20,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:04:20,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:04:20,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'ri@@', 'man@@', 'ere', 'questi', 'due', 'pa@@', 'esi', 'per', 'far@@', 'l@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'l@@', 'ett@@', 'amente', 'per', 'gli', 'St@@', 'ati', 'Un@@', 'iti@@', ',', 'che', 'per', 'l@@', '<unk>', 'in@@', 'segn@@', 'amento', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:04:20,213 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:04:20,213 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:04:20,213 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di rimanere questi due paesi per farlo, che l<unk> articlettamente per gli Stati Uniti, che per l<unk> insegnamento di 48 stati.
2025-05-29 22:04:20,213 - INFO - joeynmt.training - Example #1
2025-05-29 22:04:20,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:04:20,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:04:20,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'am@@', 'ent@@', 'e@@', ',', 'l@@', '<unk>', 'es@@', 'peri@@', 'enza', 'di', 'questo', 'spe@@', 'ci@@', 'fic@@', 'o@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'mus@@', 'ica', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 22:04:20,214 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:04:20,214 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:04:20,214 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente, l<unk> esperienza di questo specifico, perché non c<unk> è la musica del ghiaccia.
2025-05-29 22:04:20,214 - INFO - joeynmt.training - Example #2
2025-05-29 22:04:20,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:04:20,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:04:20,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'in', 'realtà', 'è', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'è', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'della', 'c@@', 'aus@@', 'a', 'della', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'at@@', 'en@@', 'a', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:04:20,215 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:04:20,215 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:04:20,215 - INFO - joeynmt.training - 	Hypothesis: In effetti, in realtà è la squadra è la squadra della causa della causa della nostra catena globale.
2025-05-29 22:04:20,215 - INFO - joeynmt.training - Example #3
2025-05-29 22:04:20,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:04:20,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:04:20,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'più', 'importante', 'nel', 'm@@', 'ezz@@', 'o', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 22:04:20,216 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:04:20,216 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:04:20,216 - INFO - joeynmt.training - 	Hypothesis: E la cosa più importante nel mezzo di un sacco di sommer.
2025-05-29 22:04:20,216 - INFO - joeynmt.training - Example #4
2025-05-29 22:04:20,216 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:04:20,216 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:04:20,216 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'etti@@', 'man@@', 'a@@', ',', 'la', 'pros@@', 'si@@', 'ma', 's@@', 'etti@@', 'man@@', 'a@@', ',', 'è', 'una', 'di@@', 'st@@', 'anza', 'per', 'la', 'prima', 'cosa', 'che', 'è', 'succ@@', 'esso', 'nel', '200@@', '5@@', '.', '</s>']
2025-05-29 22:04:20,216 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:04:20,217 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:04:20,217 - INFO - joeynmt.training - 	Hypothesis: La prossima settimana, la prossima settimana, è una distanza per la prima cosa che è successo nel 2005.
2025-05-29 22:04:23,610 - INFO - joeynmt.training - Epoch   3, Step:    28100, Batch Loss:     1.880821, Batch Acc: 0.432084, Tokens per Sec:    17373, Lr: 0.000300
2025-05-29 22:04:26,997 - INFO - joeynmt.training - Epoch   3, Step:    28200, Batch Loss:     2.126972, Batch Acc: 0.435326, Tokens per Sec:    21461, Lr: 0.000300
2025-05-29 22:04:30,371 - INFO - joeynmt.training - Epoch   3, Step:    28300, Batch Loss:     1.896845, Batch Acc: 0.438582, Tokens per Sec:    21092, Lr: 0.000300
2025-05-29 22:04:33,747 - INFO - joeynmt.training - Epoch   3, Step:    28400, Batch Loss:     1.870104, Batch Acc: 0.434015, Tokens per Sec:    20801, Lr: 0.000300
2025-05-29 22:04:37,096 - INFO - joeynmt.training - Epoch   3, Step:    28500, Batch Loss:     1.771778, Batch Acc: 0.437243, Tokens per Sec:    21192, Lr: 0.000300
2025-05-29 22:04:37,096 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:04:37,096 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:04:46,245 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.13, acc:   0.46, generation: 9.1375[sec], evaluation: 0.0000[sec]
2025-05-29 22:04:46,246 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:04:46,742 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/26000.ckpt
2025-05-29 22:04:46,766 - INFO - joeynmt.training - Example #0
2025-05-29 22:04:46,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:04:46,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:04:46,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questa', 'di@@', 're@@', 'zione', 'per', 'fare', 'le', 'due', 'v@@', 'ec@@', 'chi@@', 'e@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'per', 'le', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'questi', 'sono', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'fatto', 'il', '4@@', '8', 'ore', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 'ris@@', 'ult@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:04:46,767 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:04:46,767 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:04:46,767 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questa direzione per fare le due vecchie, che le ghiacciano che le ghiacciano per le tre milioni di anni di anni di questi sono tre milioni di anni di anni di persone che hanno fatto il 48 ore di 48 ore per cento di 48 ore per cento di un sacco di risultato.
2025-05-29 22:04:46,767 - INFO - joeynmt.training - Example #1
2025-05-29 22:04:46,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:04:46,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:04:46,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'ma', 'di', 'un', 'problema', 'di', 'ris@@', 'ol@@', 'vere', 'il', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'de@@', 'm@@', 'oc@@', 'r@@', 'azi@@', 'a', 'di', 'p@@', 'au@@', 'ra', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'are', 'il', 't@@', 'as@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:04:46,768 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:04:46,768 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:04:46,768 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forma di un problema di risolvere il problema, non è la democrazia di paura di ghiacciare il tasso di ghiaccio.
2025-05-29 22:04:46,768 - INFO - joeynmt.training - Example #2
2025-05-29 22:04:46,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:04:46,768 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:04:46,768 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 's@@', 'é', 'l@@', '<unk>', 'e@@', 'du@@', 'c@@', 'azione', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'la', 's@@', 'fi@@', 'da', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:04:46,769 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:04:46,769 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:04:46,769 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di sé l<unk> educazione artica, la sfida globale.
2025-05-29 22:04:46,769 - INFO - joeynmt.training - Example #3
2025-05-29 22:04:46,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:04:46,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:04:46,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E@@', '<unk>', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'una', 'cosa', 'che', 'è', 'stato', 'un', 's@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 22:04:46,770 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:04:46,770 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:04:46,770 - INFO - joeynmt.training - 	Hypothesis: E<unk> una cosa che è una cosa che è una cosa che è stato un sommer.
2025-05-29 22:04:46,770 - INFO - joeynmt.training - Example #4
2025-05-29 22:04:46,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:04:46,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:04:46,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cap@@', 'ac@@', 'i', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'at@@', 'en@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', 'questo', 'm@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:04:46,771 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:04:46,771 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:04:46,771 - INFO - joeynmt.training - 	Hypothesis: La prossima capaci che vi mostrerò una catena di quello che è successo in questo momento.
2025-05-29 22:04:50,173 - INFO - joeynmt.training - Epoch   3, Step:    28600, Batch Loss:     1.753116, Batch Acc: 0.436551, Tokens per Sec:    18247, Lr: 0.000300
2025-05-29 22:04:53,580 - INFO - joeynmt.training - Epoch   3, Step:    28700, Batch Loss:     1.987193, Batch Acc: 0.432515, Tokens per Sec:    21191, Lr: 0.000300
2025-05-29 22:04:56,954 - INFO - joeynmt.training - Epoch   3, Step:    28800, Batch Loss:     1.810603, Batch Acc: 0.444443, Tokens per Sec:    20553, Lr: 0.000300
2025-05-29 22:05:00,329 - INFO - joeynmt.training - Epoch   3, Step:    28900, Batch Loss:     1.754682, Batch Acc: 0.444983, Tokens per Sec:    20924, Lr: 0.000300
2025-05-29 22:05:03,704 - INFO - joeynmt.training - Epoch   3, Step:    29000, Batch Loss:     1.946669, Batch Acc: 0.439448, Tokens per Sec:    21783, Lr: 0.000300
2025-05-29 22:05:03,704 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:05:03,704 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:05:13,219 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.14, acc:   0.46, generation: 9.5033[sec], evaluation: 0.0000[sec]
2025-05-29 22:05:13,747 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/26500.ckpt
2025-05-29 22:05:13,772 - INFO - joeynmt.training - Example #0
2025-05-29 22:05:13,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:05:13,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:05:13,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'v@@', 'it@@', 'ti@@', 'me', 'di', 'queste', 'due', 'v@@', 'it@@', 'ti@@', 'me', 'di', 'v@@', 'ar@@', 't@@', 'icol@@', 'i', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'are', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'an@@', 'ni@@', ',', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'al@@', 'to', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'al@@', 'to', 'per', 'c@@', 'ento', 'di', 'ri@@', 'vel@@', 'are', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ri@@', 'min@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:05:13,774 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:05:13,774 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:05:13,774 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due vittime di queste due vittime di varticoli di ghiacciare che i ghiacciati per tre milioni di anni di anni, che ha avuto il 40 per cento di tre milioni di anni per cento di alto per il 40 percento di alto per cento di rivelare il 40 percento di criminale.
2025-05-29 22:05:13,774 - INFO - joeynmt.training - Example #1
2025-05-29 22:05:13,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:05:13,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:05:13,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'ver@@', 'amente', 'in@@', 'cre@@', 'di@@', 'bil@@', 'mente', 'la', 'ris@@', 'post@@', 'a', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'non', 'è', 'la', 'de@@', 'st@@', 'in@@', 'azione', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:05:13,775 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:05:13,775 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:05:13,775 - INFO - joeynmt.training - 	Hypothesis: Ma non è veramente incredibilmente la risposta di questo speciale di questo speciale di questo speciale, non è la destinazione del ghiaccio.
2025-05-29 22:05:13,775 - INFO - joeynmt.training - Example #2
2025-05-29 22:05:13,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:05:13,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:05:13,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'il', 'sen@@', 'so', 'di', 's@@', 'ette', 'ar@@', 't@@', 'icol@@', 'i', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'i@@', '.', '</s>']
2025-05-29 22:05:13,776 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:05:13,776 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:05:13,776 - INFO - joeynmt.training - 	Hypothesis: In effetti, il senso di sette articoli di ghiacciati di climatici.
2025-05-29 22:05:13,776 - INFO - joeynmt.training - Example #3
2025-05-29 22:05:13,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:05:13,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:05:13,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', '<unk>', 'è', 'una', 'cosa', 'che', 'si', 'può', 'essere', 'in', 'gra@@', 'do', 'di', 'fare', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:05:13,776 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:05:13,776 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:05:13,777 - INFO - joeynmt.training - 	Hypothesis: C<unk> è una cosa che si può essere in grado di fare in un certo senso.
2025-05-29 22:05:13,777 - INFO - joeynmt.training - Example #4
2025-05-29 22:05:13,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:05:13,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:05:13,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'aus@@', 'a', 'di', 'queste', 'cose', 'che', 'succ@@', 'e@@', 'de@@', 'va', 'in', 'ci@@', 'ma', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:05:13,777 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:05:13,777 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:05:13,777 - INFO - joeynmt.training - 	Hypothesis: La prossima è una cosa che vi mostrerò una causa di queste cose che succedeva in cima di quello che è successo negli ultimi 25 anni.
2025-05-29 22:05:17,131 - INFO - joeynmt.training - Epoch   3, Step:    29100, Batch Loss:     2.035228, Batch Acc: 0.436562, Tokens per Sec:    18591, Lr: 0.000300
2025-05-29 22:05:20,499 - INFO - joeynmt.training - Epoch   3, Step:    29200, Batch Loss:     1.828973, Batch Acc: 0.431110, Tokens per Sec:    20559, Lr: 0.000300
2025-05-29 22:05:23,871 - INFO - joeynmt.training - Epoch   3, Step:    29300, Batch Loss:     1.954071, Batch Acc: 0.434927, Tokens per Sec:    20966, Lr: 0.000300
2025-05-29 22:05:27,246 - INFO - joeynmt.training - Epoch   3, Step:    29400, Batch Loss:     1.920761, Batch Acc: 0.437223, Tokens per Sec:    20935, Lr: 0.000300
2025-05-29 22:05:30,610 - INFO - joeynmt.training - Epoch   3, Step:    29500, Batch Loss:     1.974359, Batch Acc: 0.436200, Tokens per Sec:    20922, Lr: 0.000300
2025-05-29 22:05:30,611 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:05:30,611 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:05:39,654 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.08, acc:   0.46, generation: 9.0307[sec], evaluation: 0.0000[sec]
2025-05-29 22:05:39,654 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:05:40,210 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/27000.ckpt
2025-05-29 22:05:40,238 - INFO - joeynmt.training - Example #0
2025-05-29 22:05:40,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:05:40,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:05:40,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'che', 'sono', 'queste', 'due', 'che', 'sono', 'in@@', 'forma@@', 'zioni', 'che', 'sono', 'le', 'persone', 'che', 'hanno', 'fatto', 'che', 'la', 'ar@@', 't@@', 'icol@@', 't@@', 'ura', 'che', 'l@@', '<unk>', 'el@@', 'et@@', 'tr@@', 'ic@@', 'e', 'che', 'ha', 'fatto', 'per', 'la', 'prima', 'volta', 'che', 'il', '4@@', '8', 'ore', 'di', 'St@@', 'ati', 'Un@@', 'iti@@', '.', '</s>']
2025-05-29 22:05:40,239 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:05:40,239 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:05:40,239 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due che sono queste due che sono informazioni che sono le persone che hanno fatto che la articoltura che l<unk> elettrice che ha fatto per la prima volta che il 48 ore di Stati Uniti.
2025-05-29 22:05:40,239 - INFO - joeynmt.training - Example #1
2025-05-29 22:05:40,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:05:40,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:05:40,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'amente', 'la', 'ris@@', 'post@@', 'a', 'in', 'questo', 'mo@@', 'd@@', 'o@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'la', 'de@@', 'st@@', 'in@@', 'azione', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:05:40,240 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:05:40,240 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:05:40,240 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente la risposta in questo modo, perché non è il Dicke non è la destinazione del ghiaccio.
2025-05-29 22:05:40,240 - INFO - joeynmt.training - Example #2
2025-05-29 22:05:40,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:05:40,241 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:05:40,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'il', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'la', 'cu@@', 'ore', 'della', 'nostra', 'c@@', 'li@@', 'mat@@', 'ica', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:05:40,241 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:05:40,241 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:05:40,241 - INFO - joeynmt.training - 	Hypothesis: In effetti, il senso di ghiaccia, la cuore della nostra climatica del nostro climatico.
2025-05-29 22:05:40,241 - INFO - joeynmt.training - Example #3
2025-05-29 22:05:40,241 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:05:40,241 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:05:40,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'eff@@', 'etti', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:05:40,242 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:05:40,242 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:05:40,242 - INFO - joeynmt.training - 	Hypothesis: E in effetti in un certo senso.
2025-05-29 22:05:40,242 - INFO - joeynmt.training - Example #4
2025-05-29 22:05:40,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:05:40,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:05:40,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cap@@', 'it@@', 'ale', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'c@@', 'aus@@', 'a', 'di', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:05:40,243 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:05:40,243 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:05:40,243 - INFO - joeynmt.training - 	Hypothesis: La prossima capitale che vi mostro è una causa di una causa di quello che è successo nel 25 anni.
2025-05-29 22:05:43,630 - INFO - joeynmt.training - Epoch   3, Step:    29600, Batch Loss:     2.051613, Batch Acc: 0.433190, Tokens per Sec:    17867, Lr: 0.000300
2025-05-29 22:05:47,012 - INFO - joeynmt.training - Epoch   3, Step:    29700, Batch Loss:     1.856405, Batch Acc: 0.444114, Tokens per Sec:    21108, Lr: 0.000300
2025-05-29 22:05:50,397 - INFO - joeynmt.training - Epoch   3, Step:    29800, Batch Loss:     1.910083, Batch Acc: 0.447814, Tokens per Sec:    21531, Lr: 0.000300
2025-05-29 22:05:53,764 - INFO - joeynmt.training - Epoch   3, Step:    29900, Batch Loss:     1.853631, Batch Acc: 0.439094, Tokens per Sec:    21126, Lr: 0.000300
2025-05-29 22:05:57,128 - INFO - joeynmt.training - Epoch   3, Step:    30000, Batch Loss:     1.707672, Batch Acc: 0.440067, Tokens per Sec:    20519, Lr: 0.000300
2025-05-29 22:05:57,129 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:05:57,129 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:06:05,524 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.04, acc:   0.47, generation: 8.3837[sec], evaluation: 0.0000[sec]
2025-05-29 22:06:05,524 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:06:06,122 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/27500.ckpt
2025-05-29 22:06:06,148 - INFO - joeynmt.training - Example #0
2025-05-29 22:06:06,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:06:06,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:06:06,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'o', 'di', 'queste', 'due', 'f@@', 'ig@@', 'li@@', ',', 'per', 'con@@', 'si@@', 'der@@', 'are', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'am@@', 'ent@@', 'e@@', ',', 'che', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'stata', 'la', 'più', 'grande', 'di', '4@@', '8', 'st@@', 'at@@', 'un@@', 'it@@', 'en@@', 'z@@', 'a@@', '.', '</s>']
2025-05-29 22:06:06,149 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:06:06,149 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:06:06,149 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato questa foto di queste due figli, per considerare che la ghiacciamente, che il ghiaccio è stata la più grande di 48 statunitenza.
2025-05-29 22:06:06,149 - INFO - joeynmt.training - Example #1
2025-05-29 22:06:06,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:06:06,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:06:06,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'in', 'realtà', 'la', 'ris@@', 'post@@', 'a', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'un', 'problema', 'spe@@', 'ci@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:06:06,150 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:06:06,150 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:06:06,150 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte in realtà la risposta di questo problema, perché non è un problema speciale.
2025-05-29 22:06:06,150 - INFO - joeynmt.training - Example #2
2025-05-29 22:06:06,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:06:06,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:06:06,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'la', 's@@', 'om@@', 'ig@@', 'lia', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:06:06,151 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:06:06,151 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:06:06,151 - INFO - joeynmt.training - 	Hypothesis: In effetti, la somiglia è la causa della nostra climassa globale.
2025-05-29 22:06:06,151 - INFO - joeynmt.training - Example #3
2025-05-29 22:06:06,151 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:06:06,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:06:06,151 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'può', 'essere', 'in', 'gra@@', 'do', 'di', 'ri@@', 'fl@@', 'et@@', 'tere', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'al', 'l@@', 'ato', 'e', 'il', 'p@@', 'es@@', 'o@@', '.', '</s>']
2025-05-29 22:06:06,152 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:06:06,152 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:06:06,152 - INFO - joeynmt.training - 	Hypothesis: E si può essere in grado di riflettere in un certo senso al lato e il peso.
2025-05-29 22:06:06,152 - INFO - joeynmt.training - Example #4
2025-05-29 22:06:06,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:06:06,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:06:06,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cap@@', 'is@@', 'co', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:06:06,152 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:06:06,152 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:06:06,152 - INFO - joeynmt.training - 	Hypothesis: La prossima capisco che vi mostrerò è una causa di quello che è successo nel 25 anni.
2025-05-29 22:06:09,549 - INFO - joeynmt.training - Epoch   3, Step:    30100, Batch Loss:     2.025294, Batch Acc: 0.442740, Tokens per Sec:    17187, Lr: 0.000300
2025-05-29 22:06:12,948 - INFO - joeynmt.training - Epoch   3, Step:    30200, Batch Loss:     2.019418, Batch Acc: 0.437986, Tokens per Sec:    21540, Lr: 0.000300
2025-05-29 22:06:16,314 - INFO - joeynmt.training - Epoch   3, Step:    30300, Batch Loss:     1.796000, Batch Acc: 0.440929, Tokens per Sec:    20804, Lr: 0.000300
2025-05-29 22:06:19,669 - INFO - joeynmt.training - Epoch   3, Step:    30400, Batch Loss:     1.793003, Batch Acc: 0.442875, Tokens per Sec:    21640, Lr: 0.000300
2025-05-29 22:06:23,027 - INFO - joeynmt.training - Epoch   3, Step:    30500, Batch Loss:     1.757913, Batch Acc: 0.441671, Tokens per Sec:    20927, Lr: 0.000300
2025-05-29 22:06:23,027 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:06:23,028 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:06:32,084 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.05, acc:   0.47, generation: 9.0444[sec], evaluation: 0.0000[sec]
2025-05-29 22:06:32,427 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/28000.ckpt
2025-05-29 22:06:32,449 - INFO - joeynmt.training - Example #0
2025-05-29 22:06:32,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:06:32,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:06:32,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'o', 'per', 'con@@', 'fr@@', 'ont@@', 'are', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'per', 'la', 'ri@@', 'vol@@', 'u@@', 'zione', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'per', 'il', '4@@', '8', 'st@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:06:32,450 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:06:32,450 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:06:32,450 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato questa foto per confrontare le ghiaccia, che la ghiaccio è che la ghiaccio per la rivoluzione di ghiaccia, per il 48 stato.
2025-05-29 22:06:32,450 - INFO - joeynmt.training - Example #1
2025-05-29 22:06:32,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:06:32,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:06:32,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stata', 'la', 'for@@', 'za', 'di', 'essere', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'la', 'D@@', 'ic@@', 'a@@', ',', 'perché', 'non', 'è', 'la', 'D@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 22:06:32,451 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:06:32,451 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:06:32,451 - INFO - joeynmt.training - 	Hypothesis: Ma non è stata la forza di essere abbastanza forte di questo problema, perché non è la Dica, perché non è la Dica.
2025-05-29 22:06:32,451 - INFO - joeynmt.training - Example #2
2025-05-29 22:06:32,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:06:32,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:06:32,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'è', 'la', 's@@', 'fi@@', 'da', 'è', 'la', 's@@', 'fi@@', 'da', 'è', 'la', 'cu@@', 'c@@', 'ina', 'del', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:06:32,452 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:06:32,452 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:06:32,452 - INFO - joeynmt.training - 	Hypothesis: In realtà è la sfida è la sfida è la cucina del sistema globale.
2025-05-29 22:06:32,452 - INFO - joeynmt.training - Example #3
2025-05-29 22:06:32,452 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:06:32,452 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:06:32,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'e', 'il', 'b@@', 'att@@', 'ito', 'di', 'un', 'f@@', 'ogli@@', 'o@@', '.', '</s>']
2025-05-29 22:06:32,453 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:06:32,453 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:06:32,453 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, e il battito di un foglio.
2025-05-29 22:06:32,453 - INFO - joeynmt.training - Example #4
2025-05-29 22:06:32,453 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:06:32,453 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:06:32,453 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'cap@@', 'ac@@', 'i', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', 'cor@@', 'so', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', 'cor@@', 'so', 'della', 'sc@@', 'or@@', 'sa', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 'po@@', '<unk>', 'di', 'in@@', 'segn@@', 'are', 'a', 'un', 'cer@@', 'to', 'sen@@', 'so', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'è', 'succ@@', 'esso', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:06:32,454 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:06:32,454 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:06:32,454 - INFO - joeynmt.training - 	Hypothesis: La prossima capaci che vi mostrerò è una dimostrazione di quello che è successo nel corso di quello che è successo nel corso della scorsa che è successo in cui è successo in un certo senso di un po<unk> di insegnare a un certo senso che vi mostrerò che vi mostrerò che è successo in un certo senso di un po<unk> .
2025-05-29 22:06:35,839 - INFO - joeynmt.training - Epoch   3, Step:    30600, Batch Loss:     1.833790, Batch Acc: 0.438946, Tokens per Sec:    18524, Lr: 0.000300
2025-05-29 22:06:39,221 - INFO - joeynmt.training - Epoch   3, Step:    30700, Batch Loss:     1.802519, Batch Acc: 0.439613, Tokens per Sec:    21053, Lr: 0.000300
2025-05-29 22:06:42,588 - INFO - joeynmt.training - Epoch   3, Step:    30800, Batch Loss:     1.854335, Batch Acc: 0.447632, Tokens per Sec:    21094, Lr: 0.000300
2025-05-29 22:06:45,969 - INFO - joeynmt.training - Epoch   3, Step:    30900, Batch Loss:     1.948826, Batch Acc: 0.438293, Tokens per Sec:    20927, Lr: 0.000300
2025-05-29 22:06:49,334 - INFO - joeynmt.training - Epoch   3, Step:    31000, Batch Loss:     1.934250, Batch Acc: 0.440205, Tokens per Sec:    20566, Lr: 0.000300
2025-05-29 22:06:49,335 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:06:49,335 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:06:59,195 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.04, acc:   0.47, generation: 9.8472[sec], evaluation: 0.0000[sec]
2025-05-29 22:06:59,574 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/29000.ckpt
2025-05-29 22:06:59,601 - INFO - joeynmt.training - Example #0
2025-05-29 22:06:59,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:06:59,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:06:59,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'col@@', 'on@@', 'ie', 'per', 'fare', 'queste', 'due', 'col@@', 'on@@', 'i@@', ',', 'per', 'fare', 'un', 'li@@', 'vello', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'persone', 'per', 'le', 'm@@', 'app@@', 'e', 'che', 'le', 'persone', 'per', 'le', 'm@@', 'ie', 'di', '4@@', '8', 'st@@', 'ati@@', 'sti@@', 'che', 'per', 'il', '4@@', '8', 'st@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:06:59,602 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:06:59,602 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:06:59,602 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due colonie per fare queste due coloni, per fare un livello di ghiaccio, che le persone per le mappe che le persone per le mie di 48 statistiche per il 48 stato.
2025-05-29 22:06:59,602 - INFO - joeynmt.training - Example #1
2025-05-29 22:06:59,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:06:59,603 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:06:59,603 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'amente', 'la', 'ris@@', 'post@@', 'a', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'de@@', 'st@@', 'in@@', 'azione', 'di', 'E@@', 'is@@', 'es', 'e', 'la', 'di@@', 'mostr@@', 'azione', 'di', 'E@@', 'is@@', '.', '</s>']
2025-05-29 22:06:59,603 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:06:59,603 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:06:59,603 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente la risposta di questo tipo di problema, perché non c<unk> è la destinazione di Eises e la dimostrazione di Eis.
2025-05-29 22:06:59,603 - INFO - joeynmt.training - Example #2
2025-05-29 22:06:59,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:06:59,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:06:59,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti', 's@@', 'anno', 'che', 'il', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:06:59,604 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:06:59,604 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:06:59,604 - INFO - joeynmt.training - 	Hypothesis: In effetti sanno che il senso di ghiaccio è la cucina del nostro climatico del nostro climatico.
2025-05-29 22:06:59,604 - INFO - joeynmt.training - Example #3
2025-05-29 22:06:59,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:06:59,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:06:59,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tutto', 'il', 'mon@@', 'd@@', 'o@@', ',', 'e', 'si', 'ri@@', 'es@@', 'ce', 'a', 'fare', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:06:59,605 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:06:59,605 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:06:59,605 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto il mondo, e si riesce a fare in un certo senso.
2025-05-29 22:06:59,605 - INFO - joeynmt.training - Example #4
2025-05-29 22:06:59,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:06:59,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:06:59,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'etti@@', 'man@@', 'e', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', 'ci@@', 'el@@', 'o', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:06:59,606 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:06:59,606 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:06:59,606 - INFO - joeynmt.training - 	Hypothesis: La prossima settimane che vi mostrerò una causa di quello che è successo nel cielo di quello che è successo negli ultimi 25 anni.
2025-05-29 22:07:03,010 - INFO - joeynmt.training - Epoch   3, Step:    31100, Batch Loss:     1.963546, Batch Acc: 0.436382, Tokens per Sec:    18510, Lr: 0.000300
2025-05-29 22:07:06,383 - INFO - joeynmt.training - Epoch   3, Step:    31200, Batch Loss:     1.944219, Batch Acc: 0.439638, Tokens per Sec:    21075, Lr: 0.000300
2025-05-29 22:07:09,761 - INFO - joeynmt.training - Epoch   3, Step:    31300, Batch Loss:     1.804547, Batch Acc: 0.443759, Tokens per Sec:    21183, Lr: 0.000300
2025-05-29 22:07:13,134 - INFO - joeynmt.training - Epoch   3, Step:    31400, Batch Loss:     1.835316, Batch Acc: 0.446411, Tokens per Sec:    21026, Lr: 0.000300
2025-05-29 22:07:16,511 - INFO - joeynmt.training - Epoch   3, Step:    31500, Batch Loss:     1.975011, Batch Acc: 0.442500, Tokens per Sec:    21427, Lr: 0.000300
2025-05-29 22:07:16,512 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:07:16,512 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:07:25,038 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.94, acc:   0.47, generation: 8.5178[sec], evaluation: 0.0000[sec]
2025-05-29 22:07:25,038 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:07:25,509 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/28500.ckpt
2025-05-29 22:07:25,533 - INFO - joeynmt.training - Example #0
2025-05-29 22:07:25,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:07:25,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:07:25,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'che', 'la', 'gente', 'che', 'ha', 'mostr@@', 'ato', 'che', 'la', 'gente', 'che', 'la', 'prima', 'volta', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'la', 'gente', 'ha', 'fatto', 'per', 'la', 'prima', 'volta', 'che', 'i', '4@@', '8', 'st@@', 'ati@@', ',', 'e', 'il', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:07:25,534 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:07:25,534 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:07:25,534 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato che la gente che ha mostrato che la gente che la prima volta che la ghiaccia, che la gente ha fatto per la prima volta che i 48 stati, e il 48 stati.
2025-05-29 22:07:25,534 - INFO - joeynmt.training - Example #1
2025-05-29 22:07:25,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:07:25,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:07:25,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'la', 'ris@@', 'post@@', 'a', 'in', 'questo', 'mo@@', 'dello', 'spe@@', 'ci@@', 'fic@@', 'o@@', ',', 'perché', 'non', 'è', 'la', 'de@@', 'fin@@', 'it@@', 'à@@', '.', '</s>']
2025-05-29 22:07:25,535 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:07:25,535 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:07:25,535 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo problema, e la risposta in questo modello specifico, perché non è la definità.
2025-05-29 22:07:25,535 - INFO - joeynmt.training - Example #2
2025-05-29 22:07:25,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:07:25,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:07:25,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'è', 'la', 's@@', 'qu@@', 'ad@@', 'ra', 'e', 'la', 'cu@@', 'ore', 'della', 'nostra', 'c@@', 'li@@', 'mat@@', 'ica', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:07:25,536 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:07:25,536 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:07:25,536 - INFO - joeynmt.training - 	Hypothesis: In effetti, la squadra è la squadra e la cuore della nostra climatica del nostro sistema globale.
2025-05-29 22:07:25,536 - INFO - joeynmt.training - Example #3
2025-05-29 22:07:25,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:07:25,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:07:25,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'et@@', 'e@@', ',', 'in', 'v@@', 'ento', 'in', 'v@@', 'in@@', 'cit@@', 't@@', 'à@@', '.', '</s>']
2025-05-29 22:07:25,536 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:07:25,537 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:07:25,537 - INFO - joeynmt.training - 	Hypothesis: Sapete, in vento in vincittà.
2025-05-29 22:07:25,537 - INFO - joeynmt.training - Example #4
2025-05-29 22:07:25,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:07:25,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:07:25,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'aus@@', 'a', 'di', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'succ@@', 'ede', 'nel', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 22:07:25,537 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:07:25,537 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:07:25,537 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostrerò una causa di causa di quello che succede nel 25 anni fa.
2025-05-29 22:07:28,885 - INFO - joeynmt.training - Epoch   3, Step:    31600, Batch Loss:     1.803033, Batch Acc: 0.445228, Tokens per Sec:    18471, Lr: 0.000300
2025-05-29 22:07:32,238 - INFO - joeynmt.training - Epoch   3, Step:    31700, Batch Loss:     1.686549, Batch Acc: 0.443864, Tokens per Sec:    21411, Lr: 0.000300
2025-05-29 22:07:35,587 - INFO - joeynmt.training - Epoch   3, Step:    31800, Batch Loss:     1.896073, Batch Acc: 0.440628, Tokens per Sec:    21668, Lr: 0.000300
2025-05-29 22:07:38,903 - INFO - joeynmt.training - Epoch   3, Step:    31900, Batch Loss:     1.761961, Batch Acc: 0.439374, Tokens per Sec:    21077, Lr: 0.000300
2025-05-29 22:07:42,252 - INFO - joeynmt.training - Epoch   3, Step:    32000, Batch Loss:     1.837106, Batch Acc: 0.442262, Tokens per Sec:    21832, Lr: 0.000300
2025-05-29 22:07:42,252 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:07:42,253 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:07:51,363 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.93, acc:   0.47, generation: 9.0974[sec], evaluation: 0.0000[sec]
2025-05-29 22:07:51,363 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:07:51,843 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/29500.ckpt
2025-05-29 22:07:51,866 - INFO - joeynmt.training - Example #0
2025-05-29 22:07:51,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:07:51,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:07:51,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questa', 'fot@@', 'o', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é', 'che', 'la', 'gente', 'che', 'ha', 'mostr@@', 'ato', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ato', 'è', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'per', 'cui', 'i', 'gi@@', 'oc@@', 'atori', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'ri@@', 'man@@', 'ere', 'il', '4@@', '8', 'st@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:07:51,867 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:07:51,867 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:07:51,867 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questa foto di un po<unk> di sé che la gente che ha mostrato che i ghiacciato è che l<unk> articolo, per cui i giocatori sono stati in grado di rimanere il 48 stato.
2025-05-29 22:07:51,867 - INFO - joeynmt.training - Example #1
2025-05-29 22:07:51,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:07:51,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:07:51,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'volta', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ic@@', 'chi@@', 'o@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ic@@', 'chi@@', 'o@@', '.', '</s>']
2025-05-29 22:07:51,868 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:07:51,868 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:07:51,868 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima volta che non è abbastanza forte, perché non è il dicchio, perché non è il dicchio.
2025-05-29 22:07:51,868 - INFO - joeynmt.training - Example #2
2025-05-29 22:07:51,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:07:51,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:07:51,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'è', 'la', 's@@', 'fi@@', 'da', 'è', 'la', 'n@@', 'ec@@', 'ess@@', 'ità', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:07:51,869 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:07:51,869 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:07:51,869 - INFO - joeynmt.training - 	Hypothesis: In realtà è la sfida è la necessità di ghiaccio di un cuore globale del nostro climatico globale.
2025-05-29 22:07:51,869 - INFO - joeynmt.training - Example #3
2025-05-29 22:07:51,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:07:51,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:07:51,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'v@@', 'ento', 'in', 'v@@', 'in@@', 'i@@', 'z@@', 'zi@@', 'a', 'e', 'sp@@', 'azi@@', 'o', 'in', 'un', 'f@@', 'ut@@', 'uro', 'di', 'un', 'f@@', 'ut@@', 'uro', 'di', 'un', 'f@@', 'ut@@', 'uro', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é', 'e', 'la', 'sua', 'f@@', 'ig@@', 'li@@', 'a@@', ',', 'e', 'la', 'sua', 'f@@', 'ig@@', 'lia', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'om@@', 'mer@@', 'c@@', 'ato', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é', 'e', 'la', 'sua', 'f@@', 'ig@@', 'li@@', 'sta', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'om@@', 'mer@@', 'c@@', 'ato', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é', 'e', 'la', 'sua', 'f@@', 'ig@@', 'li@@', 'a@@', ',', 'e', 'la', 'sua', 'f@@', 'ig@@', 'li@@', 'sta', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'po@@', '<unk>', 'di', 'più', 'di', 'un']
2025-05-29 22:07:51,870 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:07:51,870 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:07:51,870 - INFO - joeynmt.training - 	Hypothesis: E in vento in vinizzia e spazio in un futuro di un futuro di un futuro di un po<unk> di sé e la sua figlia, e la sua figlia di un po<unk> di sommercato di un po<unk> di sé e la sua figlista di un po<unk> di sommercato di un po<unk> di sé e la sua figlia, e la sua figlista di un po<unk> di sé che si tratta di un po<unk> di più di un
2025-05-29 22:07:51,870 - INFO - joeynmt.training - Example #4
2025-05-29 22:07:51,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:07:51,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:07:51,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'qu@@', 'ad@@', 'ra', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'c@@', 'r@@', 'oll@@', 'o', 'di', 'quello', 'che', 'succ@@', 'ede', 'nel', 'cor@@', 'so', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:07:51,871 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:07:51,871 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:07:51,871 - INFO - joeynmt.training - 	Hypothesis: La prossima squadra che vi mostrerò un crollo di quello che succede nel corso di quello che è successo nel 25 anni.
2025-05-29 22:07:55,228 - INFO - joeynmt.training - Epoch   3, Step:    32100, Batch Loss:     1.996780, Batch Acc: 0.448702, Tokens per Sec:    18403, Lr: 0.000300
2025-05-29 22:07:56,208 - INFO - joeynmt.training - Epoch   3: total training loss 20387.02
2025-05-29 22:07:56,208 - INFO - joeynmt.training - EPOCH 4
2025-05-29 22:07:58,606 - INFO - joeynmt.training - Epoch   4, Step:    32200, Batch Loss:     1.864512, Batch Acc: 0.453239, Tokens per Sec:    20551, Lr: 0.000300
2025-05-29 22:08:01,985 - INFO - joeynmt.training - Epoch   4, Step:    32300, Batch Loss:     1.844251, Batch Acc: 0.457439, Tokens per Sec:    20999, Lr: 0.000300
2025-05-29 22:08:05,352 - INFO - joeynmt.training - Epoch   4, Step:    32400, Batch Loss:     1.638830, Batch Acc: 0.454531, Tokens per Sec:    20590, Lr: 0.000300
2025-05-29 22:08:08,716 - INFO - joeynmt.training - Epoch   4, Step:    32500, Batch Loss:     1.777541, Batch Acc: 0.455392, Tokens per Sec:    21159, Lr: 0.000300
2025-05-29 22:08:08,717 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:08:08,717 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:08:19,032 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.93, acc:   0.47, generation: 10.2988[sec], evaluation: 0.0000[sec]
2025-05-29 22:08:19,033 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:08:19,559 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/30500.ckpt
2025-05-29 22:08:19,580 - INFO - joeynmt.training - Example #0
2025-05-29 22:08:19,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:08:19,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:08:19,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'questa', 'str@@', 'utt@@', 'ura', 'per', 'con@@', 'n@@', 'et@@', 'ter@@', 'si', 'a', 'di@@', 'mostr@@', 'are', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'questi', '4@@', '8', 'st@@', 'ati@@', ',', 'per', 'i', '4@@', '8', 'st@@', 'at@@', 'or@@', 'i@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'fer@@', 'im@@', 'ento', 'di', 'circa', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'fer@@', 'im@@', 'ento', 'di', 'ri@@', 'fer@@', 'im@@', 'ento', 'di', 'ri@@', 'fer@@', 'im@@', 'ento', 'di', 'ri@@', 'l@@', 'ev@@', 'it@@', 'are', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'fer@@', 'im@@', 'ento', 'di', 'ri@@', 'l@@', 'ev@@', 'it@@', 'are', 'i', 'ri@@', 'l@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'a', 'di']
2025-05-29 22:08:19,582 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:08:19,582 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:08:19,582 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato questa struttura per connettersi a dimostrare che i ghiacciano i ghiacciati per i tre milioni di anni di anni di questi 48 stati, per i 48 statori, il 40 per cento di riferimento di circa il 40 per cento di riferimento di riferimento di riferimento di rilevitare il 40 per cento di riferimento di rilevitare i ril<unk> industria di
2025-05-29 22:08:19,582 - INFO - joeynmt.training - Example #1
2025-05-29 22:08:19,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:08:19,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:08:19,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'lo', 'fac@@', 'ci@@', 'ano', 'abb@@', 'ast@@', 'anza', 'l@@', '<unk>', 'es@@', 'peri@@', 'enza', 'di', 'questo', 'spe@@', 'ci@@', 'e@@', ',', 'perché', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 22:08:19,583 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:08:19,583 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:08:19,583 - INFO - joeynmt.training - 	Hypothesis: Ma non lo facciano abbastanza l<unk> esperienza di questo specie, perché non è la Dicke non è la Dicke del ghiaccia.
2025-05-29 22:08:19,583 - INFO - joeynmt.training - Example #2
2025-05-29 22:08:19,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:08:19,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:08:19,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'il', 'sen@@', 'so', 'di', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'la', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', 'mo', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', '.', '</s>']
2025-05-29 22:08:19,584 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:08:19,584 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:08:19,584 - INFO - joeynmt.training - 	Hypothesis: In effetti, il senso di l<unk> artica, la cuore globale del nostro climassimo globale del nostro climassi.
2025-05-29 22:08:19,584 - INFO - joeynmt.training - Example #3
2025-05-29 22:08:19,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:08:19,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:08:19,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'ri@@', 're', 'n@@', 'ell@@', '<unk>', 'in@@', 'ten@@', 'do', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:08:19,584 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:08:19,584 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:08:19,585 - INFO - joeynmt.training - 	Hypothesis: Saprire nell<unk> intendo in un certo senso.
2025-05-29 22:08:19,585 - INFO - joeynmt.training - Example #4
2025-05-29 22:08:19,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:08:19,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:08:19,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'qu@@', 'ad@@', 'ra', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'di@@', 'men@@', 'sione', 'di', 'ciò', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:08:19,585 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:08:19,585 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:08:19,585 - INFO - joeynmt.training - 	Hypothesis: La prossima squadra che vi mostro è una dimostrazione di una dimensione di ciò che è successo negli ultimi 25 anni.
2025-05-29 22:08:22,988 - INFO - joeynmt.training - Epoch   4, Step:    32600, Batch Loss:     1.986095, Batch Acc: 0.456372, Tokens per Sec:    18159, Lr: 0.000300
2025-05-29 22:08:26,333 - INFO - joeynmt.training - Epoch   4, Step:    32700, Batch Loss:     1.905288, Batch Acc: 0.450244, Tokens per Sec:    21938, Lr: 0.000300
2025-05-29 22:08:29,705 - INFO - joeynmt.training - Epoch   4, Step:    32800, Batch Loss:     1.922499, Batch Acc: 0.450163, Tokens per Sec:    21641, Lr: 0.000300
2025-05-29 22:08:33,056 - INFO - joeynmt.training - Epoch   4, Step:    32900, Batch Loss:     1.777832, Batch Acc: 0.451988, Tokens per Sec:    21091, Lr: 0.000300
2025-05-29 22:08:36,415 - INFO - joeynmt.training - Epoch   4, Step:    33000, Batch Loss:     1.811821, Batch Acc: 0.454149, Tokens per Sec:    20907, Lr: 0.000300
2025-05-29 22:08:36,416 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:08:36,416 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:08:45,363 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.88, acc:   0.47, generation: 8.9355[sec], evaluation: 0.0000[sec]
2025-05-29 22:08:45,363 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:08:45,929 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/31000.ckpt
2025-05-29 22:08:45,950 - INFO - joeynmt.training - Example #0
2025-05-29 22:08:45,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:08:45,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:08:45,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'gi@@', 'ov@@', 'ani', 'per', 'aiut@@', 'are', 'i', 'nostri', 'an@@', 'ni@@', ',', 'che', 'la', 'gente', 'è', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'le', 'persone', 'hanno', 'in@@', 'segn@@', 'ato', 'per', 'il', '4@@', '8', 'st@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:08:45,951 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:08:45,952 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:08:45,952 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso che ho mostrato questi due giovani per aiutare i nostri anni, che la gente è il ghiaccio, che l<unk> anno scorso che le persone hanno insegnato per il 48 stato.
2025-05-29 22:08:45,952 - INFO - joeynmt.training - Example #1
2025-05-29 22:08:45,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:08:45,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:08:45,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'res@@', 'ist@@', 'enza', 'di', 'questo', 'spe@@', 'ci@@', 'fic@@', 'io', 'e', 'la', 'di@@', 'mostr@@', 'azione', 'di', 'questo', 'tipo', 'di', 'probl@@', 'emi', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:08:45,952 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:08:45,953 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:08:45,953 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la resistenza di questo specificio e la dimostrazione di questo tipo di problemi di ghiaccio.
2025-05-29 22:08:45,953 - INFO - joeynmt.training - Example #2
2025-05-29 22:08:45,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:08:45,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:08:45,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'il', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:08:45,953 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:08:45,954 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:08:45,954 - INFO - joeynmt.training - 	Hypothesis: In effetti, il senso è l<unk> articolo, il cuore del nostro sistema climatico del nostro sistema climatico del nostro sistema globale.
2025-05-29 22:08:45,954 - INFO - joeynmt.training - Example #3
2025-05-29 22:08:45,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:08:45,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:08:45,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'et@@', 'e@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:08:45,954 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:08:45,954 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:08:45,954 - INFO - joeynmt.training - 	Hypothesis: Sapete, in un certo senso.
2025-05-29 22:08:45,955 - INFO - joeynmt.training - Example #4
2025-05-29 22:08:45,955 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:08:45,955 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:08:45,955 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'otto', 'la', 'pros@@', 'si@@', 'ma', 's@@', 'otto', 'la', 'nostra', 'v@@', 'ar@@', 'i@@', 'a@@', ',', 'è', 'che', 'è', 'succ@@', 'esso', 'in', 'ulti@@', 'ma', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 22:08:45,955 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:08:45,955 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:08:45,955 - INFO - joeynmt.training - 	Hypothesis: La prossima sotto la prossima sotto la nostra varia, è che è successo in ultima 25 anni fa.
2025-05-29 22:08:49,343 - INFO - joeynmt.training - Epoch   4, Step:    33100, Batch Loss:     1.688522, Batch Acc: 0.452959, Tokens per Sec:    17406, Lr: 0.000300
2025-05-29 22:08:52,702 - INFO - joeynmt.training - Epoch   4, Step:    33200, Batch Loss:     1.824105, Batch Acc: 0.452218, Tokens per Sec:    20420, Lr: 0.000300
2025-05-29 22:08:56,056 - INFO - joeynmt.training - Epoch   4, Step:    33300, Batch Loss:     2.001388, Batch Acc: 0.452802, Tokens per Sec:    20445, Lr: 0.000300
2025-05-29 22:08:59,403 - INFO - joeynmt.training - Epoch   4, Step:    33400, Batch Loss:     1.978114, Batch Acc: 0.453538, Tokens per Sec:    20928, Lr: 0.000300
2025-05-29 22:09:02,795 - INFO - joeynmt.training - Epoch   4, Step:    33500, Batch Loss:     1.944373, Batch Acc: 0.455773, Tokens per Sec:    22026, Lr: 0.000300
2025-05-29 22:09:02,795 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:09:02,796 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:09:10,977 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.89, acc:   0.47, generation: 8.1665[sec], evaluation: 0.0000[sec]
2025-05-29 22:09:11,357 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/30000.ckpt
2025-05-29 22:09:11,383 - INFO - joeynmt.training - Example #0
2025-05-29 22:09:11,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:09:11,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:09:11,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 'cui', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'sono', 'stati', 'sc@@', 'oper@@', 'ti', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'el@@', 'et@@', 'tr@@', 'ic@@', 'e', 'che', 'i', 'su@@', 'oi', 'd@@', 'ell@@', '<unk>', 'au@@', 'to', 'per', 'il', '4@@', '8', 'st@@', 'a@@', 'di@@', 'o', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:09:11,384 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:09:11,384 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:09:11,384 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due dimensioni per cui i ghiacciati sono stati scoperti di ghiaccia, che l<unk> elettrice che i suoi dell<unk> auto per il 48 stadio di 48 stati.
2025-05-29 22:09:11,385 - INFO - joeynmt.training - Example #1
2025-05-29 22:09:11,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:09:11,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:09:11,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'lo', 'fac@@', 'ci@@', 'am@@', 'o@@', ',', 'la', 'cosa', 'più', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'non', 'è', 'la', 'n@@', 'on@@', 'ost@@', 'a', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'non', 'è', 'la', 'b@@', 're@@', 've', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'cio', 'spe@@', 'ci@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:09:11,385 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:09:11,385 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:09:11,385 - INFO - joeynmt.training - 	Hypothesis: Ma non lo facciamo, la cosa più speciale, non è la nonosta di questo problema, non è la breve del ghiaccio del ghiaccio del ghiaccio di un ghiaccio speciale.
2025-05-29 22:09:11,386 - INFO - joeynmt.training - Example #2
2025-05-29 22:09:11,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:09:11,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:09:11,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realtà', 'è', 'la', 's@@', 'itu@@', 'azione', 'di', 'un', 'e@@', 'qu@@', 'i@@', 'li@@', 'bri@@', 'o', 'di', 'al@@', 'to', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:09:11,386 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:09:11,386 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:09:11,386 - INFO - joeynmt.training - 	Hypothesis: In realtà è la situazione di un equilibrio di alto del nostro climatico del nostro climatico globale.
2025-05-29 22:09:11,386 - INFO - joeynmt.training - Example #3
2025-05-29 22:09:11,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:09:11,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:09:11,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['D@@', 'i', 'f@@', 'att@@', 'o@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', 'o@@', '.', '</s>']
2025-05-29 22:09:11,387 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:09:11,387 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:09:11,387 - INFO - joeynmt.training - 	Hypothesis: Di fatto, in un certo senso di sommergio.
2025-05-29 22:09:11,387 - INFO - joeynmt.training - Example #4
2025-05-29 22:09:11,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:09:11,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:09:11,388 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'succ@@', 'ess@@', 'o@@', ',', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'una', 'di@@', 'men@@', 'sione', 'di', 'quello', 'che', 'è', 'succ@@', 'ess@@', 'o@@', '.', '</s>']
2025-05-29 22:09:11,388 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:09:11,388 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:09:11,388 - INFO - joeynmt.training - 	Hypothesis: La prossima è successo, che vi mostrerò è una dimensione di una dimensione di quello che è successo.
2025-05-29 22:09:14,783 - INFO - joeynmt.training - Epoch   4, Step:    33600, Batch Loss:     1.959257, Batch Acc: 0.448629, Tokens per Sec:    18731, Lr: 0.000300
2025-05-29 22:09:18,161 - INFO - joeynmt.training - Epoch   4, Step:    33700, Batch Loss:     1.948986, Batch Acc: 0.455737, Tokens per Sec:    20686, Lr: 0.000300
2025-05-29 22:09:21,530 - INFO - joeynmt.training - Epoch   4, Step:    33800, Batch Loss:     1.654716, Batch Acc: 0.454246, Tokens per Sec:    21245, Lr: 0.000300
2025-05-29 22:09:24,913 - INFO - joeynmt.training - Epoch   4, Step:    33900, Batch Loss:     1.660867, Batch Acc: 0.455940, Tokens per Sec:    21637, Lr: 0.000300
2025-05-29 22:09:28,250 - INFO - joeynmt.training - Epoch   4, Step:    34000, Batch Loss:     1.793455, Batch Acc: 0.459311, Tokens per Sec:    21624, Lr: 0.000300
2025-05-29 22:09:28,251 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:09:28,251 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:09:37,961 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.86, acc:   0.47, generation: 9.6976[sec], evaluation: 0.0000[sec]
2025-05-29 22:09:37,962 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:09:38,534 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/31500.ckpt
2025-05-29 22:09:38,553 - INFO - joeynmt.training - Example #0
2025-05-29 22:09:38,553 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:09:38,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:09:38,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'di', 'cui', 'sono', 'stati', 'mostr@@', 'ati', 'che', 'l@@', '<unk>', 'in@@', 'ten@@', 'zione', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'di', '4@@', '8@@', ',', 'che', 'ha', 'sc@@', 'oper@@', 'to', 'che', 'ha', 'd@@', 'ato', 'il', '4@@', '8@@', ',', 'per', 'c@@', 'ento', 'degli', 'St@@', 'ati', 'Un@@', 'iti@@', '.', '</s>']
2025-05-29 22:09:38,554 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:09:38,554 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:09:38,554 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due dimensioni di cui sono stati mostrati che l<unk> intenzione di ghiaccia, che l<unk> influenza di 48, che ha scoperto che ha dato il 48, per cento degli Stati Uniti.
2025-05-29 22:09:38,554 - INFO - joeynmt.training - Example #1
2025-05-29 22:09:38,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:09:38,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:09:38,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'in@@', 'segn@@', 'ato', 'a', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'una', 'cosa', 'spe@@', 'ci@@', 'f@@', 'ico', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'la', 'b@@', 're@@', 've', 'lo', 'mostr@@', 'a', 'il', 't@@', 'av@@', 'olo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:09:38,555 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:09:38,555 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:09:38,555 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato insegnato a questo problema, e non è una cosa specifico di questo problema, perché non è la breve lo mostra il tavolo di ghiaccio.
2025-05-29 22:09:38,555 - INFO - joeynmt.training - Example #2
2025-05-29 22:09:38,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:09:38,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:09:38,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'in', 'un', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:09:38,556 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:09:38,556 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:09:38,556 - INFO - joeynmt.training - 	Hypothesis: In effetti, in un senso di ghiaccio artico, il nostro climatico del nostro climatico globale.
2025-05-29 22:09:38,556 - INFO - joeynmt.training - Example #3
2025-05-29 22:09:38,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:09:38,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:09:38,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tutto', 'il', 'mon@@', 'd@@', 'o@@', ',', 'e', 'si', 'ri@@', 'es@@', 'ce', 'a', 'f@@', 'av@@', 'or@@', 'e@@', '.', '</s>']
2025-05-29 22:09:38,557 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:09:38,557 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:09:38,557 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto il mondo, e si riesce a favore.
2025-05-29 22:09:38,557 - INFO - joeynmt.training - Example #4
2025-05-29 22:09:38,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:09:38,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:09:38,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'etti@@', 'man@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'c@@', 'entr@@', 'o', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'questo', 'peri@@', 'o@@', 'do', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'vi', 'mostr@@', 'er@@', 'ò', 'la', 'pros@@', 'si@@', 'ma', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:09:38,558 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:09:38,558 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:09:38,558 - INFO - joeynmt.training - 	Hypothesis: La prossima settimana che vi mostrerò un centro di quale è successo in cui è successo in questo periodo è successo in cui è successo in cui è successo in cui vi mostrerò la prossima 25 anni.
2025-05-29 22:09:41,955 - INFO - joeynmt.training - Epoch   4, Step:    34100, Batch Loss:     1.639651, Batch Acc: 0.452373, Tokens per Sec:    17702, Lr: 0.000300
2025-05-29 22:09:45,337 - INFO - joeynmt.training - Epoch   4, Step:    34200, Batch Loss:     1.920082, Batch Acc: 0.453967, Tokens per Sec:    20861, Lr: 0.000300
2025-05-29 22:09:48,700 - INFO - joeynmt.training - Epoch   4, Step:    34300, Batch Loss:     1.743671, Batch Acc: 0.448930, Tokens per Sec:    20979, Lr: 0.000300
2025-05-29 22:09:52,072 - INFO - joeynmt.training - Epoch   4, Step:    34400, Batch Loss:     1.877767, Batch Acc: 0.450002, Tokens per Sec:    21059, Lr: 0.000300
2025-05-29 22:09:55,442 - INFO - joeynmt.training - Epoch   4, Step:    34500, Batch Loss:     1.880608, Batch Acc: 0.453162, Tokens per Sec:    21022, Lr: 0.000300
2025-05-29 22:09:55,443 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:09:55,443 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:10:04,048 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.88, acc:   0.47, generation: 8.5936[sec], evaluation: 0.0000[sec]
2025-05-29 22:10:04,399 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/32000.ckpt
2025-05-29 22:10:04,418 - INFO - joeynmt.training - Example #0
2025-05-29 22:10:04,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:10:04,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:10:04,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'mostr@@', 'ano', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ono', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ono', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', '4@@', '8', 'ore', 'di', 'anni', 'di', '4@@', '8', 'ore', 'di', 'anni', 'di', '4@@', '8', 'ore', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:10:04,419 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:10:04,419 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:10:04,419 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso che ho mostrato queste due dimostrano che i ghiacciono i ghiacciono il ghiaccio di ghiaccio di un ghiaccio di 48 ore di anni di 48 ore di anni di 48 ore di cento.
2025-05-29 22:10:04,419 - INFO - joeynmt.training - Example #1
2025-05-29 22:10:04,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:10:04,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:10:04,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'at@@', 'a@@', '.', '</s>']
2025-05-29 22:10:04,420 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:10:04,420 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:10:04,420 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la risposta di questo problema, perché non è abbastanza la pata.
2025-05-29 22:10:04,420 - INFO - joeynmt.training - Example #2
2025-05-29 22:10:04,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:10:04,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:10:04,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 's@@', 'par@@', 'i@@', 're@@', ',', 'la', 'cu@@', 'or@@', 'e@@', ',', 'il', 'cu@@', 'or@@', 'e@@', ',', 'il', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:10:04,421 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:10:04,421 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:10:04,421 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di sparire, la cuore, il cuore, il nostro sistema globale.
2025-05-29 22:10:04,421 - INFO - joeynmt.training - Example #3
2025-05-29 22:10:04,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:10:04,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:10:04,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'gra@@', 'do', 'di', 'ri@@', 'fl@@', 'et@@', 'tere', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 's@@', 'om@@', 'mer@@', 'i@@', 'di@@', '.', '</s>']
2025-05-29 22:10:04,422 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:10:04,422 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:10:04,422 - INFO - joeynmt.training - 	Hypothesis: Si può essere in grado di riflettere in un certo senso di sommeridi.
2025-05-29 22:10:04,422 - INFO - joeynmt.training - Example #4
2025-05-29 22:10:04,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:10:04,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:10:04,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'etti@@', 'man@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'cui', 'ho', 'fatto', 'il', 'ris@@', 'ult@@', 'ato', 'è', 'succ@@', 'esso', 'in', 'modo', 'che', 'si', 'trov@@', 'a', 'in', 'modo', 'che', 'si', 'è', 'acc@@', 'ad@@', 'ut@@', 'a', 'in', 'modo', 'che', 'si', 'trov@@', 'a', 'un', 'pa@@', 'io', 'di', 's@@', 'otto', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:10:04,422 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:10:04,423 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:10:04,423 - INFO - joeynmt.training - 	Hypothesis: La prossima settimana che vi mostrerò un disegno di un disegno di quello che è successo in cui è successo in cui è successo in cui è successo in cui ho fatto il risultato è successo in modo che si trova in modo che si è accaduta in modo che si trova un paio di sotto anni.
2025-05-29 22:10:07,669 - INFO - joeynmt.training - Epoch   4, Step:    34600, Batch Loss:     1.809490, Batch Acc: 0.452714, Tokens per Sec:    19651, Lr: 0.000300
2025-05-29 22:10:10,930 - INFO - joeynmt.training - Epoch   4, Step:    34700, Batch Loss:     1.893266, Batch Acc: 0.451692, Tokens per Sec:    22346, Lr: 0.000300
2025-05-29 22:10:14,184 - INFO - joeynmt.training - Epoch   4, Step:    34800, Batch Loss:     1.822648, Batch Acc: 0.448064, Tokens per Sec:    21415, Lr: 0.000300
2025-05-29 22:10:17,444 - INFO - joeynmt.training - Epoch   4, Step:    34900, Batch Loss:     2.040696, Batch Acc: 0.449493, Tokens per Sec:    22111, Lr: 0.000300
2025-05-29 22:10:20,695 - INFO - joeynmt.training - Epoch   4, Step:    35000, Batch Loss:     1.771547, Batch Acc: 0.447434, Tokens per Sec:    21909, Lr: 0.000300
2025-05-29 22:10:20,696 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:10:20,696 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:10:29,889 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.86, acc:   0.48, generation: 9.1802[sec], evaluation: 0.0000[sec]
2025-05-29 22:10:29,889 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:10:30,381 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/32500.ckpt
2025-05-29 22:10:30,404 - INFO - joeynmt.training - Example #0
2025-05-29 22:10:30,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:10:30,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:10:30,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questi', 'due', 'str@@', 'um@@', 'enti', 'per', 'creare', 'un', 'po@@', '<unk>', 'di', 's@@', 'otto', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'le', 'g@@', 'hi@@', 'e@@', ',', 'che', 'le', 'g@@', 'hi@@', 'e@@', ',', 'che', 'le', 'persone', 'per', 'il', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', 'di', 'di', 'questi', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'circa', '1@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', 'di', 'più', 'di', 'un', 'po@@', '<unk>', 'di', 'più', 'o', 'meno', 'di', 'un', 'po@@', '<unk>', 'più', 'di', 'un', 'po@@', '<unk>', 'più', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'an@@', 'it@@', 'ario', 'di', 'un', 'po@@', '<unk>', 'di', 'più', 'di', 'un', 'po@@', '<unk>', 'di']
2025-05-29 22:10:30,405 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:10:30,405 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:10:30,406 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questi due strumenti per creare un po<unk> di sotto di ghiaccio che le ghie, che le ghie, che le persone per il 48% dei più grandi di di questi 40 per cento di questi 40 per cento di un 40 per cento di circa 10% di questi due anni per cento di un po<unk> di più di un po<unk> di più o meno di un po<unk> più di un po<unk> più di un po<unk> di sanitario di un po<unk> di più di un po<unk> di
2025-05-29 22:10:30,406 - INFO - joeynmt.training - Example #1
2025-05-29 22:10:30,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:10:30,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:10:30,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'D@@', 'ic@@', 'ke', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:10:30,406 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:10:30,406 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:10:30,406 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la risposta di questo problema, perché non c<unk> è la Dicke non è la Dicke del ghiaccio.
2025-05-29 22:10:30,407 - INFO - joeynmt.training - Example #2
2025-05-29 22:10:30,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:10:30,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:10:30,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'la', 's@@', 'etti@@', ',', 'la', 's@@', 'fi@@', 'da', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:10:30,407 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:10:30,407 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:10:30,407 - INFO - joeynmt.training - 	Hypothesis: In effetti, la setti, la sfida è l<unk> artica, il nostro sistema globale.
2025-05-29 22:10:30,408 - INFO - joeynmt.training - Example #3
2025-05-29 22:10:30,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:10:30,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:10:30,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'si', 'ri@@', 'fer@@', 'is@@', 'ce', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:10:30,408 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:10:30,408 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:10:30,408 - INFO - joeynmt.training - 	Hypothesis: E in un certo senso, e si riferisce in un certo senso.
2025-05-29 22:10:30,408 - INFO - joeynmt.training - Example #4
2025-05-29 22:10:30,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:10:30,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:10:30,409 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'om@@', 'ma@@', ',', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'tr@@', 'em@@', 'ore', 'di', 'un', 'c@@', 'entr@@', 'o', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', '200@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:10:30,409 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:10:30,409 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:10:30,409 - INFO - joeynmt.training - 	Hypothesis: La prossima somma, che vi mostrerò un tremore di un centro di quello che è successo nel 2005 anni.
2025-05-29 22:10:33,737 - INFO - joeynmt.training - Epoch   4, Step:    35100, Batch Loss:     1.805558, Batch Acc: 0.449266, Tokens per Sec:    18412, Lr: 0.000300
2025-05-29 22:10:37,104 - INFO - joeynmt.training - Epoch   4, Step:    35200, Batch Loss:     1.898464, Batch Acc: 0.452093, Tokens per Sec:    21565, Lr: 0.000300
2025-05-29 22:10:40,471 - INFO - joeynmt.training - Epoch   4, Step:    35300, Batch Loss:     1.872031, Batch Acc: 0.453296, Tokens per Sec:    21075, Lr: 0.000300
2025-05-29 22:10:43,846 - INFO - joeynmt.training - Epoch   4, Step:    35400, Batch Loss:     1.933805, Batch Acc: 0.447455, Tokens per Sec:    20318, Lr: 0.000300
2025-05-29 22:10:47,220 - INFO - joeynmt.training - Epoch   4, Step:    35500, Batch Loss:     1.862956, Batch Acc: 0.449863, Tokens per Sec:    21261, Lr: 0.000300
2025-05-29 22:10:47,221 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:10:47,221 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:10:55,447 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.81, acc:   0.48, generation: 8.2149[sec], evaluation: 0.0000[sec]
2025-05-29 22:10:55,447 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:10:55,954 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/33500.ckpt
2025-05-29 22:10:55,979 - INFO - joeynmt.training - Example #0
2025-05-29 22:10:55,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:10:55,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:10:55,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'per', 'con@@', 'segu@@', 'ire', 'le', 'b@@', 'atter@@', 'ie', 'che', 'hanno', 'av@@', 'uto', 'per', 'gli', 'St@@', 'ati', 'Un@@', 'iti@@', ',', 'che', 'ha', 'chiam@@', 'ato', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'al@@', 'to', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'al@@', 'to', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'al@@', 'to', 'e', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'un', 'po@@', '<unk>', 'di', 'm@@', 'e@@', ',', 'e', 'la', 'gente', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 's@@', 'fi@@', 'd@@', 'are', 'un', 'po@@']
2025-05-29 22:10:55,981 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:10:55,981 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:10:55,981 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste diapositive per ridurre il ghiaccio per conseguire le batterie che hanno avuto per gli Stati Uniti, che ha chiamato il ghiaccio per 40 per cento di anni per 40 per cento di anni per 40 per cento di 40 per cento di alto 40 per cento di alto 40 per cento di alto e l<unk> anno scorso di un po<unk> di me, e la gente che è stato un po<unk> di sfidare un po
2025-05-29 22:10:55,981 - INFO - joeynmt.training - Example #1
2025-05-29 22:10:55,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:10:55,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:10:55,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'perché', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:10:55,982 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:10:55,982 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:10:55,982 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che non è abbastanza forte, perché non è la Dicke è la Dicke del ghiaccio.
2025-05-29 22:10:55,982 - INFO - joeynmt.training - Example #2
2025-05-29 22:10:55,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:10:55,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:10:55,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'in', 'S@@', 'in@@', 'ne', 'è', 'la', 'cu@@', 'cin@@', 'a@@', ',', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:10:55,983 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:10:55,983 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:10:55,983 - INFO - joeynmt.training - 	Hypothesis: In effetti, in Sinne è la cucina, la cucina del nostro climatico globale del nostro climatico globale.
2025-05-29 22:10:55,983 - INFO - joeynmt.training - Example #3
2025-05-29 22:10:55,983 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:10:55,983 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:10:55,983 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E@@', '<unk>', 'una', 'cosa', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', '.', '</s>']
2025-05-29 22:10:55,984 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:10:55,984 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:10:55,984 - INFO - joeynmt.training - 	Hypothesis: E<unk> una cosa che si tratta di un sommergi.
2025-05-29 22:10:55,984 - INFO - joeynmt.training - Example #4
2025-05-29 22:10:55,984 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:10:55,984 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:10:55,984 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'qu@@', 'ad@@', 'ra', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'st@@', 'anza', 'di', 'una', 'sc@@', 'or@@', 'sa', 'di', 'quello', 'che', 'succ@@', 'ede', 'in', 'ulti@@', 'mo', '2@@', '5', 'anni', '<unk>', 'ulti@@', 'mo', '2@@', '5', 'anni', 'di', '1@@', '.', '</s>']
2025-05-29 22:10:55,985 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:10:55,985 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:10:55,985 - INFO - joeynmt.training - 	Hypothesis: La prossima squadra che vi mostrerò una distanza di una scorsa di quello che succede in ultimo 25 anni <unk> ultimo 25 anni di 1.
2025-05-29 22:10:59,346 - INFO - joeynmt.training - Epoch   4, Step:    35600, Batch Loss:     1.882024, Batch Acc: 0.449626, Tokens per Sec:    17808, Lr: 0.000300
2025-05-29 22:11:02,699 - INFO - joeynmt.training - Epoch   4, Step:    35700, Batch Loss:     1.627305, Batch Acc: 0.457818, Tokens per Sec:    21459, Lr: 0.000300
2025-05-29 22:11:06,054 - INFO - joeynmt.training - Epoch   4, Step:    35800, Batch Loss:     1.914960, Batch Acc: 0.452255, Tokens per Sec:    21088, Lr: 0.000300
2025-05-29 22:11:09,422 - INFO - joeynmt.training - Epoch   4, Step:    35900, Batch Loss:     1.867448, Batch Acc: 0.453766, Tokens per Sec:    21194, Lr: 0.000300
2025-05-29 22:11:12,788 - INFO - joeynmt.training - Epoch   4, Step:    36000, Batch Loss:     1.664001, Batch Acc: 0.459683, Tokens per Sec:    21376, Lr: 0.000300
2025-05-29 22:11:12,788 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:11:12,788 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:11:22,508 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.79, acc:   0.48, generation: 9.7069[sec], evaluation: 0.0000[sec]
2025-05-29 22:11:22,509 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:11:23,090 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/33000.ckpt
2025-05-29 22:11:23,117 - INFO - joeynmt.training - Example #0
2025-05-29 22:11:23,117 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:11:23,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:11:23,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'fr@@', 'on@@', 'ti@@', 'ere', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'tre', 'milioni', 'di', 'an@@', 'ni@@', ',', 'che', 'è', 'stato', 'di', 'tre', 'milioni', 'di', 'an@@', 'ni@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:11:23,118 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:11:23,118 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:11:23,118 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questi due diapositive per confrontiere che le ghiaccio articolo che i ghiaccio di tre milioni di anni, che è stato di tre milioni di anni, il 40 per cento anni.
2025-05-29 22:11:23,118 - INFO - joeynmt.training - Example #1
2025-05-29 22:11:23,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:11:23,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:11:23,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'in', 'modo', 'da', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'in', 'cui', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'e', 'la', 'cosa', 'più', 'grande', 'cos@@', 'a@@', ',', 'e', 'la', 'cosa', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'problema', 'di', 'c@@', 'a@@', 'dere', 'di', 'un', 'problema', 'di', 'c@@', 'ac@@', 'ci@@', 'o@@', ',', 'e', 'la', 'cosa', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'ott@@', 'o@@', '-@@', 's@@', 'ott@@', 'o@@', '-@@', 's@@', 'ec@@', 'ol@@', 'o@@', ',', 'e', 'la', 'maggi@@']
2025-05-29 22:11:23,119 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:11:23,119 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:11:23,119 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la risposta in modo da non è abbastanza in cui non è la Dicke è la Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio, e la cosa più grande cosa, e la cosa che si tratta di un problema di cadere di un problema di caccio, e la cosa che si tratta di un po<unk> di sotto-sotto-secolo, e la maggi
2025-05-29 22:11:23,119 - INFO - joeynmt.training - Example #2
2025-05-29 22:11:23,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:11:23,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:11:23,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'in', 'sen@@', 'so', 'è', 'la', 'cosa', 'più', 'ar@@', 't@@', 'icol@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:11:23,120 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:11:23,120 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:11:23,120 - INFO - joeynmt.training - 	Hypothesis: In effetti, in senso è la cosa più articola, il cuore del nostro sistema globale.
2025-05-29 22:11:23,120 - INFO - joeynmt.training - Example #3
2025-05-29 22:11:23,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:11:23,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:11:23,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', '<unk>', 'è', 'una', 'cosa', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:11:23,121 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:11:23,121 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:11:23,121 - INFO - joeynmt.training - 	Hypothesis: C<unk> è una cosa che si tratta di un sommergibile.
2025-05-29 22:11:23,121 - INFO - joeynmt.training - Example #4
2025-05-29 22:11:23,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:11:23,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:11:23,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'c@@', 'at@@', 'tr@@', 'azione', 'di', 'quello', 'che', 'succ@@', 'ede', 'nel', 'cor@@', 'so', 'di', 'quello', 'che', 'succ@@', 'ede', 'nel', 'cor@@', 'so', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', 'tutto', 'il', 'mon@@', 'd@@', 'o@@', ',', 'e', 'la', 'pros@@', 'si@@', 'ma', 'di', 'cosa', 'è', 'succ@@', 'esso', 'in', 'gra@@', 'do', 'di', 'far@@', 'l@@', 'o@@', ',', 'e', 'la', 'pros@@', 'si@@', 'ma', 'di', 'cosa', 'è', 'succ@@', 'esso', 'in', 'cui', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'po@@', '<unk>', 'di', 'c@@', 'las@@', 'se', 'di', 'un', 'po@@', '<unk>', 'di', 'queste', 'cos@@', 'e@@', ',', 'e', 'la', 'cosa', 'che', 'vi', 'mostr@@', 'a', 'come', 'la', 'gente', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'c@@', 'aus@@', 'a', 'di', 'un', 'c@@', 'entr@@', 'o', 'di']
2025-05-29 22:11:23,122 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:11:23,122 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:11:23,122 - INFO - joeynmt.training - 	Hypothesis: La prossima è che vi mostrerò che vi mostrerò è una cattrazione di quello che succede nel corso di quello che succede nel corso di quello che è successo in tutto il mondo, e la prossima di cosa è successo in grado di farlo, e la prossima di cosa è successo in cui si tratta di un po<unk> di classe di un po<unk> di queste cose, e la cosa che vi mostra come la gente in un certo senso di causa di un centro di
2025-05-29 22:11:26,514 - INFO - joeynmt.training - Epoch   4, Step:    36100, Batch Loss:     1.795964, Batch Acc: 0.454115, Tokens per Sec:    17410, Lr: 0.000300
2025-05-29 22:11:29,889 - INFO - joeynmt.training - Epoch   4, Step:    36200, Batch Loss:     1.916104, Batch Acc: 0.457176, Tokens per Sec:    21299, Lr: 0.000300
2025-05-29 22:11:33,241 - INFO - joeynmt.training - Epoch   4, Step:    36300, Batch Loss:     1.764329, Batch Acc: 0.450297, Tokens per Sec:    21147, Lr: 0.000300
2025-05-29 22:11:36,588 - INFO - joeynmt.training - Epoch   4, Step:    36400, Batch Loss:     1.749112, Batch Acc: 0.450344, Tokens per Sec:    20799, Lr: 0.000300
2025-05-29 22:11:39,934 - INFO - joeynmt.training - Epoch   4, Step:    36500, Batch Loss:     1.781154, Batch Acc: 0.452294, Tokens per Sec:    21310, Lr: 0.000300
2025-05-29 22:11:39,934 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:11:39,934 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:11:49,389 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.77, acc:   0.48, generation: 9.4424[sec], evaluation: 0.0000[sec]
2025-05-29 22:11:49,389 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:11:49,902 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/34500.ckpt
2025-05-29 22:11:49,922 - INFO - joeynmt.training - Example #0
2025-05-29 22:11:49,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:11:49,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:11:49,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'aiut@@', 'are', 'a', 'ri@@', 'guar@@', 'do', 'a', 'sc@@', 'or@@', 'so', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'per', 'gli', 'St@@', 'ati', 'Un@@', 'iti@@', ',', 'che', 'per', 'gli', 'St@@', 'ati', 'Un@@', 'iti@@', ',', 'per', 'il', '4@@', '8', 'or@@', 'e@@', ',', 'per', 'il', '4@@', '8', 'ore', 'di', 'c@@', 'ento', 'di', 'circa', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'è', 'stato', 'sc@@', 'rit@@', 'to', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'è', 'stato', 'sc@@', 'or@@', 'so', 'il', '4@@', '0@@', '%', 'di', 'queste', 'due', 'cos@@', 'e@@', '.', '</s>']
2025-05-29 22:11:49,923 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:11:49,923 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:11:49,924 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per aiutare a riguardo a scorso che i ghiaccio, che i ghiacciano per gli Stati Uniti, che per gli Stati Uniti, per il 48 ore, per il 48 ore di cento di circa il 40 per cento di cento è stato scritto il 40 per cento di cento è stato scorso il 40% di queste due cose.
2025-05-29 22:11:49,924 - INFO - joeynmt.training - Example #1
2025-05-29 22:11:49,924 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:11:49,924 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:11:49,924 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'lo', 'fac@@', 'ci@@', 'o@@', ',', 'la', 'cosa', 'più', 'importante', 'è', 'che', 'la', 'prima', 'volta', 'che', 'la', 'D@@', 'ic@@', 'ke', 'è', 'una', 'cosa', 'spe@@', 'ci@@', 'ale', 'spe@@', 'ci@@', 'ale', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:11:49,924 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:11:49,924 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:11:49,925 - INFO - joeynmt.training - 	Hypothesis: Ma non lo faccio, la cosa più importante è che la prima volta che la Dicke è una cosa speciale speciale di ghiaccio.
2025-05-29 22:11:49,925 - INFO - joeynmt.training - Example #2
2025-05-29 22:11:49,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:11:49,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:11:49,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'il', 's@@', 'ac@@', 'co', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'e', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', 'mo', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:11:49,925 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:11:49,925 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:11:49,925 - INFO - joeynmt.training - 	Hypothesis: In effetti, il sacco di ghiaccio è la cucina del nostro climase del nostro climassimo globale.
2025-05-29 22:11:49,926 - INFO - joeynmt.training - Example #3
2025-05-29 22:11:49,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:11:49,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:11:49,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'ri@@', 'ma@@', 'sto', 'nel', 'mon@@', 'd@@', 'o@@', ',', 'e', 'il', 't@@', 'as@@', 'so', 'di', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', '.', '</s>']
2025-05-29 22:11:49,926 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:11:49,926 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:11:49,926 - INFO - joeynmt.training - 	Hypothesis: Si può essere rimasto nel mondo, e il tasso di un sommergi.
2025-05-29 22:11:49,926 - INFO - joeynmt.training - Example #4
2025-05-29 22:11:49,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:11:49,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:11:49,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 's@@', 'ott@@', 'o@@', ',', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'c@@', 'entr@@', 'o', 'di', 'c@@', 'att@@', 'ur@@', 'are', 'il', 'ci@@', 'b@@', 'o', 'che', 'è', 'succ@@', 'esso', 'nel', 'cor@@', 'so', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:11:49,927 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:11:49,927 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:11:49,927 - INFO - joeynmt.training - 	Hypothesis: Il prossimo sotto, che vi mostrerò un centro di catturare il cibo che è successo nel corso degli ultimi 25 anni.
2025-05-29 22:11:53,298 - INFO - joeynmt.training - Epoch   4, Step:    36600, Batch Loss:     2.002550, Batch Acc: 0.457000, Tokens per Sec:    18318, Lr: 0.000300
2025-05-29 22:11:56,648 - INFO - joeynmt.training - Epoch   4, Step:    36700, Batch Loss:     1.969347, Batch Acc: 0.454860, Tokens per Sec:    21199, Lr: 0.000300
2025-05-29 22:12:00,017 - INFO - joeynmt.training - Epoch   4, Step:    36800, Batch Loss:     1.722096, Batch Acc: 0.453206, Tokens per Sec:    20618, Lr: 0.000300
2025-05-29 22:12:03,395 - INFO - joeynmt.training - Epoch   4, Step:    36900, Batch Loss:     1.751194, Batch Acc: 0.463548, Tokens per Sec:    21534, Lr: 0.000300
2025-05-29 22:12:06,778 - INFO - joeynmt.training - Epoch   4, Step:    37000, Batch Loss:     1.838280, Batch Acc: 0.458088, Tokens per Sec:    21283, Lr: 0.000300
2025-05-29 22:12:06,778 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:12:06,779 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:12:14,698 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.72, acc:   0.48, generation: 7.9119[sec], evaluation: 0.0000[sec]
2025-05-29 22:12:14,698 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:12:15,184 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/34000.ckpt
2025-05-29 22:12:15,208 - INFO - joeynmt.training - Example #0
2025-05-29 22:12:15,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:12:15,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:12:15,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'cos@@', 'e@@', ',', 'per', 'ri@@', 'dur@@', 're', 'le', 'due', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'per', 'la', 'prima', 'vol@@', 't@@', 'a@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'per', '4@@', '8', 'st@@', 'at@@', 'or@@', 'i@@', '.', '</s>']
2025-05-29 22:12:15,209 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:12:15,209 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:12:15,209 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due cose, per ridurre le due ghiaccio, che l<unk> articolo che ha avuto per la prima volta, per tre milioni di anni per il 48 per cento di anni per 48 statori.
2025-05-29 22:12:15,209 - INFO - joeynmt.training - Example #1
2025-05-29 22:12:15,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:12:15,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:12:15,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'il', 'D@@', 'ic@@', 'ke', 'è', 'una', 'cosa', 'che', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:12:15,210 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:12:15,210 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:12:15,210 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo problema, e la prima volta che la prima volta che il Dicke è una cosa che mostra il Dicke del ghiaccio.
2025-05-29 22:12:15,210 - INFO - joeynmt.training - Example #2
2025-05-29 22:12:15,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:12:15,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:12:15,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 'cu@@', 'c@@', 'ci@@', 'ol@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:12:15,211 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:12:15,211 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:12:15,211 - INFO - joeynmt.training - 	Hypothesis: In effetti, in un certo senso, la cucciola, il cuore globale del nostro sistema globale.
2025-05-29 22:12:15,211 - INFO - joeynmt.training - Example #3
2025-05-29 22:12:15,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:12:15,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:12:15,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ens@@', 'ate', 'al', 'v@@', 'ento', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'n@@', 'ell@@', '<unk>', 'est@@', 'in@@', 'zione', 'di', 's@@', 'om@@', 'mer@@', 'c@@', 'ato', 'nel', 'f@@', 'ut@@', 'ur@@', 'o@@', '.', '</s>']
2025-05-29 22:12:15,212 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:12:15,212 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:12:15,212 - INFO - joeynmt.training - 	Hypothesis: Pensate al vento e in un certo senso di nell<unk> estinzione di sommercato nel futuro.
2025-05-29 22:12:15,212 - INFO - joeynmt.training - Example #4
2025-05-29 22:12:15,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:12:15,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:12:15,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'anno', 'succ@@', 'essi@@', 'vo', 'è', 'succ@@', 'esso', 'in', 'cui', 'vi', 'mostr@@', 'o', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:12:15,213 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:12:15,213 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:12:15,213 - INFO - joeynmt.training - 	Hypothesis: Il prossimo anno successivo è successo in cui vi mostro è successo negli ultimi 25 anni.
2025-05-29 22:12:18,543 - INFO - joeynmt.training - Epoch   4, Step:    37100, Batch Loss:     1.918733, Batch Acc: 0.460993, Tokens per Sec:    19050, Lr: 0.000300
2025-05-29 22:12:21,905 - INFO - joeynmt.training - Epoch   4, Step:    37200, Batch Loss:     2.025247, Batch Acc: 0.447854, Tokens per Sec:    20431, Lr: 0.000300
2025-05-29 22:12:25,279 - INFO - joeynmt.training - Epoch   4, Step:    37300, Batch Loss:     2.164581, Batch Acc: 0.453647, Tokens per Sec:    21095, Lr: 0.000300
2025-05-29 22:12:28,660 - INFO - joeynmt.training - Epoch   4, Step:    37400, Batch Loss:     1.753707, Batch Acc: 0.453062, Tokens per Sec:    21342, Lr: 0.000300
2025-05-29 22:12:32,022 - INFO - joeynmt.training - Epoch   4, Step:    37500, Batch Loss:     1.939579, Batch Acc: 0.451728, Tokens per Sec:    20857, Lr: 0.000300
2025-05-29 22:12:32,023 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:12:32,023 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:12:41,883 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.79, acc:   0.48, generation: 9.8481[sec], evaluation: 0.0000[sec]
2025-05-29 22:12:42,250 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/35000.ckpt
2025-05-29 22:12:42,277 - INFO - joeynmt.training - Example #0
2025-05-29 22:12:42,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:12:42,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:12:42,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'etti@@', 'man@@', 'e', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'per', 'i', 'li@@', 'mit@@', 'i', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'questi', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'in@@', 'segn@@', 'are', 'il', '4@@', '8@@', '%', 'dei', 's@@', 'iti', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', 'sono', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:12:42,278 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:12:42,278 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:12:42,278 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due settimane per ridurre il ghiaccio, che i ghiacciano per i limiti di tre milioni di anni di questi sono stati in grado di insegnare il 48% dei siti per il 48% di questi sono stati.
2025-05-29 22:12:42,278 - INFO - joeynmt.training - Example #1
2025-05-29 22:12:42,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:12:42,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:12:42,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'di', 'questa', 'spe@@', 'ci@@', 'e@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'cosa', 'che', 'non', 'c@@', '<unk>', 'è', 'la', 'D@@', 'ic@@', 'ke', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'mostr@@', 'a', 'il', 't@@', 'av@@', 'olo', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:12:42,279 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:12:42,279 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:12:42,279 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la risposta di questa specie, perché non c<unk> è la cosa che non c<unk> è la Dicke mostra il Dicke mostra il tavolo di un ghiaccio.
2025-05-29 22:12:42,279 - INFO - joeynmt.training - Example #2
2025-05-29 22:12:42,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:12:42,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:12:42,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:12:42,280 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:12:42,280 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:12:42,280 - INFO - joeynmt.training - 	Hypothesis: In certo senso di un certo senso di ghiaccio, il cuore globale del nostro climatico globale.
2025-05-29 22:12:42,280 - INFO - joeynmt.training - Example #3
2025-05-29 22:12:42,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:12:42,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:12:42,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'può', 's@@', 'ent@@', 'ito', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:12:42,281 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:12:42,281 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:12:42,281 - INFO - joeynmt.training - 	Hypothesis: E si può sentito in un certo senso di un po<unk> .
2025-05-29 22:12:42,281 - INFO - joeynmt.training - Example #4
2025-05-29 22:12:42,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:12:42,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:12:42,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'men@@', 'sione', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', 'cor@@', 'so', 'della', 'nostra', 'ulti@@', 'ma', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:12:42,282 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:12:42,282 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:12:42,282 - INFO - joeynmt.training - 	Hypothesis: La prossima dimostra che vi mostrerò una dimensione di quello che è successo nel corso della nostra ultima 25 anni.
2025-05-29 22:12:45,632 - INFO - joeynmt.training - Epoch   4, Step:    37600, Batch Loss:     1.903017, Batch Acc: 0.456177, Tokens per Sec:    18790, Lr: 0.000300
2025-05-29 22:12:49,029 - INFO - joeynmt.training - Epoch   4, Step:    37700, Batch Loss:     1.783927, Batch Acc: 0.454028, Tokens per Sec:    21377, Lr: 0.000300
2025-05-29 22:12:52,391 - INFO - joeynmt.training - Epoch   4, Step:    37800, Batch Loss:     1.884688, Batch Acc: 0.454478, Tokens per Sec:    20831, Lr: 0.000300
2025-05-29 22:12:55,752 - INFO - joeynmt.training - Epoch   4, Step:    37900, Batch Loss:     1.753479, Batch Acc: 0.456020, Tokens per Sec:    21066, Lr: 0.000300
2025-05-29 22:12:59,118 - INFO - joeynmt.training - Epoch   4, Step:    38000, Batch Loss:     1.781959, Batch Acc: 0.452055, Tokens per Sec:    21306, Lr: 0.000300
2025-05-29 22:12:59,119 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:12:59,119 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:13:07,403 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.73, acc:   0.48, generation: 8.2764[sec], evaluation: 0.0000[sec]
2025-05-29 22:13:07,718 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/35500.ckpt
2025-05-29 22:13:07,742 - INFO - joeynmt.training - Example #0
2025-05-29 22:13:07,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:13:07,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:13:07,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'ec@@', 'i', 'di@@', 'sp@@', 'os@@', 'iti@@', 'vi', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'è', 'stato', 'un', 'li@@', 'vello', 'di', '4@@', '8', 'st@@', 'ati@@', ',', 'che', 'ha', 'fatto', '4@@', '8', 'ore', 'di', '4@@', '8', 'ore', 'di', '4@@', '8', 'ore', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'guar@@', 'do', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'ri@@', 'guar@@', 'do', 'il', '4@@', '0@@', '%', 'di', 'un', 'po@@', '<unk>', 'di', 'c@@', 'ento', 'di', 'ri@@', 'guar@@', 'do', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'di']
2025-05-29 22:13:07,743 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:13:07,743 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:13:07,743 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questi due dieci dispositivi per ridurre il ghiaccio, che la ghiaccia, che è stato un livello di 48 stati, che ha fatto 48 ore di 48 ore di 48 ore di 48 ore per cento di un po<unk> di 40 per cento di riguardo il 40 per cento di cento di riguardo il 40% di un po<unk> di cento di riguardo il 40 per cento di questi due anni di
2025-05-29 22:13:07,743 - INFO - joeynmt.training - Example #1
2025-05-29 22:13:07,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:13:07,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:13:07,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'è', 'abb@@', 'ast@@', 'anza', 'di', 'questo', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'non', 'c@@', '<unk>', 'è', 'una', 'cosa', 'che', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 22:13:07,744 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:13:07,744 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:13:07,744 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la risposta è abbastanza di questo speciale, non c<unk> è una cosa che non è la Dicke del ghiaccia.
2025-05-29 22:13:07,744 - INFO - joeynmt.training - Example #2
2025-05-29 22:13:07,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:13:07,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:13:07,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'la', 'c@@', 'aus@@', 'a', 'della', 'cu@@', 'c@@', 'ina', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:13:07,745 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:13:07,745 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:13:07,745 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, la causa della cucina globale.
2025-05-29 22:13:07,745 - INFO - joeynmt.training - Example #3
2025-05-29 22:13:07,745 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:13:07,745 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:13:07,745 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'hi@@', 'e@@', 'dete', 'nel', 'v@@', 'ento', 'del', 'v@@', 'ento', 'e', 'n@@', 'ell@@', '<unk>', 'est@@', 'er@@', 'o@@', '.', '</s>']
2025-05-29 22:13:07,746 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:13:07,746 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:13:07,746 - INFO - joeynmt.training - 	Hypothesis: Chiedete nel vento del vento e nell<unk> estero.
2025-05-29 22:13:07,746 - INFO - joeynmt.training - Example #4
2025-05-29 22:13:07,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:13:07,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:13:07,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'li@@', 'vello', 'succ@@', 'essi@@', 'vo@@', ',', 'è', 'una', 'di@@', 'men@@', 'sione', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'po@@', '<unk>', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:13:07,746 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:13:07,747 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:13:07,747 - INFO - joeynmt.training - 	Hypothesis: Il prossimo livello successivo, è una dimensione che vi mostrerò un po<unk> di quello che è successo negli ultimi 25 anni.
2025-05-29 22:13:11,071 - INFO - joeynmt.training - Epoch   4, Step:    38100, Batch Loss:     1.956333, Batch Acc: 0.453819, Tokens per Sec:    19574, Lr: 0.000300
2025-05-29 22:13:14,426 - INFO - joeynmt.training - Epoch   4, Step:    38200, Batch Loss:     1.706057, Batch Acc: 0.454228, Tokens per Sec:    20724, Lr: 0.000300
2025-05-29 22:13:17,802 - INFO - joeynmt.training - Epoch   4, Step:    38300, Batch Loss:     1.798393, Batch Acc: 0.458076, Tokens per Sec:    21029, Lr: 0.000300
2025-05-29 22:13:21,176 - INFO - joeynmt.training - Epoch   4, Step:    38400, Batch Loss:     1.677630, Batch Acc: 0.458371, Tokens per Sec:    21446, Lr: 0.000300
2025-05-29 22:13:24,550 - INFO - joeynmt.training - Epoch   4, Step:    38500, Batch Loss:     1.821547, Batch Acc: 0.454199, Tokens per Sec:    21015, Lr: 0.000300
2025-05-29 22:13:24,550 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:13:24,550 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:13:33,344 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.72, acc:   0.48, generation: 8.7860[sec], evaluation: 0.0000[sec]
2025-05-29 22:13:33,344 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:13:33,828 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/36000.ckpt
2025-05-29 22:13:33,852 - INFO - joeynmt.training - Example #0
2025-05-29 22:13:33,852 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:13:33,852 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:13:33,852 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 'con@@', 'segu@@', 'ire', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '8', 'st@@', 'ati@@', ',', 'per', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'st@@', 'ati@@', 'sti@@', 'ch@@', 'e@@', '.', '</s>']
2025-05-29 22:13:33,853 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:13:33,853 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:13:33,853 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due dimensioni per conseguire le ghiaccio, che le ghiaccia, che i ghiacci, per tre milioni di anni per i 48 stati, per cento di tre milioni di anni per cento di statistiche.
2025-05-29 22:13:33,853 - INFO - joeynmt.training - Example #1
2025-05-29 22:13:33,853 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:13:33,853 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:13:33,853 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'abb@@', 'ast@@', 'anza', 'per', 'il', 'problema', 'di', 'questo', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:13:33,854 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:13:33,854 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:13:33,854 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che è abbastanza per il problema di questo speciale, perché non c<unk> è la Dicke del ghiaccio.
2025-05-29 22:13:33,854 - INFO - joeynmt.training - Example #2
2025-05-29 22:13:33,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:13:33,854 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:13:33,854 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 's@@', 'ov@@', 'rap@@', 'por@@', 'to', 'che', 'è', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'per', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:13:33,855 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:13:33,855 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:13:33,855 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di sovrapporto che è il ghiaccio per il cuore del nostro sistema sistema globale.
2025-05-29 22:13:33,855 - INFO - joeynmt.training - Example #3
2025-05-29 22:13:33,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:13:33,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:13:33,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'in', 'eff@@', 'etti@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:13:33,856 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:13:33,856 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:13:33,856 - INFO - joeynmt.training - 	Hypothesis: E in effetti, in un certo senso di un sacco di sommergibile.
2025-05-29 22:13:33,856 - INFO - joeynmt.training - Example #4
2025-05-29 22:13:33,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:13:33,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:13:33,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'men@@', 'sione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ell@@', '<unk>', 'ulti@@', 'mo', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:13:33,856 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:13:33,857 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:13:33,857 - INFO - joeynmt.training - 	Hypothesis: Il prossimo è che vi mostrerò che vi mostrerò una dimensione di un disegno di quell<unk> ultimo 25 anni.
2025-05-29 22:13:37,182 - INFO - joeynmt.training - Epoch   4, Step:    38600, Batch Loss:     1.698057, Batch Acc: 0.451722, Tokens per Sec:    18507, Lr: 0.000300
2025-05-29 22:13:40,556 - INFO - joeynmt.training - Epoch   4, Step:    38700, Batch Loss:     1.765601, Batch Acc: 0.454764, Tokens per Sec:    21101, Lr: 0.000300
2025-05-29 22:13:43,912 - INFO - joeynmt.training - Epoch   4, Step:    38800, Batch Loss:     1.810994, Batch Acc: 0.458249, Tokens per Sec:    20689, Lr: 0.000300
2025-05-29 22:13:47,246 - INFO - joeynmt.training - Epoch   4, Step:    38900, Batch Loss:     1.807684, Batch Acc: 0.455412, Tokens per Sec:    21664, Lr: 0.000300
2025-05-29 22:13:50,603 - INFO - joeynmt.training - Epoch   4, Step:    39000, Batch Loss:     1.818188, Batch Acc: 0.458088, Tokens per Sec:    21261, Lr: 0.000300
2025-05-29 22:13:50,604 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:13:50,604 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:14:00,046 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.48, generation: 9.4304[sec], evaluation: 0.0000[sec]
2025-05-29 22:14:00,047 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:14:00,607 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/37500.ckpt
2025-05-29 22:14:00,633 - INFO - joeynmt.training - Example #0
2025-05-29 22:14:00,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:14:00,634 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:14:00,634 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'di@@', 're@@', ',', 'per', 'aiut@@', 'are', 'a', 'di@@', 'st@@', 'ur@@', 'b@@', 'i', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'per', 'un', 'po@@', '<unk>', 'di', 'an@@', 'ni@@', ',', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', 's@@', 'ac@@', 'ri@@', '.', '</s>']
2025-05-29 22:14:00,635 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:14:00,635 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:14:00,635 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di dire, per aiutare a disturbi che i ghiacciano i ghiaccio, che le ghiacciano per un po<unk> di anni, per il 48% di questi sacri.
2025-05-29 22:14:00,635 - INFO - joeynmt.training - Example #1
2025-05-29 22:14:00,635 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:14:00,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:14:00,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'in', 'modo', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'il', 'problema', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:14:00,636 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:14:00,636 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:14:00,636 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la risposta in modo che non è abbastanza il problema di questo tipo di problema, perché non è il Dicke del ghiaccio.
2025-05-29 22:14:00,636 - INFO - joeynmt.training - Example #2
2025-05-29 22:14:00,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:14:00,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:14:00,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'cu@@', 'b@@', 'o', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:14:00,637 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:14:00,637 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:14:00,637 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa di ghiaccia, il cubo del nostro sistema climatico globale.
2025-05-29 22:14:00,637 - INFO - joeynmt.training - Example #3
2025-05-29 22:14:00,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:14:00,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:14:00,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'se', 'si', 'trov@@', 'a', 'nel', 'v@@', 'ento', 'del', 'v@@', 'ento', 'e', 'in', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:14:00,637 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:14:00,638 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:14:00,638 - INFO - joeynmt.training - 	Hypothesis: E se si trova nel vento del vento e in un sommergibile.
2025-05-29 22:14:00,638 - INFO - joeynmt.training - Example #4
2025-05-29 22:14:00,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:14:00,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:14:00,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'p@@', 'in@@', 'to', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'men@@', 'sione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'c@@', 'entr@@', 'o', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:14:00,638 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:14:00,638 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:14:00,638 - INFO - joeynmt.training - 	Hypothesis: Il prossimo dipinto che vi mostrerò una dimensione di un disegno di un disegno di un centro di quale è successo negli ultimi 25 anni.
2025-05-29 22:14:04,054 - INFO - joeynmt.training - Epoch   4, Step:    39100, Batch Loss:     1.881972, Batch Acc: 0.459371, Tokens per Sec:    18023, Lr: 0.000300
2025-05-29 22:14:07,445 - INFO - joeynmt.training - Epoch   4, Step:    39200, Batch Loss:     1.807909, Batch Acc: 0.456029, Tokens per Sec:    21237, Lr: 0.000300
2025-05-29 22:14:10,813 - INFO - joeynmt.training - Epoch   4, Step:    39300, Batch Loss:     1.929074, Batch Acc: 0.454685, Tokens per Sec:    20498, Lr: 0.000300
2025-05-29 22:14:14,199 - INFO - joeynmt.training - Epoch   4, Step:    39400, Batch Loss:     1.691150, Batch Acc: 0.460928, Tokens per Sec:    20590, Lr: 0.000300
2025-05-29 22:14:17,563 - INFO - joeynmt.training - Epoch   4, Step:    39500, Batch Loss:     1.834534, Batch Acc: 0.458585, Tokens per Sec:    20888, Lr: 0.000300
2025-05-29 22:14:17,563 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:14:17,563 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:14:27,253 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.73, acc:   0.48, generation: 9.6768[sec], evaluation: 0.0000[sec]
2025-05-29 22:14:27,802 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/36500.ckpt
2025-05-29 22:14:27,824 - INFO - joeynmt.training - Example #0
2025-05-29 22:14:27,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:14:27,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:14:27,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 're@@', ',', 'per', 'di@@', 're@@', ',', 'per', 'di@@', 're@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'ha', 'fatto', 'per', 'il', '4@@', '8', 'st@@', 'at@@', 'o@@', ',', 'per', 'il', '4@@', '8', 'st@@', 'ati@@', ',', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'circa', '4@@', '8', 'ore', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:14:27,825 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:14:27,825 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:14:27,825 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per dire, per dire, per dire, che i ghiaccio, che i ghiaccio, che ha fatto per il 48 stato, per il 48 stati, per il 48 per cento di circa 48 ore di cento.
2025-05-29 22:14:27,825 - INFO - joeynmt.training - Example #1
2025-05-29 22:14:27,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:14:27,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:14:27,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'molto', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'ci', 'sono', 'abb@@', 'ast@@', 'anza', 'in', 'modo', 'che', 'non', 'ci', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:14:27,826 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:14:27,826 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:14:27,826 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza molto di questo tipo di problema, perché non ci sono abbastanza in modo che non ci mostra il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 22:14:27,826 - INFO - joeynmt.training - Example #2
2025-05-29 22:14:27,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:14:27,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:14:27,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'la', 's@@', 'fi@@', 'da', 'è', 'la', 'cu@@', 'i@@', 'zione', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'di', 'cui', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'è', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:14:27,827 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:14:27,827 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:14:27,827 - INFO - joeynmt.training - 	Hypothesis: In effetti, la sfida è la cuizione artica, il cuore di cui il nostro sistema climatico è il nostro sistema climatico globale.
2025-05-29 22:14:27,827 - INFO - joeynmt.training - Example #3
2025-05-29 22:14:27,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:14:27,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:14:27,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'em@@', 'br@@', 'a', 'che', 'si', 'può', 'essere', 'in', 'gra@@', 'do', 'di', 'fare', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:14:27,828 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:14:27,828 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:14:27,828 - INFO - joeynmt.training - 	Hypothesis: Sembra che si può essere in grado di fare in un certo senso.
2025-05-29 22:14:27,828 - INFO - joeynmt.training - Example #4
2025-05-29 22:14:27,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:14:27,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:14:27,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'per@@', 'anz@@', 'a@@', ',', 'la', 'pros@@', 'si@@', 'ma', 's@@', 'etti@@', 'man@@', 'a', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'nel', '200@@', '2@@', ',', 'che', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:14:27,829 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:14:27,829 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:14:27,829 - INFO - joeynmt.training - 	Hypothesis: La prossima speranza, la prossima settimana di quello che è successo nel 2002, che è successo nel 25 anni.
2025-05-29 22:14:31,223 - INFO - joeynmt.training - Epoch   4, Step:    39600, Batch Loss:     2.050116, Batch Acc: 0.455916, Tokens per Sec:    17732, Lr: 0.000300
2025-05-29 22:14:34,604 - INFO - joeynmt.training - Epoch   4, Step:    39700, Batch Loss:     1.883506, Batch Acc: 0.458107, Tokens per Sec:    21411, Lr: 0.000300
2025-05-29 22:14:37,954 - INFO - joeynmt.training - Epoch   4, Step:    39800, Batch Loss:     1.654992, Batch Acc: 0.458341, Tokens per Sec:    20745, Lr: 0.000300
2025-05-29 22:14:41,319 - INFO - joeynmt.training - Epoch   4, Step:    39900, Batch Loss:     1.807618, Batch Acc: 0.452831, Tokens per Sec:    20721, Lr: 0.000300
2025-05-29 22:14:44,680 - INFO - joeynmt.training - Epoch   4, Step:    40000, Batch Loss:     1.777672, Batch Acc: 0.457763, Tokens per Sec:    20841, Lr: 0.000300
2025-05-29 22:14:44,680 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:14:44,680 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:14:53,488 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.64, acc:   0.49, generation: 8.7997[sec], evaluation: 0.0000[sec]
2025-05-29 22:14:53,488 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:14:53,967 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/39500.ckpt
2025-05-29 22:14:53,991 - INFO - joeynmt.training - Example #0
2025-05-29 22:14:53,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:14:53,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:14:53,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'v@@', 'it@@', 'ti@@', 'me', 'per', 'aiut@@', 'are', 'a', 'di@@', 'st@@', 'in@@', 'gu@@', 'ere', 'che', 'l@@', '<unk>', 'inter@@', 'a', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'è', 'stato', 'un', 'mili@@', 'one', 'di', 'anni', 'di', 'gr@@', 'an', 'parte', 'del', '4@@', '8@@', '%', 'dei', 's@@', 'ott@@', 'om@@', 'ar@@', 'i@@', '.', '</s>']
2025-05-29 22:14:53,992 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:14:53,992 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:14:53,992 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due vittime per aiutare a distinguere che l<unk> intera ghiaccio artico, che è stato un milione di anni di gran parte del 48% dei sottomari.
2025-05-29 22:14:53,992 - INFO - joeynmt.training - Example #1
2025-05-29 22:14:53,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:14:53,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:14:53,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'importante', 'è', 'che', 'la', 'cosa', 'spe@@', 'ci@@', 'ale', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'k@@', '.', '</s>']
2025-05-29 22:14:53,993 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:14:53,993 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:14:53,993 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più importante è che la cosa speciale speciale di questo problema, perché non è il Dicke mostra il Dick.
2025-05-29 22:14:53,993 - INFO - joeynmt.training - Example #2
2025-05-29 22:14:53,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:14:53,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:14:53,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:14:53,994 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:14:53,994 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:14:53,994 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, la cucina del nostro climatico globale del nostro climatico.
2025-05-29 22:14:53,994 - INFO - joeynmt.training - Example #3
2025-05-29 22:14:53,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:14:53,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:14:53,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'eva', 'essere', 'in', 'gra@@', 'do', 'di', 'ri@@', 'dur@@', 're', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:14:53,995 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:14:53,995 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:14:53,995 - INFO - joeynmt.training - 	Hypothesis: Si poteva essere in grado di ridurre e in un certo senso.
2025-05-29 22:14:53,995 - INFO - joeynmt.training - Example #4
2025-05-29 22:14:53,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:14:53,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:14:53,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'fi@@', 'da', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'c@@', 'las@@', 'se', 'è', 'succ@@', 'esso', 'nel', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'nel', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:14:53,996 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:14:53,996 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:14:53,996 - INFO - joeynmt.training - 	Hypothesis: La prossima sfida che vi mostrerò è una classe è successo nel quale è successo nel 25 anni.
2025-05-29 22:14:57,257 - INFO - joeynmt.training - Epoch   4, Step:    40100, Batch Loss:     1.699266, Batch Acc: 0.461239, Tokens per Sec:    18787, Lr: 0.000300
2025-05-29 22:15:00,488 - INFO - joeynmt.training - Epoch   4, Step:    40200, Batch Loss:     1.811429, Batch Acc: 0.457700, Tokens per Sec:    22089, Lr: 0.000300
2025-05-29 22:15:03,690 - INFO - joeynmt.training - Epoch   4, Step:    40300, Batch Loss:     1.883943, Batch Acc: 0.466345, Tokens per Sec:    22079, Lr: 0.000300
2025-05-29 22:15:06,925 - INFO - joeynmt.training - Epoch   4, Step:    40400, Batch Loss:     1.714586, Batch Acc: 0.462277, Tokens per Sec:    22425, Lr: 0.000300
2025-05-29 22:15:10,126 - INFO - joeynmt.training - Epoch   4, Step:    40500, Batch Loss:     1.748119, Batch Acc: 0.458762, Tokens per Sec:    22151, Lr: 0.000300
2025-05-29 22:15:10,126 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:15:10,126 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:15:17,050 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.62, acc:   0.48, generation: 6.9165[sec], evaluation: 0.0000[sec]
2025-05-29 22:15:17,050 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:15:17,700 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/38000.ckpt
2025-05-29 22:15:17,725 - INFO - joeynmt.training - Example #0
2025-05-29 22:15:17,725 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:15:17,725 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:15:17,725 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'v@@', 'in@@', 'cer@@', 'e@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'per', 'i', 'su@@', 'oi', 'li@@', 'mit@@', 'i', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti@@', '.', '</s>']
2025-05-29 22:15:17,726 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:15:17,726 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:15:17,726 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due diapositive per convincere, che l<unk> artica, che i ghiacciano per tre milioni di anni di anni che per i suoi limiti 48 Stati Uniti.
2025-05-29 22:15:17,726 - INFO - joeynmt.training - Example #1
2025-05-29 22:15:17,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:15:17,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:15:17,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'grande', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'c@@', '<unk>', 'è', 'la', 'di@@', 'mostr@@', 'azione', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:15:17,727 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:15:17,727 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:15:17,727 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più grande problema, e non c<unk> è la dimostrazione di ghiaccio.
2025-05-29 22:15:17,727 - INFO - joeynmt.training - Example #2
2025-05-29 22:15:17,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:15:17,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:15:17,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 't@@', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'la', 'c@@', 'aus@@', 'a', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:15:17,728 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:15:17,728 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:15:17,728 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di tartico, la causa del nostro climatico globale.
2025-05-29 22:15:17,728 - INFO - joeynmt.training - Example #3
2025-05-29 22:15:17,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:15:17,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:15:17,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'du@@', 'ce', 'a', 'n@@', 'ell@@', '<unk>', 'est@@', 'in@@', 'zione', 'di', 'v@@', 'ento', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:15:17,729 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:15:17,729 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:15:17,729 - INFO - joeynmt.training - 	Hypothesis: Si riduce a nell<unk> estinzione di vento in un certo senso.
2025-05-29 22:15:17,729 - INFO - joeynmt.training - Example #4
2025-05-29 22:15:17,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:15:17,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:15:17,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 're@@', 'zione', 'di', 'una', 'di@@', 're@@', 'zione', 'di', 'una', 'di@@', 're@@', 'zione', 'di', '2@@', '5', 'anni', 'fa@@', '.', '</s>']
2025-05-29 22:15:17,730 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:15:17,730 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:15:17,730 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una direzione di una direzione di una direzione di 25 anni fa.
2025-05-29 22:15:21,047 - INFO - joeynmt.training - Epoch   4, Step:    40600, Batch Loss:     1.782637, Batch Acc: 0.460818, Tokens per Sec:    17513, Lr: 0.000300
2025-05-29 22:15:24,348 - INFO - joeynmt.training - Epoch   4, Step:    40700, Batch Loss:     1.875015, Batch Acc: 0.457613, Tokens per Sec:    20761, Lr: 0.000300
2025-05-29 22:15:27,670 - INFO - joeynmt.training - Epoch   4, Step:    40800, Batch Loss:     1.867685, Batch Acc: 0.463631, Tokens per Sec:    21939, Lr: 0.000300
2025-05-29 22:15:30,978 - INFO - joeynmt.training - Epoch   4, Step:    40900, Batch Loss:     1.640625, Batch Acc: 0.459402, Tokens per Sec:    21533, Lr: 0.000300
2025-05-29 22:15:34,262 - INFO - joeynmt.training - Epoch   4, Step:    41000, Batch Loss:     2.009095, Batch Acc: 0.457763, Tokens per Sec:    21636, Lr: 0.000300
2025-05-29 22:15:34,263 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:15:34,263 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:15:42,285 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.62, acc:   0.49, generation: 8.0104[sec], evaluation: 0.0000[sec]
2025-05-29 22:15:42,285 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:15:42,931 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/37000.ckpt
2025-05-29 22:15:42,955 - INFO - joeynmt.training - Example #0
2025-05-29 22:15:42,955 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:15:42,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:15:42,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'che', 'i', 'miei', 'due', 's@@', 'etti@@', 'man@@', 'e', 'per', 'di@@', 're@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'per', 'le', 'persone', 'che', 'hanno', 'av@@', 'uto', 'per', 'il', '4@@', '8', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '1@@', '0@@', '%', 'di', 'persone', 'che', 'av@@', 'evano', 'acc@@', 'esso', 'al', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'al@@', 'im@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:15:42,956 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:15:42,956 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:15:42,956 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato che i miei due settimane per dire, che i ghiaccio, che i ghiacciate che per le persone che hanno avuto per il 48 milioni di anni per il 48 per cento di anni per il 40 per cento di 10% di persone che avevano accesso al 40 per cento di cento di alimento.
2025-05-29 22:15:42,956 - INFO - joeynmt.training - Example #1
2025-05-29 22:15:42,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:15:42,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:15:42,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'for@@', 'te@@', ',', 'e', 'la', 'cosa', 'più', 'importante', 'per', 'il', 'problema', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'D@@', 'ic@@', 'ke', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'k@@', ',', 'e', 'la', 'cosa', 'più', 'for@@', 'te@@', ',', 'e', 'la', 'cosa', 'più', 'for@@', 'te@@', ',', 'e', 'la', 'cosa', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'problema', 'di', 'n@@', 'om@@', 'e', 'di', 'questo', 'problema', 'di', 'cui', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'e', 'la', 'cosa', 'più', 'for@@', 'te@@', ',', 'e', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', '.', '</s>']
2025-05-29 22:15:42,957 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:15:42,957 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:15:42,957 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più forte, e la cosa più importante per il problema di questo tipo di problema, perché non c<unk> è la Dicke mostra il Dicke mostra il Dicke mostra il Dicke mostra il Dick, e la cosa più forte, e la cosa più forte, e la cosa che si tratta di un problema di nome di questo problema di cui non è abbastanza forte, e la cosa più forte, e non è abbastanza forte.
2025-05-29 22:15:42,957 - INFO - joeynmt.training - Example #2
2025-05-29 22:15:42,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:15:42,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:15:42,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 'cosa', 'più', 'ar@@', 't@@', 'icol@@', 't@@', 'à@@', ',', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:15:42,958 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:15:42,958 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:15:42,958 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la cosa più articoltà, la cucina del nostro climatico globale.
2025-05-29 22:15:42,958 - INFO - joeynmt.training - Example #3
2025-05-29 22:15:42,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:15:42,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:15:42,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'em@@', 'br@@', 'a', 'che', 'si', 'trov@@', 'a', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:15:42,959 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:15:42,959 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:15:42,959 - INFO - joeynmt.training - 	Hypothesis: Sembra che si trova in un certo senso.
2025-05-29 22:15:42,959 - INFO - joeynmt.training - Example #4
2025-05-29 22:15:42,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:15:42,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:15:42,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'c@@', 'entr@@', 'o', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:15:42,960 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:15:42,960 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:15:42,960 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un centro di quello che è successo negli ultimi 25 anni.
2025-05-29 22:15:46,290 - INFO - joeynmt.training - Epoch   4, Step:    41100, Batch Loss:     1.741266, Batch Acc: 0.460055, Tokens per Sec:    18038, Lr: 0.000300
2025-05-29 22:15:49,587 - INFO - joeynmt.training - Epoch   4, Step:    41200, Batch Loss:     1.681946, Batch Acc: 0.459289, Tokens per Sec:    21060, Lr: 0.000300
2025-05-29 22:15:52,985 - INFO - joeynmt.training - Epoch   4, Step:    41300, Batch Loss:     1.855163, Batch Acc: 0.457806, Tokens per Sec:    21533, Lr: 0.000300
2025-05-29 22:15:56,365 - INFO - joeynmt.training - Epoch   4, Step:    41400, Batch Loss:     1.845680, Batch Acc: 0.461615, Tokens per Sec:    21021, Lr: 0.000300
2025-05-29 22:15:59,694 - INFO - joeynmt.training - Epoch   4, Step:    41500, Batch Loss:     1.601547, Batch Acc: 0.462425, Tokens per Sec:    21175, Lr: 0.000300
2025-05-29 22:15:59,695 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:15:59,695 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:16:08,304 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.48, generation: 8.6018[sec], evaluation: 0.0000[sec]
2025-05-29 22:16:08,650 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/38500.ckpt
2025-05-29 22:16:08,674 - INFO - joeynmt.training - Example #0
2025-05-29 22:16:08,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:16:08,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:16:08,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'qu@@', 'ei', 'due', 'milioni', 'di', 'persone', 'che', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'ri@@', 'port@@', 'are', 'a', 'di@@', 'st@@', 'in@@', 'gu@@', 'ere', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'i', 'miei', 'tre', 'milioni', 'di', 'anni', 'di', 'm@@', 'ezz@@', 'o', 'di', 'anni', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:16:08,676 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:16:08,676 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:16:08,676 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso quei due milioni di persone che sono stati in grado di riportare a distinguere che le ghiaccia, che i miei tre milioni di anni di mezzo di anni di 48 stati.
2025-05-29 22:16:08,676 - INFO - joeynmt.training - Example #1
2025-05-29 22:16:08,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:16:08,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:16:08,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'mia', 's@@', 'qu@@', 'ad@@', 'ra', 'che', 'non', 'c@@', '<unk>', 'è', 'la', 'd@@', 'ell@@', '<unk>', 'is@@', 'c@@', 'e@@', 'zione', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:16:08,677 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:16:08,677 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:16:08,677 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo tipo di problema, perché non c<unk> è la mia squadra che non c<unk> è la dell<unk> iscezione del ghiaccio.
2025-05-29 22:16:08,677 - INFO - joeynmt.training - Example #2
2025-05-29 22:16:08,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:16:08,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:16:08,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'è', 'l@@', '<unk>', 'in@@', 'tr@@', 'o@@', 'd@@', 'o@@', ',', 'e', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:16:08,678 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:16:08,678 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:16:08,678 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è l<unk> introdo, e la cucina del nostro sistema di climatico globale.
2025-05-29 22:16:08,678 - INFO - joeynmt.training - Example #3
2025-05-29 22:16:08,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:16:08,678 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:16:08,678 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'eva', 'essere', 'in', 'gra@@', 'do', 'di', 'di@@', 'st@@', 'in@@', 'gu@@', 'e', 'in', 'un', 'm@@', 'ot@@', 'o', 'in', 'un', 'm@@', 'ot@@', 'o', 'di', 's@@', 'om@@', 'mer@@', 'a@@', '.', '</s>']
2025-05-29 22:16:08,679 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:16:08,679 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:16:08,679 - INFO - joeynmt.training - 	Hypothesis: Si poteva essere in grado di distingue in un moto in un moto di sommera.
2025-05-29 22:16:08,679 - INFO - joeynmt.training - Example #4
2025-05-29 22:16:08,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:16:08,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:16:08,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'es@@', 'su@@', 'to', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:16:08,679 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:16:08,680 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:16:08,680 - INFO - joeynmt.training - 	Hypothesis: La prossima sessuto che vi mostrerò che vi mostrerò che è successo negli ultimi 25 anni.
2025-05-29 22:16:12,074 - INFO - joeynmt.training - Epoch   4, Step:    41600, Batch Loss:     1.714763, Batch Acc: 0.457605, Tokens per Sec:    18893, Lr: 0.000300
2025-05-29 22:16:15,444 - INFO - joeynmt.training - Epoch   4, Step:    41700, Batch Loss:     2.038535, Batch Acc: 0.461794, Tokens per Sec:    21276, Lr: 0.000300
2025-05-29 22:16:18,811 - INFO - joeynmt.training - Epoch   4, Step:    41800, Batch Loss:     1.777274, Batch Acc: 0.456148, Tokens per Sec:    21861, Lr: 0.000300
2025-05-29 22:16:22,182 - INFO - joeynmt.training - Epoch   4, Step:    41900, Batch Loss:     1.806351, Batch Acc: 0.462770, Tokens per Sec:    21699, Lr: 0.000300
2025-05-29 22:16:25,550 - INFO - joeynmt.training - Epoch   4, Step:    42000, Batch Loss:     1.957129, Batch Acc: 0.452000, Tokens per Sec:    21718, Lr: 0.000300
2025-05-29 22:16:25,551 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:16:25,551 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:16:35,195 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.56, acc:   0.49, generation: 9.6312[sec], evaluation: 0.0000[sec]
2025-05-29 22:16:35,195 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:16:35,755 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/39000.ckpt
2025-05-29 22:16:35,780 - INFO - joeynmt.training - Example #0
2025-05-29 22:16:35,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:16:35,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:16:35,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'enza', 'che', 'le', 'persone', 'che', 'hanno', 'av@@', 'uto', 'la', 'ri@@', 'chi@@', 'est@@', 'a', 'che', 'gli', 'anni', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'anni', 'di', '4@@', '8', 'st@@', 'ati@@', 'sti@@', 'che', 'per', 'i', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'circa', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '1@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 'ri@@', 'guar@@', 'do', 'a', 'questo', 'punto', 'è', 'stato', 'f@@', 'ant@@', 'ast@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:16:35,782 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:16:35,782 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:16:35,782 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato queste due diapositive per conseguenza che le persone che hanno avuto la richiesta che gli anni di questi due anni di questi due anni di questi anni di 48 statistiche per i 48 ore per cento di 48 ore per cento di 48 ore per cento di circa il 40 per cento di 10% di questi due anni per cento di riguardo a questo punto è stato fantastico.
2025-05-29 22:16:35,782 - INFO - joeynmt.training - Example #1
2025-05-29 22:16:35,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:16:35,782 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:16:35,782 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'l@@', '<unk>', 'in@@', 'segn@@', 'ante', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'è', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'è', 'un', 'di@@', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'problema', 'di', 'n@@', 'om@@', 'e', 'di', 'un', 'po@@', '<unk>', 'di', 'b@@', 're@@', 've', 'e', 'la', 'ri@@', 'chi@@', 'est@@', 'a', 'di', 'un', 'problema', 'di', 's@@', 'otto', 'la', 'c@@', 'aus@@', 'a', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é', 'abb@@', 'ast@@', 'anza', 'in@@', 'tr@@', 'ap@@', 'i@@', 'ant@@', 'e@@', ',', 'e', 'questo', 'è', 'il', 'D@@', 'ic@@', 'chi@@', 'o@@', ',', 'e', 'che', 'è', 'stato', 'in@@']
2025-05-29 22:16:35,783 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:16:35,783 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:16:35,783 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza l<unk> insegnante di questo speciale speciale di questo speciale è che non è il Dicke mostra il Dicke è un dimostra il ghiaccio di un ghiaccio di un ghiaccio di un problema di nome di un po<unk> di breve e la richiesta di un problema di sotto la causa di un po<unk> di sé abbastanza intrapiante, e questo è il Dicchio, e che è stato in
2025-05-29 22:16:35,783 - INFO - joeynmt.training - Example #2
2025-05-29 22:16:35,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:16:35,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:16:35,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'c@@', 'at@@', 'en@@', 'a', 'di', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'li@@', 'mat@@', 'ica', 'glob@@', 'ale', 'c@@', 'li@@', 'mat@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 22:16:35,784 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:16:35,784 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:16:35,784 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa della catena di causa della nostra climatica globale climatica.
2025-05-29 22:16:35,784 - INFO - joeynmt.training - Example #3
2025-05-29 22:16:35,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:16:35,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:16:35,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'eva', 'essere', 'in', 'gra@@', 'do', 'di', 'ri@@', 'l@@', 'ev@@', 'e', 'ri@@', 'm@@', 'pi@@', 'azz@@', 'ar@@', 'e@@', '.', '</s>']
2025-05-29 22:16:35,785 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:16:35,785 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:16:35,785 - INFO - joeynmt.training - 	Hypothesis: Si poteva essere in grado di rileve rimpiazzare.
2025-05-29 22:16:35,785 - INFO - joeynmt.training - Example #4
2025-05-29 22:16:35,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:16:35,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:16:35,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'tr@@', 'att@@', 'amento', 'di', 'ciò', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:16:35,786 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:16:35,786 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:16:35,786 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di un trattamento di ciò che è successo negli ultimi 25 anni.
2025-05-29 22:16:39,202 - INFO - joeynmt.training - Epoch   4, Step:    42100, Batch Loss:     1.924654, Batch Acc: 0.457167, Tokens per Sec:    17989, Lr: 0.000300
2025-05-29 22:16:42,567 - INFO - joeynmt.training - Epoch   4, Step:    42200, Batch Loss:     1.632420, Batch Acc: 0.462703, Tokens per Sec:    20345, Lr: 0.000300
2025-05-29 22:16:45,958 - INFO - joeynmt.training - Epoch   4, Step:    42300, Batch Loss:     1.795053, Batch Acc: 0.458858, Tokens per Sec:    21208, Lr: 0.000300
2025-05-29 22:16:49,341 - INFO - joeynmt.training - Epoch   4, Step:    42400, Batch Loss:     1.800874, Batch Acc: 0.453887, Tokens per Sec:    21672, Lr: 0.000300
2025-05-29 22:16:52,733 - INFO - joeynmt.training - Epoch   4, Step:    42500, Batch Loss:     1.875786, Batch Acc: 0.459854, Tokens per Sec:    21101, Lr: 0.000300
2025-05-29 22:16:52,733 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:16:52,733 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:17:01,395 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.57, acc:   0.49, generation: 8.6499[sec], evaluation: 0.0000[sec]
2025-05-29 22:17:01,795 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/40000.ckpt
2025-05-29 22:17:01,822 - INFO - joeynmt.training - Example #0
2025-05-29 22:17:01,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:17:01,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:17:01,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'on@@', 'i@@', ',', 'per', 's@@', 'ent@@', 'ito', 'che', 'le', 'persone', 'che', 'hanno', 'av@@', 'uto', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'hanno', 'av@@', 'uto', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'circa', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '1@@', '0@@', '%', 'dei', 'm@@', 'ezz@@', 'i', 'di', '1@@', '0@@', '%', 'dei', 'm@@', 'ezz@@', 'i', 'di', 'questi', 'due', 'anni', 'fa@@', ',', 'e', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 's@@', 'an@@', 'gu@@', 'e@@', '.', '</s>']
2025-05-29 22:17:01,823 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:17:01,823 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:17:01,823 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due dimensioni, per sentito che le persone che hanno avuto il ghiaccio artico, che hanno avuto il 48 per cento di tre milioni di anni di anni per il 48 per cento di circa il 40 per cento di 10% dei mezzi di 10% dei mezzi di questi due anni fa, e il 48 per cento di sangue.
2025-05-29 22:17:01,823 - INFO - joeynmt.training - Example #1
2025-05-29 22:17:01,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:17:01,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:17:01,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'spe@@', 'ci@@', 'ale', 'è', 'abb@@', 'ast@@', 'anza', 'spe@@', 'ci@@', 'e@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'D@@', 'ic@@', 'ke', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'e', 'il', 't@@', 'av@@', 'olo', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'cio', 's@@', 'otto', 'la', 's@@', 'itu@@', 'azione', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 's@@', 'ett@@', 'ore', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'p@@', 'ezz@@', 'o', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'ac@@', 'co', 'di', 's@@', 'otto', 'la', 's@@', 'itu@@', 'azione', 'di', 'un', 'problema', 'di', 's@@', 'ac@@', 'co', 'di', 's@@', 'ett@@', 'ore', 'di', 'un', 'p@@', 'ò', 'di']
2025-05-29 22:17:01,824 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:17:01,824 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:17:01,824 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa speciale è abbastanza specie, perché non c<unk> è la Dicke è la Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio e il tavolo di un ghiaccio sotto la situazione di un pezzo di settore di un pezzo di pezzo di un po<unk> di sacco di sotto la situazione di un problema di sacco di settore di un pò di
2025-05-29 22:17:01,824 - INFO - joeynmt.training - Example #2
2025-05-29 22:17:01,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:17:01,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:17:01,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 's@@', 'itu@@', 'azione', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'la', 's@@', 'fi@@', 'da', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:17:01,825 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:17:01,825 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:17:01,825 - INFO - joeynmt.training - 	Hypothesis: In certo senso, la situazione artica, la sfida del nostro climatico globale del nostro climatico globale del nostro climatico globale.
2025-05-29 22:17:01,825 - INFO - joeynmt.training - Example #3
2025-05-29 22:17:01,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:17:01,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:17:01,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'eva', 'andare', 'in', 'b@@', 'att@@', 'ag@@', 'lia', 'in', 'un', 'b@@', 'el', 'b@@', 're@@', 've', 'in', 'sal@@', 'a@@', '.', '</s>']
2025-05-29 22:17:01,826 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:17:01,826 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:17:01,826 - INFO - joeynmt.training - 	Hypothesis: Si poteva andare in battaglia in un bel breve in sala.
2025-05-29 22:17:01,826 - INFO - joeynmt.training - Example #4
2025-05-29 22:17:01,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:17:01,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:17:01,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 's@@', 'otto', 'la', 'pros@@', 'si@@', 'ma', 's@@', 'etti@@', 'man@@', 'a', 'è', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'l@@', '<unk>', 'ulti@@', 'mo', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:17:01,827 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:17:01,827 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:17:01,827 - INFO - joeynmt.training - 	Hypothesis: Il prossimo sotto la prossima settimana è che è successo in cui l<unk> ultimo 25 anni.
2025-05-29 22:17:05,248 - INFO - joeynmt.training - Epoch   4, Step:    42600, Batch Loss:     1.597690, Batch Acc: 0.467613, Tokens per Sec:    18368, Lr: 0.000300
2025-05-29 22:17:08,616 - INFO - joeynmt.training - Epoch   4, Step:    42700, Batch Loss:     1.902297, Batch Acc: 0.458068, Tokens per Sec:    20500, Lr: 0.000300
2025-05-29 22:17:11,979 - INFO - joeynmt.training - Epoch   4, Step:    42800, Batch Loss:     1.646684, Batch Acc: 0.463161, Tokens per Sec:    20961, Lr: 0.000300
2025-05-29 22:17:12,532 - INFO - joeynmt.training - Epoch   4: total training loss 19485.21
2025-05-29 22:17:12,532 - INFO - joeynmt.training - EPOCH 5
2025-05-29 22:17:15,368 - INFO - joeynmt.training - Epoch   5, Step:    42900, Batch Loss:     1.721560, Batch Acc: 0.470215, Tokens per Sec:    20255, Lr: 0.000300
2025-05-29 22:17:18,739 - INFO - joeynmt.training - Epoch   5, Step:    43000, Batch Loss:     1.759262, Batch Acc: 0.469275, Tokens per Sec:    20690, Lr: 0.000300
2025-05-29 22:17:18,739 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:17:18,739 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:17:28,214 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.54, acc:   0.49, generation: 9.4653[sec], evaluation: 0.0000[sec]
2025-05-29 22:17:28,215 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:17:28,739 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/41500.ckpt
2025-05-29 22:17:28,764 - INFO - joeynmt.training - Example #0
2025-05-29 22:17:28,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:17:28,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:17:28,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'par@@', 'ti', 'per', 'con@@', 'v@@', 'in@@', 'cer@@', 'e@@', ',', 'che', 'i', 'gi@@', 'o@@', 'chi', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'chiam@@', 'ano', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'è', 'stato', 'fatto', 'per', 'i', '4@@', '8', 'ore', 'di', '1@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:17:28,765 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:17:28,765 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:17:28,766 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso queste due parti per convincere, che i giochi di ghiaccio, che i chiamano il ghiaccio, che è stato fatto per i 48 ore di 18 stati.
2025-05-29 22:17:28,766 - INFO - joeynmt.training - Example #1
2025-05-29 22:17:28,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:17:28,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:17:28,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'l@@', '<unk>', 'in@@', 'ten@@', 'zione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'e', 'il', 'problema', 'di', 'questo', 'part@@', 'icol@@', 'are', 'il', 'd@@', 'ell@@', '<unk>', 'et@@', 'i@@', 'ch@@', 'ett@@', 'o@@', '.', '</s>']
2025-05-29 22:17:28,766 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:17:28,766 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:17:28,767 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte l<unk> intenzione di questo particolare e il problema di questo particolare il dell<unk> etichetto.
2025-05-29 22:17:28,767 - INFO - joeynmt.training - Example #2
2025-05-29 22:17:28,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:17:28,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:17:28,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'di', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'della', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:17:28,767 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:17:28,767 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:17:28,767 - INFO - joeynmt.training - 	Hypothesis: In certo senso di l<unk> articolo è l<unk> articolo della cuore del nostro climatico globale.
2025-05-29 22:17:28,768 - INFO - joeynmt.training - Example #3
2025-05-29 22:17:28,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:17:28,768 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:17:28,768 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'rebbe', 'ri@@', 'd@@', 'are', 'in', 'v@@', 'in@@', 'a@@', ',', 'e', 'si', 'ri@@', 'fer@@', 'is@@', 'ce', 'a', 's@@', 'om@@', 'mer@@', 'gi@@', '.', '</s>']
2025-05-29 22:17:28,768 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:17:28,768 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:17:28,768 - INFO - joeynmt.training - 	Hypothesis: Si potrebbe ridare in vina, e si riferisce a sommergi.
2025-05-29 22:17:28,768 - INFO - joeynmt.training - Example #4
2025-05-29 22:17:28,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:17:28,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:17:28,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 's@@', 'ec@@', 'ol@@', 'o@@', ',', 'la', 'pros@@', 'si@@', 'ma', 's@@', 'm@@', 'ett@@', 'end@@', 'o@@', ',', 'una', 'delle', 'cose', 'che', 'acc@@', 'ad@@', 'de', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:17:28,769 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:17:28,769 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:17:28,769 - INFO - joeynmt.training - 	Hypothesis: Il prossimo secolo, la prossima smettendo, una delle cose che accadde negli ultimi 25 anni.
2025-05-29 22:17:32,161 - INFO - joeynmt.training - Epoch   5, Step:    43100, Batch Loss:     1.771927, Batch Acc: 0.472145, Tokens per Sec:    17734, Lr: 0.000300
2025-05-29 22:17:35,543 - INFO - joeynmt.training - Epoch   5, Step:    43200, Batch Loss:     1.715717, Batch Acc: 0.470373, Tokens per Sec:    20723, Lr: 0.000300
2025-05-29 22:17:38,915 - INFO - joeynmt.training - Epoch   5, Step:    43300, Batch Loss:     1.815951, Batch Acc: 0.467894, Tokens per Sec:    20861, Lr: 0.000300
2025-05-29 22:17:42,277 - INFO - joeynmt.training - Epoch   5, Step:    43400, Batch Loss:     1.766023, Batch Acc: 0.472076, Tokens per Sec:    20666, Lr: 0.000300
2025-05-29 22:17:45,648 - INFO - joeynmt.training - Epoch   5, Step:    43500, Batch Loss:     1.812667, Batch Acc: 0.468262, Tokens per Sec:    20878, Lr: 0.000300
2025-05-29 22:17:45,649 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:17:45,649 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:17:54,502 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.58, acc:   0.49, generation: 8.8412[sec], evaluation: 0.0000[sec]
2025-05-29 22:17:54,892 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/40500.ckpt
2025-05-29 22:17:54,918 - INFO - joeynmt.training - Example #0
2025-05-29 22:17:54,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:17:54,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:17:54,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 'cui', 'ho', 'mostr@@', 'ato', 'per', 'f@@', 'ar', 's@@', 'ì', 'che', 'la', 'po@@', 'ver@@', 'a', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'le', 'persone', 'che', 'hanno', 'chiam@@', 'ato', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', '4@@', '8@@', ',', 'per', 'un', 'pa@@', 'io', 'di', 'anni', 'di', 'ri@@', 'fl@@', 'et@@', 'tere', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'al@@', 'to', 'per', 'c@@', 'ento', 'di', 'ri@@', 'chi@@', 'ede', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'al@@', 'to', 'per', 'c@@', 'ento', 'di', 'al@@', 'to', 'e', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'fl@@', 'et@@', 'tere', 'a', 'un', 'po@@', '<unk>', 'di', 's@@', 'ec@@', 'ol@@', 'o@@', '.', '</s>']
2025-05-29 22:17:54,919 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:17:54,919 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:17:54,919 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due dimensioni per cui ho mostrato per far sì che la povera artica, che le persone che hanno chiamato il ghiaccio, il 48, per un paio di anni di riflettere il 40 per cento di alto per cento di richiede il 40 per cento di alto per cento di alto e il 40 per cento di riflettere a un po<unk> di secolo.
2025-05-29 22:17:54,919 - INFO - joeynmt.training - Example #1
2025-05-29 22:17:54,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:17:54,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:17:54,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'importante', 'è', 'che', 'la', 'cosa', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'ver@@', 'a', 'd@@', 'ell@@', '<unk>', 'ag@@', 'ric@@', 'ol@@', 't@@', 'ur@@', 'a@@', '.', '</s>']
2025-05-29 22:17:54,920 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:17:54,920 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:17:54,920 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più importante è che la cosa speciale di questo problema, perché non c<unk> è la vera dell<unk> agricoltura.
2025-05-29 22:17:54,920 - INFO - joeynmt.training - Example #2
2025-05-29 22:17:54,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:17:54,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:17:54,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 's@@', 'itu@@', 'azione', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:17:54,921 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:17:54,921 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:17:54,921 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la situazione artica, il sistema climatico globale del nostro climassa del nostro sistema climatico.
2025-05-29 22:17:54,921 - INFO - joeynmt.training - Example #3
2025-05-29 22:17:54,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:17:54,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:17:54,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:17:54,922 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:17:54,922 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:17:54,922 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, in un certo senso.
2025-05-29 22:17:54,922 - INFO - joeynmt.training - Example #4
2025-05-29 22:17:54,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:17:54,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:17:54,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 's@@', 'b@@', 'ag@@', 'li@@', 'at@@', 'o@@', ',', 'è', 'succ@@', 'esso', 'un', 'con@@', 'si@@', 'gli@@', 'o', 'di', 'quello', 'che', 'succ@@', 'ede', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', '<unk>', '7@@', '0@@', '.', '</s>']
2025-05-29 22:17:54,923 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:17:54,923 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:17:54,923 - INFO - joeynmt.training - 	Hypothesis: Il prossimo sbagliato, è successo un consiglio di quello che succede negli ultimi 25 anni <unk> 70.
2025-05-29 22:17:58,337 - INFO - joeynmt.training - Epoch   5, Step:    43600, Batch Loss:     1.695509, Batch Acc: 0.466966, Tokens per Sec:    18778, Lr: 0.000300
2025-05-29 22:18:01,723 - INFO - joeynmt.training - Epoch   5, Step:    43700, Batch Loss:     1.727073, Batch Acc: 0.469715, Tokens per Sec:    21309, Lr: 0.000300
2025-05-29 22:18:05,095 - INFO - joeynmt.training - Epoch   5, Step:    43800, Batch Loss:     1.738711, Batch Acc: 0.466905, Tokens per Sec:    21279, Lr: 0.000300
2025-05-29 22:18:08,465 - INFO - joeynmt.training - Epoch   5, Step:    43900, Batch Loss:     1.833407, Batch Acc: 0.468476, Tokens per Sec:    21200, Lr: 0.000300
2025-05-29 22:18:11,838 - INFO - joeynmt.training - Epoch   5, Step:    44000, Batch Loss:     1.707537, Batch Acc: 0.470235, Tokens per Sec:    21827, Lr: 0.000300
2025-05-29 22:18:11,838 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:18:11,839 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:18:21,259 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.54, acc:   0.49, generation: 9.4083[sec], evaluation: 0.0000[sec]
2025-05-29 22:18:21,260 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:18:21,939 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/41000.ckpt
2025-05-29 22:18:21,957 - INFO - joeynmt.training - Example #0
2025-05-29 22:18:21,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:18:21,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:18:21,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'sp@@', 'on@@', 'i@@', 'bili', 'per', 's@@', 'fr@@', 'utt@@', 'are', 'che', 'la', 'storia', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'la', 'gente', 'che', 'ha', 'in@@', 'segn@@', 'ato', 'per', 'i', 'ter@@', 'ri@@', 'bi@@', 'li@@', ',', 'che', 'è', 'stato', 'il', '4@@', '8@@', '%', 'di', 'con@@', 'si@@', 'der@@', 'are', 'il', '4@@', '8@@', '%', 'di', 's@@', 'otto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:18:21,958 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:18:21,958 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:18:21,958 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno che ho mostrato queste due disponibili per sfruttare che la storia artica, che la gente che ha insegnato per i terribili, che è stato il 48% di considerare il 48% di sotto per il 40 per cento di anni.
2025-05-29 22:18:21,958 - INFO - joeynmt.training - Example #1
2025-05-29 22:18:21,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:18:21,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:18:21,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:18:21,959 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:18:21,959 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:18:21,959 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la risposta di questo problema, e non c<unk> è il Dicke del ghiaccio.
2025-05-29 22:18:21,959 - INFO - joeynmt.training - Example #2
2025-05-29 22:18:21,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:18:21,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:18:21,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 'c@@', 'aus@@', 'a', 'della', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'c@@', 'li@@', 'mat@@', 'ica', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:18:21,960 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:18:21,960 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:18:21,960 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la causa della popolazione di climatica del nostro climassa globale.
2025-05-29 22:18:21,960 - INFO - joeynmt.training - Example #3
2025-05-29 22:18:21,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:18:21,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:18:21,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:18:21,960 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:18:21,960 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:18:21,961 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, in un certo senso.
2025-05-29 22:18:21,961 - INFO - joeynmt.training - Example #4
2025-05-29 22:18:21,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:18:21,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:18:21,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'qu@@', 'ad@@', 'ra', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'cer@@', 'to', 'che', 'è', 'succ@@', 'esso', 'nel', 'qu@@', 'ale', 'è', 'succ@@', 'ess@@', 'o@@', '.', '</s>']
2025-05-29 22:18:21,961 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:18:21,961 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:18:21,961 - INFO - joeynmt.training - 	Hypothesis: La prossima squadra che vi mostrerò è un disegno di un certo che è successo nel quale è successo.
2025-05-29 22:18:25,351 - INFO - joeynmt.training - Epoch   5, Step:    44100, Batch Loss:     1.826863, Batch Acc: 0.468108, Tokens per Sec:    17205, Lr: 0.000300
2025-05-29 22:18:28,737 - INFO - joeynmt.training - Epoch   5, Step:    44200, Batch Loss:     1.906262, Batch Acc: 0.468291, Tokens per Sec:    21411, Lr: 0.000300
2025-05-29 22:18:32,097 - INFO - joeynmt.training - Epoch   5, Step:    44300, Batch Loss:     1.722234, Batch Acc: 0.469465, Tokens per Sec:    20826, Lr: 0.000300
2025-05-29 22:18:35,470 - INFO - joeynmt.training - Epoch   5, Step:    44400, Batch Loss:     1.701436, Batch Acc: 0.473716, Tokens per Sec:    21515, Lr: 0.000300
2025-05-29 22:18:38,835 - INFO - joeynmt.training - Epoch   5, Step:    44500, Batch Loss:     1.741498, Batch Acc: 0.465523, Tokens per Sec:    21098, Lr: 0.000300
2025-05-29 22:18:38,836 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:18:38,836 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:18:48,665 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.55, acc:   0.49, generation: 9.8173[sec], evaluation: 0.0000[sec]
2025-05-29 22:18:49,009 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/43500.ckpt
2025-05-29 22:18:49,027 - INFO - joeynmt.training - Example #0
2025-05-29 22:18:49,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:18:49,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:18:49,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 'cui', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'i', 'm@@', 'ett@@', 'ono', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'ha', 'in@@', 'segn@@', 'ato', 'per', 'il', '4@@', '8', 'st@@', 'at@@', 'o@@', ',', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'circa', 'il', '4@@', '8', 'ore', 'di', '4@@', '8', 'st@@', 'at@@', 'un@@', 'it@@', 'en@@', 'i@@', '.', '</s>']
2025-05-29 22:18:49,028 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:18:49,028 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:18:49,028 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due dimensioni per cui ho mostrato queste due dimensioni artici, che i mettono di ghiaccia, che ha insegnato per il 48 stato, il 48 per cento di circa il 48 ore di 48 statuniteni.
2025-05-29 22:18:49,028 - INFO - joeynmt.training - Example #1
2025-05-29 22:18:49,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:18:49,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:18:49,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'con@@', 'fer@@', 'enza', 'di', 'questo', 'problema', 'è', 'il', 'problema', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'è', 'che', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'n@@', 'ell@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'a', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'v@@', 'eg@@', 'li@@', 'o@@', ',', 'e', 'che', 'è', 'stata', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'è', 'che', 'è', 'stata', 'la', 'stessa', 'cos@@', 'a@@', '.', '</s>']
2025-05-29 22:18:49,029 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:18:49,029 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:18:49,029 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la conferenza di questo problema è il problema di questo speciale speciale di questo speciale è che mostra il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di un ghiaccio di nell<unk> industria del ghiaccio di un sacco di sveglio, e che è stata una cosa che è successo è che è stata la stessa cosa.
2025-05-29 22:18:49,029 - INFO - joeynmt.training - Example #2
2025-05-29 22:18:49,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:18:49,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:18:49,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'la', 's@@', 'itu@@', 'azione', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:18:49,030 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:18:49,030 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:18:49,030 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, la situazione artica, il sistema climatico globale.
2025-05-29 22:18:49,030 - INFO - joeynmt.training - Example #3
2025-05-29 22:18:49,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:18:49,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:18:49,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:18:49,030 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:18:49,030 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:18:49,030 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, e in un certo senso.
2025-05-29 22:18:49,031 - INFO - joeynmt.training - Example #4
2025-05-29 22:18:49,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:18:49,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:18:49,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'con@@', 'si@@', 'gli@@', 'o', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:18:49,031 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:18:49,031 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:18:49,031 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un consiglio di quello che è successo negli ultimi 25 anni.
2025-05-29 22:18:52,354 - INFO - joeynmt.training - Epoch   5, Step:    44600, Batch Loss:     1.638821, Batch Acc: 0.466797, Tokens per Sec:    19428, Lr: 0.000300
2025-05-29 22:18:55,734 - INFO - joeynmt.training - Epoch   5, Step:    44700, Batch Loss:     1.805738, Batch Acc: 0.471236, Tokens per Sec:    20766, Lr: 0.000300
2025-05-29 22:18:59,123 - INFO - joeynmt.training - Epoch   5, Step:    44800, Batch Loss:     1.853398, Batch Acc: 0.472557, Tokens per Sec:    21048, Lr: 0.000300
2025-05-29 22:19:02,495 - INFO - joeynmt.training - Epoch   5, Step:    44900, Batch Loss:     1.802330, Batch Acc: 0.464235, Tokens per Sec:    20883, Lr: 0.000300
2025-05-29 22:19:05,874 - INFO - joeynmt.training - Epoch   5, Step:    45000, Batch Loss:     1.642936, Batch Acc: 0.473113, Tokens per Sec:    21246, Lr: 0.000300
2025-05-29 22:19:05,874 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:19:05,874 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:19:15,470 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.53, acc:   0.49, generation: 9.5833[sec], evaluation: 0.0000[sec]
2025-05-29 22:19:15,470 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:19:16,054 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/42500.ckpt
2025-05-29 22:19:16,082 - INFO - joeynmt.training - Example #0
2025-05-29 22:19:16,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:19:16,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:19:16,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'anni', 'per', 's@@', 'fr@@', 'utt@@', 'are', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ono', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'are', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'are', 'per', 'il', '4@@', '8', 'ore', 'di', 'circa', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:19:16,083 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:19:16,083 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:19:16,083 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questi due anni per sfruttare che le ghiacciono le ghiacciare le ghiacciare per il 48 ore di circa tre milioni di anni di anni di 48 stati.
2025-05-29 22:19:16,083 - INFO - joeynmt.training - Example #1
2025-05-29 22:19:16,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:19:16,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:19:16,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'mor@@', 'to', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'p@@', 'op@@', 'ol@@', 'are', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'di@@', 'mostr@@', 'azione', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'd@@', 'ell@@', '<unk>', 'oc@@', 'chi@@', 'o@@', '.', '</s>']
2025-05-29 22:19:16,084 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:19:16,084 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:19:16,084 - INFO - joeynmt.training - 	Hypothesis: Ma non è morto abbastanza forte di popolare questo problema, perché non c<unk> è la dimostrazione del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio dell<unk> occhio.
2025-05-29 22:19:16,084 - INFO - joeynmt.training - Example #2
2025-05-29 22:19:16,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:19:16,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:19:16,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', ',', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'ass@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:19:16,085 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:19:16,085 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:19:16,085 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di climatico, è l<unk> articolo che è il cuore del nostro climassico.
2025-05-29 22:19:16,085 - INFO - joeynmt.training - Example #3
2025-05-29 22:19:16,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:19:16,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:19:16,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'eva', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'e', 'il', 'v@@', 'ento', 'del', 'v@@', 'ento', 'd@@', 'ell@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:19:16,086 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:19:16,086 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:19:16,086 - INFO - joeynmt.training - 	Hypothesis: Si poteva essere in inverno, e si rivela e il vento del vento dell<unk> estate.
2025-05-29 22:19:16,086 - INFO - joeynmt.training - Example #4
2025-05-29 22:19:16,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:19:16,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:19:16,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'li@@', 'vello', 'succ@@', 'essi@@', 'vo', 'è', 'succ@@', 'esso', 'a', 'questo', 'è', 'un', 'c@@', 'entr@@', 'o', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:19:16,087 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:19:16,087 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:19:16,087 - INFO - joeynmt.training - 	Hypothesis: Il prossimo livello successivo è successo a questo è un centro di quello che è successo negli ultimi 25 anni.
2025-05-29 22:19:19,501 - INFO - joeynmt.training - Epoch   5, Step:    45100, Batch Loss:     1.710731, Batch Acc: 0.466996, Tokens per Sec:    18198, Lr: 0.000300
2025-05-29 22:19:22,870 - INFO - joeynmt.training - Epoch   5, Step:    45200, Batch Loss:     1.896156, Batch Acc: 0.473364, Tokens per Sec:    20691, Lr: 0.000300
2025-05-29 22:19:26,241 - INFO - joeynmt.training - Epoch   5, Step:    45300, Batch Loss:     1.726837, Batch Acc: 0.470810, Tokens per Sec:    21483, Lr: 0.000300
2025-05-29 22:19:29,624 - INFO - joeynmt.training - Epoch   5, Step:    45400, Batch Loss:     1.629326, Batch Acc: 0.471359, Tokens per Sec:    21157, Lr: 0.000300
2025-05-29 22:19:33,005 - INFO - joeynmt.training - Epoch   5, Step:    45500, Batch Loss:     1.661824, Batch Acc: 0.470408, Tokens per Sec:    21206, Lr: 0.000300
2025-05-29 22:19:33,005 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:19:33,005 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:19:41,803 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.51, acc:   0.49, generation: 8.7884[sec], evaluation: 0.0000[sec]
2025-05-29 22:19:41,803 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:19:42,313 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/42000.ckpt
2025-05-29 22:19:42,336 - INFO - joeynmt.training - Example #0
2025-05-29 22:19:42,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:19:42,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:19:42,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'en@@', 'z@@', 'a@@', ',', 'che', 'gli', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'gli', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'per', '4@@', '8', 'st@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:19:42,337 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:19:42,337 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:19:42,337 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due diapositive per conseguenza, che gli ghiaccio, che gli ghiaccio, che i ghiacciano per tre milioni di anni di persone che hanno insegnato per 48 stato.
2025-05-29 22:19:42,337 - INFO - joeynmt.training - Example #1
2025-05-29 22:19:42,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:19:42,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:19:42,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'non', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:19:42,338 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:19:42,338 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:19:42,338 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte non abbastanza forte di questo problema, perché non è la Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 22:19:42,338 - INFO - joeynmt.training - Example #2
2025-05-29 22:19:42,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:19:42,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:19:42,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'un', 'gr@@', 'an', 'm@@', 'ass@@', 'a@@', '.', '</s>']
2025-05-29 22:19:42,338 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:19:42,338 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:19:42,339 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, il cuore di un gran massa.
2025-05-29 22:19:42,339 - INFO - joeynmt.training - Example #3
2025-05-29 22:19:42,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:19:42,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:19:42,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:19:42,339 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:19:42,339 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:19:42,339 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, in un certo senso.
2025-05-29 22:19:42,339 - INFO - joeynmt.training - Example #4
2025-05-29 22:19:42,340 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:19:42,340 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:19:42,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'v@@', 'a@@', ',', 'è', 'una', 'con@@', 'segu@@', 'enza', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:19:42,340 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:19:42,340 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:19:42,340 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva, è una conseguenza di un certo senso di quello che è successo negli ultimi 25 anni.
2025-05-29 22:19:45,664 - INFO - joeynmt.training - Epoch   5, Step:    45600, Batch Loss:     1.786716, Batch Acc: 0.465114, Tokens per Sec:    17979, Lr: 0.000300
2025-05-29 22:19:48,935 - INFO - joeynmt.training - Epoch   5, Step:    45700, Batch Loss:     1.785183, Batch Acc: 0.470387, Tokens per Sec:    21757, Lr: 0.000300
2025-05-29 22:19:52,209 - INFO - joeynmt.training - Epoch   5, Step:    45800, Batch Loss:     1.956029, Batch Acc: 0.471567, Tokens per Sec:    21597, Lr: 0.000300
2025-05-29 22:19:55,540 - INFO - joeynmt.training - Epoch   5, Step:    45900, Batch Loss:     1.628240, Batch Acc: 0.463857, Tokens per Sec:    21168, Lr: 0.000300
2025-05-29 22:19:58,833 - INFO - joeynmt.training - Epoch   5, Step:    46000, Batch Loss:     1.847362, Batch Acc: 0.476114, Tokens per Sec:    21634, Lr: 0.000300
2025-05-29 22:19:58,833 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:19:58,834 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:20:06,054 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.47, acc:   0.49, generation: 7.2137[sec], evaluation: 0.0000[sec]
2025-05-29 22:20:06,055 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:20:06,525 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/44500.ckpt
2025-05-29 22:20:06,549 - INFO - joeynmt.training - Example #0
2025-05-29 22:20:06,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:20:06,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:20:06,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'ec@@', 'ol@@', 'i', 'per', 'ri@@', 'fer@@', 'im@@', 'ent@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'm@@', 'ezz@@', 'o', 'di', 'anni', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:20:06,550 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:20:06,550 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:20:06,551 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due secoli per riferimento, che l<unk> artica, che l<unk> artica, che la popolazione di tre milioni di anni di anni di mezzo di anni di 48 stati.
2025-05-29 22:20:06,551 - INFO - joeynmt.training - Example #1
2025-05-29 22:20:06,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:20:06,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:20:06,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'di', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'es@@', 'ist@@', 'ent@@', 'e@@', '.', '</s>']
2025-05-29 22:20:06,551 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:20:06,552 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:20:06,552 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte, la risposta di questo speciale di problema, perché non c<unk> è il dell<unk> isesistente.
2025-05-29 22:20:06,552 - INFO - joeynmt.training - Example #2
2025-05-29 22:20:06,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:20:06,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:20:06,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'ale', 'ar@@', 't@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:20:06,552 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:20:06,552 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:20:06,552 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> originale artico.
2025-05-29 22:20:06,553 - INFO - joeynmt.training - Example #3
2025-05-29 22:20:06,553 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:20:06,553 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:20:06,553 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ens@@', 'ate', 'al', 'v@@', 'ento', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:20:06,553 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:20:06,553 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:20:06,553 - INFO - joeynmt.training - 	Hypothesis: Pensate al vento e in un certo senso.
2025-05-29 22:20:06,553 - INFO - joeynmt.training - Example #4
2025-05-29 22:20:06,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:20:06,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:20:06,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 's@@', 'otto', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'c@@', 'at@@', 'en@@', 'a', 'di', 'un', 'cer@@', 'to', 'punto', 'di', 'vi@@', 'sta', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:20:06,554 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:20:06,554 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:20:06,554 - INFO - joeynmt.training - 	Hypothesis: Il prossimo sotto che vi mostrerò è una catena di un certo punto di vista che è successo negli ultimi 25 anni.
2025-05-29 22:20:09,839 - INFO - joeynmt.training - Epoch   5, Step:    46100, Batch Loss:     1.664214, Batch Acc: 0.470079, Tokens per Sec:    18561, Lr: 0.000300
2025-05-29 22:20:13,132 - INFO - joeynmt.training - Epoch   5, Step:    46200, Batch Loss:     1.885916, Batch Acc: 0.471333, Tokens per Sec:    21987, Lr: 0.000300
2025-05-29 22:20:16,390 - INFO - joeynmt.training - Epoch   5, Step:    46300, Batch Loss:     1.694277, Batch Acc: 0.468700, Tokens per Sec:    21823, Lr: 0.000300
2025-05-29 22:20:19,636 - INFO - joeynmt.training - Epoch   5, Step:    46400, Batch Loss:     1.819435, Batch Acc: 0.472123, Tokens per Sec:    22430, Lr: 0.000300
2025-05-29 22:20:22,954 - INFO - joeynmt.training - Epoch   5, Step:    46500, Batch Loss:     1.786987, Batch Acc: 0.473963, Tokens per Sec:    21662, Lr: 0.000300
2025-05-29 22:20:22,954 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:20:22,954 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:20:31,263 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.48, acc:   0.50, generation: 8.2977[sec], evaluation: 0.0000[sec]
2025-05-29 22:20:31,813 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/43000.ckpt
2025-05-29 22:20:31,838 - INFO - joeynmt.training - Example #0
2025-05-29 22:20:31,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:20:31,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:20:31,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 'vi', 'per', 'di@@', 're@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'ar@@', 't@@', 'ico', 'che', 'per', 'le', 'm@@', 'ie', 'ar@@', 't@@', 'ico', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8@@', '0@@', '%', 'di', 'più', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:20:31,840 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:20:31,840 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:20:31,840 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositivi per dire, che la ghiaccio che l<unk> artico artico che per le mie artico per tre milioni di anni di anni di 480% di più di 48 stati.
2025-05-29 22:20:31,840 - INFO - joeynmt.training - Example #1
2025-05-29 22:20:31,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:20:31,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:20:31,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'ol@@', 'o@@', '.', '</s>']
2025-05-29 22:20:31,841 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:20:31,841 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:20:31,841 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo problema, perché non è abbastanza di questo problema, perché non è il dell<unk> isolo.
2025-05-29 22:20:31,841 - INFO - joeynmt.training - Example #2
2025-05-29 22:20:31,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:20:31,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:20:31,841 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'd@@', 'ell@@', '<unk>', 'is@@', 'c@@', 'a@@', ',', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:20:31,841 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:20:31,841 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:20:31,841 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa dell<unk> isca, la cucina del nostro climatico globale.
2025-05-29 22:20:31,842 - INFO - joeynmt.training - Example #3
2025-05-29 22:20:31,842 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:20:31,842 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:20:31,842 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'em@@', 'br@@', 'a', 'che', 'si', 'può', 'essere', 'in', 'gra@@', 'do', 'di', 'far@@', 'l@@', 'o@@', '.', '</s>']
2025-05-29 22:20:31,842 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:20:31,842 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:20:31,842 - INFO - joeynmt.training - 	Hypothesis: Sembra che si può essere in grado di farlo.
2025-05-29 22:20:31,842 - INFO - joeynmt.training - Example #4
2025-05-29 22:20:31,843 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:20:31,843 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:20:31,843 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'apos@@', 'iti@@', 'vo', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'c@@', 'at@@', 'eg@@', 'ia', 'di', 'un', 'c@@', 'ic@@', 'lo', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:20:31,843 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:20:31,843 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:20:31,843 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostro è una categia di un ciclo di quello che è successo negli ultimi 25 anni.
2025-05-29 22:20:35,226 - INFO - joeynmt.training - Epoch   5, Step:    46600, Batch Loss:     1.950922, Batch Acc: 0.472056, Tokens per Sec:    17373, Lr: 0.000300
2025-05-29 22:20:38,603 - INFO - joeynmt.training - Epoch   5, Step:    46700, Batch Loss:     1.746890, Batch Acc: 0.469313, Tokens per Sec:    21188, Lr: 0.000300
2025-05-29 22:20:41,966 - INFO - joeynmt.training - Epoch   5, Step:    46800, Batch Loss:     1.708310, Batch Acc: 0.467471, Tokens per Sec:    21386, Lr: 0.000300
2025-05-29 22:20:45,326 - INFO - joeynmt.training - Epoch   5, Step:    46900, Batch Loss:     1.664325, Batch Acc: 0.474968, Tokens per Sec:    20939, Lr: 0.000300
2025-05-29 22:20:48,688 - INFO - joeynmt.training - Epoch   5, Step:    47000, Batch Loss:     1.632650, Batch Acc: 0.472866, Tokens per Sec:    21529, Lr: 0.000300
2025-05-29 22:20:48,688 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:20:48,689 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:20:56,541 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.48, acc:   0.49, generation: 7.8383[sec], evaluation: 0.0000[sec]
2025-05-29 22:20:56,943 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/44000.ckpt
2025-05-29 22:20:56,958 - INFO - joeynmt.training - Example #0
2025-05-29 22:20:56,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:20:56,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:20:56,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 's@@', 'é', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', ',', 'che', 'l@@', '<unk>', 'anno', 'per', 'le', 'b@@', 'arri@@', 'ere', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'i', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:20:56,962 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:20:56,962 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:20:56,962 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questi due dimensioni per sé che l<unk> anno scorso, che l<unk> anno per le barriere di ghiaccia, i tre milioni di anni di anni di 48 stati.
2025-05-29 22:20:56,963 - INFO - joeynmt.training - Example #1
2025-05-29 22:20:56,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:20:56,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:20:56,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'ti', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'd@@', 'ell@@', '<unk>', 'in@@', 'tr@@', 'o@@', 'du@@', 'c@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:20:56,963 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:20:56,963 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:20:56,963 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forti di questo problema, e non è abbastanza speciale, perché non è il Dicke è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio dell<unk> introducato.
2025-05-29 22:20:56,963 - INFO - joeynmt.training - Example #2
2025-05-29 22:20:56,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:20:56,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:20:56,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'inter@@', 'a', 'c@@', 'aus@@', 'a', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'sistema', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:20:56,964 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:20:56,964 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:20:56,964 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> intera causa del nostro sistema climatico sistema climatico.
2025-05-29 22:20:56,964 - INFO - joeynmt.training - Example #3
2025-05-29 22:20:56,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:20:56,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:20:56,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'em@@', 'br@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'es@@', 'ce', 'a', 'far@@', 'l@@', 'o@@', '.', '</s>']
2025-05-29 22:20:56,966 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:20:56,966 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:20:56,966 - INFO - joeynmt.training - 	Hypothesis: Sembra in inverno, e si riesce a farlo.
2025-05-29 22:20:56,966 - INFO - joeynmt.training - Example #4
2025-05-29 22:20:56,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:20:56,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:20:56,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'ci@@', 'o@@', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:20:56,967 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:20:56,967 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:20:56,967 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è un disegno di un certo senso di cioè successo negli ultimi 25 anni.
2025-05-29 22:21:00,472 - INFO - joeynmt.training - Epoch   5, Step:    47100, Batch Loss:     1.935050, Batch Acc: 0.473968, Tokens per Sec:    18023, Lr: 0.000300
2025-05-29 22:21:03,826 - INFO - joeynmt.training - Epoch   5, Step:    47200, Batch Loss:     1.806957, Batch Acc: 0.464165, Tokens per Sec:    21223, Lr: 0.000300
2025-05-29 22:21:07,288 - INFO - joeynmt.training - Epoch   5, Step:    47300, Batch Loss:     1.885895, Batch Acc: 0.470143, Tokens per Sec:    20423, Lr: 0.000300
2025-05-29 22:21:10,885 - INFO - joeynmt.training - Epoch   5, Step:    47400, Batch Loss:     1.735800, Batch Acc: 0.472043, Tokens per Sec:    19767, Lr: 0.000300
2025-05-29 22:21:14,492 - INFO - joeynmt.training - Epoch   5, Step:    47500, Batch Loss:     1.712635, Batch Acc: 0.470623, Tokens per Sec:    19704, Lr: 0.000300
2025-05-29 22:21:14,493 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:21:14,493 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:21:23,609 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.50, generation: 9.1085[sec], evaluation: 0.0000[sec]
2025-05-29 22:21:23,610 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:21:24,140 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/45000.ckpt
2025-05-29 22:21:24,164 - INFO - joeynmt.training - Example #0
2025-05-29 22:21:24,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:21:24,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:21:24,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'fr@@', 'ont@@', 'are', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'cio', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'anni', 'che', 'hanno', 'l@@', '<unk>', 'in@@', 'segn@@', 'ante', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', 'p@@', 'es@@', 'o', 'del', '4@@', '0@@', '%', 'dei', 'p@@', 'es@@', 'ci', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'ri@@', 'fl@@', 'et@@', 'tere', 'in', 'cui', 'i', 'nostri', 's@@', 'ett@@', 'ori', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'essere', 'in', 'gra@@', 'do', 'di', 'con@@', 'segu@@', 'enza', 'di', 'un', 'pa@@', 'io', 'di', 'di', 's@@', 'ett@@', 'e@@', '.', '</s>']
2025-05-29 22:21:24,165 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:21:24,165 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:21:24,165 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due diapositive per confrontare che la ghiaccio artico che i ghiaccio per tre milioni di anni di anni di anni che hanno l<unk> insegnante per il 40 per cento di anni per il 40% del 40% del peso del 40% dei pesci sono stati in grado di riflettere in cui i nostri settori sono stati in grado di essere in grado di conseguenza di un paio di di sette.
2025-05-29 22:21:24,165 - INFO - joeynmt.training - Example #1
2025-05-29 22:21:24,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:21:24,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:21:24,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'ti', 'di', 'essere', 'abb@@', 'ast@@', 'anza', 'in', 'questo', 'mo@@', 'd@@', 'o@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'a', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 22:21:24,166 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:21:24,166 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:21:24,166 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forti di essere abbastanza in questo modo, perché non è il dell<unk> industria del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di questo tipo di problema.
2025-05-29 22:21:24,166 - INFO - joeynmt.training - Example #2
2025-05-29 22:21:24,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:21:24,167 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:21:24,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'ar@@', 't@@', 'ico', 'e', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:21:24,167 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:21:24,167 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:21:24,167 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> artico artico e il cuore del nostro climatico globale del nostro climatico globale di climatico.
2025-05-29 22:21:24,167 - INFO - joeynmt.training - Example #3
2025-05-29 22:21:24,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:21:24,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:21:24,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'per', 'la', 's@@', 'itu@@', 'azione', 'e', 'la', 's@@', 'itu@@', 'azione', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'é', 'di', 's@@', 'é', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'é', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'li@@', 'a@@', '.', '</s>']
2025-05-29 22:21:24,168 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:21:24,168 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:21:24,168 - INFO - joeynmt.training - 	Hypothesis: Sta per la situazione e la situazione in un sacco di sé di sé di un sacco di sé e la sua famiglia e la sua famiglia e la sua famiglia.
2025-05-29 22:21:24,168 - INFO - joeynmt.training - Example #4
2025-05-29 22:21:24,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:21:24,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:21:24,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'li@@', 'vello', 'di', 'mostr@@', 'ar@@', 'vi', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'cosa', 'è', 'succ@@', 'esso', 'in', 'ci@@', 'ma', 'a', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:21:24,169 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:21:24,169 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:21:24,169 - INFO - joeynmt.training - 	Hypothesis: Il prossimo livello di mostrarvi è una dimostrazione di cosa è successo in cima a quello che è successo negli ultimi 25 anni.
2025-05-29 22:21:27,242 - INFO - joeynmt.training - Epoch   5, Step:    47600, Batch Loss:     1.794222, Batch Acc: 0.470430, Tokens per Sec:    19665, Lr: 0.000300
2025-05-29 22:21:30,550 - INFO - joeynmt.training - Epoch   5, Step:    47700, Batch Loss:     1.739435, Batch Acc: 0.467739, Tokens per Sec:    21114, Lr: 0.000300
2025-05-29 22:21:33,872 - INFO - joeynmt.training - Epoch   5, Step:    47800, Batch Loss:     1.793231, Batch Acc: 0.468804, Tokens per Sec:    22009, Lr: 0.000300
2025-05-29 22:21:37,172 - INFO - joeynmt.training - Epoch   5, Step:    47900, Batch Loss:     1.683108, Batch Acc: 0.468138, Tokens per Sec:    21509, Lr: 0.000300
2025-05-29 22:21:40,449 - INFO - joeynmt.training - Epoch   5, Step:    48000, Batch Loss:     1.739366, Batch Acc: 0.470979, Tokens per Sec:    21390, Lr: 0.000300
2025-05-29 22:21:40,450 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:21:40,450 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:21:48,644 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.50, generation: 8.1818[sec], evaluation: 0.0000[sec]
2025-05-29 22:21:48,644 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:21:49,128 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/45500.ckpt
2025-05-29 22:21:49,152 - INFO - joeynmt.training - Example #0
2025-05-29 22:21:49,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:21:49,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:21:49,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 'con@@', 'segu@@', 'en@@', 'z@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'l@@', '<unk>', 'in@@', 'segn@@', 'amento', 'del', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'di', 'persone', 'che', 'ha', 'fatto', 'il', '4@@', '0@@', '%', 'di', 'questo', 'è', 'stato', 'f@@', 'att@@', 'o@@', '.', '</s>']
2025-05-29 22:21:49,153 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:21:49,153 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:21:49,153 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato questi due dimensioni per conseguenza, che l<unk> articolo che l<unk> articolo che ha avuto per tre milioni di anni di anni di persone che hanno l<unk> insegnamento del 40 per cento di anni per il 40% di persone che ha fatto il 40% di questo è stato fatto.
2025-05-29 22:21:49,153 - INFO - joeynmt.training - Example #1
2025-05-29 22:21:49,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:21:49,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:21:49,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ris@@', 'post@@', 'a', 'in', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'ol@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'ol@@', 'o@@', '.', '</s>']
2025-05-29 22:21:49,154 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:21:49,154 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:21:49,154 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la risposta in questo problema, perché non c<unk> è il dell<unk> isola, perché non c<unk> è il dell<unk> isolo.
2025-05-29 22:21:49,154 - INFO - joeynmt.training - Example #2
2025-05-29 22:21:49,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:21:49,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:21:49,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'l@@', '<unk>', 'em@@', 'is@@', 'c@@', 'e@@', ',', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:21:49,154 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:21:49,154 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:21:49,154 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di l<unk> emisce, la cucina del nostro climatico globale del nostro sistema climatico globale.
2025-05-29 22:21:49,155 - INFO - joeynmt.training - Example #3
2025-05-29 22:21:49,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:21:49,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:21:49,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'oi', 'si', 'ri@@', 'vel@@', 'a', 'e', 'ri@@', 'man@@', 'ere', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:21:49,155 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:21:49,155 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:21:49,155 - INFO - joeynmt.training - 	Hypothesis: Poi si rivela e rimanere in un certo senso.
2025-05-29 22:21:49,155 - INFO - joeynmt.training - Example #4
2025-05-29 22:21:49,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:21:49,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:21:49,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'è', 'succ@@', 'esso', 'in', 'gra@@', 'do', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:21:49,156 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:21:49,156 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:21:49,156 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una diapositiva che è successo in grado di quello che è successo negli ultimi 25 anni.
2025-05-29 22:21:52,402 - INFO - joeynmt.training - Epoch   5, Step:    48100, Batch Loss:     1.615616, Batch Acc: 0.469933, Tokens per Sec:    18698, Lr: 0.000300
2025-05-29 22:21:55,692 - INFO - joeynmt.training - Epoch   5, Step:    48200, Batch Loss:     1.757040, Batch Acc: 0.474318, Tokens per Sec:    21097, Lr: 0.000300
2025-05-29 22:21:58,984 - INFO - joeynmt.training - Epoch   5, Step:    48300, Batch Loss:     1.874339, Batch Acc: 0.465244, Tokens per Sec:    21278, Lr: 0.000300
2025-05-29 22:22:02,269 - INFO - joeynmt.training - Epoch   5, Step:    48400, Batch Loss:     1.648169, Batch Acc: 0.470989, Tokens per Sec:    21877, Lr: 0.000300
2025-05-29 22:22:05,545 - INFO - joeynmt.training - Epoch   5, Step:    48500, Batch Loss:     1.810992, Batch Acc: 0.468387, Tokens per Sec:    21221, Lr: 0.000300
2025-05-29 22:22:05,546 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:22:05,546 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:22:14,477 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.42, acc:   0.50, generation: 8.9191[sec], evaluation: 0.0000[sec]
2025-05-29 22:22:14,478 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:22:14,998 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/47000.ckpt
2025-05-29 22:22:15,018 - INFO - joeynmt.training - Example #0
2025-05-29 22:22:15,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:22:15,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:22:15,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'questi', 'due', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 'cui', 'ho', 'mostr@@', 'ato', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'in@@', 'segn@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'l@@', '<unk>', '4@@', '8', 'st@@', 'azioni', 'di', '4@@', '8', 'st@@', 'azioni', 'di', 'circa', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'è', 'stato', 'acc@@', 'ad@@', 'ut@@', 'o@@', '.', '</s>']
2025-05-29 22:22:15,019 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:22:15,019 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:22:15,019 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno questi due due dimensioni per cui ho mostrato che l<unk> articolo artico, che l<unk> articolo che ha insegnato per tre milioni di anni di persone che hanno l<unk> 48 stazioni di 48 stazioni di circa il 40 per cento è stato accaduto.
2025-05-29 22:22:15,019 - INFO - joeynmt.training - Example #1
2025-05-29 22:22:15,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:22:15,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:22:15,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'che', 'non', 'è', 'il', 'd@@', 'ato', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:22:15,020 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:22:15,020 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:22:15,020 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo problema, che non è il dato di questo problema, perché non c<unk> è il dell<unk> origine del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 22:22:15,020 - INFO - joeynmt.training - Example #2
2025-05-29 22:22:15,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:22:15,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:22:15,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:22:15,021 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:22:15,021 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:22:15,021 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio artico, il ghiaccio globale.
2025-05-29 22:22:15,021 - INFO - joeynmt.training - Example #3
2025-05-29 22:22:15,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:22:15,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:22:15,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'rebbe', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'in', 'un', 'f@@', 'en@@', 'om@@', 'en@@', 'o', 'in', 'un', 'f@@', 'en@@', 'om@@', 'en@@', 'o@@', '.', '</s>']
2025-05-29 22:22:15,022 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:22:15,022 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:22:15,022 - INFO - joeynmt.training - 	Hypothesis: Si potrebbe essere in inverno, e in un fenomeno in un fenomeno.
2025-05-29 22:22:15,022 - INFO - joeynmt.training - Example #4
2025-05-29 22:22:15,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:22:15,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:22:15,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'con@@', 'segu@@', 'enza', 'succ@@', 'essi@@', 'va', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'con@@', 'su@@', 'mo', 'di', 'di@@', 're@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:22:15,023 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:22:15,023 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:22:15,023 - INFO - joeynmt.training - 	Hypothesis: La prossima conseguenza successiva è una dimensione di un disegno di un consumo di dire, che è successo negli ultimi 25 anni.
2025-05-29 22:22:18,330 - INFO - joeynmt.training - Epoch   5, Step:    48600, Batch Loss:     1.912047, Batch Acc: 0.472715, Tokens per Sec:    17863, Lr: 0.000300
2025-05-29 22:22:21,614 - INFO - joeynmt.training - Epoch   5, Step:    48700, Batch Loss:     1.721477, Batch Acc: 0.464705, Tokens per Sec:    21184, Lr: 0.000300
2025-05-29 22:22:24,915 - INFO - joeynmt.training - Epoch   5, Step:    48800, Batch Loss:     1.752742, Batch Acc: 0.468323, Tokens per Sec:    21468, Lr: 0.000300
2025-05-29 22:22:28,222 - INFO - joeynmt.training - Epoch   5, Step:    48900, Batch Loss:     1.734392, Batch Acc: 0.464183, Tokens per Sec:    21756, Lr: 0.000300
2025-05-29 22:22:31,513 - INFO - joeynmt.training - Epoch   5, Step:    49000, Batch Loss:     1.727473, Batch Acc: 0.470117, Tokens per Sec:    21415, Lr: 0.000300
2025-05-29 22:22:31,513 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:22:31,513 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:22:40,969 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.43, acc:   0.50, generation: 9.4430[sec], evaluation: 0.0000[sec]
2025-05-29 22:22:41,330 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/46500.ckpt
2025-05-29 22:22:41,357 - INFO - joeynmt.training - Example #0
2025-05-29 22:22:41,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:22:41,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:22:41,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'par@@', 'ti', 'di', 's@@', 'ott@@', 'op@@', 'ost@@', 'o', 'per', 's@@', 'v@@', 'eg@@', 'li@@', 'are', 'che', 'gli', 'oc@@', 'chi', 'e', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'miei', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8@@', ',', 'per', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'circa', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'circa', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:22:41,358 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:22:41,358 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:22:41,358 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due parti di sottoposto per svegliare che gli occhi e i ghiaccio, che i miei tre milioni di anni di anni di anni di 48, per 48 ore per cento di circa 40 per cento di 40 per cento di circa 40 per cento.
2025-05-29 22:22:41,358 - INFO - joeynmt.training - Example #1
2025-05-29 22:22:41,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:22:41,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:22:41,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'che', 'la', 'res@@', 'pon@@', 's@@', 'abil@@', 'ità', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'ar@@', 'i@@', 'a@@', '.', '</s>']
2025-05-29 22:22:41,359 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:22:41,359 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:22:41,359 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte che la responsabilità di questo speciale che non c<unk> è il dell<unk> aria.
2025-05-29 22:22:41,359 - INFO - joeynmt.training - Example #2
2025-05-29 22:22:41,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:22:41,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:22:41,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'ar@@', 't@@', 'ico', 'e', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:22:41,360 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:22:41,360 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:22:41,360 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico artico e il nostro sistema climatico globale.
2025-05-29 22:22:41,360 - INFO - joeynmt.training - Example #3
2025-05-29 22:22:41,360 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:22:41,360 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:22:41,360 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'eva', 'essere', 'in', 'in@@', 'ver@@', 'no', 'nel', 'v@@', 'ento', 'del', 'v@@', 'ento', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:22:41,361 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:22:41,361 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:22:41,361 - INFO - joeynmt.training - 	Hypothesis: Si poteva essere in inverno nel vento del vento e in un certo senso.
2025-05-29 22:22:41,361 - INFO - joeynmt.training - Example #4
2025-05-29 22:22:41,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:22:41,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:22:41,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'con@@', 'segu@@', 'enza', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:22:41,361 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:22:41,361 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:22:41,362 - INFO - joeynmt.training - 	Hypothesis: La prossima conseguenza che vi mostro è una dimensione di un disegno di quello che è successo negli ultimi 25 anni.
2025-05-29 22:22:44,677 - INFO - joeynmt.training - Epoch   5, Step:    49100, Batch Loss:     1.741146, Batch Acc: 0.468725, Tokens per Sec:    18985, Lr: 0.000300
2025-05-29 22:22:47,968 - INFO - joeynmt.training - Epoch   5, Step:    49200, Batch Loss:     1.946169, Batch Acc: 0.471022, Tokens per Sec:    21374, Lr: 0.000300
2025-05-29 22:22:51,270 - INFO - joeynmt.training - Epoch   5, Step:    49300, Batch Loss:     1.746526, Batch Acc: 0.472202, Tokens per Sec:    21899, Lr: 0.000300
2025-05-29 22:22:54,556 - INFO - joeynmt.training - Epoch   5, Step:    49400, Batch Loss:     1.973005, Batch Acc: 0.472248, Tokens per Sec:    21592, Lr: 0.000300
2025-05-29 22:22:57,830 - INFO - joeynmt.training - Epoch   5, Step:    49500, Batch Loss:     1.753806, Batch Acc: 0.462433, Tokens per Sec:    21279, Lr: 0.000300
2025-05-29 22:22:57,830 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:22:57,830 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:23:06,783 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.42, acc:   0.49, generation: 8.9408[sec], evaluation: 0.0000[sec]
2025-05-29 22:23:06,783 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:23:07,307 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/46000.ckpt
2025-05-29 22:23:07,332 - INFO - joeynmt.training - Example #0
2025-05-29 22:23:07,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:23:07,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:23:07,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'con@@', 'segu@@', 'enze', 'per', 'ri@@', 'dur@@', 're', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'ha', 'fatto', 'per', 'il', '4@@', '8', 'st@@', 'ati@@', 'vo', 'per', 'il', '4@@', '8', 'st@@', 'ati@@', 'vo', 'per', 'il', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:23:07,333 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:23:07,333 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:23:07,333 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due conseguenze per ridurre che le ghiaccio, che le ghiaccio che le ghiaccio che ha fatto per il 48 stativo per il 48 stativo per il 48 stati.
2025-05-29 22:23:07,333 - INFO - joeynmt.training - Example #1
2025-05-29 22:23:07,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:23:07,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:23:07,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'una', 'cosa', 'spe@@', 'ci@@', 'ale', 'a', 'questa', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'c@@', '<unk>', 'è', 'la', 'mia', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'c@@', '<unk>', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'la', 'mia', 'v@@', 'it@@', 'a@@', '.', '</s>']
2025-05-29 22:23:07,334 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:23:07,334 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:23:07,334 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di una cosa speciale a questa speciale che non c<unk> è la mia speciale che non c<unk> è la Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio che è la mia vita.
2025-05-29 22:23:07,334 - INFO - joeynmt.training - Example #2
2025-05-29 22:23:07,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:23:07,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:23:07,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'la', 'cu@@', 'c@@', 'ina', 'di', 'c@@', 'li@@', 'mat@@', 'ica', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:23:07,335 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:23:07,335 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:23:07,335 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccio artico, la cucina di climatica globale.
2025-05-29 22:23:07,336 - INFO - joeynmt.training - Example #3
2025-05-29 22:23:07,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:23:07,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:23:07,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'pren@@', 'dere', 'in', 'in@@', 'ver@@', 'no', 'nel', 'mon@@', 'd@@', 'o@@', '.', '</s>']
2025-05-29 22:23:07,336 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:23:07,336 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:23:07,336 - INFO - joeynmt.training - 	Hypothesis: Si può riprendere in inverno nel mondo.
2025-05-29 22:23:07,336 - INFO - joeynmt.training - Example #4
2025-05-29 22:23:07,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:23:07,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:23:07,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'con@@', 'segu@@', 'enza', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'apos@@', 'iti@@', 'va', 'di', 'cosa', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:23:07,337 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:23:07,337 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:23:07,337 - INFO - joeynmt.training - 	Hypothesis: La prossima conseguenza che vi mostro è una diapositiva di cosa è successo in cui è successo negli ultimi 25 anni.
2025-05-29 22:23:10,665 - INFO - joeynmt.training - Epoch   5, Step:    49600, Batch Loss:     1.752595, Batch Acc: 0.463822, Tokens per Sec:    18588, Lr: 0.000300
2025-05-29 22:23:13,966 - INFO - joeynmt.training - Epoch   5, Step:    49700, Batch Loss:     1.843434, Batch Acc: 0.468320, Tokens per Sec:    21565, Lr: 0.000300
2025-05-29 22:23:17,280 - INFO - joeynmt.training - Epoch   5, Step:    49800, Batch Loss:     1.691104, Batch Acc: 0.466668, Tokens per Sec:    21924, Lr: 0.000300
2025-05-29 22:23:20,571 - INFO - joeynmt.training - Epoch   5, Step:    49900, Batch Loss:     1.670522, Batch Acc: 0.466506, Tokens per Sec:    21444, Lr: 0.000300
2025-05-29 22:23:23,887 - INFO - joeynmt.training - Epoch   5, Step:    50000, Batch Loss:     1.874464, Batch Acc: 0.473775, Tokens per Sec:    22225, Lr: 0.000300
2025-05-29 22:23:23,887 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:23:23,887 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:23:31,207 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.50, generation: 7.3118[sec], evaluation: 0.0000[sec]
2025-05-29 22:23:31,207 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:23:31,656 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/47500.ckpt
2025-05-29 22:23:31,673 - INFO - joeynmt.training - Example #0
2025-05-29 22:23:31,673 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:23:31,674 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:23:31,674 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'ri@@', 'fl@@', 'ett@@', 'e@@', ',', 'per', 's@@', 'fr@@', 'utt@@', 'are', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '8@@', '%', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questo', 'è', 'stato', 'f@@', 'att@@', 'o@@', '.', '</s>']
2025-05-29 22:23:31,674 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:23:31,674 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:23:31,674 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di riflette, per sfruttare che la ghiaccia, che i ghiaccio, che ha avuto il 48% di tre milioni di anni di anni che ha avuto il 40 per cento di 40 per cento di 40 per cento di questo è stato fatto.
2025-05-29 22:23:31,674 - INFO - joeynmt.training - Example #1
2025-05-29 22:23:31,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:23:31,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:23:31,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'un', 'problema', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'un', 'po@@', '<unk>', 'di', 's@@', 'é@@', 'li@@', 'te', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'un', 'po@@', '<unk>', 'di', 's@@', 'ott@@', 'o@@', ',', 'e', 'che', 'è', 'stato', 'in@@', 'tr@@', 'o@@', 'd@@', 'otto', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'di']
2025-05-29 22:23:31,675 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:23:31,675 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:23:31,675 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che è un problema di questo speciale problema, perché non c<unk> è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio che è un po<unk> di sélite e la sua famiglia di un pezzo di ghiaccio che è un po<unk> di sotto, e che è stato introdotto la popolazione di un sacco di problema, e non è abbastanza di
2025-05-29 22:23:31,675 - INFO - joeynmt.training - Example #2
2025-05-29 22:23:31,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:23:31,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:23:31,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 's@@', 'fi@@', 'da', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:23:31,676 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:23:31,676 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:23:31,676 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la causa della sfida del nostro climatico globale.
2025-05-29 22:23:31,676 - INFO - joeynmt.training - Example #3
2025-05-29 22:23:31,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:23:31,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:23:31,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'em@@', 'br@@', 'a', 'nel', 'v@@', 'ento', 'della', 'm@@', 'em@@', 'or@@', 'ia', 'nel', 's@@', 'ett@@', 'o@@', '.', '</s>']
2025-05-29 22:23:31,677 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:23:31,677 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:23:31,677 - INFO - joeynmt.training - 	Hypothesis: Sembra nel vento della memoria nel setto.
2025-05-29 22:23:31,677 - INFO - joeynmt.training - Example #4
2025-05-29 22:23:31,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:23:31,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:23:31,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'fr@@', 'utt@@', 'ata', 'che', 'vi', 'ho', 'mostr@@', 'ato', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'cosa', 'è', 'succ@@', 'esso', 'nel', 'cor@@', 'so', 'della', 'sc@@', 'or@@', 'sa', 'cosa', 'succ@@', 'e@@', 'de@@', '.', '</s>']
2025-05-29 22:23:31,678 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:23:31,678 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:23:31,678 - INFO - joeynmt.training - 	Hypothesis: La prossima sfruttata che vi ho mostrato è una dimensione di un disegno di cosa è successo nel corso della scorsa cosa succede.
2025-05-29 22:23:34,984 - INFO - joeynmt.training - Epoch   5, Step:    50100, Batch Loss:     1.785802, Batch Acc: 0.469118, Tokens per Sec:    18673, Lr: 0.000300
2025-05-29 22:23:38,272 - INFO - joeynmt.training - Epoch   5, Step:    50200, Batch Loss:     1.907783, Batch Acc: 0.465561, Tokens per Sec:    20916, Lr: 0.000300
2025-05-29 22:23:41,558 - INFO - joeynmt.training - Epoch   5, Step:    50300, Batch Loss:     1.842001, Batch Acc: 0.460334, Tokens per Sec:    21340, Lr: 0.000300
2025-05-29 22:23:44,847 - INFO - joeynmt.training - Epoch   5, Step:    50400, Batch Loss:     1.847732, Batch Acc: 0.472440, Tokens per Sec:    20743, Lr: 0.000300
2025-05-29 22:23:48,146 - INFO - joeynmt.training - Epoch   5, Step:    50500, Batch Loss:     1.795486, Batch Acc: 0.473672, Tokens per Sec:    22097, Lr: 0.000300
2025-05-29 22:23:48,146 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:23:48,146 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:23:56,524 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.38, acc:   0.50, generation: 8.3660[sec], evaluation: 0.0000[sec]
2025-05-29 22:23:56,525 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:23:57,025 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/48000.ckpt
2025-05-29 22:23:57,046 - INFO - joeynmt.training - Example #0
2025-05-29 22:23:57,047 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:23:57,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:23:57,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questi', 'due', 'di@@', 'mostr@@', 'ano', 'che', 'le', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'v@@', 'in@@', 'zion@@', 'are', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'per', 'il', '4@@', '8', 'st@@', 'ati@@', 'sti@@', 'che', 'per', 'il', '4@@', '8', 'st@@', 'ati', 'per', 'il', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:23:57,048 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:23:57,048 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:23:57,048 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questi due dimostrano che le due diapositive per convinzionare che le ghiacciate che le ghiacciate che per il 48 statistiche per il 48 stati per il 48 stati.
2025-05-29 22:23:57,048 - INFO - joeynmt.training - Example #1
2025-05-29 22:23:57,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:23:57,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:23:57,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'ri@@', 'vol@@', 'u@@', 'zione', 'di', 'questo', 'problema', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'di@@', 'mostr@@', 'azione', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 's@@', 'ott@@', 'o@@', '.', '</s>']
2025-05-29 22:23:57,049 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:23:57,049 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:23:57,049 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato abbastanza forte la rivoluzione di questo problema di questo speciale problema, perché non c<unk> è la dimostrazione del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di un ghiaccio di sotto.
2025-05-29 22:23:57,049 - INFO - joeynmt.training - Example #2
2025-05-29 22:23:57,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:23:57,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:23:57,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:23:57,050 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:23:57,050 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:23:57,050 - INFO - joeynmt.training - 	Hypothesis: In certo senso di ghiaccio artico, il cuore del nostro climatico globale del nostro sistema climatico globale.
2025-05-29 22:23:57,050 - INFO - joeynmt.training - Example #3
2025-05-29 22:23:57,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:23:57,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:23:57,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'nel', 's@@', 'ett@@', 'ore', 'del', 's@@', 'ett@@', 'o@@', '.', '</s>']
2025-05-29 22:23:57,050 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:23:57,050 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:23:57,051 - INFO - joeynmt.training - 	Hypothesis: Si può essere in inverno, e si rivela nel settore del setto.
2025-05-29 22:23:57,051 - INFO - joeynmt.training - Example #4
2025-05-29 22:23:57,051 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:23:57,051 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:23:57,051 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'con@@', 'segu@@', 'enza', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'con@@', 'fer@@', 'enza', 'di', 'di@@', 'mostr@@', 'azione', 'che', 'è', 'succ@@', 'esso', 'in', 'questo', 'mo@@', 'd@@', 'o@@', '.', '</s>']
2025-05-29 22:23:57,051 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:23:57,051 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:23:57,051 - INFO - joeynmt.training - 	Hypothesis: La prossima conseguenza che vi mostro è una conferenza di dimostrazione che è successo in questo modo.
2025-05-29 22:24:00,363 - INFO - joeynmt.training - Epoch   5, Step:    50600, Batch Loss:     1.649928, Batch Acc: 0.471990, Tokens per Sec:    18517, Lr: 0.000300
2025-05-29 22:24:03,650 - INFO - joeynmt.training - Epoch   5, Step:    50700, Batch Loss:     1.843958, Batch Acc: 0.469796, Tokens per Sec:    20986, Lr: 0.000300
2025-05-29 22:24:06,939 - INFO - joeynmt.training - Epoch   5, Step:    50800, Batch Loss:     1.960067, Batch Acc: 0.475341, Tokens per Sec:    21185, Lr: 0.000300
2025-05-29 22:24:10,253 - INFO - joeynmt.training - Epoch   5, Step:    50900, Batch Loss:     1.668919, Batch Acc: 0.469446, Tokens per Sec:    22004, Lr: 0.000300
2025-05-29 22:24:13,541 - INFO - joeynmt.training - Epoch   5, Step:    51000, Batch Loss:     1.519456, Batch Acc: 0.474801, Tokens per Sec:    21486, Lr: 0.000300
2025-05-29 22:24:13,541 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:24:13,541 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:24:23,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.37, acc:   0.50, generation: 9.5799[sec], evaluation: 0.0000[sec]
2025-05-29 22:24:23,133 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:24:23,810 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/49000.ckpt
2025-05-29 22:24:23,835 - INFO - joeynmt.training - Example #0
2025-05-29 22:24:23,836 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:24:23,836 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:24:23,836 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questi', 'due', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'enza', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'in@@', 'segn@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'per', 'il', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:24:23,837 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:24:23,837 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:24:23,837 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questi due due diapositive per conseguenza che l<unk> artica, che l<unk> articolo che ha insegnato per tre milioni di anni di anni che hanno insegnato per il 48% dei più grandi 48 stati.
2025-05-29 22:24:23,837 - INFO - joeynmt.training - Example #1
2025-05-29 22:24:23,837 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:24:23,837 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:24:23,837 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'stata', 'la', 'prima', 'cosa', 'che', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:24:23,838 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:24:23,838 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:24:23,838 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che è stata la prima cosa che è il Dicke del ghiaccio.
2025-05-29 22:24:23,838 - INFO - joeynmt.training - Example #2
2025-05-29 22:24:23,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:24:23,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:24:23,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:24:23,839 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:24:23,839 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:24:23,839 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, l<unk> articolo del nostro sistema globale.
2025-05-29 22:24:23,839 - INFO - joeynmt.training - Example #3
2025-05-29 22:24:23,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:24:23,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:24:23,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'rebbe', 'essere', 'in', 'in@@', 'ver@@', 'no', 'nel', 'v@@', 'ento', 'della', 's@@', 'om@@', 'mer@@', 'c@@', 'ato', 'nel', 's@@', 'ett@@', 'ore', 'di', 's@@', 'om@@', 'mer@@', 'c@@', 'ato', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:24:23,840 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:24:23,840 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:24:23,840 - INFO - joeynmt.training - 	Hypothesis: Si potrebbe essere in inverno nel vento della sommercato nel settore di sommercato e in un certo senso.
2025-05-29 22:24:23,840 - INFO - joeynmt.training - Example #4
2025-05-29 22:24:23,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:24:23,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:24:23,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:24:23,841 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:24:23,841 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:24:23,841 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di cosa è successo negli ultimi 25 anni.
2025-05-29 22:24:27,162 - INFO - joeynmt.training - Epoch   5, Step:    51100, Batch Loss:     1.820656, Batch Acc: 0.467763, Tokens per Sec:    17326, Lr: 0.000300
2025-05-29 22:24:30,481 - INFO - joeynmt.training - Epoch   5, Step:    51200, Batch Loss:     1.711251, Batch Acc: 0.469672, Tokens per Sec:    22102, Lr: 0.000300
2025-05-29 22:24:33,797 - INFO - joeynmt.training - Epoch   5, Step:    51300, Batch Loss:     1.611813, Batch Acc: 0.472706, Tokens per Sec:    21717, Lr: 0.000300
2025-05-29 22:24:37,112 - INFO - joeynmt.training - Epoch   5, Step:    51400, Batch Loss:     1.676494, Batch Acc: 0.475357, Tokens per Sec:    21806, Lr: 0.000300
2025-05-29 22:24:40,427 - INFO - joeynmt.training - Epoch   5, Step:    51500, Batch Loss:     1.651638, Batch Acc: 0.472969, Tokens per Sec:    21947, Lr: 0.000300
2025-05-29 22:24:40,427 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:24:40,427 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:24:49,166 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.37, acc:   0.50, generation: 8.7267[sec], evaluation: 0.0000[sec]
2025-05-29 22:24:49,166 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:24:49,703 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/48500.ckpt
2025-05-29 22:24:49,728 - INFO - joeynmt.training - Example #0
2025-05-29 22:24:49,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:24:49,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:24:49,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'en@@', 'z@@', 'a@@', ',', 'che', 'le', 'persone', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'per', 'con@@', 'segu@@', 'en@@', 'z@@', 'a@@', ',', 'che', 'ha', 'in@@', 'segn@@', 'ato', 'per', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'di', '4@@', '8@@', ',', 'per', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', 'mondo', 'è', 'stato', 'sc@@', 'rit@@', 'to', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'questo', 'è', 'stato', 'f@@', 'att@@', 'o@@', ',', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'per', 'con@@', 'si@@', 'der@@', 'are', 'il', '4@@', '0@@', '%', 'dei', 'nostri', 'cor@@', 'si', 'di', 'c@@', 'ura']
2025-05-29 22:24:49,729 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:24:49,729 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:24:49,730 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per conseguenza, che le persone che hanno insegnato per conseguenza, che ha insegnato per il 40% di questi due anni di 48, per il 40% di questi due anni per il 40% di questi due anni per il 40% del 40% del mondo è stato scritto in un certo senso, e questo è stato fatto, e la sua famiglia per considerare il 40% dei nostri corsi di cura
2025-05-29 22:24:49,730 - INFO - joeynmt.training - Example #1
2025-05-29 22:24:49,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:24:49,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:24:49,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'volta', 'che', 'non', 'è', 'un', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'la', 'd@@', 'ell@@', '<unk>', 'in@@', 'f@@', 'lu@@', 'enza', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:24:49,730 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:24:49,730 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:24:49,731 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima volta che non è un problema, perché non è la dell<unk> influenza del ghiaccio.
2025-05-29 22:24:49,731 - INFO - joeynmt.training - Example #2
2025-05-29 22:24:49,731 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:24:49,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:24:49,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'ura', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:24:49,731 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:24:49,731 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:24:49,731 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la cura artica, il cuore del nostro climatico globale.
2025-05-29 22:24:49,732 - INFO - joeynmt.training - Example #3
2025-05-29 22:24:49,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:24:49,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:24:49,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'fer@@', 'ir@@', 'si', 'nel', 'v@@', 'ento', 'e', 'in', 'in@@', 'ver@@', 'no', 'nel', 'sen@@', 'so', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'om@@', 'mer@@', 'c@@', 'ato', 'e', 'l@@', '<unk>', 'est@@', 'at@@', 'e@@', ',', 'e', 'si', 'ri@@', 'fer@@', 'is@@', 'ce', 'a', 'c@@', 'aus@@', 'a', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'om@@', 'mer@@', 'si', 'e', 'a', 'c@@', 'aus@@', 'a', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'perim@@', 'ent@@', 'are', 'e', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'perim@@', 'ent@@', 'are', 'e', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'lia', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'perim@@', 'ent@@', 'o@@', ',', 'e', 'non', 'è', 'un', 'p@@', 'es@@', 'o', 'di', 's@@', 'om@@', 'mer@@', 'si', 'e', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:24:49,732 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:24:49,732 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:24:49,732 - INFO - joeynmt.training - 	Hypothesis: Si può riferirsi nel vento e in inverno nel senso di un sacco di sommercato e l<unk> estate, e si riferisce a causa di un sacco di sommersi e a causa di un sacco di sperimentare e di un sacco di sperimentare e la sua famiglia di un po<unk> di sperimento, e non è un peso di sommersi e in inverno.
2025-05-29 22:24:49,732 - INFO - joeynmt.training - Example #4
2025-05-29 22:24:49,733 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:24:49,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:24:49,733 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:24:49,733 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:24:49,733 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:24:49,733 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è un disegno di un disegno di un disegno di quei 25 anni.
2025-05-29 22:24:53,043 - INFO - joeynmt.training - Epoch   5, Step:    51600, Batch Loss:     1.708475, Batch Acc: 0.472245, Tokens per Sec:    18918, Lr: 0.000300
2025-05-29 22:24:56,327 - INFO - joeynmt.training - Epoch   5, Step:    51700, Batch Loss:     1.879042, Batch Acc: 0.475309, Tokens per Sec:    20986, Lr: 0.000300
2025-05-29 22:24:59,623 - INFO - joeynmt.training - Epoch   5, Step:    51800, Batch Loss:     1.668956, Batch Acc: 0.477858, Tokens per Sec:    21866, Lr: 0.000300
2025-05-29 22:25:02,927 - INFO - joeynmt.training - Epoch   5, Step:    51900, Batch Loss:     1.796237, Batch Acc: 0.466197, Tokens per Sec:    22184, Lr: 0.000300
2025-05-29 22:25:06,253 - INFO - joeynmt.training - Epoch   5, Step:    52000, Batch Loss:     1.694130, Batch Acc: 0.469018, Tokens per Sec:    21571, Lr: 0.000300
2025-05-29 22:25:06,253 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:25:06,253 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:25:14,304 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.34, acc:   0.50, generation: 8.0432[sec], evaluation: 0.0000[sec]
2025-05-29 22:25:14,304 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:25:14,935 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/49500.ckpt
2025-05-29 22:25:14,960 - INFO - joeynmt.training - Example #0
2025-05-29 22:25:14,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:25:14,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:25:14,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'sc@@', 'o@@', 'pr@@', 'ire', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'le', 'chiam@@', 'ano', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'per', 'il', '4@@', '0@@', '%', 'dei', 'più', 'gran@@', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 'più', 'gran@@', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'di', 'c@@', 'ento', 'di', 'un', 'p@@', 'ò', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'ri@@', 'l@@', 'ev@@', 'are', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 'ri@@', 'l@@', 'ev@@', 'it@@', 'abil@@', 'e@@', '.', '</s>']
2025-05-29 22:25:14,961 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:25:14,961 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:25:14,961 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato queste due diapositive per scoprire che le ghiaccia, che le chiamano i ghiaccio, che hanno insegnato per il 40% dei più grandi anni per il 40% dei più grandi anni per il 40% di cento di un pò di 40 per cento di rilevare il 40% di questi due anni per cento di rilevitabile.
2025-05-29 22:25:14,962 - INFO - joeynmt.training - Example #1
2025-05-29 22:25:14,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:25:14,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:25:14,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'in@@', 'segn@@', 'amento', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'spe@@', 'ci@@', 'ale', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:25:14,962 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:25:14,962 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:25:14,962 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è un po<unk> di insegnamento di questo speciale speciale di questo speciale speciale di ghiaccio.
2025-05-29 22:25:14,962 - INFO - joeynmt.training - Example #2
2025-05-29 22:25:14,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:25:14,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:25:14,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:25:14,963 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:25:14,963 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:25:14,963 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio artico, il cuore di climatico.
2025-05-29 22:25:14,963 - INFO - joeynmt.training - Example #3
2025-05-29 22:25:14,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:25:14,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:25:14,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'fer@@', 'm@@', 'are', 'in', 'in@@', 'ver@@', 'no', 'nel', 's@@', 'ett@@', 'ore', 'e', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:25:14,964 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:25:14,964 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:25:14,964 - INFO - joeynmt.training - 	Hypothesis: Si può rifermare in inverno nel settore e in inverno.
2025-05-29 22:25:14,964 - INFO - joeynmt.training - Example #4
2025-05-29 22:25:14,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:25:14,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:25:14,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:25:14,965 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:25:14,965 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:25:14,965 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di una dimostrazione di cosa è successo negli ultimi 25 anni.
2025-05-29 22:25:18,264 - INFO - joeynmt.training - Epoch   5, Step:    52100, Batch Loss:     1.867509, Batch Acc: 0.464369, Tokens per Sec:    18096, Lr: 0.000300
2025-05-29 22:25:21,558 - INFO - joeynmt.training - Epoch   5, Step:    52200, Batch Loss:     1.691649, Batch Acc: 0.474298, Tokens per Sec:    21489, Lr: 0.000300
2025-05-29 22:25:24,857 - INFO - joeynmt.training - Epoch   5, Step:    52300, Batch Loss:     1.697088, Batch Acc: 0.473893, Tokens per Sec:    21275, Lr: 0.000300
2025-05-29 22:25:28,152 - INFO - joeynmt.training - Epoch   5, Step:    52400, Batch Loss:     1.788713, Batch Acc: 0.468222, Tokens per Sec:    21423, Lr: 0.000300
2025-05-29 22:25:31,441 - INFO - joeynmt.training - Epoch   5, Step:    52500, Batch Loss:     1.809340, Batch Acc: 0.465347, Tokens per Sec:    21547, Lr: 0.000300
2025-05-29 22:25:31,442 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:25:31,442 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:25:38,761 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.36, acc:   0.50, generation: 7.3116[sec], evaluation: 0.0000[sec]
2025-05-29 22:25:39,067 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/50000.ckpt
2025-05-29 22:25:39,089 - INFO - joeynmt.training - Example #0
2025-05-29 22:25:39,090 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:25:39,090 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:25:39,090 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'enza', 'per', 'con@@', 'segu@@', 'ire', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'ar@@', 't@@', 'icol@@', 'i@@', ',', 'che', 'le', 'sc@@', 'u@@', 'ole', 'che', 'le', 'sc@@', 'u@@', 'ole', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'la', 'maggi@@', 'or', 'parte', 'di', 'questi', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', 'm@@', 'em@@', 'or@@', 'i@@', 'o@@', '.', '</s>']
2025-05-29 22:25:39,090 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:25:39,090 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:25:39,090 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due diapositive per conseguenza per conseguire le ghiaccio, che le articoli, che le scuole che le scuole per tre milioni di anni per la maggior parte di questi tre milioni di anni per il 40% del 40% del 40% del 40% del 40% del memorio.
2025-05-29 22:25:39,090 - INFO - joeynmt.training - Example #1
2025-05-29 22:25:39,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:25:39,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:25:39,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'in@@', 'segn@@', 'amento', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'un', 'problema', 'in', 'modo', 'da', 'far@@', 'e@@', ',', 'perché', 'non', 'è', 'un', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'non', 'è', 'un', 'p@@', 'ò', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:25:39,091 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:25:39,091 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:25:39,091 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di insegnamento di questo problema, e non è un problema in modo da fare, perché non è un motivo per cui non è un pò di ghiaccio.
2025-05-29 22:25:39,091 - INFO - joeynmt.training - Example #2
2025-05-29 22:25:39,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:25:39,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:25:39,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 'cosa', 'più', 'grande', 'è', 'la', 'cu@@', 'c@@', 'ina', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'glob@@', 'ale', 'per', 'la', 'sua', 'f@@', 'am@@', 'ig@@', 'li@@', 'a@@', '.', '</s>']
2025-05-29 22:25:39,092 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:25:39,092 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:25:39,092 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la cosa più grande è la cucina del nostro sistema globale climatico globale del nostro sistema globale del nostro sistema globale globale del nostro sistema globale globale per la sua famiglia.
2025-05-29 22:25:39,092 - INFO - joeynmt.training - Example #3
2025-05-29 22:25:39,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:25:39,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:25:39,093 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 'c@@', 'entr@@', 'o', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:25:39,093 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:25:39,093 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:25:39,093 - INFO - joeynmt.training - 	Hypothesis: Si può essere in inverno e in inverno e in un centro di sommergibile.
2025-05-29 22:25:39,093 - INFO - joeynmt.training - Example #4
2025-05-29 22:25:39,093 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:25:39,093 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:25:39,093 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'due', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:25:39,094 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:25:39,094 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:25:39,094 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è un disegno di un disegno di un disegno di due anni.
2025-05-29 22:25:42,365 - INFO - joeynmt.training - Epoch   5, Step:    52600, Batch Loss:     2.051969, Batch Acc: 0.467695, Tokens per Sec:    19259, Lr: 0.000300
2025-05-29 22:25:45,675 - INFO - joeynmt.training - Epoch   5, Step:    52700, Batch Loss:     1.721144, Batch Acc: 0.472075, Tokens per Sec:    21564, Lr: 0.000300
2025-05-29 22:25:48,967 - INFO - joeynmt.training - Epoch   5, Step:    52800, Batch Loss:     1.712730, Batch Acc: 0.471286, Tokens per Sec:    21637, Lr: 0.000300
2025-05-29 22:25:52,257 - INFO - joeynmt.training - Epoch   5, Step:    52900, Batch Loss:     1.810097, Batch Acc: 0.471824, Tokens per Sec:    21485, Lr: 0.000300
2025-05-29 22:25:55,546 - INFO - joeynmt.training - Epoch   5, Step:    53000, Batch Loss:     1.729949, Batch Acc: 0.471043, Tokens per Sec:    21694, Lr: 0.000300
2025-05-29 22:25:55,546 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:25:55,546 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:26:03,174 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.50, generation: 7.6210[sec], evaluation: 0.0000[sec]
2025-05-29 22:26:03,175 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:26:03,740 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/50500.ckpt
2025-05-29 22:26:03,765 - INFO - joeynmt.training - Example #0
2025-05-29 22:26:03,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:26:03,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:26:03,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'inter@@', 'o', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'che', 'si', 'è', 'chiam@@', 'a', '<unk>', 'O@@', 'c@@', 'ci@@', 'd@@', 'ent@@', 'e@@', ',', 'che', 'è', 'stato', 'd@@', 'ato', 'per', 'ri@@', 'dur@@', 're', 'il', '4@@', '0@@', '%', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:26:03,765 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:26:03,765 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:26:03,766 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per ridurre che l<unk> intero ghiaccio, che l<unk> Eiskappe che si è chiama <unk> Occidente, che è stato dato per ridurre il 40% di cento.
2025-05-29 22:26:03,766 - INFO - joeynmt.training - Example #1
2025-05-29 22:26:03,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:26:03,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:26:03,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'stato', 'in@@', 'segn@@', 'ato', 'a', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 't@@', 'opo', 'di', 'questo', 'tipo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:26:03,766 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:26:03,766 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:26:03,766 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che è stato insegnato a questo problema, perché non è il topo di questo tipo di ghiaccio.
2025-05-29 22:26:03,766 - INFO - joeynmt.training - Example #2
2025-05-29 22:26:03,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:26:03,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:26:03,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'la', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:26:03,767 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:26:03,767 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:26:03,767 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, la cuore artica, il cuore globale.
2025-05-29 22:26:03,767 - INFO - joeynmt.training - Example #3
2025-05-29 22:26:03,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:26:03,768 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:26:03,768 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'dur@@', 're', 'e', 'ri@@', 'vel@@', 'a', 'e', 'nel', 'sen@@', 'so', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:26:03,768 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:26:03,768 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:26:03,768 - INFO - joeynmt.training - 	Hypothesis: Si può ridurre e rivela e nel senso di un sacco di sommergibile.
2025-05-29 22:26:03,768 - INFO - joeynmt.training - Example #4
2025-05-29 22:26:03,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:26:03,768 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:26:03,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'mostr@@', 'a', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:26:03,769 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:26:03,769 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:26:03,769 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una dimostra che è successo negli ultimi 25 anni.
2025-05-29 22:26:07,044 - INFO - joeynmt.training - Epoch   5, Step:    53100, Batch Loss:     1.948669, Batch Acc: 0.468288, Tokens per Sec:    17941, Lr: 0.000300
2025-05-29 22:26:10,330 - INFO - joeynmt.training - Epoch   5, Step:    53200, Batch Loss:     1.733435, Batch Acc: 0.470069, Tokens per Sec:    21398, Lr: 0.000300
2025-05-29 22:26:13,558 - INFO - joeynmt.training - Epoch   5, Step:    53300, Batch Loss:     1.600890, Batch Acc: 0.468107, Tokens per Sec:    21654, Lr: 0.000300
2025-05-29 22:26:16,688 - INFO - joeynmt.training - Epoch   5, Step:    53400, Batch Loss:     1.804536, Batch Acc: 0.476982, Tokens per Sec:    22931, Lr: 0.000300
2025-05-29 22:26:19,826 - INFO - joeynmt.training - Epoch   5, Step:    53500, Batch Loss:     1.756761, Batch Acc: 0.476023, Tokens per Sec:    22622, Lr: 0.000300
2025-05-29 22:26:19,827 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:26:19,827 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:26:28,075 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.50, generation: 8.2371[sec], evaluation: 0.0000[sec]
2025-05-29 22:26:28,384 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/51000.ckpt
2025-05-29 22:26:28,405 - INFO - joeynmt.training - Example #0
2025-05-29 22:26:28,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:26:28,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:26:28,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', ',', 'per', 'vedere', 'questi', 'due', 'anni', 'per', 'ri@@', 'dur@@', 're', 'che', 'gli', 'oc@@', 'chi', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'gli', 'oc@@', 'chi', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'si', 'è', 'ri@@', 'ma@@', 'sto', 'per', 'il', '4@@', '8@@', ',', 'per', 'c@@', 'ent@@', 'o@@', ',', 'il', '4@@', '0@@', '%', 'di', 'questi', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:26:28,406 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:26:28,406 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:26:28,406 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso, per vedere questi due anni per ridurre che gli occhi di ghiaccio, che gli occhi di tre milioni di anni di anni che si è rimasto per il 48, per cento, il 40% di questi 40 per cento.
2025-05-29 22:26:28,406 - INFO - joeynmt.training - Example #1
2025-05-29 22:26:28,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:26:28,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:26:28,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'un', 'p@@', 'ezz@@', 'o', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:26:28,407 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:26:28,407 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:26:28,407 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la popolazione di questo problema speciale, perché non c<unk> è un pezzo di ghiaccio.
2025-05-29 22:26:28,407 - INFO - joeynmt.training - Example #2
2025-05-29 22:26:28,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:26:28,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:26:28,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 's@@', 'é', 'la', 'c@@', 'aus@@', 'a', 'del', 'c@@', 'ri@@', 'm@@', 'ine', 'd@@', 'ell@@', '<unk>', 'in@@', 'contr@@', 'o', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:26:28,408 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:26:28,408 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:26:28,408 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di sé la causa del crimine dell<unk> incontro del nostro sistema globale.
2025-05-29 22:26:28,408 - INFO - joeynmt.training - Example #3
2025-05-29 22:26:28,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:26:28,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:26:28,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'n@@', 'ell@@', '<unk>', 'est@@', 'ate', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:26:28,409 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:26:28,409 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:26:28,409 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, e si rivela nell<unk> estate in un certo senso.
2025-05-29 22:26:28,409 - INFO - joeynmt.training - Example #4
2025-05-29 22:26:28,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:26:28,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:26:28,409 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'li@@', 'vello', 'succ@@', 'essi@@', 'vo@@', ',', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:26:28,410 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:26:28,410 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:26:28,410 - INFO - joeynmt.training - 	Hypothesis: Il prossimo livello successivo, è che vi mostrerò un disegno di un certo senso di quello che è successo negli ultimi 25 anni.
2025-05-29 22:26:28,820 - INFO - joeynmt.training - Epoch   5: total training loss 18933.19
2025-05-29 22:26:28,821 - INFO - joeynmt.training - EPOCH 6
2025-05-29 22:26:31,539 - INFO - joeynmt.training - Epoch   6, Step:    53600, Batch Loss:     2.000663, Batch Acc: 0.477296, Tokens per Sec:    22683, Lr: 0.000300
2025-05-29 22:26:34,625 - INFO - joeynmt.training - Epoch   6, Step:    53700, Batch Loss:     1.628415, Batch Acc: 0.480556, Tokens per Sec:    22918, Lr: 0.000300
2025-05-29 22:26:37,770 - INFO - joeynmt.training - Epoch   6, Step:    53800, Batch Loss:     1.763002, Batch Acc: 0.485995, Tokens per Sec:    22080, Lr: 0.000300
2025-05-29 22:26:40,923 - INFO - joeynmt.training - Epoch   6, Step:    53900, Batch Loss:     1.526568, Batch Acc: 0.486434, Tokens per Sec:    22060, Lr: 0.000300
2025-05-29 22:26:44,083 - INFO - joeynmt.training - Epoch   6, Step:    54000, Batch Loss:     1.738075, Batch Acc: 0.479192, Tokens per Sec:    21817, Lr: 0.000300
2025-05-29 22:26:44,084 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:26:44,084 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:26:52,873 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.50, generation: 8.7794[sec], evaluation: 0.0000[sec]
2025-05-29 22:26:53,175 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/51500.ckpt
2025-05-29 22:26:53,192 - INFO - joeynmt.training - Example #0
2025-05-29 22:26:53,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:26:53,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:26:53,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ann@@', 'o@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'f@@', 'etti', 'per', 'con@@', 'segu@@', 'enze', 'ar@@', 't@@', 'icol@@', 'i', 'ar@@', 't@@', 'icol@@', 'i', 'ar@@', 't@@', 'icol@@', 'i', 'che', 'ar@@', 't@@', 'icol@@', 'i', 'che', 'hanno', 'chiam@@', 'ato', 'il', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:26:53,192 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:26:53,193 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:26:53,193 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno, ho mostrato queste due difetti per conseguenze articoli articoli articoli che articoli che hanno chiamato il 40 per cento, il 40 per cento.
2025-05-29 22:26:53,193 - INFO - joeynmt.training - Example #1
2025-05-29 22:26:53,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:26:53,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:26:53,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'l@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'a', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'inter@@', 'a', 'd@@', 'ell@@', '<unk>', 'inter@@', 'a', 'p@@', 'op@@', 'ol@@', 'are', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:26:53,193 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:26:53,193 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:26:53,193 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte abbastanza l<unk> industria di questo problema speciale di questo tipo di problema, perché non è il dell<unk> intera dell<unk> intera popolare il ghiaccio di ghiaccio.
2025-05-29 22:26:53,193 - INFO - joeynmt.training - Example #2
2025-05-29 22:26:53,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:26:53,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:26:53,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:26:53,194 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:26:53,194 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:26:53,194 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore del nostro climatico globale.
2025-05-29 22:26:53,194 - INFO - joeynmt.training - Example #3
2025-05-29 22:26:53,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:26:53,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:26:53,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'vel@@', 'are', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:26:53,195 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:26:53,195 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:26:53,195 - INFO - joeynmt.training - 	Hypothesis: Si può rivelare in inverno e l<unk> estate.
2025-05-29 22:26:53,195 - INFO - joeynmt.training - Example #4
2025-05-29 22:26:53,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:26:53,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:26:53,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:26:53,195 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:26:53,196 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:26:53,196 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo in un certo senso, che è successo negli ultimi 25 anni.
2025-05-29 22:26:56,494 - INFO - joeynmt.training - Epoch   6, Step:    54100, Batch Loss:     1.573123, Batch Acc: 0.485820, Tokens per Sec:    19791, Lr: 0.000300
2025-05-29 22:26:59,747 - INFO - joeynmt.training - Epoch   6, Step:    54200, Batch Loss:     1.920475, Batch Acc: 0.480267, Tokens per Sec:    21794, Lr: 0.000300
2025-05-29 22:27:02,972 - INFO - joeynmt.training - Epoch   6, Step:    54300, Batch Loss:     1.934114, Batch Acc: 0.481367, Tokens per Sec:    21643, Lr: 0.000300
2025-05-29 22:27:06,272 - INFO - joeynmt.training - Epoch   6, Step:    54400, Batch Loss:     1.669144, Batch Acc: 0.486716, Tokens per Sec:    21243, Lr: 0.000300
2025-05-29 22:27:09,566 - INFO - joeynmt.training - Epoch   6, Step:    54500, Batch Loss:     1.952730, Batch Acc: 0.481836, Tokens per Sec:    21400, Lr: 0.000300
2025-05-29 22:27:09,568 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:27:09,568 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:27:18,170 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.34, acc:   0.50, generation: 8.5881[sec], evaluation: 0.0000[sec]
2025-05-29 22:27:18,536 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/52500.ckpt
2025-05-29 22:27:18,567 - INFO - joeynmt.training - Example #0
2025-05-29 22:27:18,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:27:18,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:27:18,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'f@@', 'att@@', 'ori', 'per', 'sc@@', 'ar@@', 'p@@', 'e', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ent@@', 'o@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:27:18,568 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:27:18,569 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:27:18,569 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di queste due fattori per scarpe che l<unk> anno scorso che il ghiaccio artico per tre milioni di anni di anni di 48 per cento, il 40 per cento.
2025-05-29 22:27:18,569 - INFO - joeynmt.training - Example #1
2025-05-29 22:27:18,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:27:18,569 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:27:18,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'res@@', 'pon@@', 's@@', 'abil@@', 'ità', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'un', 'gr@@', 'u@@', 'ppo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:27:18,569 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:27:18,569 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:27:18,570 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la responsabilità di questo problema, perché non è un gruppo di ghiaccio.
2025-05-29 22:27:18,570 - INFO - joeynmt.training - Example #2
2025-05-29 22:27:18,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:27:18,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:27:18,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:27:18,570 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:27:18,570 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:27:18,570 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa della ghiaccio artico.
2025-05-29 22:27:18,571 - INFO - joeynmt.training - Example #3
2025-05-29 22:27:18,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:27:18,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:27:18,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'dur@@', 're', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'nel', 'sen@@', 'so', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'ott@@', 'o@@', '.', '</s>']
2025-05-29 22:27:18,571 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:27:18,571 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:27:18,571 - INFO - joeynmt.training - 	Hypothesis: Si può ridurre in inverno e in inverno nel senso di un sacco di sotto.
2025-05-29 22:27:18,572 - INFO - joeynmt.training - Example #4
2025-05-29 22:27:18,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:27:18,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:27:18,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:27:18,572 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:27:18,572 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:27:18,572 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 22:27:21,902 - INFO - joeynmt.training - Epoch   6, Step:    54600, Batch Loss:     1.750939, Batch Acc: 0.476634, Tokens per Sec:    19207, Lr: 0.000300
2025-05-29 22:27:25,263 - INFO - joeynmt.training - Epoch   6, Step:    54700, Batch Loss:     1.878774, Batch Acc: 0.479388, Tokens per Sec:    20622, Lr: 0.000300
2025-05-29 22:27:28,641 - INFO - joeynmt.training - Epoch   6, Step:    54800, Batch Loss:     1.657894, Batch Acc: 0.480027, Tokens per Sec:    21106, Lr: 0.000300
2025-05-29 22:27:32,013 - INFO - joeynmt.training - Epoch   6, Step:    54900, Batch Loss:     1.666248, Batch Acc: 0.484559, Tokens per Sec:    21211, Lr: 0.000300
2025-05-29 22:27:35,388 - INFO - joeynmt.training - Epoch   6, Step:    55000, Batch Loss:     1.589809, Batch Acc: 0.480840, Tokens per Sec:    21079, Lr: 0.000300
2025-05-29 22:27:35,388 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:27:35,388 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:27:44,939 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.50, generation: 9.5391[sec], evaluation: 0.0000[sec]
2025-05-29 22:27:45,342 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/53500.ckpt
2025-05-29 22:27:45,370 - INFO - joeynmt.training - Example #0
2025-05-29 22:27:45,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:27:45,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:27:45,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'qu@@', 'ei', 'due', 'di@@', 'sp@@', 'os@@', 'i@@', 'zione', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'la', 'chiam@@', 'a', '4@@', '8', 'st@@', 'ati@@', 'va', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'circa', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', '4@@', '0@@', '%', 'di', '1@@', '0@@', '%', 'di', 'questi', 'due', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:27:45,371 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:27:45,371 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:27:45,371 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso quei due disposizione per ridurre che l<unk> anno scorso che l<unk> anno scorso che l<unk> anno scorso che la chiama 48 stativa per 40 per cento di circa 40 per cento di 40 per cento di 40 per cento di un 40% di 10% di questi due anni.
2025-05-29 22:27:45,371 - INFO - joeynmt.training - Example #1
2025-05-29 22:27:45,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:27:45,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:27:45,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'importante', 'per', 'il', 'con@@', 'si@@', 'gli@@', 'o', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'un', 'p@@', 'ezz@@', 'o', 'di', 's@@', 'ott@@', 'op@@', 'ost@@', 'o', 'che', 'non', 'è', 'un', 'altro', 'che', 'ha', 'un', 's@@', 'ac@@', 'co', 'di', 'ris@@', 'ult@@', 'ati', 'e', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 'ris@@', 'ol@@', 'vere', 'il', 'problema', 'di', 'questo', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 22:27:45,372 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:27:45,372 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:27:45,372 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più importante per il consiglio di questo problema, perché non c<unk> è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio che è un pezzo di sottoposto che non è un altro che ha un sacco di risultati e che si tratta di un sacco di risolvere il problema di questo problema.
2025-05-29 22:27:45,372 - INFO - joeynmt.training - Example #2
2025-05-29 22:27:45,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:27:45,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:27:45,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'cosa', 'più', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:27:45,373 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:27:45,373 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:27:45,373 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la cosa più artica, il cuore del sistema climatico del nostro sistema climatico globale.
2025-05-29 22:27:45,373 - INFO - joeynmt.training - Example #3
2025-05-29 22:27:45,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:27:45,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:27:45,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'vel@@', 'are', 'nel', 'cor@@', 'so', 'di', 's@@', 'otto', 'nel', 's@@', 'ito', 'del', 's@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 22:27:45,374 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:27:45,374 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:27:45,374 - INFO - joeynmt.training - 	Hypothesis: Si può rivelare nel corso di sotto nel sito del sommer.
2025-05-29 22:27:45,374 - INFO - joeynmt.training - Example #4
2025-05-29 22:27:45,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:27:45,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:27:45,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'o', 'è', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:27:45,375 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:27:45,375 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:27:45,375 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una cosa che vi mostro è che è successo negli ultimi 25 anni.
2025-05-29 22:27:48,777 - INFO - joeynmt.training - Epoch   6, Step:    55100, Batch Loss:     1.825703, Batch Acc: 0.481373, Tokens per Sec:    18762, Lr: 0.000300
2025-05-29 22:27:52,156 - INFO - joeynmt.training - Epoch   6, Step:    55200, Batch Loss:     1.678929, Batch Acc: 0.476637, Tokens per Sec:    21418, Lr: 0.000300
2025-05-29 22:27:55,541 - INFO - joeynmt.training - Epoch   6, Step:    55300, Batch Loss:     1.731878, Batch Acc: 0.477433, Tokens per Sec:    21380, Lr: 0.000300
2025-05-29 22:27:58,917 - INFO - joeynmt.training - Epoch   6, Step:    55400, Batch Loss:     1.723868, Batch Acc: 0.479830, Tokens per Sec:    21154, Lr: 0.000300
2025-05-29 22:28:02,290 - INFO - joeynmt.training - Epoch   6, Step:    55500, Batch Loss:     1.778653, Batch Acc: 0.483216, Tokens per Sec:    21437, Lr: 0.000300
2025-05-29 22:28:02,291 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:28:02,291 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:28:11,406 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.50, generation: 9.1022[sec], evaluation: 0.0000[sec]
2025-05-29 22:28:11,407 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:28:11,973 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/54500.ckpt
2025-05-29 22:28:11,993 - INFO - joeynmt.training - Example #0
2025-05-29 22:28:11,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:28:11,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:28:11,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'che', 'si', 'trov@@', 'a', 'la', 'g@@', 'hi@@', 'r@@', 'on@@', 'na', 'che', 'gli', 'el@@', 'em@@', 'i@@', ',', 'che', 'si', 'chiam@@', 'a', 'g@@', 'hi@@', 'ac@@', 'cio', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'av@@', 'evano', 'il', '4@@', '8@@', '%', 'dei', 'm@@', 'ezz@@', 'i', 'di', 'anni', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:28:11,995 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:28:11,995 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:28:11,995 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso queste due dimensioni che si trova la ghironna che gli elemi, che si chiama ghiaccio per tre milioni di anni di anni che avevano il 48% dei mezzi di anni di 48 stati.
2025-05-29 22:28:11,995 - INFO - joeynmt.training - Example #1
2025-05-29 22:28:11,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:28:11,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:28:11,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'grande', 'probl@@', 'em@@', 'a@@', ',', 'la', 'sua', 'res@@', 'pon@@', 's@@', 'abil@@', 'ità', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'per', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'questo', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 22:28:11,996 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:28:11,996 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:28:11,996 - INFO - joeynmt.training - 	Hypothesis: Ma non è un grande problema, la sua responsabilità di questo speciale di questo speciale di questo speciale per il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di questo problema.
2025-05-29 22:28:11,996 - INFO - joeynmt.training - Example #2
2025-05-29 22:28:11,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:28:11,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:28:11,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'e', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:28:11,997 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:28:11,997 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:28:11,997 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa di ghiaccio artico e il nostro sistema climatico globale del nostro sistema climatico.
2025-05-29 22:28:11,997 - INFO - joeynmt.training - Example #3
2025-05-29 22:28:11,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:28:11,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:28:11,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'es@@', 'ce', 'a', 'v@@', 'ento', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:28:11,998 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:28:11,998 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:28:11,998 - INFO - joeynmt.training - 	Hypothesis: Si può riesce a vento in inverno e in un certo senso.
2025-05-29 22:28:11,998 - INFO - joeynmt.training - Example #4
2025-05-29 22:28:11,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:28:11,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:28:11,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:28:11,998 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:28:11,999 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:28:11,999 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una cosa che è successo negli ultimi 25 anni.
2025-05-29 22:28:15,377 - INFO - joeynmt.training - Epoch   6, Step:    55600, Batch Loss:     1.745206, Batch Acc: 0.483311, Tokens per Sec:    17755, Lr: 0.000300
2025-05-29 22:28:18,764 - INFO - joeynmt.training - Epoch   6, Step:    55700, Batch Loss:     1.836112, Batch Acc: 0.479685, Tokens per Sec:    21327, Lr: 0.000300
2025-05-29 22:28:22,142 - INFO - joeynmt.training - Epoch   6, Step:    55800, Batch Loss:     1.658156, Batch Acc: 0.479094, Tokens per Sec:    21165, Lr: 0.000300
2025-05-29 22:28:25,516 - INFO - joeynmt.training - Epoch   6, Step:    55900, Batch Loss:     1.846271, Batch Acc: 0.481874, Tokens per Sec:    20888, Lr: 0.000300
2025-05-29 22:28:28,901 - INFO - joeynmt.training - Epoch   6, Step:    56000, Batch Loss:     1.534023, Batch Acc: 0.489212, Tokens per Sec:    21239, Lr: 0.000300
2025-05-29 22:28:28,901 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:28:28,901 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:28:37,626 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.51, generation: 8.7162[sec], evaluation: 0.0000[sec]
2025-05-29 22:28:37,626 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:28:38,109 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/52000.ckpt
2025-05-29 22:28:38,135 - INFO - joeynmt.training - Example #0
2025-05-29 22:28:38,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:28:38,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:28:38,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'gli', 'g@@', 'hi@@', 'es@@', 'c@@', 'enti', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'gli', 'in@@', 'segn@@', 'ano', 'che', 'le', 'in@@', 'forma@@', 'zioni', 'ar@@', 't@@', 'ic@@', 'ali', 'che', 'sono', 'stati', 'in@@', 'tor@@', 'no', 'a', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'ott@@', 'o@@', '.', '</s>']
2025-05-29 22:28:38,136 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:28:38,136 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:28:38,137 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di queste due diapositive per ridurre che gli ghiescenti artici, che gli insegnano che le informazioni articali che sono stati intorno a 40 per cento di 40 per cento di 40 per cento di 40 per cento di sotto.
2025-05-29 22:28:38,137 - INFO - joeynmt.training - Example #1
2025-05-29 22:28:38,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:28:38,137 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:28:38,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'in@@', 'tr@@', 'ap@@', 'pol@@', 'ato', 'la', 'sua', 's@@', 'itu@@', 'azione', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'E@@', 'is@@', 'es@@', 'e@@', '.', '</s>']
2025-05-29 22:28:38,137 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:28:38,137 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:28:38,138 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato intrappolato la sua situazione di questo speciale problema, perché non c<unk> è il dell<unk> Eisese.
2025-05-29 22:28:38,138 - INFO - joeynmt.training - Example #2
2025-05-29 22:28:38,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:28:38,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:28:38,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:28:38,138 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:28:38,138 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:28:38,138 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiacciaio di ghiaccia, il cuore del nostro sistema climatico.
2025-05-29 22:28:38,138 - INFO - joeynmt.training - Example #3
2025-05-29 22:28:38,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:28:38,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:28:38,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'en@@', 'siamo', 'in', 'in@@', 'ver@@', 'no', 'al', 'l@@', 'ato', 'e', 'l@@', '<unk>', 'est@@', 'ate', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 22:28:38,139 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:28:38,139 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:28:38,139 - INFO - joeynmt.training - 	Hypothesis: Pensiamo in inverno al lato e l<unk> estate in un sacco di sommer.
2025-05-29 22:28:38,139 - INFO - joeynmt.training - Example #4
2025-05-29 22:28:38,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:28:38,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:28:38,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'con@@', 'segu@@', 'enza', 'succ@@', 'essi@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'm@@', 'em@@', 'or@@', 'ia', 'di', 'm@@', 'e@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:28:38,140 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:28:38,140 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:28:38,140 - INFO - joeynmt.training - 	Hypothesis: La conseguenza successiva che vi mostrerò è una memoria di me, che è successo negli ultimi 25 anni.
2025-05-29 22:28:41,531 - INFO - joeynmt.training - Epoch   6, Step:    56100, Batch Loss:     1.786615, Batch Acc: 0.478751, Tokens per Sec:    18055, Lr: 0.000300
2025-05-29 22:28:44,890 - INFO - joeynmt.training - Epoch   6, Step:    56200, Batch Loss:     1.687759, Batch Acc: 0.484666, Tokens per Sec:    20412, Lr: 0.000300
2025-05-29 22:28:48,225 - INFO - joeynmt.training - Epoch   6, Step:    56300, Batch Loss:     1.933538, Batch Acc: 0.475697, Tokens per Sec:    21460, Lr: 0.000300
2025-05-29 22:28:51,603 - INFO - joeynmt.training - Epoch   6, Step:    56400, Batch Loss:     1.725232, Batch Acc: 0.484553, Tokens per Sec:    21353, Lr: 0.000300
2025-05-29 22:28:54,957 - INFO - joeynmt.training - Epoch   6, Step:    56500, Batch Loss:     1.772634, Batch Acc: 0.482841, Tokens per Sec:    21165, Lr: 0.000300
2025-05-29 22:28:54,957 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:28:54,957 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:29:03,819 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.28, acc:   0.50, generation: 8.8512[sec], evaluation: 0.0000[sec]
2025-05-29 22:29:03,820 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:29:04,505 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/55000.ckpt
2025-05-29 22:29:04,530 - INFO - joeynmt.training - Example #0
2025-05-29 22:29:04,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:29:04,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:29:04,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'le', 'persone', 'che', 'hanno', 'chiam@@', 'ato', 'il', '4@@', '8', 'st@@', 'ati@@', 'vo', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'dei', 'con@@', 'si@@', 'gli@@', 'eri', 'che', 'è', 'stato', 'acc@@', 'a@@', 'du@@', 'to', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'un', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:29:04,532 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:29:04,532 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:29:04,532 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per ridurre che l<unk> articolo che i ghiaccia, che le persone che hanno chiamato il 48 stativo per tre milioni di anni per cento dei consiglieri che è stato accaduto per 40 per cento di cento di un 40 per cento di un po<unk> .
2025-05-29 22:29:04,532 - INFO - joeynmt.training - Example #1
2025-05-29 22:29:04,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:29:04,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:29:04,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'l@@', '<unk>', 'in@@', 'st@@', 'all@@', 'ato', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'e', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:29:04,533 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:29:04,533 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:29:04,533 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, l<unk> installato di questo particolare problemi di questo particolare e perché non è il Dicke del ghiaccio.
2025-05-29 22:29:04,533 - INFO - joeynmt.training - Example #2
2025-05-29 22:29:04,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:29:04,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:29:04,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'li@@', 'm@@', 'ass@@', 'ic@@', 'ur@@', 'are', 'il', 'nostro', 'sistema', 'li@@', 'vello', 'glob@@', 'ale', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:29:04,534 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:29:04,534 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:29:04,534 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo è l<unk> articolo del nostro sistema climatico globale del nostro sistema climatico globale del nostro sistema climatico globale del nostro sistema limassicurare il nostro sistema livello globale climatico.
2025-05-29 22:29:04,534 - INFO - joeynmt.training - Example #3
2025-05-29 22:29:04,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:29:04,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:29:04,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'fer@@', 'im@@', 'ento', 'in', 'in@@', 'ver@@', 'no', 'al', 'm@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:29:04,534 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:29:04,535 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:29:04,535 - INFO - joeynmt.training - 	Hypothesis: Si può riferimento in inverno al momento.
2025-05-29 22:29:04,535 - INFO - joeynmt.training - Example #4
2025-05-29 22:29:04,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:29:04,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:29:04,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:29:04,535 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:29:04,536 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:29:04,536 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una cosa che è successo negli ultimi 25 anni.
2025-05-29 22:29:07,927 - INFO - joeynmt.training - Epoch   6, Step:    56600, Batch Loss:     1.650892, Batch Acc: 0.482994, Tokens per Sec:    17139, Lr: 0.000300
2025-05-29 22:29:11,297 - INFO - joeynmt.training - Epoch   6, Step:    56700, Batch Loss:     1.517581, Batch Acc: 0.479068, Tokens per Sec:    20537, Lr: 0.000300
2025-05-29 22:29:14,682 - INFO - joeynmt.training - Epoch   6, Step:    56800, Batch Loss:     1.723570, Batch Acc: 0.482012, Tokens per Sec:    20695, Lr: 0.000300
2025-05-29 22:29:18,053 - INFO - joeynmt.training - Epoch   6, Step:    56900, Batch Loss:     1.822199, Batch Acc: 0.479862, Tokens per Sec:    21208, Lr: 0.000300
2025-05-29 22:29:21,409 - INFO - joeynmt.training - Epoch   6, Step:    57000, Batch Loss:     1.694779, Batch Acc: 0.477450, Tokens per Sec:    20894, Lr: 0.000300
2025-05-29 22:29:21,409 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:29:21,409 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:29:29,337 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.50, generation: 7.9169[sec], evaluation: 0.0000[sec]
2025-05-29 22:29:29,858 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/54000.ckpt
2025-05-29 22:29:29,884 - INFO - joeynmt.training - Example #0
2025-05-29 22:29:29,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:29:29,885 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:29:29,885 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'ire', 'le', 'con@@', 'segu@@', 'enze', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'le', 'su@@', 'e', 'm@@', 'ezz@@', 'o', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'st@@', 'at@@', 'un@@', 'it@@', 'en@@', 'se', 'è', 'stato', 'f@@', 'att@@', 'o@@', '.', '</s>']
2025-05-29 22:29:29,885 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:29:29,885 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:29:29,885 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per conseguire le conseguenze artici, che i ghiacciati per tre milioni di anni che hanno le sue mezzo di tre milioni di anni di persone che hanno insegnato il 40 per cento di statunitense è stato fatto.
2025-05-29 22:29:29,885 - INFO - joeynmt.training - Example #1
2025-05-29 22:29:29,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:29:29,886 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:29:29,886 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'essere', 'abb@@', 'ast@@', 'anza', 'l@@', '<unk>', 'in@@', 'st@@', 'all@@', 'azione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:29:29,886 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:29:29,886 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:29:29,886 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di essere abbastanza l<unk> installazione di questo particolare problemi di questo particolare il Dicke del ghiaccio.
2025-05-29 22:29:29,886 - INFO - joeynmt.training - Example #2
2025-05-29 22:29:29,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:29:29,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:29:29,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'or@@', 'ig@@', 'ine', 'ar@@', 't@@', 'ico', 'che', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:29:29,887 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:29:29,887 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:29:29,887 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> origine artico che è il cuore del nostro sistema climatico globale.
2025-05-29 22:29:29,887 - INFO - joeynmt.training - Example #3
2025-05-29 22:29:29,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:29:29,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:29:29,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'in@@', 'contr@@', 'a', 'il', 's@@', 'ett@@', 'ore', 'e', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'é', 'st@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:29:29,888 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:29:29,888 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:29:29,888 - INFO - joeynmt.training - 	Hypothesis: Si può essere in inverno, e si incontra il settore e in un sacco di sé stato.
2025-05-29 22:29:29,888 - INFO - joeynmt.training - Example #4
2025-05-29 22:29:29,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:29:29,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:29:29,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'di@@', 'st@@', 'anza', 'di', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:29:29,889 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:29:29,889 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:29:29,889 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di una distanza di una cosa che è successo negli ultimi 25 anni.
2025-05-29 22:29:33,282 - INFO - joeynmt.training - Epoch   6, Step:    57100, Batch Loss:     1.714006, Batch Acc: 0.478063, Tokens per Sec:    18217, Lr: 0.000300
2025-05-29 22:29:36,657 - INFO - joeynmt.training - Epoch   6, Step:    57200, Batch Loss:     1.746295, Batch Acc: 0.478234, Tokens per Sec:    20866, Lr: 0.000300
2025-05-29 22:29:40,028 - INFO - joeynmt.training - Epoch   6, Step:    57300, Batch Loss:     1.760357, Batch Acc: 0.483116, Tokens per Sec:    21596, Lr: 0.000300
2025-05-29 22:29:43,384 - INFO - joeynmt.training - Epoch   6, Step:    57400, Batch Loss:     1.701132, Batch Acc: 0.478294, Tokens per Sec:    21422, Lr: 0.000300
2025-05-29 22:29:46,729 - INFO - joeynmt.training - Epoch   6, Step:    57500, Batch Loss:     1.844227, Batch Acc: 0.473511, Tokens per Sec:    20895, Lr: 0.000300
2025-05-29 22:29:46,730 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:29:46,730 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:29:54,668 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.30, acc:   0.50, generation: 7.9265[sec], evaluation: 0.0000[sec]
2025-05-29 22:29:55,022 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/53000.ckpt
2025-05-29 22:29:55,046 - INFO - joeynmt.training - Example #0
2025-05-29 22:29:55,046 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:29:55,046 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:29:55,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've@@', ',', 'per', 's@@', 'met@@', 'tere', 'che', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'si', 'è', 'sc@@', 'rit@@', 't@@', 'ura', 'che', 'si', 'chiam@@', 'a', '<unk>', '4@@', '8@@', '%', 'dei', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'per', 'il', '4@@', '8@@', '%', 'delle', 'persone', 'che', 'hanno', 'fatto', 'è', 'stata', 'sc@@', 'att@@', 'ata', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:29:55,047 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:29:55,047 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:29:55,047 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive, per smettere che il ghiaccio artico che si è scrittura che si chiama <unk> 48% dei tre milioni di anni di persone che hanno insegnato per il 48% delle persone che hanno fatto è stata scattata per il 40 per cento di cento.
2025-05-29 22:29:55,047 - INFO - joeynmt.training - Example #1
2025-05-29 22:29:55,047 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:29:55,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:29:55,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'che', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'a@@', '.', '</s>']
2025-05-29 22:29:55,048 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:29:55,048 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:29:55,048 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la capacità di questo particolare è che non è la dimostra che non è il dell<unk> ora.
2025-05-29 22:29:55,048 - INFO - joeynmt.training - Example #2
2025-05-29 22:29:55,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:29:55,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:29:55,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:29:55,049 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:29:55,049 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:29:55,049 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa della ghiaccia, il cuore globale del nostro sistema climatico globale.
2025-05-29 22:29:55,049 - INFO - joeynmt.training - Example #3
2025-05-29 22:29:55,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:29:55,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:29:55,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'm@@', 'pi@@', 'azz@@', 'ar@@', 'e@@', ',', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:29:55,050 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:29:55,050 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:29:55,050 - INFO - joeynmt.training - 	Hypothesis: Si può rimpiazzare, in inverno.
2025-05-29 22:29:55,050 - INFO - joeynmt.training - Example #4
2025-05-29 22:29:55,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:29:55,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:29:55,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'm@@', 'em@@', 'or@@', 'ia', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:29:55,050 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:29:55,050 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:29:55,050 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di memoria che è successo negli ultimi 25 anni.
2025-05-29 22:29:58,433 - INFO - joeynmt.training - Epoch   6, Step:    57600, Batch Loss:     1.957807, Batch Acc: 0.478486, Tokens per Sec:    18798, Lr: 0.000300
2025-05-29 22:30:01,818 - INFO - joeynmt.training - Epoch   6, Step:    57700, Batch Loss:     1.803665, Batch Acc: 0.479021, Tokens per Sec:    21241, Lr: 0.000300
2025-05-29 22:30:05,121 - INFO - joeynmt.training - Epoch   6, Step:    57800, Batch Loss:     1.623021, Batch Acc: 0.483200, Tokens per Sec:    22419, Lr: 0.000300
2025-05-29 22:30:08,396 - INFO - joeynmt.training - Epoch   6, Step:    57900, Batch Loss:     1.801627, Batch Acc: 0.481329, Tokens per Sec:    21683, Lr: 0.000300
2025-05-29 22:30:11,684 - INFO - joeynmt.training - Epoch   6, Step:    58000, Batch Loss:     1.670788, Batch Acc: 0.478400, Tokens per Sec:    21602, Lr: 0.000300
2025-05-29 22:30:11,684 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:30:11,684 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:30:20,383 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.50, generation: 8.6869[sec], evaluation: 0.0000[sec]
2025-05-29 22:30:20,736 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/55500.ckpt
2025-05-29 22:30:20,757 - INFO - joeynmt.training - Example #0
2025-05-29 22:30:20,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:30:20,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:30:20,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'par@@', 'ti', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'a', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'le', 'persone', 'che', 'si', 'chiam@@', 'ano', 'il', '4@@', '8@@', '%', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'questi', '4@@', '8@@', ',', 'e', 'il', '4@@', '0@@', '%', 'di', 'questi', '4@@', '8@@', '<unk>', '.', '</s>']
2025-05-29 22:30:20,758 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:30:20,758 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:30:20,758 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso queste due parti di ghiaccio, che l<unk> industria artica, che le persone che si chiamano il 48% di tre milioni di anni di questi 48, e il 40% di questi 48<unk> .
2025-05-29 22:30:20,758 - INFO - joeynmt.training - Example #1
2025-05-29 22:30:20,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:30:20,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:30:20,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'l@@', '<unk>', 'in@@', 'st@@', 'all@@', 'azione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:30:20,759 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:30:20,759 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:30:20,759 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, l<unk> installazione di questo particolare problemi di questo particolare problemi di ghiaccio.
2025-05-29 22:30:20,759 - INFO - joeynmt.training - Example #2
2025-05-29 22:30:20,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:30:20,760 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:30:20,760 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:30:20,760 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:30:20,760 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:30:20,760 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo di ghiaccio, il cuore globale di climatico.
2025-05-29 22:30:20,760 - INFO - joeynmt.training - Example #3
2025-05-29 22:30:20,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:30:20,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:30:20,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'lo', 'sp@@', 'azi@@', 'o', 'in', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:30:20,761 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:30:20,761 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:30:20,761 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, in inverno, e lo spazio in un sommergibile.
2025-05-29 22:30:20,761 - INFO - joeynmt.training - Example #4
2025-05-29 22:30:20,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:30:20,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:30:20,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'po@@', '<unk>', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'po@@', '<unk>', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'po@@', '<unk>', 'di', 'tem@@', 'po@@', '.', '</s>']
2025-05-29 22:30:20,762 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:30:20,762 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:30:20,762 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un disegno di un disegno di un disegno di un disegno di un disegno di un disegno di un po<unk> di disegno di un po<unk> di disegno di un pezzo di disegno di un po<unk> di tempo.
2025-05-29 22:30:24,037 - INFO - joeynmt.training - Epoch   6, Step:    58100, Batch Loss:     1.782251, Batch Acc: 0.476660, Tokens per Sec:    18358, Lr: 0.000300
2025-05-29 22:30:27,292 - INFO - joeynmt.training - Epoch   6, Step:    58200, Batch Loss:     1.570603, Batch Acc: 0.480511, Tokens per Sec:    21700, Lr: 0.000300
2025-05-29 22:30:30,580 - INFO - joeynmt.training - Epoch   6, Step:    58300, Batch Loss:     1.643872, Batch Acc: 0.484180, Tokens per Sec:    21599, Lr: 0.000300
2025-05-29 22:30:33,968 - INFO - joeynmt.training - Epoch   6, Step:    58400, Batch Loss:     1.934211, Batch Acc: 0.479031, Tokens per Sec:    21244, Lr: 0.000300
2025-05-29 22:30:37,353 - INFO - joeynmt.training - Epoch   6, Step:    58500, Batch Loss:     1.604192, Batch Acc: 0.481222, Tokens per Sec:    21127, Lr: 0.000300
2025-05-29 22:30:37,353 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:30:37,353 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:30:46,489 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.50, generation: 9.1246[sec], evaluation: 0.0000[sec]
2025-05-29 22:30:46,882 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/57500.ckpt
2025-05-29 22:30:46,910 - INFO - joeynmt.training - Example #0
2025-05-29 22:30:46,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:30:46,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:30:46,910 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'guard@@', 'are', 'il', '4@@', '8@@', '%', 'di', 'c@@', 'ent@@', 'in@@', 'a@@', 'ia', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'av@@', 'evano', 'fatto', 'per', 'il', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', '4@@', '8@@', '%', 'di', 'questi', '4@@', '8@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:30:46,911 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:30:46,911 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:30:46,911 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per guardare il 48% di centinaia che l<unk> artica, che ha fatto per tre milioni di anni di anni che avevano fatto per il 48% dei più grandi 48% di questi 480 per cento.
2025-05-29 22:30:46,911 - INFO - joeynmt.training - Example #1
2025-05-29 22:30:46,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:30:46,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:30:46,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questa', 's@@', 'itu@@', 'azione', 'di', 'questo', 'part@@', 'icol@@', 'ar@@', 'e@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:30:46,912 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:30:46,912 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:30:46,912 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questa situazione di questo particolare, perché non c<unk> è il Dicke del ghiaccio.
2025-05-29 22:30:46,912 - INFO - joeynmt.training - Example #2
2025-05-29 22:30:46,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:30:46,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:30:46,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'è', 'la', 'c@@', 'at@@', 'en@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 22:30:46,913 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:30:46,913 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:30:46,913 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la catena di ghiacciaio di il nostro sistema climatico globale di climatica.
2025-05-29 22:30:46,913 - INFO - joeynmt.training - Example #3
2025-05-29 22:30:46,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:30:46,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:30:46,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 'f@@', 'ut@@', 'uro', 'in', 'un', 'f@@', 'ut@@', 'uro', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:30:46,914 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:30:46,914 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:30:46,914 - INFO - joeynmt.training - 	Hypothesis: Sta crescita in inverno e in un futuro in un futuro di sommergibile.
2025-05-29 22:30:46,914 - INFO - joeynmt.training - Example #4
2025-05-29 22:30:46,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:30:46,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:30:46,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:30:46,915 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:30:46,915 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:30:46,915 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è un disegno di un disegno di disegno di un disegno di quei 25 anni.
2025-05-29 22:30:50,344 - INFO - joeynmt.training - Epoch   6, Step:    58600, Batch Loss:     1.637133, Batch Acc: 0.483314, Tokens per Sec:    18881, Lr: 0.000300
2025-05-29 22:30:53,720 - INFO - joeynmt.training - Epoch   6, Step:    58700, Batch Loss:     1.732401, Batch Acc: 0.480587, Tokens per Sec:    21716, Lr: 0.000300
2025-05-29 22:30:57,116 - INFO - joeynmt.training - Epoch   6, Step:    58800, Batch Loss:     1.835834, Batch Acc: 0.480129, Tokens per Sec:    21032, Lr: 0.000300
2025-05-29 22:31:00,499 - INFO - joeynmt.training - Epoch   6, Step:    58900, Batch Loss:     1.715944, Batch Acc: 0.476117, Tokens per Sec:    20958, Lr: 0.000300
2025-05-29 22:31:03,880 - INFO - joeynmt.training - Epoch   6, Step:    59000, Batch Loss:     1.667992, Batch Acc: 0.481973, Tokens per Sec:    20720, Lr: 0.000300
2025-05-29 22:31:03,880 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:31:03,881 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:31:13,504 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.26, acc:   0.50, generation: 9.6112[sec], evaluation: 0.0000[sec]
2025-05-29 22:31:13,504 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:31:14,078 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/57000.ckpt
2025-05-29 22:31:14,104 - INFO - joeynmt.training - Example #0
2025-05-29 22:31:14,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:31:14,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:31:14,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'sono', 'stati', 'in@@', 'tor@@', 'no', 'a', '4@@', '8@@', '%', 'di', 'questi', 'sono', 'stati', 'con@@', 'v@@', 'in@@', 'ti', 'di', '4@@', '8@@', '%', 'di', 'questi', 'due', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:31:14,105 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:31:14,105 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:31:14,105 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso, ho mostrato queste due diapositive per ridurre che le ghiacciate che l<unk> articolo che i ghiaccio, che sono stati intorno a 48% di questi sono stati convinti di 48% di questi due stati.
2025-05-29 22:31:14,105 - INFO - joeynmt.training - Example #1
2025-05-29 22:31:14,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:31:14,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:31:14,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'p@@', 'oco', 'che', 'è', 'stato', 'un', 'problema', 'di', 'ris@@', 'ol@@', 'vere', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'un', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'es@@', 'c@@', 'e@@', '.', '</s>']
2025-05-29 22:31:14,106 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:31:14,106 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:31:14,106 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di poco che è stato un problema di risolvere questo problema, perché non è un motivo per cui non è il dell<unk> isesce.
2025-05-29 22:31:14,106 - INFO - joeynmt.training - Example #2
2025-05-29 22:31:14,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:31:14,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:31:14,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'd@@', 'ell@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:31:14,107 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:31:14,107 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:31:14,107 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> artico dell<unk> articolo del nostro sistema climatico globale del nostro sistema climatico globale.
2025-05-29 22:31:14,107 - INFO - joeynmt.training - Example #3
2025-05-29 22:31:14,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:31:14,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:31:14,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'in', 'l@@', '<unk>', 'est@@', 'ate', 'in', 'l@@', '<unk>', 'est@@', 'ate', 'di', 'sc@@', 'al@@', 'a@@', '.', '</s>']
2025-05-29 22:31:14,107 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:31:14,108 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:31:14,108 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, e si rivela in l<unk> estate in l<unk> estate di scala.
2025-05-29 22:31:14,108 - INFO - joeynmt.training - Example #4
2025-05-29 22:31:14,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:31:14,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:31:14,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'li@@', 'vello', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'di@@', 'men@@', 'sione', 'di', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:31:14,108 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:31:14,108 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:31:14,108 - INFO - joeynmt.training - 	Hypothesis: Il prossimo livello che vi mostrerò è una dimostrazione di una dimensione di una cosa che è successo negli ultimi 25 anni.
2025-05-29 22:31:17,533 - INFO - joeynmt.training - Epoch   6, Step:    59100, Batch Loss:     1.857773, Batch Acc: 0.477371, Tokens per Sec:    17753, Lr: 0.000300
2025-05-29 22:31:20,935 - INFO - joeynmt.training - Epoch   6, Step:    59200, Batch Loss:     1.727305, Batch Acc: 0.477392, Tokens per Sec:    21343, Lr: 0.000300
2025-05-29 22:31:24,311 - INFO - joeynmt.training - Epoch   6, Step:    59300, Batch Loss:     1.928511, Batch Acc: 0.481753, Tokens per Sec:    20594, Lr: 0.000300
2025-05-29 22:31:27,692 - INFO - joeynmt.training - Epoch   6, Step:    59400, Batch Loss:     1.652177, Batch Acc: 0.484222, Tokens per Sec:    21407, Lr: 0.000300
2025-05-29 22:31:31,079 - INFO - joeynmt.training - Epoch   6, Step:    59500, Batch Loss:     1.580975, Batch Acc: 0.482296, Tokens per Sec:    20427, Lr: 0.000300
2025-05-29 22:31:31,079 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:31:31,079 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:31:40,911 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.26, acc:   0.50, generation: 9.8237[sec], evaluation: 0.0000[sec]
2025-05-29 22:31:41,246 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/56000.ckpt
2025-05-29 22:31:41,272 - INFO - joeynmt.training - Example #0
2025-05-29 22:31:41,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:31:41,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:31:41,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'per', 'c@@', 'aus@@', 'are', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'chiam@@', 'ato', 'il', '4@@', '8@@', '%', 'di', 'questi', 'due', 'milioni', 'di', 'anni', 'per', 'la', 'c@@', 'ent@@', 'u@@', 'si@@', 'as@@', 'm@@', 'ati@@', 'ch@@', 'e@@', '.', '</s>']
2025-05-29 22:31:41,273 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:31:41,273 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:31:41,273 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per dimostrare che le ghiacciate che le ghiacciate per causare i tre milioni di anni che hanno chiamato il 48% di questi due milioni di anni per la centusiasmatiche.
2025-05-29 22:31:41,273 - INFO - joeynmt.training - Example #1
2025-05-29 22:31:41,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:31:41,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:31:41,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'ic@@', 'eb@@', 'er@@', 'e@@', '.', '</s>']
2025-05-29 22:31:41,274 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:31:41,274 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:31:41,274 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la capacità di questo particolare problemi di questo particolare problemi di ghiaccia, perché non è il dell<unk> icebere.
2025-05-29 22:31:41,274 - INFO - joeynmt.training - Example #2
2025-05-29 22:31:41,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:31:41,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:31:41,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'c@@', 'aus@@', 'a', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 22:31:41,275 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:31:41,275 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:31:41,275 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio che è la causa di causa di climatica.
2025-05-29 22:31:41,275 - INFO - joeynmt.training - Example #3
2025-05-29 22:31:41,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:31:41,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:31:41,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'vel@@', 'are', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'n@@', 'ell@@', '<unk>', 'est@@', 'i@@', 'gi@@', 'os@@', 'a@@', '.', '</s>']
2025-05-29 22:31:41,276 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:31:41,276 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:31:41,276 - INFO - joeynmt.training - 	Hypothesis: Si può rivelare in inverno, e si rivela nell<unk> estigiosa.
2025-05-29 22:31:41,276 - INFO - joeynmt.training - Example #4
2025-05-29 22:31:41,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:31:41,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:31:41,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'di@@', 'apos@@', 'iti@@', 'v@@', 'a@@', ',', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:31:41,277 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:31:41,277 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:31:41,277 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimensione di diapositiva, è successo negli ultimi 25 anni.
2025-05-29 22:31:44,689 - INFO - joeynmt.training - Epoch   6, Step:    59600, Batch Loss:     1.646405, Batch Acc: 0.472450, Tokens per Sec:    18950, Lr: 0.000300
2025-05-29 22:31:48,097 - INFO - joeynmt.training - Epoch   6, Step:    59700, Batch Loss:     1.616098, Batch Acc: 0.483438, Tokens per Sec:    21213, Lr: 0.000300
2025-05-29 22:31:51,494 - INFO - joeynmt.training - Epoch   6, Step:    59800, Batch Loss:     1.716145, Batch Acc: 0.478740, Tokens per Sec:    21130, Lr: 0.000300
2025-05-29 22:31:54,876 - INFO - joeynmt.training - Epoch   6, Step:    59900, Batch Loss:     1.741295, Batch Acc: 0.477897, Tokens per Sec:    21225, Lr: 0.000300
2025-05-29 22:31:58,258 - INFO - joeynmt.training - Epoch   6, Step:    60000, Batch Loss:     1.815956, Batch Acc: 0.480212, Tokens per Sec:    21397, Lr: 0.000300
2025-05-29 22:31:58,259 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:31:58,259 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:32:06,897 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.51, generation: 8.6269[sec], evaluation: 0.0000[sec]
2025-05-29 22:32:06,898 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:32:07,484 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/58500.ckpt
2025-05-29 22:32:07,511 - INFO - joeynmt.training - Example #0
2025-05-29 22:32:07,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:32:07,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:32:07,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'ire', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'si', 'chiam@@', 'a', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', 'anni', 'che', 'si', 'è', 'ri@@', 'ma@@', 'sto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 'un', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 's@@', 'ott@@', 'o@@', '.', '</s>']
2025-05-29 22:32:07,512 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:32:07,512 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:32:07,512 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per conseguire le ghiacciaio di artico, che i ghiacciano per tre milioni di anni che si chiama 48% dei più grandi anni che si è rimasto per il 40 per cento di questi due anni per cento di un 40 per cento di questi due anni per cento di sotto.
2025-05-29 22:32:07,512 - INFO - joeynmt.training - Example #1
2025-05-29 22:32:07,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:32:07,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:32:07,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'di@@', 're@@', 'zione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:32:07,513 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:32:07,513 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:32:07,513 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la direzione di questo particolare problemi di questo particolare problemi di ghiaccio.
2025-05-29 22:32:07,513 - INFO - joeynmt.training - Example #2
2025-05-29 22:32:07,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:32:07,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:32:07,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:32:07,514 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:32:07,514 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:32:07,514 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di climatico, il cuore artico, il nostro sistema di climatico.
2025-05-29 22:32:07,514 - INFO - joeynmt.training - Example #3
2025-05-29 22:32:07,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:32:07,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:32:07,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'nel', 'vent@@', 'o@@', ',', 'e', 'si', 'ri@@', 'vol@@', 'gono', 'in', 'gi@@', 'ro@@', '.', '</s>']
2025-05-29 22:32:07,515 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:32:07,515 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:32:07,515 - INFO - joeynmt.training - 	Hypothesis: Sta crescita nel vento, e si rivolgono in giro.
2025-05-29 22:32:07,515 - INFO - joeynmt.training - Example #4
2025-05-29 22:32:07,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:32:07,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:32:07,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'anno', 'succ@@', 'essi@@', 'vo', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'cosa', 'succ@@', 'ede', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:32:07,516 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:32:07,516 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:32:07,516 - INFO - joeynmt.training - 	Hypothesis: Il prossimo anno successivo è che vi mostrerò è un disegno di un certo senso di cosa succede negli ultimi 25 anni.
2025-05-29 22:32:10,927 - INFO - joeynmt.training - Epoch   6, Step:    60100, Batch Loss:     1.841962, Batch Acc: 0.484827, Tokens per Sec:    17338, Lr: 0.000300
2025-05-29 22:32:14,305 - INFO - joeynmt.training - Epoch   6, Step:    60200, Batch Loss:     1.689581, Batch Acc: 0.477191, Tokens per Sec:    20624, Lr: 0.000300
2025-05-29 22:32:17,691 - INFO - joeynmt.training - Epoch   6, Step:    60300, Batch Loss:     1.771073, Batch Acc: 0.481372, Tokens per Sec:    21503, Lr: 0.000300
2025-05-29 22:32:21,079 - INFO - joeynmt.training - Epoch   6, Step:    60400, Batch Loss:     1.647375, Batch Acc: 0.480204, Tokens per Sec:    21311, Lr: 0.000300
2025-05-29 22:32:24,478 - INFO - joeynmt.training - Epoch   6, Step:    60500, Batch Loss:     1.700917, Batch Acc: 0.478287, Tokens per Sec:    21143, Lr: 0.000300
2025-05-29 22:32:24,479 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:32:24,479 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:32:32,530 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.51, generation: 8.0429[sec], evaluation: 0.0000[sec]
2025-05-29 22:32:32,530 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:32:33,034 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/58000.ckpt
2025-05-29 22:32:33,057 - INFO - joeynmt.training - Example #0
2025-05-29 22:32:33,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:32:33,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:32:33,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questi', 'due', 'di@@', 'ec@@', 'i', 'di', 's@@', 'ett@@', 'ori', 'per', 'con@@', 'si@@', 'der@@', 'are', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'ha', 'chiam@@', 'ato', 'i', '3@@', '0@@', '<unk>', '.', '</s>']
2025-05-29 22:32:33,058 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:32:33,058 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:32:33,058 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questi due dieci di settori per considerare che le ghiaccio, che le ghiaccia, che ha chiamato i 30<unk> .
2025-05-29 22:32:33,059 - INFO - joeynmt.training - Example #1
2025-05-29 22:32:33,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:32:33,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:32:33,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'stato', 'il', 'problema', 'di', 'questo', 'problema', 'è', 'che', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'ar@@', 'ea', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:32:33,059 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:32:33,059 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:32:33,060 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che è stato il problema di questo problema è che non è il dell<unk> area del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 22:32:33,060 - INFO - joeynmt.training - Example #2
2025-05-29 22:32:33,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:32:33,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:32:33,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:32:33,060 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:32:33,060 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:32:33,060 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio di ghiaccio, il cuore globale.
2025-05-29 22:32:33,060 - INFO - joeynmt.training - Example #3
2025-05-29 22:32:33,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:32:33,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:32:33,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:32:33,061 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:32:33,061 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:32:33,061 - INFO - joeynmt.training - 	Hypothesis: Si può essere in inverno, in inverno.
2025-05-29 22:32:33,061 - INFO - joeynmt.training - Example #4
2025-05-29 22:32:33,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:32:33,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:32:33,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:32:33,062 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:32:33,062 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:32:33,062 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è che è successo negli ultimi 25 anni.
2025-05-29 22:32:36,463 - INFO - joeynmt.training - Epoch   6, Step:    60600, Batch Loss:     1.667558, Batch Acc: 0.481033, Tokens per Sec:    17605, Lr: 0.000300
2025-05-29 22:32:39,841 - INFO - joeynmt.training - Epoch   6, Step:    60700, Batch Loss:     1.654250, Batch Acc: 0.477323, Tokens per Sec:    19842, Lr: 0.000300
2025-05-29 22:32:43,240 - INFO - joeynmt.training - Epoch   6, Step:    60800, Batch Loss:     1.783924, Batch Acc: 0.476240, Tokens per Sec:    21164, Lr: 0.000300
2025-05-29 22:32:46,634 - INFO - joeynmt.training - Epoch   6, Step:    60900, Batch Loss:     1.764785, Batch Acc: 0.475959, Tokens per Sec:    21259, Lr: 0.000300
2025-05-29 22:32:50,042 - INFO - joeynmt.training - Epoch   6, Step:    61000, Batch Loss:     1.645218, Batch Acc: 0.481254, Tokens per Sec:    21725, Lr: 0.000300
2025-05-29 22:32:50,042 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:32:50,043 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:32:57,934 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.51, generation: 7.8804[sec], evaluation: 0.0000[sec]
2025-05-29 22:32:57,935 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:32:58,441 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/56500.ckpt
2025-05-29 22:32:58,464 - INFO - joeynmt.training - Example #0
2025-05-29 22:32:58,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:32:58,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:32:58,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questi', 'due', 'di@@', 'str@@', 'utt@@', 'a@@', ',', 'per', 'vedere', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cia', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'ha', 'chiam@@', 'ato', '4@@', '8', 'milioni', 'di', 'anni', 'di', 'anni', 'per', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:32:58,465 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:32:58,465 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:32:58,465 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questi due distrutta, per vedere le ghiaccio, che la ghiaccia di ghiaccio che i ghiaccio, che ha chiamato 48 milioni di anni di anni per 48 stati.
2025-05-29 22:32:58,465 - INFO - joeynmt.training - Example #1
2025-05-29 22:32:58,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:32:58,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:32:58,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'in@@', 't@@', 'eg@@', 'r@@', 'ale', 'che', 'non', 'è', 'un', 'problema', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'è', 'la', 'di@@', 'mostr@@', 'azione', 'che', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'a@@', '.', '</s>']
2025-05-29 22:32:58,466 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:32:58,466 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:32:58,466 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte integrale che non è un problema speciale che non è la dimostrazione che non è il dell<unk> ora.
2025-05-29 22:32:58,466 - INFO - joeynmt.training - Example #2
2025-05-29 22:32:58,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:32:58,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:32:58,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'il', 'cu@@', 'ore', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:32:58,467 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:32:58,467 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:32:58,467 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio è il cuore di ghiaccio che il nostro sistema climatico.
2025-05-29 22:32:58,467 - INFO - joeynmt.training - Example #3
2025-05-29 22:32:58,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:32:58,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:32:58,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'sp@@', 'ost@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:32:58,467 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:32:58,468 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:32:58,468 - INFO - joeynmt.training - 	Hypothesis: E si può essere in inverno, e si sposta in inverno.
2025-05-29 22:32:58,468 - INFO - joeynmt.training - Example #4
2025-05-29 22:32:58,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:32:58,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:32:58,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'ec@@', 'i', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:32:58,468 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:32:58,468 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:32:58,468 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un disegno di dieci anni.
2025-05-29 22:33:01,802 - INFO - joeynmt.training - Epoch   6, Step:    61100, Batch Loss:     1.838831, Batch Acc: 0.477040, Tokens per Sec:    18326, Lr: 0.000300
2025-05-29 22:33:05,196 - INFO - joeynmt.training - Epoch   6, Step:    61200, Batch Loss:     1.876693, Batch Acc: 0.490016, Tokens per Sec:    20968, Lr: 0.000300
2025-05-29 22:33:08,609 - INFO - joeynmt.training - Epoch   6, Step:    61300, Batch Loss:     1.778396, Batch Acc: 0.476904, Tokens per Sec:    20938, Lr: 0.000300
2025-05-29 22:33:12,001 - INFO - joeynmt.training - Epoch   6, Step:    61400, Batch Loss:     1.597388, Batch Acc: 0.484896, Tokens per Sec:    21242, Lr: 0.000300
2025-05-29 22:33:15,400 - INFO - joeynmt.training - Epoch   6, Step:    61500, Batch Loss:     1.767506, Batch Acc: 0.477250, Tokens per Sec:    20648, Lr: 0.000300
2025-05-29 22:33:15,400 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:33:15,400 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:33:23,296 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.50, generation: 7.8886[sec], evaluation: 0.0000[sec]
2025-05-29 22:33:23,784 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/59500.ckpt
2025-05-29 22:33:23,810 - INFO - joeynmt.training - Example #0
2025-05-29 22:33:23,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:33:23,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:33:23,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'en@@', 'z@@', 'a@@', ',', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'è', 'stato', 'in@@', 'segn@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'si', 'è', 'sc@@', 'rit@@', 't@@', 'ura', 'di', 'circa', '4@@', '8', 'st@@', 'ati@@', ',', 'il', '4@@', '8@@', ',', 'il', '4@@', '8@@', '0@@', '%', 'di', 'c@@', 'ento', 'di', 'st@@', 'at@@', 'un@@', 'it@@', 'en@@', 'z@@', 'a@@', '.', '</s>']
2025-05-29 22:33:23,811 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:33:23,811 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:33:23,811 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per conseguenza, per ridurre che l<unk> articolo artico, che è stato insegnato per tre milioni di anni di anni che si è scrittura di circa 48 stati, il 48, il 480% di cento di statunitenza.
2025-05-29 22:33:23,811 - INFO - joeynmt.training - Example #1
2025-05-29 22:33:23,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:33:23,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:33:23,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'st@@', 'anza', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 't@@', 'as@@', 'so', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'ol@@', 'o@@', '.', '</s>']
2025-05-29 22:33:23,812 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:33:23,812 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:33:23,812 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la stanza di questo problema, perché non c<unk> è il tasso di questo problema, perché non è il dell<unk> isolo.
2025-05-29 22:33:23,812 - INFO - joeynmt.training - Example #2
2025-05-29 22:33:23,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:33:23,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:33:23,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'c@@', 'aus@@', 'a', 'della', 'nostra', 'c@@', 'li@@', 'ma', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:33:23,813 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:33:23,813 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:33:23,813 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa della causa della nostra clima globale.
2025-05-29 22:33:23,813 - INFO - joeynmt.training - Example #3
2025-05-29 22:33:23,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:33:23,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:33:23,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'pot@@', 'eva', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:33:23,814 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:33:23,814 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:33:23,814 - INFO - joeynmt.training - 	Hypothesis: Si poteva essere in inverno, e si rivela e in un certo senso.
2025-05-29 22:33:23,814 - INFO - joeynmt.training - Example #4
2025-05-29 22:33:23,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:33:23,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:33:23,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'in', 'questo', 'mo@@', 'd@@', 'o@@', ',', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:33:23,815 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:33:23,815 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:33:23,815 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo in questo modo, è successo negli ultimi 25 anni.
2025-05-29 22:33:27,159 - INFO - joeynmt.training - Epoch   6, Step:    61600, Batch Loss:     1.774110, Batch Acc: 0.487382, Tokens per Sec:    18025, Lr: 0.000300
2025-05-29 22:33:30,490 - INFO - joeynmt.training - Epoch   6, Step:    61700, Batch Loss:     1.713402, Batch Acc: 0.479701, Tokens per Sec:    20898, Lr: 0.000300
2025-05-29 22:33:33,776 - INFO - joeynmt.training - Epoch   6, Step:    61800, Batch Loss:     1.784657, Batch Acc: 0.481744, Tokens per Sec:    21755, Lr: 0.000300
2025-05-29 22:33:37,065 - INFO - joeynmt.training - Epoch   6, Step:    61900, Batch Loss:     1.622710, Batch Acc: 0.480758, Tokens per Sec:    21677, Lr: 0.000300
2025-05-29 22:33:40,370 - INFO - joeynmt.training - Epoch   6, Step:    62000, Batch Loss:     1.752059, Batch Acc: 0.474980, Tokens per Sec:    21758, Lr: 0.000300
2025-05-29 22:33:40,370 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:33:40,370 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:33:47,214 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.51, generation: 6.8365[sec], evaluation: 0.0000[sec]
2025-05-29 22:33:47,214 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:33:47,688 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/59000.ckpt
2025-05-29 22:33:47,707 - INFO - joeynmt.training - Example #0
2025-05-29 22:33:47,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:33:47,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:33:47,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'le', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'en@@', 'z@@', 'a@@', ',', 'per', 'f@@', 'ar', 's@@', 'ì', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '8@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'che', 'si', 'è', 'sc@@', 'oper@@', 'to', 'che', 'i', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '8@@', '0@@', '%', 'di', 'questi', 'str@@', 'um@@', 'enti', 'di', '4@@', '8@@', '0@@', '%', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:33:47,708 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:33:47,708 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:33:47,708 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno le due diapositive per conseguenza, per far sì che la ghiaccio artico che ha avuto il 4880 per cento di anni che si è scoperto che i 480 per cento di 480% di questi strumenti di 480% di cento.
2025-05-29 22:33:47,709 - INFO - joeynmt.training - Example #1
2025-05-29 22:33:47,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:33:47,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:33:47,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'non', 'è', 'la', 'prima', 'volta', 'che', 'non', 'c@@', '<unk>', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'c@@', '<unk>', 'è', 'la', 'di@@', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:33:47,709 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:33:47,709 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:33:47,709 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la prima volta che la prima volta che non è la prima volta che non c<unk> è la dimostra che non c<unk> è la dimostra il ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 22:33:47,709 - INFO - joeynmt.training - Example #2
2025-05-29 22:33:47,710 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:33:47,710 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:33:47,710 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:33:47,710 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:33:47,710 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:33:47,710 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio artico, il cuore del nostro sistema di climatico.
2025-05-29 22:33:47,710 - INFO - joeynmt.training - Example #3
2025-05-29 22:33:47,710 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:33:47,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:33:47,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'fer@@', 'ire', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:33:47,711 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:33:47,711 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:33:47,711 - INFO - joeynmt.training - 	Hypothesis: Si può riferire in inverno.
2025-05-29 22:33:47,711 - INFO - joeynmt.training - Example #4
2025-05-29 22:33:47,711 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:33:47,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:33:47,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:33:47,712 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:33:47,712 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:33:47,712 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un disegno di disegno di quello che è successo negli ultimi 25 anni.
2025-05-29 22:33:51,044 - INFO - joeynmt.training - Epoch   6, Step:    62100, Batch Loss:     1.780339, Batch Acc: 0.481726, Tokens per Sec:    18737, Lr: 0.000300
2025-05-29 22:33:54,356 - INFO - joeynmt.training - Epoch   6, Step:    62200, Batch Loss:     1.773826, Batch Acc: 0.479383, Tokens per Sec:    21203, Lr: 0.000300
2025-05-29 22:33:57,669 - INFO - joeynmt.training - Epoch   6, Step:    62300, Batch Loss:     1.588530, Batch Acc: 0.478460, Tokens per Sec:    21572, Lr: 0.000300
2025-05-29 22:34:00,956 - INFO - joeynmt.training - Epoch   6, Step:    62400, Batch Loss:     1.791515, Batch Acc: 0.480059, Tokens per Sec:    21339, Lr: 0.000300
2025-05-29 22:34:04,277 - INFO - joeynmt.training - Epoch   6, Step:    62500, Batch Loss:     1.767795, Batch Acc: 0.479042, Tokens per Sec:    21832, Lr: 0.000300
2025-05-29 22:34:04,278 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:34:04,278 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:34:12,376 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.51, generation: 8.0901[sec], evaluation: 0.0000[sec]
2025-05-29 22:34:12,376 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:34:12,857 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/61500.ckpt
2025-05-29 22:34:12,879 - INFO - joeynmt.training - Example #0
2025-05-29 22:34:12,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:34:12,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:34:12,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'stru@@', 'g@@', 'g@@', 'g@@', 'ere', 'per', 's@@', 'é', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'per', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:34:12,880 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:34:12,880 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:34:12,880 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due distrugggere per sé che l<unk> articolo che i ghiacciano che i ghiacciati per tre milioni di anni di anni di 48 per cento di anni di 48 per cento di anni per 48 per cento di anni.
2025-05-29 22:34:12,881 - INFO - joeynmt.training - Example #1
2025-05-29 22:34:12,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:34:12,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:34:12,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'st@@', 'amp@@', 'a', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'la', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:34:12,881 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:34:12,881 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:34:12,881 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la stampa di questo problema, perché non c<unk> è la dell<unk> origine del ghiaccio.
2025-05-29 22:34:12,881 - INFO - joeynmt.training - Example #2
2025-05-29 22:34:12,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:34:12,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:34:12,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sen@@', 'so', 'di', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:34:12,882 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:34:12,882 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:34:12,882 - INFO - joeynmt.training - 	Hypothesis: In un senso di senso è la causa del ghiaccio, il cuore del nostro climatico globale.
2025-05-29 22:34:12,882 - INFO - joeynmt.training - Example #3
2025-05-29 22:34:12,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:34:12,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:34:12,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'ri@@', 'ma@@', 'sto', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'es@@', 'ce', 'a', 'ri@@', 'vol@@', 'u@@', 'zion@@', 'e@@', '.', '</s>']
2025-05-29 22:34:12,883 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:34:12,883 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:34:12,883 - INFO - joeynmt.training - 	Hypothesis: Si può essere rimasto in inverno, e si riesce a rivoluzione.
2025-05-29 22:34:12,883 - INFO - joeynmt.training - Example #4
2025-05-29 22:34:12,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:34:12,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:34:12,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:34:12,884 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:34:12,884 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:34:12,884 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un disegno di disegno di un disegno di un disegno di quei 25 anni.
2025-05-29 22:34:16,175 - INFO - joeynmt.training - Epoch   6, Step:    62600, Batch Loss:     1.620155, Batch Acc: 0.482853, Tokens per Sec:    18662, Lr: 0.000300
2025-05-29 22:34:19,448 - INFO - joeynmt.training - Epoch   6, Step:    62700, Batch Loss:     1.511990, Batch Acc: 0.486343, Tokens per Sec:    22436, Lr: 0.000300
2025-05-29 22:34:22,721 - INFO - joeynmt.training - Epoch   6, Step:    62800, Batch Loss:     1.730332, Batch Acc: 0.486949, Tokens per Sec:    22315, Lr: 0.000300
2025-05-29 22:34:26,062 - INFO - joeynmt.training - Epoch   6, Step:    62900, Batch Loss:     1.653417, Batch Acc: 0.480967, Tokens per Sec:    20838, Lr: 0.000300
2025-05-29 22:34:29,420 - INFO - joeynmt.training - Epoch   6, Step:    63000, Batch Loss:     1.691080, Batch Acc: 0.480556, Tokens per Sec:    21166, Lr: 0.000300
2025-05-29 22:34:29,420 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:34:29,420 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:34:38,374 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.51, generation: 8.9422[sec], evaluation: 0.0000[sec]
2025-05-29 22:34:38,374 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:34:38,885 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/60000.ckpt
2025-05-29 22:34:38,902 - INFO - joeynmt.training - Example #0
2025-05-29 22:34:38,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:34:38,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:34:38,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questa', 'sc@@', 'or@@', 'sa', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'che', 'ha', 'chiam@@', 'ato', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'che', 'av@@', 'evano', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 't@@', 'ag@@', 'li@@', '.', '</s>']
2025-05-29 22:34:38,904 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:34:38,904 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:34:38,904 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di questa scorsa che l<unk> anno scorso che l<unk> anno scorso articolo, che l<unk> articolo, che ha chiamato il 40 per cento di anni che avevano il 40 percento di anni per il 40 percento di anni per il 40% dei tagli.
2025-05-29 22:34:38,904 - INFO - joeynmt.training - Example #1
2025-05-29 22:34:38,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:34:38,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:34:38,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'ci', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:34:38,905 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:34:38,905 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:34:38,905 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la prima volta che la prima volta che non è la dimostra questo problema, perché non ci mostra il dell<unk> originale.
2025-05-29 22:34:38,905 - INFO - joeynmt.training - Example #2
2025-05-29 22:34:38,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:34:38,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:34:38,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'ur@@', 'va', 'del', 'cu@@', 'ore', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:34:38,906 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:34:38,906 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:34:38,906 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la curva del cuore articolo, il cuore del nostro sistema climatico globale.
2025-05-29 22:34:38,906 - INFO - joeynmt.training - Example #3
2025-05-29 22:34:38,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:34:38,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:34:38,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'dur@@', 're', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'in', 'm@@', 'ezz@@', 'o@@', '.', '</s>']
2025-05-29 22:34:38,906 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:34:38,906 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:34:38,907 - INFO - joeynmt.training - 	Hypothesis: Si può ridurre in inverno, e in mezzo.
2025-05-29 22:34:38,907 - INFO - joeynmt.training - Example #4
2025-05-29 22:34:38,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:34:38,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:34:38,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'd@@', 'ell@@', '<unk>', 'ulti@@', 'mo', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:34:38,907 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:34:38,907 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:34:38,907 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un disegno di disegno dell<unk> ultimo 25 anni.
2025-05-29 22:34:42,280 - INFO - joeynmt.training - Epoch   6, Step:    63100, Batch Loss:     1.644967, Batch Acc: 0.484678, Tokens per Sec:    18534, Lr: 0.000300
2025-05-29 22:34:45,620 - INFO - joeynmt.training - Epoch   6, Step:    63200, Batch Loss:     1.759467, Batch Acc: 0.484228, Tokens per Sec:    20716, Lr: 0.000300
2025-05-29 22:34:48,957 - INFO - joeynmt.training - Epoch   6, Step:    63300, Batch Loss:     1.879992, Batch Acc: 0.479904, Tokens per Sec:    20392, Lr: 0.000300
2025-05-29 22:34:52,277 - INFO - joeynmt.training - Epoch   6, Step:    63400, Batch Loss:     1.662636, Batch Acc: 0.487242, Tokens per Sec:    21103, Lr: 0.000300
2025-05-29 22:34:55,583 - INFO - joeynmt.training - Epoch   6, Step:    63500, Batch Loss:     1.696501, Batch Acc: 0.474920, Tokens per Sec:    21947, Lr: 0.000300
2025-05-29 22:34:55,584 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:34:55,584 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:35:04,569 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.51, generation: 8.9774[sec], evaluation: 0.0000[sec]
2025-05-29 22:35:04,913 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/60500.ckpt
2025-05-29 22:35:04,935 - INFO - joeynmt.training - Example #0
2025-05-29 22:35:04,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:35:04,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:35:04,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'ha', 'l@@', '<unk>', 'av@@', 'uto', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'di', 'l@@', '<unk>', 'av@@', 'rebbe', 'fatto', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:35:04,936 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:35:04,936 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:35:04,937 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso queste due diapositive per ridurre che l<unk> anno scorso che l<unk> anno scorso di ghiaccio che ha l<unk> avuto per il 48 per cento di anni di l<unk> avrebbe fatto per il 48 per cento di cento di cento di cento.
2025-05-29 22:35:04,937 - INFO - joeynmt.training - Example #1
2025-05-29 22:35:04,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:35:04,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:35:04,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'problema', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:35:04,937 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:35:04,937 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:35:04,938 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo problema di questo particolare problemi di questo particolare problemi di questo particolare problemi di ghiaccio.
2025-05-29 22:35:04,938 - INFO - joeynmt.training - Example #2
2025-05-29 22:35:04,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:35:04,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:35:04,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:35:04,938 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:35:04,938 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:35:04,938 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo che il cuore del nostro sistema climatico globale.
2025-05-29 22:35:04,938 - INFO - joeynmt.training - Example #3
2025-05-29 22:35:04,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:35:04,939 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:35:04,939 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'vel@@', 'are', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 't@@', 'av@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 22:35:04,939 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:35:04,939 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:35:04,939 - INFO - joeynmt.training - 	Hypothesis: Si può rivelare in inverno e in tavola.
2025-05-29 22:35:04,939 - INFO - joeynmt.training - Example #4
2025-05-29 22:35:04,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:35:04,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:35:04,940 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'ni', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:35:04,940 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:35:04,940 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:35:04,940 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un disegno di disegni di quello che è successo negli ultimi 25 anni.
2025-05-29 22:35:08,335 - INFO - joeynmt.training - Epoch   6, Step:    63600, Batch Loss:     1.900453, Batch Acc: 0.480806, Tokens per Sec:    18749, Lr: 0.000300
2025-05-29 22:35:11,667 - INFO - joeynmt.training - Epoch   6, Step:    63700, Batch Loss:     1.621590, Batch Acc: 0.483733, Tokens per Sec:    21432, Lr: 0.000300
2025-05-29 22:35:15,055 - INFO - joeynmt.training - Epoch   6, Step:    63800, Batch Loss:     1.756905, Batch Acc: 0.482558, Tokens per Sec:    20759, Lr: 0.000300
2025-05-29 22:35:18,452 - INFO - joeynmt.training - Epoch   6, Step:    63900, Batch Loss:     1.521454, Batch Acc: 0.477011, Tokens per Sec:    21616, Lr: 0.000300
2025-05-29 22:35:21,824 - INFO - joeynmt.training - Epoch   6, Step:    64000, Batch Loss:     1.783405, Batch Acc: 0.483158, Tokens per Sec:    20512, Lr: 0.000300
2025-05-29 22:35:21,824 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:35:21,824 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:35:32,413 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.51, generation: 10.5763[sec], evaluation: 0.0000[sec]
2025-05-29 22:35:32,787 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/61000.ckpt
2025-05-29 22:35:32,811 - INFO - joeynmt.training - Example #0
2025-05-29 22:35:32,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:35:32,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:35:32,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'enze', 'per', 'con@@', 'v@@', 'in@@', 'to', 'che', 'l@@', '<unk>', 'inter@@', 'o', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', '4@@', '8@@', ',', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:35:32,812 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:35:32,812 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:35:32,812 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno che ho mostrato questi due diapositive per conseguenze per convinto che l<unk> intero articolo che ha fatto per tre milioni di anni di ghiaccio, il 48, per cento di anni, il 40 per cento di anni.
2025-05-29 22:35:32,812 - INFO - joeynmt.training - Example #1
2025-05-29 22:35:32,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:35:32,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:35:32,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:35:32,813 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:35:32,813 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:35:32,813 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la prima cosa che non è abbastanza la prima cosa che non c<unk> è il Dicke del ghiaccio.
2025-05-29 22:35:32,813 - INFO - joeynmt.training - Example #2
2025-05-29 22:35:32,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:35:32,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:35:32,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'b@@', 'ere', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:35:32,814 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:35:32,814 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:35:32,814 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la causa di ghiacciaio di bere del nostro sistema climatico globale.
2025-05-29 22:35:32,814 - INFO - joeynmt.training - Example #3
2025-05-29 22:35:32,814 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:35:32,814 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:35:32,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'vel@@', 'are', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:35:32,815 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:35:32,815 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:35:32,815 - INFO - joeynmt.training - 	Hypothesis: Si può rivelare in inverno, e in inverno.
2025-05-29 22:35:32,815 - INFO - joeynmt.training - Example #4
2025-05-29 22:35:32,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:35:32,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:35:32,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'apos@@', 'iti@@', 'vo', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:35:32,816 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:35:32,816 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:35:32,816 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostrerò è una cosa che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 22:35:36,232 - INFO - joeynmt.training - Epoch   6, Step:    64100, Batch Loss:     1.622582, Batch Acc: 0.478863, Tokens per Sec:    19384, Lr: 0.000300
2025-05-29 22:35:39,622 - INFO - joeynmt.training - Epoch   6, Step:    64200, Batch Loss:     1.891366, Batch Acc: 0.475077, Tokens per Sec:    20039, Lr: 0.000300
2025-05-29 22:35:39,624 - INFO - joeynmt.training - Epoch   6: total training loss 18495.74
2025-05-29 22:35:39,624 - INFO - joeynmt.training - EPOCH 7
2025-05-29 22:35:43,031 - INFO - joeynmt.training - Epoch   7, Step:    64300, Batch Loss:     1.385023, Batch Acc: 0.488790, Tokens per Sec:    20901, Lr: 0.000300
2025-05-29 22:35:46,410 - INFO - joeynmt.training - Epoch   7, Step:    64400, Batch Loss:     1.632255, Batch Acc: 0.488990, Tokens per Sec:    20690, Lr: 0.000300
2025-05-29 22:35:49,807 - INFO - joeynmt.training - Epoch   7, Step:    64500, Batch Loss:     1.898887, Batch Acc: 0.495650, Tokens per Sec:    21394, Lr: 0.000300
2025-05-29 22:35:49,807 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:35:49,807 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:35:58,274 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.51, generation: 8.4544[sec], evaluation: 0.0000[sec]
2025-05-29 22:35:58,275 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:35:58,846 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/62000.ckpt
2025-05-29 22:35:58,868 - INFO - joeynmt.training - Example #0
2025-05-29 22:35:58,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:35:58,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:35:58,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'enza', 'che', 'l@@', '<unk>', 'inter@@', 'o', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'inter@@', 'o', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'chiam@@', 'ato', 'il', '4@@', '8@@', ',', 'per', 'il', '4@@', '8@@', ',', 'per', 'c@@', 'ent@@', 'o@@', ',', 'il', '4@@', '8@@', ',', 'per', 'il', '4@@', '8@@', '%', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:35:58,870 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:35:58,870 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:35:58,870 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato queste due diapositive per conseguenza che l<unk> intero articolo che l<unk> intero articolo che ha chiamato il 48, per il 48, per cento, il 48, per il 48% per cento.
2025-05-29 22:35:58,870 - INFO - joeynmt.training - Example #1
2025-05-29 22:35:58,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:35:58,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:35:58,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'st@@', 'ag@@', 'ione', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'stato', 'un', 'p@@', 'ezz@@', 'o', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'e', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'problema', 'che', 'non', 'c@@', '<unk>', 'è', 'abb@@', 'ast@@', 'anza', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'e', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'c@@', '<unk>', 'è', 'abb@@', 'ast@@', 'anza', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'e', 'non', 'c@@', '<unk>', 'è', 'abb@@', 'ast@@', 'anza']
2025-05-29 22:35:58,871 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:35:58,871 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:35:58,871 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la stagione di questo problema speciale, perché non c<unk> è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio che è stato un pezzo di ghiaccio, e la distanza di questo problema che non c<unk> è abbastanza di ghiaccia, e la dimostra che non c<unk> è abbastanza di ghiaccia, e non c<unk> è abbastanza
2025-05-29 22:35:58,871 - INFO - joeynmt.training - Example #2
2025-05-29 22:35:58,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:35:58,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:35:58,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:35:58,872 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:35:58,872 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:35:58,872 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio artico, il cuore del nostro sistema climatico globale.
2025-05-29 22:35:58,872 - INFO - joeynmt.training - Example #3
2025-05-29 22:35:58,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:35:58,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:35:58,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'dur@@', 're', 'il', 'v@@', 'ento', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:35:58,873 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:35:58,873 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:35:58,873 - INFO - joeynmt.training - 	Hypothesis: Si può ridurre il vento in inverno, e in inverno.
2025-05-29 22:35:58,873 - INFO - joeynmt.training - Example #4
2025-05-29 22:35:58,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:35:58,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:35:58,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'apos@@', 'iti@@', 'v@@', 'a@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:35:58,873 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:35:58,873 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:35:58,873 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una diapositiva, che è successo negli ultimi 25 anni.
2025-05-29 22:36:02,283 - INFO - joeynmt.training - Epoch   7, Step:    64600, Batch Loss:     1.608209, Batch Acc: 0.497134, Tokens per Sec:    18061, Lr: 0.000300
2025-05-29 22:36:05,666 - INFO - joeynmt.training - Epoch   7, Step:    64700, Batch Loss:     1.739650, Batch Acc: 0.490650, Tokens per Sec:    21741, Lr: 0.000300
2025-05-29 22:36:09,032 - INFO - joeynmt.training - Epoch   7, Step:    64800, Batch Loss:     1.736428, Batch Acc: 0.495248, Tokens per Sec:    20604, Lr: 0.000300
2025-05-29 22:36:12,364 - INFO - joeynmt.training - Epoch   7, Step:    64900, Batch Loss:     1.679170, Batch Acc: 0.489143, Tokens per Sec:    20868, Lr: 0.000300
2025-05-29 22:36:15,716 - INFO - joeynmt.training - Epoch   7, Step:    65000, Batch Loss:     1.848977, Batch Acc: 0.489499, Tokens per Sec:    21466, Lr: 0.000300
2025-05-29 22:36:15,716 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:36:15,716 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:36:24,804 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.51, generation: 9.0798[sec], evaluation: 0.0000[sec]
2025-05-29 22:36:24,805 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:36:25,329 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/64000.ckpt
2025-05-29 22:36:25,355 - INFO - joeynmt.training - Example #0
2025-05-29 22:36:25,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:36:25,356 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:36:25,356 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ai', 'che', 'i', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'i', 'ar@@', 't@@', 'icol@@', 'i', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'si', 'è', 'sc@@', 'oper@@', 'to', 'che', 'av@@', 'evano', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'c@@', 'ento', 'di', 'quest@@', 'o@@', '.', '</s>']
2025-05-29 22:36:25,356 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:36:25,356 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:36:25,356 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato queste due diapositive per vedere che i ghiacciai che i artici, che i articoli per tre milioni di anni di anni che si è scoperto che avevano il 48 per cento di anni per il 40 per cento per cento di questo.
2025-05-29 22:36:25,357 - INFO - joeynmt.training - Example #1
2025-05-29 22:36:25,357 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:36:25,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:36:25,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'ar@@', 'ea', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'di@@', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:36:25,357 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:36:25,357 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:36:25,358 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo problema, la prima cosa che non è il dell<unk> area di questo problema, perché non dimostra il dell<unk> ghiaccio.
2025-05-29 22:36:25,358 - INFO - joeynmt.training - Example #2
2025-05-29 22:36:25,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:36:25,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:36:25,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:36:25,358 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:36:25,358 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:36:25,358 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è il cuore articolo di ghiaccia, il cuore del nostro sistema di climatico globale.
2025-05-29 22:36:25,359 - INFO - joeynmt.training - Example #3
2025-05-29 22:36:25,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:36:25,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:36:25,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ol@@', 'v@@', 'eva', 'in', 'in@@', 'ver@@', 'no@@', ',', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:36:25,359 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:36:25,359 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:36:25,359 - INFO - joeynmt.training - 	Hypothesis: Solveva in inverno, in inverno.
2025-05-29 22:36:25,359 - INFO - joeynmt.training - Example #4
2025-05-29 22:36:25,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:36:25,360 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:36:25,360 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'etti@@', 'man@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:36:25,360 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:36:25,360 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:36:25,360 - INFO - joeynmt.training - 	Hypothesis: La prossima settimana che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 22:36:28,750 - INFO - joeynmt.training - Epoch   7, Step:    65100, Batch Loss:     1.913793, Batch Acc: 0.491841, Tokens per Sec:    17820, Lr: 0.000300
2025-05-29 22:36:32,123 - INFO - joeynmt.training - Epoch   7, Step:    65200, Batch Loss:     1.619990, Batch Acc: 0.487008, Tokens per Sec:    20611, Lr: 0.000300
2025-05-29 22:36:35,480 - INFO - joeynmt.training - Epoch   7, Step:    65300, Batch Loss:     1.904020, Batch Acc: 0.486433, Tokens per Sec:    20479, Lr: 0.000300
2025-05-29 22:36:38,847 - INFO - joeynmt.training - Epoch   7, Step:    65400, Batch Loss:     1.927002, Batch Acc: 0.485239, Tokens per Sec:    20786, Lr: 0.000300
2025-05-29 22:36:42,202 - INFO - joeynmt.training - Epoch   7, Step:    65500, Batch Loss:     1.825739, Batch Acc: 0.490451, Tokens per Sec:    20608, Lr: 0.000300
2025-05-29 22:36:42,202 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:36:42,203 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:36:50,711 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.51, generation: 8.4970[sec], evaluation: 0.0000[sec]
2025-05-29 22:36:50,728 - INFO - joeynmt.training - Example #0
2025-05-29 22:36:50,729 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:36:50,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:36:50,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'si', 'chiam@@', 'a', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ai', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'chiam@@', 'ato', 'il', '4@@', '8@@', ',', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', 'due', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:36:50,730 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:36:50,730 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:36:50,730 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso, ho mostrato queste due diapositive per vedere il ghiaccio, che le ghiacciate che si chiama ghiacciai tre milioni di anni che hanno chiamato il 48, per il 48% di questi due 48 stati.
2025-05-29 22:36:50,730 - INFO - joeynmt.training - Example #1
2025-05-29 22:36:50,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:36:50,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:36:50,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'l@@', '<unk>', 'in@@', 'st@@', 'all@@', 'are', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', '<unk>', 'or@@', 'a@@', '.', '</s>']
2025-05-29 22:36:50,731 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:36:50,731 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:36:50,731 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza l<unk> installare di questo problema, perché non c<unk> è il d<unk> ora.
2025-05-29 22:36:50,731 - INFO - joeynmt.training - Example #2
2025-05-29 22:36:50,731 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:36:50,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:36:50,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:36:50,732 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:36:50,732 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:36:50,732 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccia, il cuore articolo di climatico.
2025-05-29 22:36:50,732 - INFO - joeynmt.training - Example #3
2025-05-29 22:36:50,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:36:50,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:36:50,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'vel@@', 'are', 'in', 'in@@', 'ver@@', 'no', 'e', 'r@@', 'os@@', 'so@@', ',', 'e', 'non', 'è', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', 'bile', 'e', 'la', 'sua', 'c@@', 'at@@', 'en@@', 'a', 'di', 'sc@@', 'al@@', 'a@@', '.', '</s>']
2025-05-29 22:36:50,733 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:36:50,733 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:36:50,733 - INFO - joeynmt.training - 	Hypothesis: Si può rivelare in inverno e rosso, e non è un sommergibile e la sua catena di scala.
2025-05-29 22:36:50,733 - INFO - joeynmt.training - Example #4
2025-05-29 22:36:50,733 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:36:50,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:36:50,733 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'di@@', 'seg@@', 'no', 'a', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'sol@@', 'i', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'la', 'gente', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'è', 'succ@@', 'esso', 'in', 'questi', 'mo@@', 'd@@', 'elli', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'la', 'gente', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:36:50,734 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:36:50,734 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:36:50,734 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una cosa che vi mostrerò un disegno di un disegno di un disegno di un disegno di un disegno di un pezzo di disegno di un pezzo di disegno di un po<unk> di un pezzo di disegno a un po<unk> di un po<unk> di soli che vi mostrerò che la gente vi mostrerò che è successo in questi modelli che vi mostrerò che la gente è successo negli ultimi 25 anni.
2025-05-29 22:36:54,131 - INFO - joeynmt.training - Epoch   7, Step:    65600, Batch Loss:     1.588432, Batch Acc: 0.487574, Tokens per Sec:    21455, Lr: 0.000300
2025-05-29 22:36:57,523 - INFO - joeynmt.training - Epoch   7, Step:    65700, Batch Loss:     1.630704, Batch Acc: 0.488370, Tokens per Sec:    21007, Lr: 0.000300
2025-05-29 22:37:00,913 - INFO - joeynmt.training - Epoch   7, Step:    65800, Batch Loss:     1.818137, Batch Acc: 0.494612, Tokens per Sec:    20811, Lr: 0.000300
2025-05-29 22:37:04,309 - INFO - joeynmt.training - Epoch   7, Step:    65900, Batch Loss:     1.733256, Batch Acc: 0.492236, Tokens per Sec:    21206, Lr: 0.000300
2025-05-29 22:37:07,679 - INFO - joeynmt.training - Epoch   7, Step:    66000, Batch Loss:     1.807219, Batch Acc: 0.492704, Tokens per Sec:    20891, Lr: 0.000300
2025-05-29 22:37:07,679 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:37:07,680 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:37:16,660 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.51, generation: 8.9721[sec], evaluation: 0.0000[sec]
2025-05-29 22:37:17,159 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/63500.ckpt
2025-05-29 22:37:17,185 - INFO - joeynmt.training - Example #0
2025-05-29 22:37:17,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:37:17,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:37:17,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'le', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'è', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'anni', 'di', '4@@', '8@@', '%', 'di', 'anni', 'di', '4@@', '8@@', '%', 'di', 'anni', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'c@@', 'ento', 'di', 'ri@@', 'guar@@', 'do', 'al', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'di', '1@@', '0@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'due', 'anni', 'di', 'm@@', 'em@@', 'br@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:37:17,186 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:37:17,186 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:37:17,186 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per ridurre le diapositive per ridurre le ghiacci, che le ghiaccio, che è l<unk> anno scorso che si tratta di anni di 48% di anni di 48% di anni per 40 per cento per cento di riguardo al 40% di questi due anni di 100% di questi due anni di questi due anni di membraccio.
2025-05-29 22:37:17,186 - INFO - joeynmt.training - Example #1
2025-05-29 22:37:17,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:37:17,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:37:17,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questa', 'part@@', 'icol@@', 'are', 'problema', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'ci', 'sono', 'i', 'd@@', 'ell@@', '<unk>', 'is@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 22:37:17,187 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:37:17,187 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:37:17,187 - INFO - joeynmt.training - 	Hypothesis: Ma non è forte abbastanza forte di questa particolare problema di questo particolare problema, perché non ci sono i dell<unk> isola.
2025-05-29 22:37:17,187 - INFO - joeynmt.training - Example #2
2025-05-29 22:37:17,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:37:17,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:37:17,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:37:17,188 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:37:17,188 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:37:17,188 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, il cuore articolo di climatico.
2025-05-29 22:37:17,188 - INFO - joeynmt.training - Example #3
2025-05-29 22:37:17,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:37:17,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:37:17,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'guar@@', 'do', 'in', 'un', 'est@@', 'i@@', 'gi@@', 'o@@', '.', '</s>']
2025-05-29 22:37:17,189 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:37:17,189 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:37:17,189 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, in inverno e riguardo in un estigio.
2025-05-29 22:37:17,189 - INFO - joeynmt.training - Example #4
2025-05-29 22:37:17,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:37:17,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:37:17,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:37:17,190 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:37:17,190 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:37:17,190 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 22:37:20,588 - INFO - joeynmt.training - Epoch   7, Step:    66100, Batch Loss:     1.748823, Batch Acc: 0.488686, Tokens per Sec:    17780, Lr: 0.000300
2025-05-29 22:37:23,992 - INFO - joeynmt.training - Epoch   7, Step:    66200, Batch Loss:     2.025065, Batch Acc: 0.488080, Tokens per Sec:    20782, Lr: 0.000300
2025-05-29 22:37:27,395 - INFO - joeynmt.training - Epoch   7, Step:    66300, Batch Loss:     1.663886, Batch Acc: 0.489318, Tokens per Sec:    21172, Lr: 0.000300
2025-05-29 22:37:30,795 - INFO - joeynmt.training - Epoch   7, Step:    66400, Batch Loss:     1.713673, Batch Acc: 0.486146, Tokens per Sec:    21417, Lr: 0.000300
2025-05-29 22:37:34,189 - INFO - joeynmt.training - Epoch   7, Step:    66500, Batch Loss:     1.792770, Batch Acc: 0.487890, Tokens per Sec:    21271, Lr: 0.000300
2025-05-29 22:37:34,189 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:37:34,190 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:37:43,833 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.51, generation: 9.6310[sec], evaluation: 0.0000[sec]
2025-05-29 22:37:44,194 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/62500.ckpt
2025-05-29 22:37:44,220 - INFO - joeynmt.training - Example #0
2025-05-29 22:37:44,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:37:44,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:37:44,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'qu@@', 'ell@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'fl@@', 'et@@', 'tere', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'tre', 'milioni', 'di', 'an@@', 'ni@@', ',', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'per', 'il', '4@@', '8@@', '%', 'dei', 'ter@@', 'rit@@', 'ori', 'di', 'anni', 'di', '4@@', '8@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:37:44,221 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:37:44,221 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:37:44,221 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso quell<unk> anno scorso queste due diapositive per riflettere che l<unk> articolo che l<unk> anno scorso di tre milioni di anni, che hanno insegnato per il 48% dei territori di anni di 48% di questi due anni per il 48% di questi due anni per cento.
2025-05-29 22:37:44,222 - INFO - joeynmt.training - Example #1
2025-05-29 22:37:44,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:37:44,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:37:44,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'l@@', '<unk>', 'in@@', 'st@@', 'all@@', 'azione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'spe@@', 'ci@@', 'al@@', 'i@@', ',', 'perché', 'non', 'ci', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 22:37:44,222 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:37:44,222 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:37:44,222 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza l<unk> installazione di questo particolare problemi speciali, perché non ci mostra il ghiaccio di ghiaccia.
2025-05-29 22:37:44,223 - INFO - joeynmt.training - Example #2
2025-05-29 22:37:44,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:37:44,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:37:44,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:37:44,223 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:37:44,223 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:37:44,223 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore di climatico.
2025-05-29 22:37:44,223 - INFO - joeynmt.training - Example #3
2025-05-29 22:37:44,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:37:44,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:37:44,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'in', 'in@@', 'ver@@', 'no', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:37:44,224 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:37:44,224 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:37:44,224 - INFO - joeynmt.training - 	Hypothesis: Sta crescita in inverno in inverno e in un sommergibile.
2025-05-29 22:37:44,224 - INFO - joeynmt.training - Example #4
2025-05-29 22:37:44,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:37:44,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:37:44,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'p@@', 'al@@', 'cos@@', 'c@@', 'en@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:37:44,225 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:37:44,225 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:37:44,225 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è un disegno di un disegno di un disegno di un disegno di un palcoscenico.
2025-05-29 22:37:47,615 - INFO - joeynmt.training - Epoch   7, Step:    66600, Batch Loss:     1.764798, Batch Acc: 0.493609, Tokens per Sec:    18909, Lr: 0.000300
2025-05-29 22:37:50,995 - INFO - joeynmt.training - Epoch   7, Step:    66700, Batch Loss:     1.758137, Batch Acc: 0.487940, Tokens per Sec:    21120, Lr: 0.000300
2025-05-29 22:37:54,381 - INFO - joeynmt.training - Epoch   7, Step:    66800, Batch Loss:     1.758775, Batch Acc: 0.493592, Tokens per Sec:    20902, Lr: 0.000300
2025-05-29 22:37:57,766 - INFO - joeynmt.training - Epoch   7, Step:    66900, Batch Loss:     1.801463, Batch Acc: 0.484366, Tokens per Sec:    21067, Lr: 0.000300
2025-05-29 22:38:01,145 - INFO - joeynmt.training - Epoch   7, Step:    67000, Batch Loss:     1.831174, Batch Acc: 0.484407, Tokens per Sec:    21376, Lr: 0.000300
2025-05-29 22:38:01,146 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:38:01,146 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:38:09,785 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.12, acc:   0.51, generation: 8.6277[sec], evaluation: 0.0000[sec]
2025-05-29 22:38:09,786 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:38:10,379 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/63000.ckpt
2025-05-29 22:38:10,403 - INFO - joeynmt.training - Example #0
2025-05-29 22:38:10,404 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:38:10,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:38:10,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'per', 'c@@', 'ent@@', 'o@@', ',', 'per', 'guard@@', 'are', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'av@@', 'evano', 'il', '4@@', '8@@', ',', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'degli', 'in@@', 'segn@@', 'anti', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:38:10,405 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:38:10,405 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:38:10,405 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due per cento, per guardare l<unk> anno scorso che l<unk> anno scorso articolo che avevano il 48, che ha avuto per tre milioni di anni di 48 per cento degli insegnanti di 48 stati.
2025-05-29 22:38:10,405 - INFO - joeynmt.training - Example #1
2025-05-29 22:38:10,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:38:10,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:38:10,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'essere', 'abb@@', 'ast@@', 'anza', 'in', 'modo', 'che', 'non', 'c@@', '<unk>', 'è', 'un', 'problema', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 22:38:10,405 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:38:10,405 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:38:10,405 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di essere abbastanza in modo che non c<unk> è un problema speciale che non c<unk> è il dell<unk> isola.
2025-05-29 22:38:10,406 - INFO - joeynmt.training - Example #2
2025-05-29 22:38:10,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:38:10,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:38:10,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:38:10,406 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:38:10,406 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:38:10,406 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo articolo artico.
2025-05-29 22:38:10,406 - INFO - joeynmt.training - Example #3
2025-05-29 22:38:10,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:38:10,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:38:10,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'es@@', 'ce', 'a', 'ri@@', 'guar@@', 'da', 'al', 'vent@@', 'o@@', '.', '</s>']
2025-05-29 22:38:10,407 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:38:10,407 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:38:10,407 - INFO - joeynmt.training - 	Hypothesis: Si riesce a riguarda al vento.
2025-05-29 22:38:10,407 - INFO - joeynmt.training - Example #4
2025-05-29 22:38:10,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:38:10,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:38:10,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'mostr@@', 'are', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:38:10,408 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:38:10,408 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:38:10,408 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è un disegno di disegno di un disegno di disegno di un disegno di dimostrare che è successo negli ultimi 25 anni.
2025-05-29 22:38:13,828 - INFO - joeynmt.training - Epoch   7, Step:    67100, Batch Loss:     1.689524, Batch Acc: 0.490918, Tokens per Sec:    18019, Lr: 0.000300
2025-05-29 22:38:17,197 - INFO - joeynmt.training - Epoch   7, Step:    67200, Batch Loss:     1.699111, Batch Acc: 0.491791, Tokens per Sec:    20199, Lr: 0.000300
2025-05-29 22:38:20,575 - INFO - joeynmt.training - Epoch   7, Step:    67300, Batch Loss:     1.670279, Batch Acc: 0.491703, Tokens per Sec:    21379, Lr: 0.000300
2025-05-29 22:38:23,889 - INFO - joeynmt.training - Epoch   7, Step:    67400, Batch Loss:     1.617829, Batch Acc: 0.485187, Tokens per Sec:    21825, Lr: 0.000300
2025-05-29 22:38:27,236 - INFO - joeynmt.training - Epoch   7, Step:    67500, Batch Loss:     1.504164, Batch Acc: 0.492384, Tokens per Sec:    21228, Lr: 0.000300
2025-05-29 22:38:27,236 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:38:27,236 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:38:34,806 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.13, acc:   0.51, generation: 7.5586[sec], evaluation: 0.0000[sec]
2025-05-29 22:38:35,167 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/64500.ckpt
2025-05-29 22:38:35,191 - INFO - joeynmt.training - Example #0
2025-05-29 22:38:35,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:38:35,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:38:35,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'il', '4@@', '8@@', ',', 'e', 'guard@@', 'are', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'è', 'stato', 'in@@', 'segn@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 'questo', 'è', 'stato', 'sc@@', 'or@@', 'so', 'che', 'è', 'stato', 'ri@@', 'ma@@', 'sto', 'per', 'il', '4@@', '8@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'fare', 'un', 'po@@', '<unk>', 'di', 'tempo', 'e', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', ',', 'e', 'il', 't@@', 'as@@', 'so', 'di', 'un']
2025-05-29 22:38:35,192 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:38:35,192 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:38:35,192 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due diapositive per vedere il 48, e guardare che la ghiacciaio di ghiaccio, che è stato insegnato per tre milioni di anni di questi due anni di questi due anni di questi due anni per cento di questi due anni per cento di questi due anni per cento di questo è stato scorso che è stato rimasto per il 480% di questi due anni sono stati in grado di fare un po<unk> di tempo e l<unk> anno scorso, e il tasso di un
2025-05-29 22:38:35,192 - INFO - joeynmt.training - Example #1
2025-05-29 22:38:35,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:38:35,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:38:35,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'part@@', 'icol@@', 'ar@@', 'e@@', ',', 'perché', 'non', 'ci', 'mostr@@', 'a', 'i', 'D@@', 'ic@@', 'ke', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:38:35,193 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:38:35,193 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:38:35,193 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la capacità di questo particolare, perché non ci mostra i Dicke dell<unk> origine del ghiaccio.
2025-05-29 22:38:35,193 - INFO - joeynmt.training - Example #2
2025-05-29 22:38:35,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:38:35,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:38:35,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:38:35,194 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:38:35,194 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:38:35,194 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore globale.
2025-05-29 22:38:35,194 - INFO - joeynmt.training - Example #3
2025-05-29 22:38:35,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:38:35,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:38:35,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'v@@', 'eg@@', 'li@@', 'ano', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'in', 't@@', 'al@@', 'ità', 'e', 's@@', 'om@@', 'mer@@', 'i@@', '.', '</s>']
2025-05-29 22:38:35,195 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:38:35,195 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:38:35,195 - INFO - joeynmt.training - 	Hypothesis: Si svegliano in inverno, e in talità e sommeri.
2025-05-29 22:38:35,195 - INFO - joeynmt.training - Example #4
2025-05-29 22:38:35,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:38:35,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:38:35,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'di@@', 'apos@@', 'iti@@', 'va', 'è', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', 'tem@@', 'pi', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:38:35,196 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:38:35,196 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:38:35,196 - INFO - joeynmt.training - 	Hypothesis: La diapositiva è che vi mostrerò è un disegno di un disegno di quei tempi di quello che è successo negli ultimi 25 anni.
2025-05-29 22:38:38,565 - INFO - joeynmt.training - Epoch   7, Step:    67600, Batch Loss:     1.911346, Batch Acc: 0.488290, Tokens per Sec:    19209, Lr: 0.000300
2025-05-29 22:38:41,920 - INFO - joeynmt.training - Epoch   7, Step:    67700, Batch Loss:     1.730453, Batch Acc: 0.486282, Tokens per Sec:    21562, Lr: 0.000300
2025-05-29 22:38:45,319 - INFO - joeynmt.training - Epoch   7, Step:    67800, Batch Loss:     1.513720, Batch Acc: 0.491505, Tokens per Sec:    20874, Lr: 0.000300
2025-05-29 22:38:48,713 - INFO - joeynmt.training - Epoch   7, Step:    67900, Batch Loss:     2.031366, Batch Acc: 0.492028, Tokens per Sec:    21090, Lr: 0.000300
2025-05-29 22:38:52,097 - INFO - joeynmt.training - Epoch   7, Step:    68000, Batch Loss:     1.818308, Batch Acc: 0.488121, Tokens per Sec:    20553, Lr: 0.000300
2025-05-29 22:38:52,097 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:38:52,098 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:39:00,534 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.13, acc:   0.51, generation: 8.4291[sec], evaluation: 0.0000[sec]
2025-05-29 22:39:01,049 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/66000.ckpt
2025-05-29 22:39:01,076 - INFO - joeynmt.training - Example #0
2025-05-29 22:39:01,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:39:01,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:39:01,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'e', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'per', 'i', 'miei', 'tre', 'milioni', 'di', 'anni', 'sono', 'i', '4@@', '8', 'st@@', 'ati@@', ',', 'per', 'il', '4@@', '8@@', '%', 'dei', 'più', 'al@@', 'ti', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:39:01,077 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:39:01,077 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:39:01,077 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso queste due diapositive per vedere questi due diapositive per vedere che i ghiacciati e che le ghiacciate che per i miei tre milioni di anni sono i 48 stati, per il 48% dei più alti di 40 per cento di 40 per cento di anni per cento di 40 per cento di anni.
2025-05-29 22:39:01,077 - INFO - joeynmt.training - Example #1
2025-05-29 22:39:01,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:39:01,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:39:01,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'perché', 'non', 'mostr@@', 'a', 'i', 't@@', 'est', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:39:01,078 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:39:01,078 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:39:01,078 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la capacità di questo particolare problemi di ghiacciati perché non mostra i test del ghiaccio.
2025-05-29 22:39:01,078 - INFO - joeynmt.training - Example #2
2025-05-29 22:39:01,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:39:01,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:39:01,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:39:01,079 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:39:01,079 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:39:01,079 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore globale del nostro climatico globale.
2025-05-29 22:39:01,079 - INFO - joeynmt.training - Example #3
2025-05-29 22:39:01,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:39:01,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:39:01,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'p@@', 'et@@', 'ta', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'in', 'r@@', 'om@@', 'p@@', 'e@@', '.', '</s>']
2025-05-29 22:39:01,080 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:39:01,080 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:39:01,080 - INFO - joeynmt.training - 	Hypothesis: Si ripetta in inverno, e in rompe.
2025-05-29 22:39:01,080 - INFO - joeynmt.training - Example #4
2025-05-29 22:39:01,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:39:01,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:39:01,081 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'apos@@', 'iti@@', 'vo', 'che', 'vi', 'mostr@@', 'i', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'mostr@@', 'are', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 't@@', 'o@@', '.', '</s>']
2025-05-29 22:39:01,081 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:39:01,081 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:39:01,081 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostri è un disegno di dimostrare un disegno di un disegno di un dito.
2025-05-29 22:39:04,484 - INFO - joeynmt.training - Epoch   7, Step:    68100, Batch Loss:     1.811016, Batch Acc: 0.489547, Tokens per Sec:    17784, Lr: 0.000300
2025-05-29 22:39:07,873 - INFO - joeynmt.training - Epoch   7, Step:    68200, Batch Loss:     1.907624, Batch Acc: 0.484913, Tokens per Sec:    21270, Lr: 0.000300
2025-05-29 22:39:11,241 - INFO - joeynmt.training - Epoch   7, Step:    68300, Batch Loss:     1.753172, Batch Acc: 0.484648, Tokens per Sec:    20896, Lr: 0.000300
2025-05-29 22:39:14,638 - INFO - joeynmt.training - Epoch   7, Step:    68400, Batch Loss:     1.831529, Batch Acc: 0.496382, Tokens per Sec:    21240, Lr: 0.000300
2025-05-29 22:39:18,013 - INFO - joeynmt.training - Epoch   7, Step:    68500, Batch Loss:     1.657018, Batch Acc: 0.489092, Tokens per Sec:    21288, Lr: 0.000300
2025-05-29 22:39:18,013 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:39:18,014 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:39:27,441 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.12, acc:   0.51, generation: 9.4157[sec], evaluation: 0.0000[sec]
2025-05-29 22:39:27,442 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:39:28,029 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/66500.ckpt
2025-05-29 22:39:28,054 - INFO - joeynmt.training - Example #0
2025-05-29 22:39:28,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:39:28,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:39:28,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 's@@', 'om@@', 'ma', 'per', 'guard@@', 'are', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', 'il', '4@@', '8@@', '%', 'di', 'questi', 'anni', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questi', 'anni', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questi', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'ri@@', 'fer@@', 'im@@', 'ento', 'per', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'due', 's@@', 'ett@@', 'ori', 'di', 'in@@', 'segn@@', 'are', 'il', '4@@', '0', 'per@@', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:39:28,055 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:39:28,055 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:39:28,055 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato queste due somma per guardare il ghiaccio di ghiaccio, che la ghiacciaio di tre milioni di anni che hanno avuto il 48% di questi anni di 40 percento di questi anni di 40 percento di questi sono stati in grado di riferimento per il 40% di questi due anni di questi due anni di questi due anni di questi due settori di insegnare il 40 percento.
2025-05-29 22:39:28,055 - INFO - joeynmt.training - Example #1
2025-05-29 22:39:28,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:39:28,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:39:28,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'lo', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:39:28,056 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:39:28,056 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:39:28,056 - INFO - joeynmt.training - 	Hypothesis: Ma non lo è abbastanza forte di questo problema, perché non c<unk> è il Dicke del ghiaccio di ghiaccio.
2025-05-29 22:39:28,056 - INFO - joeynmt.training - Example #2
2025-05-29 22:39:28,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:39:28,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:39:28,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:39:28,057 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:39:28,057 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:39:28,057 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, il cuore di climatico del nostro sistema globale.
2025-05-29 22:39:28,057 - INFO - joeynmt.training - Example #3
2025-05-29 22:39:28,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:39:28,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:39:28,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'dur@@', 're', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'p@@', 'et@@', 'o@@', '.', '</s>']
2025-05-29 22:39:28,058 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:39:28,058 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:39:28,058 - INFO - joeynmt.training - 	Hypothesis: Si può ridurre in inverno e ripeto.
2025-05-29 22:39:28,058 - INFO - joeynmt.training - Example #4
2025-05-29 22:39:28,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:39:28,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:39:28,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'om@@', 'ma', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:39:28,058 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:39:28,059 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:39:28,059 - INFO - joeynmt.training - 	Hypothesis: La prossima somma che vi mostrerò è una dimostrazione di un disegno di quei 25 anni.
2025-05-29 22:39:31,450 - INFO - joeynmt.training - Epoch   7, Step:    68600, Batch Loss:     1.653260, Batch Acc: 0.485509, Tokens per Sec:    17182, Lr: 0.000300
2025-05-29 22:39:34,821 - INFO - joeynmt.training - Epoch   7, Step:    68700, Batch Loss:     1.960641, Batch Acc: 0.488148, Tokens per Sec:    20745, Lr: 0.000300
2025-05-29 22:39:38,230 - INFO - joeynmt.training - Epoch   7, Step:    68800, Batch Loss:     1.682170, Batch Acc: 0.483090, Tokens per Sec:    21267, Lr: 0.000300
2025-05-29 22:39:41,596 - INFO - joeynmt.training - Epoch   7, Step:    68900, Batch Loss:     1.811660, Batch Acc: 0.484202, Tokens per Sec:    20651, Lr: 0.000300
2025-05-29 22:39:44,973 - INFO - joeynmt.training - Epoch   7, Step:    69000, Batch Loss:     1.842163, Batch Acc: 0.485269, Tokens per Sec:    20902, Lr: 0.000300
2025-05-29 22:39:44,973 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:39:44,973 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:39:53,453 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.12, acc:   0.51, generation: 8.4680[sec], evaluation: 0.0000[sec]
2025-05-29 22:39:53,854 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/65000.ckpt
2025-05-29 22:39:53,880 - INFO - joeynmt.training - Example #0
2025-05-29 22:39:53,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:39:53,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:39:53,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'in@@', 'segn@@', 'are', 'a', 'un', 'po@@', '<unk>', 'di', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'le', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'la', 'storia', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'è', 'stata', 'chiam@@', 'ata', '<unk>', '4@@', '8', 'st@@', 'at@@', 'o@@', ',', 'e', 'il', '4@@', '8', 'st@@', 'at@@', 'o@@', ',', 'per', 'il', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:39:53,881 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:39:53,881 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:39:53,881 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per insegnare a un po<unk> di articolo che le articolo che la storia artica, che è stata chiamata <unk> 48 stato, e il 48 stato, per il 480 per cento di cento.
2025-05-29 22:39:53,882 - INFO - joeynmt.training - Example #1
2025-05-29 22:39:53,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:39:53,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:39:53,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'a@@', ',', 'la', 'ter@@', 'ra', 'di', 'questa', 'part@@', 'icol@@', 'ar@@', 'e@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'é@@', 'li@@', 'te', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'di', 'sol@@', 'ito', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', '.', '</s>']
2025-05-29 22:39:53,882 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:39:53,882 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:39:53,882 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunata, la terra di questa particolare, perché non è il dell<unk> origine del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di un po<unk> di sélite di ghiaccio che di solito è abbastanza forte abbastanza forte abbastanza forte abbastanza forte abbastanza forte.
2025-05-29 22:39:53,883 - INFO - joeynmt.training - Example #2
2025-05-29 22:39:53,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:39:53,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:39:53,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:39:53,883 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:39:53,883 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:39:53,883 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa di ghiaccio che è il cuore del nostro sistema climatico.
2025-05-29 22:39:53,884 - INFO - joeynmt.training - Example #3
2025-05-29 22:39:53,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:39:53,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:39:53,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'vel@@', 'a', 'e', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 'c@@', 'entr@@', 'o', 'di', 'c@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 22:39:53,884 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:39:53,884 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:39:53,884 - INFO - joeynmt.training - 	Hypothesis: Si può rivela e cresce in inverno in inverno e in un centro di caccia.
2025-05-29 22:39:53,884 - INFO - joeynmt.training - Example #4
2025-05-29 22:39:53,885 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:39:53,885 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:39:53,885 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'pr@@', 'ec@@', 'is@@', 'ione', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:39:53,885 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:39:53,885 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:39:53,885 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una precisione di dimostrarvi è successo negli ultimi 25 anni.
2025-05-29 22:39:57,295 - INFO - joeynmt.training - Epoch   7, Step:    69100, Batch Loss:     1.416555, Batch Acc: 0.490459, Tokens per Sec:    18979, Lr: 0.000300
2025-05-29 22:40:00,694 - INFO - joeynmt.training - Epoch   7, Step:    69200, Batch Loss:     1.880659, Batch Acc: 0.493100, Tokens per Sec:    21596, Lr: 0.000300
2025-05-29 22:40:04,023 - INFO - joeynmt.training - Epoch   7, Step:    69300, Batch Loss:     1.641744, Batch Acc: 0.488865, Tokens per Sec:    21116, Lr: 0.000300
2025-05-29 22:40:07,309 - INFO - joeynmt.training - Epoch   7, Step:    69400, Batch Loss:     1.635662, Batch Acc: 0.485842, Tokens per Sec:    21260, Lr: 0.000300
2025-05-29 22:40:10,599 - INFO - joeynmt.training - Epoch   7, Step:    69500, Batch Loss:     1.703265, Batch Acc: 0.492727, Tokens per Sec:    21654, Lr: 0.000300
2025-05-29 22:40:10,599 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:40:10,599 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:40:18,577 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.52, generation: 7.9665[sec], evaluation: 0.0000[sec]
2025-05-29 22:40:18,577 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:40:19,126 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/67500.ckpt
2025-05-29 22:40:19,148 - INFO - joeynmt.training - Example #0
2025-05-29 22:40:19,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:40:19,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:40:19,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 's@@', 'etti@@', 'man@@', 'e', 'per', 'os@@', 'serv@@', 'are', 'le', 'loro', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ai@@', 'o@@', ',', 'che', 'è', 'stato', 'in@@', 'f@@', 'lu@@', 'enza', 'è', 'stato', 'f@@', 'att@@', 'o@@', ',', 'il', '4@@', '8@@', '%', 'di', 'questi', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'mili@@', 'on@@', 'i@@', ',', 'il', '4@@', '0@@', '%', 'dei', 'più', 'di', '1@@', '0@@', '%', 'di', 'questi', 'due', 'mili@@', 'ar@@', 'di', 'di', 'anni', 'di', 'doll@@', 'ar@@', 'i@@', '.', '</s>']
2025-05-29 22:40:19,149 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:40:19,149 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:40:19,149 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due settimane per osservare le loro articolo che le ghiaccio, che le ghiacciaio, che è stato influenza è stato fatto, il 48% di questi tre milioni di anni per cento di questi due milioni, il 40% dei più di 10% di questi due miliardi di anni di dollari.
2025-05-29 22:40:19,149 - INFO - joeynmt.training - Example #1
2025-05-29 22:40:19,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:40:19,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:40:19,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'amente', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'i@@', ',', 'perché', 'non', 'è', 'la', 'd@@', 'ell@@', '<unk>', 'or@@', 'a@@', '.', '</s>']
2025-05-29 22:40:19,150 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:40:19,150 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:40:19,150 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente la capacità di questo particolare problemi, perché non è la dell<unk> ora.
2025-05-29 22:40:19,150 - INFO - joeynmt.training - Example #2
2025-05-29 22:40:19,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:40:19,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:40:19,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'd@@', 'ell@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:40:19,151 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:40:19,151 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:40:19,151 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa dell<unk> articolo che il cuore del nostro sistema climatico globale.
2025-05-29 22:40:19,151 - INFO - joeynmt.training - Example #3
2025-05-29 22:40:19,151 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:40:19,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:40:19,151 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'fer@@', 'im@@', 'ent@@', 'are', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:40:19,152 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:40:19,152 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:40:19,152 - INFO - joeynmt.training - 	Hypothesis: Si può riferimentare in inverno e in un certo senso.
2025-05-29 22:40:19,152 - INFO - joeynmt.training - Example #4
2025-05-29 22:40:19,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:40:19,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:40:19,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', 'due', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:40:19,153 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:40:19,153 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:40:19,153 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di un disegno di quei due anni.
2025-05-29 22:40:22,469 - INFO - joeynmt.training - Epoch   7, Step:    69600, Batch Loss:     1.693146, Batch Acc: 0.485337, Tokens per Sec:    18489, Lr: 0.000300
2025-05-29 22:40:25,780 - INFO - joeynmt.training - Epoch   7, Step:    69700, Batch Loss:     1.699606, Batch Acc: 0.484922, Tokens per Sec:    21048, Lr: 0.000300
2025-05-29 22:40:29,097 - INFO - joeynmt.training - Epoch   7, Step:    69800, Batch Loss:     1.610340, Batch Acc: 0.483535, Tokens per Sec:    21456, Lr: 0.000300
2025-05-29 22:40:32,418 - INFO - joeynmt.training - Epoch   7, Step:    69900, Batch Loss:     1.524748, Batch Acc: 0.496179, Tokens per Sec:    21047, Lr: 0.000300
2025-05-29 22:40:35,798 - INFO - joeynmt.training - Epoch   7, Step:    70000, Batch Loss:     1.824013, Batch Acc: 0.494052, Tokens per Sec:    20452, Lr: 0.000300
2025-05-29 22:40:35,798 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:40:35,798 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:40:44,412 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.51, generation: 8.6023[sec], evaluation: 0.0000[sec]
2025-05-29 22:40:44,413 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:40:44,935 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/68000.ckpt
2025-05-29 22:40:44,962 - INFO - joeynmt.training - Example #0
2025-05-29 22:40:44,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:40:44,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:40:44,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 'r@@', 'acc@@', 'ogli@@', 'ere', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ono', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'are', 'per', 'il', '4@@', '8@@', '0@@', '%', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'anni', 'di', 's@@', 'otto', 'ore', 'di', '1@@', '8@@', ',', 'per', 'il', '4@@', '8@@', '0@@', '%', 'di', 's@@', 'otto', 'ore', 'di', '1@@', '0@@', '%', 'di', 'più', 'di', '4@@', '8', 'st@@', 'at@@', 'or@@', 'i@@', '.', '</s>']
2025-05-29 22:40:44,963 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:40:44,963 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:40:44,963 - INFO - joeynmt.training - 	Hypothesis: Lo scorso anno ho mostrato queste due dimensioni per raccogliere che le ghiacciono di ghiacciare per il 480% di tre milioni di anni di anni di anni di sotto ore di 18, per il 480% di sotto ore di 10% di più di 48 statori.
2025-05-29 22:40:44,963 - INFO - joeynmt.training - Example #1
2025-05-29 22:40:44,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:40:44,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:40:44,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'p@@', 'oco', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:40:44,964 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:40:44,964 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:40:44,964 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di poco la capacità di questo particolare problemi di questo particolare è che non c<unk> è il Dicke del ghiaccio.
2025-05-29 22:40:44,964 - INFO - joeynmt.training - Example #2
2025-05-29 22:40:44,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:40:44,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:40:44,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'un', 'c@@', 'li@@', 'mat@@', 'ico', 'ar@@', 't@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:40:44,965 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:40:44,965 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:40:44,965 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiacciaio di un climatico artico di climatico.
2025-05-29 22:40:44,965 - INFO - joeynmt.training - Example #3
2025-05-29 22:40:44,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:40:44,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:40:44,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'in', 'in@@', 'ver@@', 'no', 'e', 'r@@', 'os@@', 'so', 'in', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:40:44,965 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:40:44,966 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:40:44,966 - INFO - joeynmt.training - 	Hypothesis: Sta crescita in inverno e rosso in un sommergibile.
2025-05-29 22:40:44,966 - INFO - joeynmt.training - Example #4
2025-05-29 22:40:44,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:40:44,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:40:44,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'ta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'cosa', 'che', 'vi', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:40:44,966 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:40:44,966 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:40:44,966 - INFO - joeynmt.training - 	Hypothesis: La prossima dita che vi mostrerò è una dimostrazione di una cosa che vi è successo negli ultimi 25 anni.
2025-05-29 22:40:48,375 - INFO - joeynmt.training - Epoch   7, Step:    70100, Batch Loss:     1.590260, Batch Acc: 0.483664, Tokens per Sec:    18109, Lr: 0.000300
2025-05-29 22:40:51,762 - INFO - joeynmt.training - Epoch   7, Step:    70200, Batch Loss:     1.624607, Batch Acc: 0.480807, Tokens per Sec:    20655, Lr: 0.000300
2025-05-29 22:40:55,125 - INFO - joeynmt.training - Epoch   7, Step:    70300, Batch Loss:     1.814054, Batch Acc: 0.485309, Tokens per Sec:    20561, Lr: 0.000300
2025-05-29 22:40:58,506 - INFO - joeynmt.training - Epoch   7, Step:    70400, Batch Loss:     1.806861, Batch Acc: 0.481857, Tokens per Sec:    20831, Lr: 0.000300
2025-05-29 22:41:01,862 - INFO - joeynmt.training - Epoch   7, Step:    70500, Batch Loss:     1.782086, Batch Acc: 0.485743, Tokens per Sec:    20480, Lr: 0.000300
2025-05-29 22:41:01,862 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:41:01,862 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:41:10,266 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.11, acc:   0.51, generation: 8.3927[sec], evaluation: 0.0000[sec]
2025-05-29 22:41:10,799 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/67000.ckpt
2025-05-29 22:41:10,825 - INFO - joeynmt.training - Example #0
2025-05-29 22:41:10,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:41:10,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:41:10,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'man@@', 'ere', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'è', 'stato', 'chi@@', 'esto', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:41:10,827 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:41:10,827 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:41:10,827 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato queste due diapositive per rimanere le ghiaccia, che le ghiaccia, che è stato chiesto di tre milioni di anni di anni di 48 per cento di anni di 48 per cento di cento.
2025-05-29 22:41:10,827 - INFO - joeynmt.training - Example #1
2025-05-29 22:41:10,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:41:10,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:41:10,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:41:10,828 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:41:10,828 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:41:10,828 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la capacità di questo speciale problema, perché non c<unk> è il dell<unk> origine del ghiaccio.
2025-05-29 22:41:10,828 - INFO - joeynmt.training - Example #2
2025-05-29 22:41:10,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:41:10,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:41:10,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:41:10,829 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:41:10,829 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:41:10,829 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il cuore di climatico.
2025-05-29 22:41:10,829 - INFO - joeynmt.training - Example #3
2025-05-29 22:41:10,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:41:10,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:41:10,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'chi@@', 'ede', 'nel', 's@@', 'ett@@', 'ore', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', '.', '</s>']
2025-05-29 22:41:10,829 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:41:10,829 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:41:10,830 - INFO - joeynmt.training - 	Hypothesis: Si può essere in inverno e richiede nel settore di sommergi.
2025-05-29 22:41:10,830 - INFO - joeynmt.training - Example #4
2025-05-29 22:41:10,830 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:41:10,830 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:41:10,830 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'di@@', 'apos@@', 'iti@@', 'v@@', 'a@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:41:10,830 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:41:10,830 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:41:10,830 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimensione di diapositiva, che è successo negli ultimi 25 anni.
2025-05-29 22:41:14,220 - INFO - joeynmt.training - Epoch   7, Step:    70600, Batch Loss:     1.690312, Batch Acc: 0.491211, Tokens per Sec:    17556, Lr: 0.000300
2025-05-29 22:41:17,591 - INFO - joeynmt.training - Epoch   7, Step:    70700, Batch Loss:     1.831159, Batch Acc: 0.491756, Tokens per Sec:    20929, Lr: 0.000300
2025-05-29 22:41:20,991 - INFO - joeynmt.training - Epoch   7, Step:    70800, Batch Loss:     1.640904, Batch Acc: 0.494714, Tokens per Sec:    21179, Lr: 0.000300
2025-05-29 22:41:24,357 - INFO - joeynmt.training - Epoch   7, Step:    70900, Batch Loss:     1.688979, Batch Acc: 0.491374, Tokens per Sec:    20584, Lr: 0.000300
2025-05-29 22:41:27,732 - INFO - joeynmt.training - Epoch   7, Step:    71000, Batch Loss:     1.469030, Batch Acc: 0.484368, Tokens per Sec:    20580, Lr: 0.000300
2025-05-29 22:41:27,732 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:41:27,732 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:41:36,778 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.51, generation: 9.0383[sec], evaluation: 0.0000[sec]
2025-05-29 22:41:37,150 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/69000.ckpt
2025-05-29 22:41:37,173 - INFO - joeynmt.training - Example #0
2025-05-29 22:41:37,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:41:37,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:41:37,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'il', '4@@', '0@@', '%', 'delle', 'persone', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'sono', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'si', 'sono', 'ri@@', 'un@@', 'iti', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'dei', 'più', 'al@@', 'ti', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questo', 't@@', 'as@@', 'so', 'di', 'cui', 'il', '4@@', '0@@', '%', 'di', 'questi', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'ri@@', 'fl@@', 'et@@', 'tere', 'di', 'in@@', 'forma@@', 'zioni', 'ar@@', 'g@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:41:37,174 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:41:37,174 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:41:37,174 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso che ho mostrato queste due diapositive per ridurre il 40% delle persone artici, che sono i ghiacciati per tre milioni di anni che si sono riuniti per tre milioni di anni di persone che hanno insegnato per il 40% del 40% dei più alti di 40 per cento di questo tasso di cui il 40% di questi sono stati in grado di riflettere di informazioni argomento.
2025-05-29 22:41:37,174 - INFO - joeynmt.training - Example #1
2025-05-29 22:41:37,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:41:37,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:41:37,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'p@@', 'op@@', 'ol@@', 'azione', 'che', 'è', 'stato', 'un', 'problema', 'di', 'questo', 'spe@@', 'ci@@', 'fic@@', 'o@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:41:37,175 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:41:37,175 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:41:37,175 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di popolazione che è stato un problema di questo specifico, perché non c<unk> è il Dicke del ghiaccio.
2025-05-29 22:41:37,175 - INFO - joeynmt.training - Example #2
2025-05-29 22:41:37,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:41:37,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:41:37,175 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'ar@@', 't@@', 'ico', 'che', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:41:37,176 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:41:37,176 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:41:37,176 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa artico che il cuore artico del nostro sistema climatico globale.
2025-05-29 22:41:37,176 - INFO - joeynmt.training - Example #3
2025-05-29 22:41:37,176 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:41:37,176 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:41:37,176 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'p@@', 'et@@', 'on@@', 'o@@', '.', '</s>']
2025-05-29 22:41:37,177 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:41:37,177 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:41:37,177 - INFO - joeynmt.training - 	Hypothesis: Sta crescita in inverno, e si ripetono.
2025-05-29 22:41:37,177 - INFO - joeynmt.training - Example #4
2025-05-29 22:41:37,177 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:41:37,177 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:41:37,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'di@@', 'mostr@@', 'azione', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:41:37,178 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:41:37,178 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:41:37,178 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimensione di dimostrazione che è successo negli ultimi 25 anni.
2025-05-29 22:41:40,581 - INFO - joeynmt.training - Epoch   7, Step:    71100, Batch Loss:     1.691695, Batch Acc: 0.488167, Tokens per Sec:    18705, Lr: 0.000300
2025-05-29 22:41:43,974 - INFO - joeynmt.training - Epoch   7, Step:    71200, Batch Loss:     1.598301, Batch Acc: 0.491938, Tokens per Sec:    20953, Lr: 0.000300
2025-05-29 22:41:47,356 - INFO - joeynmt.training - Epoch   7, Step:    71300, Batch Loss:     1.492786, Batch Acc: 0.488638, Tokens per Sec:    20460, Lr: 0.000300
2025-05-29 22:41:50,763 - INFO - joeynmt.training - Epoch   7, Step:    71400, Batch Loss:     1.787069, Batch Acc: 0.487765, Tokens per Sec:    21179, Lr: 0.000300
2025-05-29 22:41:54,150 - INFO - joeynmt.training - Epoch   7, Step:    71500, Batch Loss:     1.559627, Batch Acc: 0.489779, Tokens per Sec:    20917, Lr: 0.000300
2025-05-29 22:41:54,150 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:41:54,150 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:42:02,424 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.11, acc:   0.51, generation: 8.2622[sec], evaluation: 0.0000[sec]
2025-05-29 22:42:02,819 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/68500.ckpt
2025-05-29 22:42:02,847 - INFO - joeynmt.training - Example #0
2025-05-29 22:42:02,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:42:02,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:42:02,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'il', '4@@', '0@@', '%', 'dei', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'le', 'di@@', 'st@@', 'anz@@', 'e@@', ',', 'il', '4@@', '8@@', '%', 'dei', 'più', 'al@@', 'ti', 'del', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:42:02,849 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:42:02,849 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:42:02,849 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per ridurre il 40% dei ghiaccio, che i ghiaccio, che per tre milioni di anni di anni le distanze, il 48% dei più alti del 40 per cento di cento.
2025-05-29 22:42:02,849 - INFO - joeynmt.training - Example #1
2025-05-29 22:42:02,849 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:42:02,849 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:42:02,849 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'a@@', ',', 'la', 'ris@@', 'post@@', 'a', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'di@@', 'mostr@@', 'o', 'il', 't@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:42:02,850 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:42:02,850 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:42:02,850 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunata, la risposta speciale di questo problema, perché non è il dimostro il ticke del ghiaccio.
2025-05-29 22:42:02,850 - INFO - joeynmt.training - Example #2
2025-05-29 22:42:02,850 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:42:02,850 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:42:02,850 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'e', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:42:02,850 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:42:02,851 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:42:02,851 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico e il nostro sistema climatico globale.
2025-05-29 22:42:02,851 - INFO - joeynmt.training - Example #3
2025-05-29 22:42:02,851 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:42:02,851 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:42:02,851 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'ri@@', 'ma@@', 'sta', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:42:02,851 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:42:02,851 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:42:02,851 - INFO - joeynmt.training - 	Hypothesis: Si può essere rimasta in inverno e in un sommergibile.
2025-05-29 22:42:02,852 - INFO - joeynmt.training - Example #4
2025-05-29 22:42:02,852 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:42:02,852 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:42:02,852 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'di@@', 'apos@@', 'iti@@', 'va', 'succ@@', 'essi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'apos@@', 'iti@@', 'va', 'di', 'di@@', 'apos@@', 'iti@@', 'v@@', 'a@@', '.', '</s>']
2025-05-29 22:42:02,852 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:42:02,852 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:42:02,852 - INFO - joeynmt.training - 	Hypothesis: La diapositiva successiva che vi mostro è una diapositiva di diapositiva.
2025-05-29 22:42:06,273 - INFO - joeynmt.training - Epoch   7, Step:    71600, Batch Loss:     1.566416, Batch Acc: 0.483216, Tokens per Sec:    18902, Lr: 0.000300
2025-05-29 22:42:09,667 - INFO - joeynmt.training - Epoch   7, Step:    71700, Batch Loss:     1.820851, Batch Acc: 0.490671, Tokens per Sec:    20902, Lr: 0.000300
2025-05-29 22:42:13,054 - INFO - joeynmt.training - Epoch   7, Step:    71800, Batch Loss:     1.632826, Batch Acc: 0.486606, Tokens per Sec:    20983, Lr: 0.000300
2025-05-29 22:42:16,423 - INFO - joeynmt.training - Epoch   7, Step:    71900, Batch Loss:     1.617741, Batch Acc: 0.483210, Tokens per Sec:    21122, Lr: 0.000300
2025-05-29 22:42:19,806 - INFO - joeynmt.training - Epoch   7, Step:    72000, Batch Loss:     1.774931, Batch Acc: 0.491317, Tokens per Sec:    21214, Lr: 0.000300
2025-05-29 22:42:19,806 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:42:19,806 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:42:28,693 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.52, generation: 8.8798[sec], evaluation: 0.0000[sec]
2025-05-29 22:42:28,694 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:42:29,190 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/70500.ckpt
2025-05-29 22:42:29,218 - INFO - joeynmt.training - Example #0
2025-05-29 22:42:29,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:42:29,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:42:29,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 'vi', 'per', 'sc@@', 'o@@', 'pr@@', 'ire', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ar@@', 't@@', 'ico', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ar@@', 't@@', 'ico', 'che', 'ha', 'in@@', 'contr@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questo', '4@@', '0', 'per', 'c@@', 'ento', 'è', 'stato', 'sc@@', 'oper@@', 'to', 'che', 'è', 'stato', 'ri@@', 'ma@@', 'sto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questo', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'è', 'stato', 'ri@@', 'ma@@', 'sto', 'per', 'vedere', 'la', 'sua', 'v@@', 'it@@', 'a@@', '.', '</s>']
2025-05-29 22:42:29,219 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:42:29,219 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:42:29,219 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositivi per scoprire che l<unk> anno scorso artico che l<unk> anno scorso artico che ha incontrato per tre milioni di anni di anni di 40 per cento di anni per il 40 per cento di questo 40 per cento è stato scoperto che è stato rimasto per il 40 per cento di questo motivo per cui è stato rimasto per vedere la sua vita.
2025-05-29 22:42:29,219 - INFO - joeynmt.training - Example #1
2025-05-29 22:42:29,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:42:29,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:42:29,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'l@@', '<unk>', 'in@@', 'st@@', 'all@@', 'azione', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'ic@@', 'chi@@', 'o@@', '.', '</s>']
2025-05-29 22:42:29,220 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:42:29,220 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:42:29,220 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza l<unk> installazione di questo speciale problema, perché non c<unk> è il dell<unk> icchio.
2025-05-29 22:42:29,220 - INFO - joeynmt.training - Example #2
2025-05-29 22:42:29,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:42:29,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:42:29,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'un', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:42:29,221 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:42:29,221 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:42:29,221 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore di un sistema di climatico.
2025-05-29 22:42:29,221 - INFO - joeynmt.training - Example #3
2025-05-29 22:42:29,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:42:29,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:42:29,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'p@@', 'et@@', 'ono', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:42:29,222 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:42:29,222 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:42:29,222 - INFO - joeynmt.training - 	Hypothesis: Si ripetono in inverno e l<unk> inverno.
2025-05-29 22:42:29,222 - INFO - joeynmt.training - Example #4
2025-05-29 22:42:29,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:42:29,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:42:29,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'v@@', 'ario', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:42:29,223 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:42:29,223 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:42:29,223 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un divario che è successo negli ultimi 25 anni.
2025-05-29 22:42:32,630 - INFO - joeynmt.training - Epoch   7, Step:    72100, Batch Loss:     1.929550, Batch Acc: 0.479205, Tokens per Sec:    18027, Lr: 0.000300
2025-05-29 22:42:35,981 - INFO - joeynmt.training - Epoch   7, Step:    72200, Batch Loss:     1.872169, Batch Acc: 0.491675, Tokens per Sec:    20747, Lr: 0.000300
2025-05-29 22:42:39,365 - INFO - joeynmt.training - Epoch   7, Step:    72300, Batch Loss:     1.544152, Batch Acc: 0.489280, Tokens per Sec:    20953, Lr: 0.000300
2025-05-29 22:42:42,744 - INFO - joeynmt.training - Epoch   7, Step:    72400, Batch Loss:     1.766178, Batch Acc: 0.487696, Tokens per Sec:    21337, Lr: 0.000300
2025-05-29 22:42:46,127 - INFO - joeynmt.training - Epoch   7, Step:    72500, Batch Loss:     1.864037, Batch Acc: 0.487359, Tokens per Sec:    20958, Lr: 0.000300
2025-05-29 22:42:46,128 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:42:46,128 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:42:54,469 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.52, generation: 8.3296[sec], evaluation: 0.0000[sec]
2025-05-29 22:42:54,469 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:42:55,041 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/71500.ckpt
2025-05-29 22:42:55,069 - INFO - joeynmt.training - Example #0
2025-05-29 22:42:55,069 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:42:55,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:42:55,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'con@@', 'segu@@', 'enze', 'ar@@', 't@@', 'icol@@', 'i', 'ar@@', 't@@', 'icol@@', 'i', 'ar@@', 't@@', 'icol@@', 'i', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'i', 'li@@', 'mit@@', 'i', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'questi', 'due', 'anni', 'hanno', 'l@@', '<unk>', 'av@@', 'uto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:42:55,070 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:42:55,070 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:42:55,070 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di conseguenze articoli articoli articoli artici, che i limiti di ghiaccio, che per tre milioni di anni di questi due anni hanno l<unk> avuto per il 40 per cento.
2025-05-29 22:42:55,070 - INFO - joeynmt.training - Example #1
2025-05-29 22:42:55,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:42:55,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:42:55,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'si', 'tr@@', 'at@@', 'ta', 'di', 'una', 'cosa', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'ci', 'sia', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'ci', 'mostr@@', 'a', 'il', 'd@@', '<unk>', 'or@@', 'a@@', '.', '</s>']
2025-05-29 22:42:55,071 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:42:55,071 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:42:55,071 - INFO - joeynmt.training - 	Hypothesis: Ma non si tratta di una cosa che non è abbastanza la prima cosa che ci sia la dimostra che non ci mostra il d<unk> ora.
2025-05-29 22:42:55,071 - INFO - joeynmt.training - Example #2
2025-05-29 22:42:55,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:42:55,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:42:55,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'm@@', 'ass@@', 'ac@@', 'ro', 'di', 'un', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:42:55,072 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:42:55,072 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:42:55,072 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il massacro di un sistema di climatico globale.
2025-05-29 22:42:55,072 - INFO - joeynmt.training - Example #3
2025-05-29 22:42:55,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:42:55,073 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:42:55,073 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'p@@', 'et@@', 'ono', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'p@@', 'et@@', 'ono', 'in', 'un', 'c@@', 'entr@@', 'o', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', '.', '</s>']
2025-05-29 22:42:55,073 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:42:55,073 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:42:55,073 - INFO - joeynmt.training - 	Hypothesis: Si ripetono in inverno e si ripetono in un centro di sommergi.
2025-05-29 22:42:55,073 - INFO - joeynmt.training - Example #4
2025-05-29 22:42:55,073 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:42:55,073 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:42:55,073 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:42:55,074 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:42:55,074 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:42:55,074 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di un disegno di quei 25 anni.
2025-05-29 22:42:58,464 - INFO - joeynmt.training - Epoch   7, Step:    72600, Batch Loss:     1.762853, Batch Acc: 0.489494, Tokens per Sec:    17501, Lr: 0.000300
2025-05-29 22:43:01,850 - INFO - joeynmt.training - Epoch   7, Step:    72700, Batch Loss:     1.878228, Batch Acc: 0.490124, Tokens per Sec:    20539, Lr: 0.000300
2025-05-29 22:43:05,215 - INFO - joeynmt.training - Epoch   7, Step:    72800, Batch Loss:     1.547644, Batch Acc: 0.488952, Tokens per Sec:    20645, Lr: 0.000300
2025-05-29 22:43:08,596 - INFO - joeynmt.training - Epoch   7, Step:    72900, Batch Loss:     1.815511, Batch Acc: 0.484660, Tokens per Sec:    21216, Lr: 0.000300
2025-05-29 22:43:11,974 - INFO - joeynmt.training - Epoch   7, Step:    73000, Batch Loss:     1.711649, Batch Acc: 0.484499, Tokens per Sec:    20842, Lr: 0.000300
2025-05-29 22:43:11,975 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:43:11,975 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:43:20,632 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.08, acc:   0.51, generation: 8.6494[sec], evaluation: 0.0000[sec]
2025-05-29 22:43:20,957 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/71000.ckpt
2025-05-29 22:43:20,975 - INFO - joeynmt.training - Example #0
2025-05-29 22:43:20,975 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:43:20,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:43:20,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'enze', 'per', 'con@@', 'segu@@', 'enza', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'ha', 'in@@', 'contr@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'il', '4@@', '8@@', ',', 'e', 'la', 'maggi@@', 'or', 'parte', 'di', 'questi', 'due', 'anni', 'di', '1@@', '0@@', ',', 'per', 'c@@', 'ento', 'di', 'un', 't@@', 'as@@', 'so', 'di', 'a@@', 'str@@', 'on@@', 'i@@', '.', '</s>']
2025-05-29 22:43:20,976 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:43:20,976 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:43:20,976 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso queste due diapositive per conseguenze per conseguenza che l<unk> articolo artico, che ha incontrato per tre milioni di anni che avevano il 48, e la maggior parte di questi due anni di 10, per cento di un tasso di astroni.
2025-05-29 22:43:20,976 - INFO - joeynmt.training - Example #1
2025-05-29 22:43:20,977 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:43:20,977 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:43:20,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'non', 'c@@', '<unk>', 'è', 'un', 'problema', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'po@@', '<unk>', 'di', 'tempo', 'e', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'un', 'po@@', '<unk>', 'di', 'b@@', 're@@', 'v@@', 'ett@@', 'o@@', ',', 'e', 'non', 'c@@', '<unk>', 'è', 'un', 'po@@', '<unk>', 'di', 'm@@', 'ess@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 's@@', 'ac@@', 'co', 'di', 'g@@', 'hi@@', 'ac@@']
2025-05-29 22:43:20,977 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:43:20,977 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:43:20,977 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che non c<unk> è un problema di ghiaccio perché non c<unk> è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di un po<unk> di tempo e la popolazione di un po<unk> di brevetto, e non c<unk> è un po<unk> di messa di ghiaccio di ghiaccio di ghiaccio di ghiaccio di un sacco di ghiac
2025-05-29 22:43:20,977 - INFO - joeynmt.training - Example #2
2025-05-29 22:43:20,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:43:20,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:43:20,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'un', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:43:20,978 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:43:20,978 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:43:20,978 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio artico, il cuore di un sistema di climatico globale.
2025-05-29 22:43:20,978 - INFO - joeynmt.training - Example #3
2025-05-29 22:43:20,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:43:20,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:43:20,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'es@@', 'ce', 'a', 's@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 22:43:20,979 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:43:20,979 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:43:20,979 - INFO - joeynmt.training - 	Hypothesis: E si può essere in inverno, e si riesce a sommer.
2025-05-29 22:43:20,979 - INFO - joeynmt.training - Example #4
2025-05-29 22:43:20,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:43:20,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:43:20,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'di@@', 'mostr@@', 'azione', 'che', 'cosa', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:43:20,980 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:43:20,980 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:43:20,980 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di dimostrazione che cosa negli ultimi 25 anni.
2025-05-29 22:43:24,383 - INFO - joeynmt.training - Epoch   7, Step:    73100, Batch Loss:     1.611853, Batch Acc: 0.488769, Tokens per Sec:    19243, Lr: 0.000300
2025-05-29 22:43:27,762 - INFO - joeynmt.training - Epoch   7, Step:    73200, Batch Loss:     1.793046, Batch Acc: 0.491037, Tokens per Sec:    20506, Lr: 0.000300
2025-05-29 22:43:31,145 - INFO - joeynmt.training - Epoch   7, Step:    73300, Batch Loss:     1.787924, Batch Acc: 0.488400, Tokens per Sec:    20381, Lr: 0.000300
2025-05-29 22:43:34,543 - INFO - joeynmt.training - Epoch   7, Step:    73400, Batch Loss:     1.581715, Batch Acc: 0.487930, Tokens per Sec:    21613, Lr: 0.000300
2025-05-29 22:43:37,901 - INFO - joeynmt.training - Epoch   7, Step:    73500, Batch Loss:     1.591036, Batch Acc: 0.486426, Tokens per Sec:    21153, Lr: 0.000300
2025-05-29 22:43:37,901 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:43:37,901 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:43:45,568 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.52, generation: 7.6560[sec], evaluation: 0.0000[sec]
2025-05-29 22:43:45,569 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:43:46,153 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/69500.ckpt
2025-05-29 22:43:46,180 - INFO - joeynmt.training - Example #0
2025-05-29 22:43:46,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:43:46,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:43:46,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 's@@', 'fi@@', 'da', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ar@@', 't@@', 'ico', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', 'il', '4@@', '8@@', ',', 'per', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'c@@', 'ento', 'per', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'c@@', 'ento', 'di', 'ri@@', 'l@@', 'ev@@', 'are', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'che', 'si', 'sono', 'ri@@', 'ma@@', 'st@@', 'i', 'che', 'si', 'trov@@', 'ano', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'l@@', '<unk>', 'in@@', 'forma@@', 'zione', 'di', 'cui', 'ho', 'mostr@@', 'ato']
2025-05-29 22:43:46,181 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:43:46,181 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:43:46,181 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per sfida che l<unk> anno scorso artico che l<unk> artico che ha fatto per tre milioni di anni che hanno avuto tre milioni di anni che hanno avuto il 48, per cento per il 40 per cento per cento per cento per il 40 per cento per cento di rilevare il 40 per cento di questi due anni che si sono rimasti che si trovano in un certo senso, e l<unk> informazione di cui ho mostrato
2025-05-29 22:43:46,181 - INFO - joeynmt.training - Example #1
2025-05-29 22:43:46,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:43:46,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:43:46,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'volta', 'che', 'non', 'c@@', '<unk>', 'è', 'un', 'problema', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'o@@', '.', '</s>']
2025-05-29 22:43:46,182 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:43:46,182 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:43:46,182 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la prima volta che non c<unk> è un problema di questo particolare problema, perché non c<unk> è il dell<unk> origino.
2025-05-29 22:43:46,182 - INFO - joeynmt.training - Example #2
2025-05-29 22:43:46,183 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:43:46,183 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:43:46,183 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'd@@', 'ell@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:43:46,183 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:43:46,183 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:43:46,183 - INFO - joeynmt.training - 	Hypothesis: In certo senso è la ghiaccio dell<unk> articolo del nostro climassa globale.
2025-05-29 22:43:46,183 - INFO - joeynmt.training - Example #3
2025-05-29 22:43:46,183 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:43:46,183 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:43:46,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'es@@', 'ce', 'a', 'ri@@', 'guar@@', 'da', 'al', 'v@@', 'ento', 'di', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:43:46,184 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:43:46,184 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:43:46,184 - INFO - joeynmt.training - 	Hypothesis: Si riesce a riguarda al vento di sommergibile.
2025-05-29 22:43:46,184 - INFO - joeynmt.training - Example #4
2025-05-29 22:43:46,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:43:46,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:43:46,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:43:46,185 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:43:46,185 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:43:46,185 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 22:43:49,587 - INFO - joeynmt.training - Epoch   7, Step:    73600, Batch Loss:     1.525467, Batch Acc: 0.488801, Tokens per Sec:    17811, Lr: 0.000300
2025-05-29 22:43:52,969 - INFO - joeynmt.training - Epoch   7, Step:    73700, Batch Loss:     1.759094, Batch Acc: 0.489894, Tokens per Sec:    20708, Lr: 0.000300
2025-05-29 22:43:56,359 - INFO - joeynmt.training - Epoch   7, Step:    73800, Batch Loss:     1.548069, Batch Acc: 0.486736, Tokens per Sec:    20732, Lr: 0.000300
2025-05-29 22:43:59,727 - INFO - joeynmt.training - Epoch   7, Step:    73900, Batch Loss:     1.474360, Batch Acc: 0.487135, Tokens per Sec:    20849, Lr: 0.000300
2025-05-29 22:44:03,101 - INFO - joeynmt.training - Epoch   7, Step:    74000, Batch Loss:     1.437792, Batch Acc: 0.490069, Tokens per Sec:    20775, Lr: 0.000300
2025-05-29 22:44:03,101 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:44:03,101 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:44:11,813 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.51, generation: 8.7002[sec], evaluation: 0.0000[sec]
2025-05-29 22:44:12,306 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/70000.ckpt
2025-05-29 22:44:12,333 - INFO - joeynmt.training - Example #0
2025-05-29 22:44:12,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:44:12,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:44:12,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'sc@@', 'ar@@', 'ic@@', 'are', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'in@@', 'segn@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 's@@', 'ott@@', 'o@@', ',', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:44:12,334 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:44:12,334 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:44:12,334 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per scaricare queste due diapositive che l<unk> articolo che ha fatto per tre milioni di anni di persone che hanno insegnato per tre milioni di anni di sotto, per il 48% di questi tre milioni di anni per cento di anni per cento di anni per il 40 percento di anni.
2025-05-29 22:44:12,334 - INFO - joeynmt.training - Example #1
2025-05-29 22:44:12,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:44:12,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:44:12,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'problema', 'è', 'che', 'non', 'ci', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:44:12,335 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:44:12,335 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:44:12,335 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di popolazione di questo problema è che non ci mostra il Dicke di ghiaccio.
2025-05-29 22:44:12,335 - INFO - joeynmt.training - Example #2
2025-05-29 22:44:12,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:44:12,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:44:12,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'di', 'il', 'nostro', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:44:12,336 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:44:12,336 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:44:12,336 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio, la ghiaccio di climassa di il nostro climassa globale.
2025-05-29 22:44:12,336 - INFO - joeynmt.training - Example #3
2025-05-29 22:44:12,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:44:12,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:44:12,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no@@', ',', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:44:12,337 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:44:12,337 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:44:12,337 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno, in inverno.
2025-05-29 22:44:12,337 - INFO - joeynmt.training - Example #4
2025-05-29 22:44:12,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:44:12,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:44:12,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'apos@@', 'iti@@', 'v@@', 'a@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:44:12,338 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:44:12,338 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:44:12,338 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una diapositiva, che è successo negli ultimi 25 anni.
2025-05-29 22:44:15,730 - INFO - joeynmt.training - Epoch   7, Step:    74100, Batch Loss:     1.934797, Batch Acc: 0.489029, Tokens per Sec:    17663, Lr: 0.000300
2025-05-29 22:44:19,110 - INFO - joeynmt.training - Epoch   7, Step:    74200, Batch Loss:     1.730343, Batch Acc: 0.488849, Tokens per Sec:    20995, Lr: 0.000300
2025-05-29 22:44:22,481 - INFO - joeynmt.training - Epoch   7, Step:    74300, Batch Loss:     1.352330, Batch Acc: 0.492983, Tokens per Sec:    20952, Lr: 0.000300
2025-05-29 22:44:25,854 - INFO - joeynmt.training - Epoch   7, Step:    74400, Batch Loss:     1.851564, Batch Acc: 0.486690, Tokens per Sec:    20870, Lr: 0.000300
2025-05-29 22:44:29,243 - INFO - joeynmt.training - Epoch   7, Step:    74500, Batch Loss:     1.747467, Batch Acc: 0.488330, Tokens per Sec:    21142, Lr: 0.000300
2025-05-29 22:44:29,243 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:44:29,244 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:44:37,158 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.52, generation: 7.9027[sec], evaluation: 0.0000[sec]
2025-05-29 22:44:37,559 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/73000.ckpt
2025-05-29 22:44:37,585 - INFO - joeynmt.training - Example #0
2025-05-29 22:44:37,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:44:37,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:44:37,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'qu@@', 'ell@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'è', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'd@@', 'ell@@', '<unk>', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'il', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', '4@@', '8', 'st@@', 'ati@@', ',', 'e', 'il', '4@@', '8@@', '%', 'dei', 'più', 'am@@', 'pi@@', '.', '</s>']
2025-05-29 22:44:37,586 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:44:37,586 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:44:37,586 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso quell<unk> anno scorso queste due diapositive per ridurre il ghiaccio artico, che è il ghiaccio dell<unk> articolo, il 48% dei più grandi 48 stati, e il 48% dei più ampi.
2025-05-29 22:44:37,586 - INFO - joeynmt.training - Example #1
2025-05-29 22:44:37,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:44:37,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:44:37,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'amente', 'la', 'prima', 'cosa', 'che', 'è', 'succ@@', 'esso', 'è', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'c@@', '<unk>', 'è', 'un', 'po@@', '<unk>', 'di', 'm@@', 'oti@@', 'v@@', 'azione', 'di', 'questo', 'problema', 'è', 'che', 'non', 'è', 'stato', 'in@@', 'tr@@', 'ap@@', 'res@@', 'o', 'con@@', 'to', 'che', 'non', 'c@@', '<unk>', 'è', 'una', 'cosa', 'che', 'è', 'n@@', 'ec@@', 'ess@@', 'ario', 'per', 'la', 'prima', 'volta', 'che', 'non', 'c@@', '<unk>', 'è', 'un', 'po@@', '<unk>', 'di', 's@@', 'qu@@', 'ad@@', 'ra', 'e', 'la', 'maggi@@', 'or', 'parte', 'delle', 'persone', 'che', 'si', 'trov@@', 'a']
2025-05-29 22:44:37,587 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:44:37,587 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:44:37,587 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente la prima cosa che è successo è che non c<unk> è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio che non c<unk> è un po<unk> di motivazione di questo problema è che non è stato intrapreso conto che non c<unk> è una cosa che è necessario per la prima volta che non c<unk> è un po<unk> di squadra e la maggior parte delle persone che si trova
2025-05-29 22:44:37,587 - INFO - joeynmt.training - Example #2
2025-05-29 22:44:37,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:44:37,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:44:37,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'del', 'nostro', 'c@@', 'li@@', 'ma', 'di', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', 'mo', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:44:37,588 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:44:37,588 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:44:37,588 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo del nostro clima di climassa del nostro climassimo globale.
2025-05-29 22:44:37,588 - INFO - joeynmt.training - Example #3
2025-05-29 22:44:37,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:44:37,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:44:37,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'oi', 'si', 'ri@@', 'fer@@', 'is@@', 'ce', 'a', 'ri@@', 'guar@@', 'do', 'al', 'v@@', 'ento', 'di', 's@@', 'ett@@', 'or@@', 'e@@', '.', '</s>']
2025-05-29 22:44:37,589 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:44:37,589 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:44:37,589 - INFO - joeynmt.training - 	Hypothesis: Poi si riferisce a riguardo al vento di settore.
2025-05-29 22:44:37,589 - INFO - joeynmt.training - Example #4
2025-05-29 22:44:37,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:44:37,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:44:37,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'di@@', 'mostr@@', 'a', 'che', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:44:37,590 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:44:37,590 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:44:37,590 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di una dimostra che cosa è successo negli ultimi 25 anni.
2025-05-29 22:44:40,956 - INFO - joeynmt.training - Epoch   7, Step:    74600, Batch Loss:     1.838337, Batch Acc: 0.489048, Tokens per Sec:    18248, Lr: 0.000300
2025-05-29 22:44:44,285 - INFO - joeynmt.training - Epoch   7, Step:    74700, Batch Loss:     1.690356, Batch Acc: 0.490088, Tokens per Sec:    21147, Lr: 0.000300
2025-05-29 22:44:47,650 - INFO - joeynmt.training - Epoch   7, Step:    74800, Batch Loss:     1.727637, Batch Acc: 0.488481, Tokens per Sec:    20834, Lr: 0.000300
2025-05-29 22:44:51,001 - INFO - joeynmt.training - Epoch   7, Step:    74900, Batch Loss:     1.821604, Batch Acc: 0.490997, Tokens per Sec:    21504, Lr: 0.000300
2025-05-29 22:44:51,677 - INFO - joeynmt.training - Epoch   7: total training loss 18227.22
2025-05-29 22:44:51,677 - INFO - joeynmt.training - EPOCH 8
2025-05-29 22:44:54,375 - INFO - joeynmt.training - Epoch   8, Step:    75000, Batch Loss:     1.452766, Batch Acc: 0.496954, Tokens per Sec:    21372, Lr: 0.000300
2025-05-29 22:44:54,375 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:44:54,375 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:45:02,693 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.52, generation: 8.3050[sec], evaluation: 0.0000[sec]
2025-05-29 22:45:03,085 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/74500.ckpt
2025-05-29 22:45:03,105 - INFO - joeynmt.training - Example #0
2025-05-29 22:45:03,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:45:03,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:45:03,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'sc@@', 'eg@@', 'li@@', 'ere', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'sono', 'stati', 'in', '4@@', '8@@', ',', 'che', 'ha', 'pres@@', 'o', 'i', '4@@', '8@@', ',', 'per', 'c@@', 'ento', 'di', 'circa', '4@@', '8@@', ',', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:45:03,106 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:45:03,106 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:45:03,106 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per scegliere che i ghiaccio, che i ghiacciano per tre milioni di anni che sono stati in 48, che ha preso i 48, per cento di circa 48, per 40 per cento per cento.
2025-05-29 22:45:03,106 - INFO - joeynmt.training - Example #1
2025-05-29 22:45:03,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:45:03,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:45:03,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'l@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'a', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'spe@@', 'ci@@', 'al@@', 'i@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'ale', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'che', 'il', 'p@@', 'ezz@@', 'o', 'di', 'un', 'po@@', '<unk>', 'di', 'sol@@', 'ito', 'di', 'per', 'il', 'suo', 'inter@@', 'no', 'di', 'un', 'po@@', '<unk>', 'di', 'pi@@', 'ù@@', '.', '</s>']
2025-05-29 22:45:03,107 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:45:03,107 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:45:03,107 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, l<unk> industria di questo particolare problemi speciali, perché non c<unk> è il dell<unk> originale del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di questo particolare è che il pezzo di un po<unk> di solito di per il suo interno di un po<unk> di più.
2025-05-29 22:45:03,107 - INFO - joeynmt.training - Example #2
2025-05-29 22:45:03,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:45:03,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:45:03,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'ar@@', 't@@', 'ico', 'ar@@', 't@@', 'ico', 'che', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'ass@@', 'a', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:45:03,108 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:45:03,108 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:45:03,108 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> artico artico artico che il cuore del nostro climassa globale.
2025-05-29 22:45:03,108 - INFO - joeynmt.training - Example #3
2025-05-29 22:45:03,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:45:03,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:45:03,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'ri@@', 'es@@', 'ce', 'a', 'ri@@', 'guard@@', 'o@@', ',', 'e', 'in', 't@@', 'ur@@', 'a@@', '.', '</s>']
2025-05-29 22:45:03,109 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:45:03,109 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:45:03,109 - INFO - joeynmt.training - 	Hypothesis: E si riesce a riguardo, e in tura.
2025-05-29 22:45:03,109 - INFO - joeynmt.training - Example #4
2025-05-29 22:45:03,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:45:03,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:45:03,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 's@@', 'itu@@', 'azione', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'di@@', 'apos@@', 'iti@@', 'vo@@', '.', '</s>']
2025-05-29 22:45:03,110 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:45:03,110 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:45:03,110 - INFO - joeynmt.training - 	Hypothesis: La situazione che vi mostro è una diapositiva che vi mostro è un disegno di un disegno di un pezzo di un pezzo di un pezzo di diapositivo.
2025-05-29 22:45:06,479 - INFO - joeynmt.training - Epoch   8, Step:    75100, Batch Loss:     1.760259, Batch Acc: 0.503974, Tokens per Sec:    18515, Lr: 0.000300
2025-05-29 22:45:09,846 - INFO - joeynmt.training - Epoch   8, Step:    75200, Batch Loss:     1.537642, Batch Acc: 0.499430, Tokens per Sec:    21354, Lr: 0.000300
2025-05-29 22:45:13,214 - INFO - joeynmt.training - Epoch   8, Step:    75300, Batch Loss:     1.637877, Batch Acc: 0.503927, Tokens per Sec:    21216, Lr: 0.000300
2025-05-29 22:45:16,565 - INFO - joeynmt.training - Epoch   8, Step:    75400, Batch Loss:     1.682168, Batch Acc: 0.503668, Tokens per Sec:    21327, Lr: 0.000300
2025-05-29 22:45:19,917 - INFO - joeynmt.training - Epoch   8, Step:    75500, Batch Loss:     1.646828, Batch Acc: 0.496927, Tokens per Sec:    21461, Lr: 0.000300
2025-05-29 22:45:19,917 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:45:19,917 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:45:27,301 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.52, generation: 7.3735[sec], evaluation: 0.0000[sec]
2025-05-29 22:45:27,302 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:45:27,853 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/72000.ckpt
2025-05-29 22:45:27,878 - INFO - joeynmt.training - Example #0
2025-05-29 22:45:27,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:45:27,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:45:27,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 's@@', 'f@@', 'am@@', 'are', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'hanno', 'chiam@@', 'ato', '<unk>', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'chiam@@', 'ato', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'or@@', 'e@@', ',', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'or@@', 'e@@', '.', '</s>']
2025-05-29 22:45:27,880 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:45:27,880 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:45:27,880 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per sfamare che i ghiaccio, che hanno chiamato <unk> l<unk> articolo di tre milioni di anni che hanno chiamato 48 per cento di 48 ore, il 48 per cento di 48 ore.
2025-05-29 22:45:27,880 - INFO - joeynmt.training - Example #1
2025-05-29 22:45:27,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:45:27,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:45:27,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'di@@', 'mostr@@', 'o', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'di@@', 'mostr@@', 'o', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:45:27,881 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:45:27,881 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:45:27,881 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che non è abbastanza forte, perché non c<unk> è il dimostro che non c<unk> è il dimostro di ghiaccio.
2025-05-29 22:45:27,881 - INFO - joeynmt.training - Example #2
2025-05-29 22:45:27,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:45:27,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:45:27,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'd@@', 'ell@@', '<unk>', 'in@@', 'tel@@', 'li@@', 'gen@@', 'za', 'c@@', 'li@@', 'mat@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 22:45:27,882 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:45:27,882 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:45:27,882 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è l<unk> articolo artico, il cuore del nostro climatico globale del nostro climatico globale del nostro climatico globale del nostro climatico globale dell<unk> intelligenza climatica.
2025-05-29 22:45:27,882 - INFO - joeynmt.training - Example #3
2025-05-29 22:45:27,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:45:27,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:45:27,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'es@@', 'ce', 'a', 'v@@', 'it@@', 'a@@', ',', 'e', 'si', 'ri@@', 'p@@', 'et@@', 'er@@', 'e@@', '.', '</s>']
2025-05-29 22:45:27,882 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:45:27,882 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:45:27,882 - INFO - joeynmt.training - 	Hypothesis: Si riesce a vita, e si ripetere.
2025-05-29 22:45:27,883 - INFO - joeynmt.training - Example #4
2025-05-29 22:45:27,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:45:27,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:45:27,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'di@@', 'seg@@', 'no', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:45:27,883 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:45:27,883 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:45:27,883 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di un disegno di un pezzo di un pezzo di un pezzo di disegno negli ultimi 25 anni.
2025-05-29 22:45:31,258 - INFO - joeynmt.training - Epoch   8, Step:    75600, Batch Loss:     1.706667, Batch Acc: 0.503896, Tokens per Sec:    17941, Lr: 0.000300
2025-05-29 22:45:34,619 - INFO - joeynmt.training - Epoch   8, Step:    75700, Batch Loss:     1.765932, Batch Acc: 0.496688, Tokens per Sec:    21253, Lr: 0.000300
2025-05-29 22:45:37,957 - INFO - joeynmt.training - Epoch   8, Step:    75800, Batch Loss:     1.600265, Batch Acc: 0.495517, Tokens per Sec:    20787, Lr: 0.000300
2025-05-29 22:45:41,317 - INFO - joeynmt.training - Epoch   8, Step:    75900, Batch Loss:     1.613175, Batch Acc: 0.503169, Tokens per Sec:    21371, Lr: 0.000300
2025-05-29 22:45:44,616 - INFO - joeynmt.training - Epoch   8, Step:    76000, Batch Loss:     1.605927, Batch Acc: 0.500503, Tokens per Sec:    21394, Lr: 0.000300
2025-05-29 22:45:44,616 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:45:44,616 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:45:53,409 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.52, generation: 8.7816[sec], evaluation: 0.0000[sec]
2025-05-29 22:45:53,410 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:45:53,936 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/72500.ckpt
2025-05-29 22:45:53,960 - INFO - joeynmt.training - Example #0
2025-05-29 22:45:53,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:45:53,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:45:53,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 're@@', ',', 'per', 'sc@@', 'ambi@@', 'are', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'd@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'chiam@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'tre', 'milioni', 'di', 'anni', 'per', '4@@', '8@@', ',', 'per', '4@@', '8@@', ',', 'per', '4@@', '8@@', ',', 'per', '4@@', '8@@', ',', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:45:53,961 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:45:53,961 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:45:53,961 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per dire, per scambiare che l<unk> articolo che ha dato per tre milioni di anni che hanno chiamato per tre milioni di anni che avevano tre milioni di anni per 48, per 48, per 48, per 48, per 40 per cento di cento.
2025-05-29 22:45:53,961 - INFO - joeynmt.training - Example #1
2025-05-29 22:45:53,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:45:53,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:45:53,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:45:53,962 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:45:53,962 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:45:53,962 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che non è abbastanza forte, perché non è il Dicke del ghiaccio.
2025-05-29 22:45:53,962 - INFO - joeynmt.training - Example #2
2025-05-29 22:45:53,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:45:53,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:45:53,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'ar@@', 't@@', 'ico', 'che', 'il', 'cu@@', 'ore', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:45:53,963 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:45:53,963 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:45:53,963 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> artico artico che il cuore di climatico globale del nostro sistema di climatico globale.
2025-05-29 22:45:53,963 - INFO - joeynmt.training - Example #3
2025-05-29 22:45:53,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:45:53,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:45:53,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'p@@', 'et@@', 'ono', 'in', 'in@@', 'ver@@', 'no', 'e', 't@@', 'ag@@', 'li@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:45:53,964 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:45:53,964 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:45:53,964 - INFO - joeynmt.training - 	Hypothesis: Si ripetono in inverno e tagliato.
2025-05-29 22:45:53,964 - INFO - joeynmt.training - Example #4
2025-05-29 22:45:53,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:45:53,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:45:53,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:45:53,965 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:45:53,965 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:45:53,965 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di un disegno di disegno negli ultimi 25 anni.
2025-05-29 22:45:57,293 - INFO - joeynmt.training - Epoch   8, Step:    76100, Batch Loss:     1.593207, Batch Acc: 0.494798, Tokens per Sec:    17698, Lr: 0.000300
2025-05-29 22:46:00,612 - INFO - joeynmt.training - Epoch   8, Step:    76200, Batch Loss:     1.612244, Batch Acc: 0.499153, Tokens per Sec:    21186, Lr: 0.000300
2025-05-29 22:46:03,932 - INFO - joeynmt.training - Epoch   8, Step:    76300, Batch Loss:     1.575185, Batch Acc: 0.501221, Tokens per Sec:    21585, Lr: 0.000300
2025-05-29 22:46:07,292 - INFO - joeynmt.training - Epoch   8, Step:    76400, Batch Loss:     1.723853, Batch Acc: 0.505225, Tokens per Sec:    21306, Lr: 0.000300
2025-05-29 22:46:10,629 - INFO - joeynmt.training - Epoch   8, Step:    76500, Batch Loss:     1.687917, Batch Acc: 0.495599, Tokens per Sec:    21183, Lr: 0.000300
2025-05-29 22:46:10,630 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:46:10,630 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:46:18,405 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.52, generation: 7.7643[sec], evaluation: 0.0000[sec]
2025-05-29 22:46:18,806 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/74000.ckpt
2025-05-29 22:46:18,832 - INFO - joeynmt.training - Example #0
2025-05-29 22:46:18,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:46:18,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:46:18,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'questo', 'per', 'di@@', 're@@', ',', 'per', 'con@@', 'segu@@', 'ire', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'era', 'il', '4@@', '8@@', ',', 'che', 'av@@', 'evano', 'il', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', '4@@', '8@@', ',', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:46:18,833 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:46:18,833 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:46:18,833 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di questo per dire, per conseguire il ghiaccio che i ghiaccio artico, che era il 48, che avevano il 48% dei più grandi 48, per cento.
2025-05-29 22:46:18,833 - INFO - joeynmt.training - Example #1
2025-05-29 22:46:18,834 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:46:18,834 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:46:18,834 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'au@@', 'ra', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'i@@', ',', 'perché', 'non', 'è', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'questo', 'part@@', 'icol@@', 'are', 'e', 'il', 'loro', 'st@@', 'ile', 'di', 'di@@', 're@@', ',', 'e', 'la', 'maggi@@', 'or', 'parte', 'dei', 'nostri', 'c@@', 'li@@', 'enti', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'i@@', ',', 'e', 'la', 'loro', 'st@@', 'ia', 'di@@', 'sp@@', 'os@@', 'i@@', 'zione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'la', 'maggi@@', 'or', 'parte', 'dei', 'nostri', 'c@@', 'li@@', 'v@@', 'elli', 'che', 'si', 'ri@@', 'fer@@', 'is@@', 'cono', 'a', 'di@@', 'st@@', 'ur@@', 'b@@']
2025-05-29 22:46:18,834 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:46:18,834 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:46:18,834 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la paura di questo particolare problemi, perché non è il ghiaccio il ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di questo particolare e il loro stile di dire, e la maggior parte dei nostri clienti di questo tipo di problemi, e la loro stia disposizione di questo problema, e la maggior parte dei nostri clivelli che si riferiscono a disturb
2025-05-29 22:46:18,834 - INFO - joeynmt.training - Example #2
2025-05-29 22:46:18,835 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:46:18,835 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:46:18,835 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:46:18,835 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:46:18,835 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:46:18,835 - INFO - joeynmt.training - 	Hypothesis: In un certo senso di ghiaccio artico, il ghiaccio globale.
2025-05-29 22:46:18,835 - INFO - joeynmt.training - Example #3
2025-05-29 22:46:18,836 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:46:18,836 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:46:18,836 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'ri@@', 'ma@@', 'sta', 'ri@@', 'p@@', 'et@@', 'ere', 'nel', 'v@@', 'ento', 'della', 'p@@', 'at@@', 'ri@@', 'a', 'nel', 'm@@', 'ezz@@', 'o@@', '.', '</s>']
2025-05-29 22:46:18,836 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:46:18,836 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:46:18,836 - INFO - joeynmt.training - 	Hypothesis: Si può essere rimasta ripetere nel vento della patria nel mezzo.
2025-05-29 22:46:18,836 - INFO - joeynmt.training - Example #4
2025-05-29 22:46:18,836 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:46:18,837 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:46:18,837 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'di@@', 'st@@', 'anza', 'di', 'di@@', 'seg@@', 'na', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:46:18,837 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:46:18,837 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:46:18,837 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una dimostrazione di una distanza di disegna che è successo negli ultimi 25 anni.
2025-05-29 22:46:22,235 - INFO - joeynmt.training - Epoch   8, Step:    76600, Batch Loss:     1.722709, Batch Acc: 0.496604, Tokens per Sec:    18722, Lr: 0.000300
2025-05-29 22:46:25,607 - INFO - joeynmt.training - Epoch   8, Step:    76700, Batch Loss:     1.581331, Batch Acc: 0.498047, Tokens per Sec:    21343, Lr: 0.000300
2025-05-29 22:46:28,988 - INFO - joeynmt.training - Epoch   8, Step:    76800, Batch Loss:     1.666828, Batch Acc: 0.497779, Tokens per Sec:    21575, Lr: 0.000300
2025-05-29 22:46:32,396 - INFO - joeynmt.training - Epoch   8, Step:    76900, Batch Loss:     1.578916, Batch Acc: 0.493571, Tokens per Sec:    20867, Lr: 0.000300
2025-05-29 22:46:35,777 - INFO - joeynmt.training - Epoch   8, Step:    77000, Batch Loss:     1.674520, Batch Acc: 0.496456, Tokens per Sec:    20035, Lr: 0.000300
2025-05-29 22:46:35,777 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:46:35,777 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:46:44,487 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.52, generation: 8.7018[sec], evaluation: 0.0000[sec]
2025-05-29 22:46:44,500 - INFO - joeynmt.training - Example #0
2025-05-29 22:46:44,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:46:44,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:46:44,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 'vi', 'per', 'con@@', 'segu@@', 'ire', 'le', 'di@@', 'apos@@', 'iti@@', 'che', 'che', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ano', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'av@@', 'evano', 'mostr@@', 'ato', 'che', 'la', 'gente', 'av@@', 'rebbe', 'pot@@', 'uto', 'per', 'essere', 'il', '4@@', '8@@', '%', 'di', 'più', 'di', '4@@', '8', 'or@@', 'e@@', '.', '</s>']
2025-05-29 22:46:44,501 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:46:44,501 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:46:44,501 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositivi per conseguire le diapositiche che che i ghiacciano che i ghiaccia, che avevano mostrato che la gente avrebbe potuto per essere il 48% di più di 48 ore.
2025-05-29 22:46:44,501 - INFO - joeynmt.training - Example #1
2025-05-29 22:46:44,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:46:44,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:46:44,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'ter@@', 'ra', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:46:44,502 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:46:44,502 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:46:44,502 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la terra di questo problema speciale di questo problema speciale che non c<unk> è il dell<unk> ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 22:46:44,502 - INFO - joeynmt.training - Example #2
2025-05-29 22:46:44,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:46:44,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:46:44,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'k@@', 'et@@', ',', 'il', 'cu@@', 'ore', 'd@@', 'ell@@', '<unk>', 'in@@', 'tel@@', 'li@@', 'gen@@', 'za', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:46:44,502 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:46:44,502 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:46:44,503 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articket, il cuore dell<unk> intelligenza globale.
2025-05-29 22:46:44,503 - INFO - joeynmt.training - Example #3
2025-05-29 22:46:44,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:46:44,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:46:44,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'fare', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:46:44,503 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:46:44,503 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:46:44,503 - INFO - joeynmt.training - 	Hypothesis: Si può fare in inverno e in inverno in inverno.
2025-05-29 22:46:44,503 - INFO - joeynmt.training - Example #4
2025-05-29 22:46:44,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:46:44,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:46:44,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'di@@', 'st@@', 'anza', 'di', 'di@@', 'seg@@', 'no', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:46:44,504 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:46:44,504 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:46:44,504 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una dimostrazione di una distanza di disegno che è successo negli ultimi 25 anni.
2025-05-29 22:46:47,906 - INFO - joeynmt.training - Epoch   8, Step:    77100, Batch Loss:     1.642822, Batch Acc: 0.488379, Tokens per Sec:    21076, Lr: 0.000300
2025-05-29 22:46:51,283 - INFO - joeynmt.training - Epoch   8, Step:    77200, Batch Loss:     1.594595, Batch Acc: 0.492753, Tokens per Sec:    21130, Lr: 0.000300
2025-05-29 22:46:54,678 - INFO - joeynmt.training - Epoch   8, Step:    77300, Batch Loss:     1.652576, Batch Acc: 0.497454, Tokens per Sec:    21005, Lr: 0.000300
2025-05-29 22:46:58,079 - INFO - joeynmt.training - Epoch   8, Step:    77400, Batch Loss:     1.595313, Batch Acc: 0.500400, Tokens per Sec:    20962, Lr: 0.000300
2025-05-29 22:47:01,459 - INFO - joeynmt.training - Epoch   8, Step:    77500, Batch Loss:     1.581594, Batch Acc: 0.495913, Tokens per Sec:    21398, Lr: 0.000300
2025-05-29 22:47:01,460 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:47:01,460 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:47:09,398 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.52, generation: 7.9270[sec], evaluation: 0.0000[sec]
2025-05-29 22:47:09,399 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:47:09,982 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/76500.ckpt
2025-05-29 22:47:10,008 - INFO - joeynmt.training - Example #0
2025-05-29 22:47:10,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:47:10,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:47:10,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 's@@', 'ott@@', 'op@@', 'or@@', 'zioni', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'che', 'la', 'gente', 'chiam@@', 'a', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'ha', 'il', '4@@', '8@@', ',', 'che', 'ha', 'il', '4@@', '8@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'si', 'è', 'sc@@', 'ar@@', 'ic@@', 'ato', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'ott@@', 'op@@', 'or@@', 'zioni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:47:10,009 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:47:10,009 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:47:10,009 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di sottoporzioni di ghiacciaio che la gente chiama ghiaccia, che ha il 48, che ha il 48, per tre milioni di anni che si è scaricato per il 40 per cento di sottoporzioni di 40 per cento di cento.
2025-05-29 22:47:10,009 - INFO - joeynmt.training - Example #1
2025-05-29 22:47:10,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:47:10,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:47:10,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'pot@@', 'ente', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'per', 'questo', 'spe@@', 'ci@@', 'ale', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:47:10,010 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:47:10,010 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:47:10,010 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza potente abbastanza la popolazione di questo speciale per questo speciale perché non è il Dicke del ghiaccio.
2025-05-29 22:47:10,010 - INFO - joeynmt.training - Example #2
2025-05-29 22:47:10,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:47:10,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:47:10,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'ma', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:47:10,011 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:47:10,011 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:47:10,011 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> artico del nostro clima di climatico.
2025-05-29 22:47:10,011 - INFO - joeynmt.training - Example #3
2025-05-29 22:47:10,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:47:10,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:47:10,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'in@@', 'du@@', 'stri@@', 'a', 'del', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:47:10,012 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:47:10,012 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:47:10,012 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno e l<unk> inverno e l<unk> industria del sommergibile.
2025-05-29 22:47:10,012 - INFO - joeynmt.training - Example #4
2025-05-29 22:47:10,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:47:10,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:47:10,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:47:10,013 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:47:10,013 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:47:10,013 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un disegno di un disegno di un disegno di un certo senso.
2025-05-29 22:47:13,438 - INFO - joeynmt.training - Epoch   8, Step:    77600, Batch Loss:     1.762242, Batch Acc: 0.500070, Tokens per Sec:    17789, Lr: 0.000300
2025-05-29 22:47:16,841 - INFO - joeynmt.training - Epoch   8, Step:    77700, Batch Loss:     1.573364, Batch Acc: 0.497379, Tokens per Sec:    21143, Lr: 0.000300
2025-05-29 22:47:20,246 - INFO - joeynmt.training - Epoch   8, Step:    77800, Batch Loss:     1.528218, Batch Acc: 0.492959, Tokens per Sec:    20945, Lr: 0.000300
2025-05-29 22:47:23,624 - INFO - joeynmt.training - Epoch   8, Step:    77900, Batch Loss:     1.870960, Batch Acc: 0.493408, Tokens per Sec:    20212, Lr: 0.000300
2025-05-29 22:47:27,016 - INFO - joeynmt.training - Epoch   8, Step:    78000, Batch Loss:     1.715901, Batch Acc: 0.491365, Tokens per Sec:    21067, Lr: 0.000300
2025-05-29 22:47:27,017 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:47:27,017 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:47:34,362 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.52, generation: 7.3342[sec], evaluation: 0.0000[sec]
2025-05-29 22:47:34,918 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/75000.ckpt
2025-05-29 22:47:34,939 - INFO - joeynmt.training - Example #0
2025-05-29 22:47:34,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:47:34,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:47:34,940 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'qu@@', 'i@@', ',', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'enze', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'i', 'ar@@', 't@@', 'ic@@', 'i@@', 'p@@', 'ali', 'che', 'hanno', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'av@@', 'uto', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'che', 'ha', 'fatto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:47:34,940 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:47:34,940 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:47:34,940 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso qui, ho mostrato queste diapositive per conseguenze artici, che i articipali che hanno avuto per tre milioni di anni che avevano avuto il 40 per cento di anni che ha fatto per il 40 per cento di questi 40 per cento.
2025-05-29 22:47:34,940 - INFO - joeynmt.training - Example #1
2025-05-29 22:47:34,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:47:34,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:47:34,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'ter@@', 'ra', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:47:34,941 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:47:34,941 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:47:34,941 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la terra di questo particolare problemi di questo particolare è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio.
2025-05-29 22:47:34,942 - INFO - joeynmt.training - Example #2
2025-05-29 22:47:34,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:47:34,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:47:34,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:47:34,942 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:47:34,942 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:47:34,942 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore del nostro sistema globale globale del nostro sistema globale.
2025-05-29 22:47:34,942 - INFO - joeynmt.training - Example #3
2025-05-29 22:47:34,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:47:34,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:47:34,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:47:34,943 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:47:34,943 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:47:34,943 - INFO - joeynmt.training - 	Hypothesis: Si può essere in inverno e l<unk> estate.
2025-05-29 22:47:34,943 - INFO - joeynmt.training - Example #4
2025-05-29 22:47:34,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:47:34,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:47:34,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:47:34,944 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:47:34,944 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:47:34,944 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 22:47:38,364 - INFO - joeynmt.training - Epoch   8, Step:    78100, Batch Loss:     1.946530, Batch Acc: 0.489097, Tokens per Sec:    17960, Lr: 0.000300
2025-05-29 22:47:41,766 - INFO - joeynmt.training - Epoch   8, Step:    78200, Batch Loss:     1.763043, Batch Acc: 0.499117, Tokens per Sec:    20966, Lr: 0.000300
2025-05-29 22:47:45,153 - INFO - joeynmt.training - Epoch   8, Step:    78300, Batch Loss:     1.911671, Batch Acc: 0.499479, Tokens per Sec:    20708, Lr: 0.000300
2025-05-29 22:47:48,545 - INFO - joeynmt.training - Epoch   8, Step:    78400, Batch Loss:     1.569219, Batch Acc: 0.497663, Tokens per Sec:    21327, Lr: 0.000300
2025-05-29 22:47:51,898 - INFO - joeynmt.training - Epoch   8, Step:    78500, Batch Loss:     1.825393, Batch Acc: 0.500820, Tokens per Sec:    20916, Lr: 0.000300
2025-05-29 22:47:51,898 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:47:51,898 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:48:00,477 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.52, generation: 8.5711[sec], evaluation: 0.0000[sec]
2025-05-29 22:48:00,830 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/73500.ckpt
2025-05-29 22:48:00,856 - INFO - joeynmt.training - Example #0
2025-05-29 22:48:00,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:48:00,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:48:00,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 's@@', 'par@@', 'are', 'che', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'la', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'è', 'stato', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'che', 'è', 'stato', 'fatto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:48:00,857 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:48:00,857 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:48:00,857 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per sparare che la popolazione artica, che la articolo di ghiaccio, che è stato il 40 per cento di anni che è stato fatto per il 40 per cento di anni.
2025-05-29 22:48:00,857 - INFO - joeynmt.training - Example #1
2025-05-29 22:48:00,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:48:00,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:48:00,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:48:00,858 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:48:00,858 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:48:00,858 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la popolazione di questo problema speciale, perché non c<unk> è il Dicke del ghiaccio.
2025-05-29 22:48:00,858 - INFO - joeynmt.training - Example #2
2025-05-29 22:48:00,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:48:00,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:48:00,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'ine', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:48:00,858 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:48:00,859 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:48:00,859 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico del nostro climine globale.
2025-05-29 22:48:00,859 - INFO - joeynmt.training - Example #3
2025-05-29 22:48:00,859 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:48:00,859 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:48:00,859 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'nel', 'v@@', 'ento', 'e', 'ri@@', 'p@@', 'et@@', 'ere', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:48:00,859 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:48:00,859 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:48:00,859 - INFO - joeynmt.training - 	Hypothesis: Sta crescita nel vento e ripetere in inverno e in sommergibile.
2025-05-29 22:48:00,860 - INFO - joeynmt.training - Example #4
2025-05-29 22:48:00,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:48:00,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:48:00,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'di@@', 'seg@@', 'no', 'del', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:48:00,860 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:48:00,860 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:48:00,860 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di disegno del 25 anni.
2025-05-29 22:48:04,269 - INFO - joeynmt.training - Epoch   8, Step:    78600, Batch Loss:     1.596243, Batch Acc: 0.497841, Tokens per Sec:    18571, Lr: 0.000300
2025-05-29 22:48:07,650 - INFO - joeynmt.training - Epoch   8, Step:    78700, Batch Loss:     1.797361, Batch Acc: 0.494532, Tokens per Sec:    20344, Lr: 0.000300
2025-05-29 22:48:11,035 - INFO - joeynmt.training - Epoch   8, Step:    78800, Batch Loss:     1.629082, Batch Acc: 0.495366, Tokens per Sec:    20435, Lr: 0.000300
2025-05-29 22:48:14,441 - INFO - joeynmt.training - Epoch   8, Step:    78900, Batch Loss:     1.575902, Batch Acc: 0.490071, Tokens per Sec:    21151, Lr: 0.000300
2025-05-29 22:48:17,846 - INFO - joeynmt.training - Epoch   8, Step:    79000, Batch Loss:     1.803275, Batch Acc: 0.493074, Tokens per Sec:    21354, Lr: 0.000300
2025-05-29 22:48:17,846 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:48:17,846 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:48:26,290 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.01, acc:   0.52, generation: 8.4324[sec], evaluation: 0.0000[sec]
2025-05-29 22:48:26,291 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:48:26,857 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/75500.ckpt
2025-05-29 22:48:26,882 - INFO - joeynmt.training - Example #0
2025-05-29 22:48:26,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:48:26,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:48:26,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'ire', 'le', 's@@', 'fi@@', 'de', 'per', 'con@@', 'segu@@', 'enze', 'che', 'i', 'ar@@', 't@@', 'icol@@', 'i', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'la', 'po@@', 'es@@', 'ia', 'di', 'tre', 'milioni', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:48:26,883 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:48:26,884 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:48:26,884 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per conseguire le sfide per conseguenze che i articoli di ghiaccia, che la poesia di tre milioni di anni di 48 per cento di anni di 40 per cento di 40 per cento di 40 per cento di cento.
2025-05-29 22:48:26,884 - INFO - joeynmt.training - Example #1
2025-05-29 22:48:26,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:48:26,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:48:26,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'volta', 'che', 'la', 'prima', 'volta', 'che', 'non', 'c@@', '<unk>', 'è', 'la', 'd@@', 'ell@@', '<unk>', 'ar@@', 'ea', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 22:48:26,884 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:48:26,885 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:48:26,885 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la prima volta che la prima volta che non c<unk> è la dell<unk> area di ghiaccia.
2025-05-29 22:48:26,885 - INFO - joeynmt.training - Example #2
2025-05-29 22:48:26,885 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:48:26,885 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:48:26,885 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'br@@', 'ac@@', 'cio', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:48:26,885 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:48:26,885 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:48:26,886 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo di ghiaccio, il braccio del nostro sistema climatico globale.
2025-05-29 22:48:26,886 - INFO - joeynmt.training - Example #3
2025-05-29 22:48:26,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:48:26,886 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:48:26,886 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'di', 'tut@@', 't@@', 'o@@', ',', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:48:26,886 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:48:26,886 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:48:26,886 - INFO - joeynmt.training - 	Hypothesis: Prima di tutto, in inverno e in inverno e in sommergibile.
2025-05-29 22:48:26,886 - INFO - joeynmt.training - Example #4
2025-05-29 22:48:26,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:48:26,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:48:26,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'co', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:48:26,887 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:48:26,887 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:48:26,887 - INFO - joeynmt.training - 	Hypothesis: Il prossimo dico che vi mostro è una dimostrazione di un disegno di disegno di quello che è successo negli ultimi 25 anni.
2025-05-29 22:48:30,298 - INFO - joeynmt.training - Epoch   8, Step:    79100, Batch Loss:     1.627942, Batch Acc: 0.491256, Tokens per Sec:    17782, Lr: 0.000300
2025-05-29 22:48:33,688 - INFO - joeynmt.training - Epoch   8, Step:    79200, Batch Loss:     1.842426, Batch Acc: 0.502462, Tokens per Sec:    21334, Lr: 0.000300
2025-05-29 22:48:37,099 - INFO - joeynmt.training - Epoch   8, Step:    79300, Batch Loss:     1.690621, Batch Acc: 0.492163, Tokens per Sec:    21479, Lr: 0.000300
2025-05-29 22:48:40,474 - INFO - joeynmt.training - Epoch   8, Step:    79400, Batch Loss:     1.577194, Batch Acc: 0.498429, Tokens per Sec:    21034, Lr: 0.000300
2025-05-29 22:48:43,851 - INFO - joeynmt.training - Epoch   8, Step:    79500, Batch Loss:     1.605155, Batch Acc: 0.494432, Tokens per Sec:    21144, Lr: 0.000300
2025-05-29 22:48:43,852 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:48:43,852 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:48:51,383 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.52, generation: 7.5199[sec], evaluation: 0.0000[sec]
2025-05-29 22:48:51,790 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/76000.ckpt
2025-05-29 22:48:51,816 - INFO - joeynmt.training - Example #0
2025-05-29 22:48:51,817 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:48:51,817 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:48:51,817 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'sc@@', 'eg@@', 'li@@', 'ere', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'un', 't@@', 'as@@', 'so', 'di', '4@@', '8', 'st@@', 'ati@@', ',', 'per', 'il', '4@@', '8@@', '0@@', '%', 'dei', 'più', 'gran@@', 'di', '4@@', '8', 'st@@', 'ati@@', ',', 'per', 'il', '4@@', '0@@', '%', 'dei', 'v@@', 'it@@', 'tor@@', 'i@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', 't@@', 'as@@', 'so', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'ett@@', 'or@@', 'i@@', '.', '</s>']
2025-05-29 22:48:51,817 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:48:51,818 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:48:51,818 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno scorso queste due diapositive per scegliere che l<unk> articolo di ghiaccia, che l<unk> anno scorso di un tasso di 48 stati, per il 480% dei più grandi 48 stati, per il 40% dei vittori, il 40 per cento di un 40 per cento di un tasso di 40 per cento di settori.
2025-05-29 22:48:51,818 - INFO - joeynmt.training - Example #1
2025-05-29 22:48:51,818 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:48:51,818 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:48:51,818 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'di@@', 'mostr@@', 'o', 'che', 'non', 'è', 'il', 'di@@', 'mostr@@', 'o', 'che', 'non', 'è', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:48:51,818 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:48:51,818 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:48:51,819 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la popolazione di questo particolare problema, perché non c<unk> è il dimostro che non è il dimostro che non è un po<unk> .
2025-05-29 22:48:51,819 - INFO - joeynmt.training - Example #2
2025-05-29 22:48:51,819 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:48:51,819 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:48:51,819 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'un', 'sistema', 'di', 'p@@', 'eg@@', 'gi@@', 'o', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:48:51,819 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:48:51,819 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:48:51,820 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa di ghiacciaio di un sistema di peggio globale.
2025-05-29 22:48:51,820 - INFO - joeynmt.training - Example #3
2025-05-29 22:48:51,820 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:48:51,820 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:48:51,820 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'a', 'un', 'p@@', 'ezz@@', 'o', 'di', 'un', 'p@@', 'at@@', 'o@@', '.', '</s>']
2025-05-29 22:48:51,820 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:48:51,820 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:48:51,820 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno e in inverno a un pezzo di un pato.
2025-05-29 22:48:51,820 - INFO - joeynmt.training - Example #4
2025-05-29 22:48:51,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:48:51,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:48:51,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'ess@@', 'o@@', ',', 'è', 'succ@@', 'ess@@', 'o@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:48:51,821 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:48:51,821 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:48:51,821 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo, è successo, che è successo negli ultimi 25 anni.
2025-05-29 22:48:55,208 - INFO - joeynmt.training - Epoch   8, Step:    79600, Batch Loss:     1.676538, Batch Acc: 0.478863, Tokens per Sec:    18082, Lr: 0.000300
2025-05-29 22:48:58,560 - INFO - joeynmt.training - Epoch   8, Step:    79700, Batch Loss:     1.713707, Batch Acc: 0.495472, Tokens per Sec:    21579, Lr: 0.000300
2025-05-29 22:49:01,906 - INFO - joeynmt.training - Epoch   8, Step:    79800, Batch Loss:     1.648924, Batch Acc: 0.492727, Tokens per Sec:    20964, Lr: 0.000300
2025-05-29 22:49:05,266 - INFO - joeynmt.training - Epoch   8, Step:    79900, Batch Loss:     1.671340, Batch Acc: 0.489593, Tokens per Sec:    20327, Lr: 0.000300
2025-05-29 22:49:08,640 - INFO - joeynmt.training - Epoch   8, Step:    80000, Batch Loss:     1.665514, Batch Acc: 0.496075, Tokens per Sec:    21295, Lr: 0.000300
2025-05-29 22:49:08,640 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:49:08,640 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:49:16,943 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.00, acc:   0.52, generation: 8.2918[sec], evaluation: 0.0000[sec]
2025-05-29 22:49:16,943 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:49:17,486 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/78000.ckpt
2025-05-29 22:49:17,507 - INFO - joeynmt.training - Example #0
2025-05-29 22:49:17,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:49:17,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:49:17,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'sc@@', 'ar@@', 'ic@@', 'are', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'un', '4@@', '8', 'st@@', 'at@@', 'o@@', ',', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', 'due', 's@@', 'iti', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 's@@', 'é', 'di', 'circa', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'ett@@', 'or@@', 'i@@', '.', '</s>']
2025-05-29 22:49:17,509 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:49:17,509 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:49:17,509 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato queste due diapositive per scaricare che l<unk> articolo artico che ha fatto per tre milioni di anni ha avuto tre milioni di anni ha avuto un 48 stato, per il 48% di questi due siti per 40 per cento di cento di sé di circa 40 per cento di settori.
2025-05-29 22:49:17,509 - INFO - joeynmt.training - Example #1
2025-05-29 22:49:17,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:49:17,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:49:17,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'spe@@', 'ci@@', 'al@@', 'i@@', ',', 'perché', 'non', 'ci', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:49:17,510 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:49:17,510 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:49:17,510 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte la popolazione di questo particolare problemi speciali, perché non ci mostra il ghiaccio.
2025-05-29 22:49:17,510 - INFO - joeynmt.training - Example #2
2025-05-29 22:49:17,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:49:17,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:49:17,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'e', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:49:17,511 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:49:17,511 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:49:17,511 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico e il cuore artico del nostro climatico globale.
2025-05-29 22:49:17,511 - INFO - joeynmt.training - Example #3
2025-05-29 22:49:17,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:49:17,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:49:17,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'm@@', 'om@@', 'in@@', 'a@@', '.', '</s>']
2025-05-29 22:49:17,512 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:49:17,512 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:49:17,512 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno e in inverno e in momina.
2025-05-29 22:49:17,512 - INFO - joeynmt.training - Example #4
2025-05-29 22:49:17,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:49:17,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:49:17,512 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:49:17,512 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:49:17,513 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:49:17,513 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 22:49:20,921 - INFO - joeynmt.training - Epoch   8, Step:    80100, Batch Loss:     1.548391, Batch Acc: 0.497320, Tokens per Sec:    17966, Lr: 0.000300
2025-05-29 22:49:24,299 - INFO - joeynmt.training - Epoch   8, Step:    80200, Batch Loss:     1.546552, Batch Acc: 0.498599, Tokens per Sec:    20721, Lr: 0.000300
2025-05-29 22:49:27,686 - INFO - joeynmt.training - Epoch   8, Step:    80300, Batch Loss:     1.922961, Batch Acc: 0.494294, Tokens per Sec:    20832, Lr: 0.000300
2025-05-29 22:49:31,068 - INFO - joeynmt.training - Epoch   8, Step:    80400, Batch Loss:     2.006517, Batch Acc: 0.492813, Tokens per Sec:    21211, Lr: 0.000300
2025-05-29 22:49:34,438 - INFO - joeynmt.training - Epoch   8, Step:    80500, Batch Loss:     1.736293, Batch Acc: 0.496425, Tokens per Sec:    20843, Lr: 0.000300
2025-05-29 22:49:34,438 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:49:34,438 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:49:43,048 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.00, acc:   0.52, generation: 8.5984[sec], evaluation: 0.0000[sec]
2025-05-29 22:49:43,445 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/79500.ckpt
2025-05-29 22:49:43,470 - INFO - joeynmt.training - Example #0
2025-05-29 22:49:43,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:49:43,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:49:43,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'ire', 'le', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'ire', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'è', 'stato', 'il', '4@@', '8', 'ore', 'di', 'St@@', 'ati', 'Un@@', 'iti@@', '.', '</s>']
2025-05-29 22:49:43,471 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:49:43,471 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:49:43,471 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso queste due diapositive per conseguire le due diapositive per conseguire il ghiaccio artico che i ghiaccio artico, che è stato il 48 ore di Stati Uniti.
2025-05-29 22:49:43,471 - INFO - joeynmt.training - Example #1
2025-05-29 22:49:43,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:49:43,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:49:43,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'che', 'non', 'ci', 'mostr@@', 'a', 'il', 'di@@', 'mostr@@', 'a', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'di@@', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:49:43,472 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:49:43,472 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:49:43,472 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte di questo particolare problemi che non ci mostra il dimostra che non c<unk> è il dimostra il dell<unk> ghiaccio.
2025-05-29 22:49:43,472 - INFO - joeynmt.training - Example #2
2025-05-29 22:49:43,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:49:43,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:49:43,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'che', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:49:43,473 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:49:43,473 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:49:43,473 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è il cuore artico che il cuore artico il nostro sistema climatico globale.
2025-05-29 22:49:43,473 - INFO - joeynmt.training - Example #3
2025-05-29 22:49:43,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:49:43,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:49:43,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'vel@@', 'a', 'il', 'v@@', 'ento', 'di', 'un', 'po@@', '<unk>', 'di', 'sc@@', 'al@@', 'a@@', '.', '</s>']
2025-05-29 22:49:43,474 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:49:43,474 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:49:43,474 - INFO - joeynmt.training - 	Hypothesis: Si rivela il vento di un po<unk> di scala.
2025-05-29 22:49:43,474 - INFO - joeynmt.training - Example #4
2025-05-29 22:49:43,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:49:43,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:49:43,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'una', 'di@@', 'men@@', 'sione', 'di', 'qu@@', 'ale', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:49:43,475 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:49:43,475 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:49:43,475 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di una dimensione di quale negli ultimi 25 anni.
2025-05-29 22:49:46,883 - INFO - joeynmt.training - Epoch   8, Step:    80600, Batch Loss:     1.860026, Batch Acc: 0.494905, Tokens per Sec:    18478, Lr: 0.000300
2025-05-29 22:49:50,255 - INFO - joeynmt.training - Epoch   8, Step:    80700, Batch Loss:     1.688919, Batch Acc: 0.494140, Tokens per Sec:    20249, Lr: 0.000300
2025-05-29 22:49:53,630 - INFO - joeynmt.training - Epoch   8, Step:    80800, Batch Loss:     1.681976, Batch Acc: 0.490286, Tokens per Sec:    20899, Lr: 0.000300
2025-05-29 22:49:57,027 - INFO - joeynmt.training - Epoch   8, Step:    80900, Batch Loss:     1.825482, Batch Acc: 0.498963, Tokens per Sec:    21009, Lr: 0.000300
2025-05-29 22:50:00,412 - INFO - joeynmt.training - Epoch   8, Step:    81000, Batch Loss:     1.709471, Batch Acc: 0.490679, Tokens per Sec:    21039, Lr: 0.000300
2025-05-29 22:50:00,412 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:50:00,412 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:50:08,626 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   4.99, acc:   0.52, generation: 8.2061[sec], evaluation: 0.0000[sec]
2025-05-29 22:50:08,627 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:50:09,255 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/78500.ckpt
2025-05-29 22:50:09,273 - INFO - joeynmt.training - Example #0
2025-05-29 22:50:09,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:50:09,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:50:09,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'con@@', 'segu@@', 'enti', 'per', 'ri@@', 'fl@@', 'et@@', 'tere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'ha', 'il', '3@@', '0@@', '%', 'del', '4@@', '8@@', '%', 'di', 'anni', 'che', 'ha', 'd@@', 'ato', 'il', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', '4@@', '8', 'stati', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:50:09,273 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:50:09,274 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:50:09,274 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due conseguenti per riflettere che la ghiaccio artico che la ghiaccio artico che ha il 30% del 48% di anni che ha dato il 48% dei più grandi 48 stati per cento.
2025-05-29 22:50:09,274 - INFO - joeynmt.training - Example #1
2025-05-29 22:50:09,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:50:09,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:50:09,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'è', 'stato', 'il', 'prim@@', 'o', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'c@@', '<unk>', 'è', 'un', 'po@@', '<unk>', 'di', 'più', 'o', 'meno', 'che', 'non', 'c@@', '<unk>', 'è', 'un', 'po@@', '<unk>', 'di', 's@@', 'f@@', 'era', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'f@@', 'era', 'abb@@', 'ast@@', 'anza', 'e', 'di', 'un', 'po@@', '<unk>', 'di', 'qu@@', 'ale', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'più', 'di', 'un', 'po@@', '<unk>', 'di', 'qu@@', 'ale', 'è', 'un', 'po@@', '<unk>', 'di', 'qu@@', 'ale', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 22:50:09,275 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:50:09,275 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:50:09,275 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la prima cosa che è stato il primo problema, perché non c<unk> è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio che non c<unk> è un po<unk> di più o meno che non c<unk> è un po<unk> di sfera di un po<unk> di sfera abbastanza e di un po<unk> di quale è stato un po<unk> di più di un po<unk> di quale è un po<unk> di quale problema.
2025-05-29 22:50:09,275 - INFO - joeynmt.training - Example #2
2025-05-29 22:50:09,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:50:09,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:50:09,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:50:09,275 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:50:09,276 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:50:09,276 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico del nostro sistema climatico globale.
2025-05-29 22:50:09,276 - INFO - joeynmt.training - Example #3
2025-05-29 22:50:09,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:50:09,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:50:09,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'ce', 'nel', 'vent@@', 'o@@', ',', 'nel', 'vent@@', 'o@@', ',', 'e', 'si', 'ri@@', 'fer@@', 'is@@', 'ce', 'nel', 'f@@', 'ut@@', 'ur@@', 'o@@', '.', '</s>']
2025-05-29 22:50:09,276 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:50:09,276 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:50:09,276 - INFO - joeynmt.training - 	Hypothesis: Sta cresce nel vento, nel vento, e si riferisce nel futuro.
2025-05-29 22:50:09,277 - INFO - joeynmt.training - Example #4
2025-05-29 22:50:09,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:50:09,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:50:09,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'essi@@', 'on@@', 'e@@', ',', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:50:09,277 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:50:09,277 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:50:09,277 - INFO - joeynmt.training - 	Hypothesis: La prossima sessione, che vi mostrerò è un disegno di un disegno di quei 25 anni.
2025-05-29 22:50:12,574 - INFO - joeynmt.training - Epoch   8, Step:    81100, Batch Loss:     1.759921, Batch Acc: 0.494483, Tokens per Sec:    17910, Lr: 0.000300
2025-05-29 22:50:15,879 - INFO - joeynmt.training - Epoch   8, Step:    81200, Batch Loss:     1.697731, Batch Acc: 0.493778, Tokens per Sec:    21647, Lr: 0.000300
2025-05-29 22:50:19,151 - INFO - joeynmt.training - Epoch   8, Step:    81300, Batch Loss:     1.444408, Batch Acc: 0.498030, Tokens per Sec:    21264, Lr: 0.000300
2025-05-29 22:50:22,454 - INFO - joeynmt.training - Epoch   8, Step:    81400, Batch Loss:     1.712717, Batch Acc: 0.493417, Tokens per Sec:    22176, Lr: 0.000300
2025-05-29 22:50:25,790 - INFO - joeynmt.training - Epoch   8, Step:    81500, Batch Loss:     1.709274, Batch Acc: 0.489331, Tokens per Sec:    21573, Lr: 0.000300
2025-05-29 22:50:25,790 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:50:25,790 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:50:34,838 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   4.99, acc:   0.52, generation: 9.0354[sec], evaluation: 0.0000[sec]
2025-05-29 22:50:35,221 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/77500.ckpt
2025-05-29 22:50:35,245 - INFO - joeynmt.training - Example #0
2025-05-29 22:50:35,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:50:35,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:50:35,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 'vi', 'per', 'vedere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'ha', 'la', 'chiam@@', 'ata', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', '3@@', '00', 'per', 'c@@', 'ent@@', 'o@@', ',', 'il', '4@@', '8@@', '%', 'di', 'questi', 'due', 's@@', 'ott@@', 'om@@', 'ar@@', 'e@@', '.', '</s>']
2025-05-29 22:50:35,246 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:50:35,246 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:50:35,246 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositivi per vedere che la ghiaccio artico, che la ghiaccio artico, che ha la chiamata di ghiaccio di 300 per cento, il 48% di questi due sottomare.
2025-05-29 22:50:35,246 - INFO - joeynmt.training - Example #1
2025-05-29 22:50:35,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:50:35,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:50:35,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'è', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'il', 'di@@', 'mostr@@', 'o', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'e', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'da', 'un', 'po@@', '<unk>', 'più', 'di', 'un', 'po@@', '<unk>', 'più', 'grande', 'e', 'a', 'li@@', 'vello', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'ha', 'fatto', 'è', 'stata', 'la', 'prima', 'cosa', 'che', 'è', 'stato', 'in@@', 'vent@@', 'ato', 'da', 'un', 'po@@', '<unk>', 'più', 'grande', 'e', 'la', 'di@@', 'st@@', 'anza', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'il', 'di@@', 'mostr@@', 'o', 'di', 'un']
2025-05-29 22:50:35,247 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:50:35,247 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:50:35,247 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la prima cosa che è la prima cosa che non è il dimostro il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio e il ghiaccio che non è abbastanza forte da un po<unk> più di un po<unk> più grande e a livello di ghiaccio che ha fatto è stata la prima cosa che è stato inventato da un po<unk> più grande e la distanza di ghiaccio che è il dimostro di un
2025-05-29 22:50:35,247 - INFO - joeynmt.training - Example #2
2025-05-29 22:50:35,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:50:35,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:50:35,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:50:35,248 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:50:35,248 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:50:35,248 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico del ghiaccio globale del nostro sistema climatico globale.
2025-05-29 22:50:35,248 - INFO - joeynmt.training - Example #3
2025-05-29 22:50:35,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:50:35,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:50:35,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'in', 'in@@', 'ver@@', 'no', 'in', 'in@@', 'ver@@', 'no', 'in', 'in@@', 'ver@@', 'no', 'a', 'm@@', 'e@@', '.', '</s>']
2025-05-29 22:50:35,248 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:50:35,248 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:50:35,249 - INFO - joeynmt.training - 	Hypothesis: Sta cresce in inverno in inverno in inverno in inverno a me.
2025-05-29 22:50:35,249 - INFO - joeynmt.training - Example #4
2025-05-29 22:50:35,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:50:35,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:50:35,249 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'apos@@', 'iti@@', 'vo', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'st@@', 'anza', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', 'due', 'due', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:50:35,249 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:50:35,249 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:50:35,249 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostrerò è una distanza di un disegno di un disegno di quei due due anni.
2025-05-29 22:50:38,631 - INFO - joeynmt.training - Epoch   8, Step:    81600, Batch Loss:     1.743817, Batch Acc: 0.502415, Tokens per Sec:    18834, Lr: 0.000300
2025-05-29 22:50:41,997 - INFO - joeynmt.training - Epoch   8, Step:    81700, Batch Loss:     1.889835, Batch Acc: 0.493866, Tokens per Sec:    21053, Lr: 0.000300
2025-05-29 22:50:45,368 - INFO - joeynmt.training - Epoch   8, Step:    81800, Batch Loss:     1.630439, Batch Acc: 0.495583, Tokens per Sec:    21228, Lr: 0.000300
2025-05-29 22:50:48,723 - INFO - joeynmt.training - Epoch   8, Step:    81900, Batch Loss:     1.722307, Batch Acc: 0.493932, Tokens per Sec:    21102, Lr: 0.000300
2025-05-29 22:50:52,063 - INFO - joeynmt.training - Epoch   8, Step:    82000, Batch Loss:     1.904354, Batch Acc: 0.496431, Tokens per Sec:    20856, Lr: 0.000300
2025-05-29 22:50:52,063 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:50:52,063 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:51:01,022 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   4.99, acc:   0.52, generation: 8.9475[sec], evaluation: 0.0000[sec]
2025-05-29 22:51:01,387 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/79000.ckpt
2025-05-29 22:51:01,412 - INFO - joeynmt.training - Example #0
2025-05-29 22:51:01,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:51:01,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:51:01,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'ha', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ato', 'per', 'il', '4@@', '8@@', ',', 'che', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'di', '4@@', '8@@', ',', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:51:01,413 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:51:01,413 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:51:01,413 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per ridurre che il ghiaccio artico, che ha il ghiacciato per il 48, che ha avuto tre milioni di anni di 48, per cento di questi due anni di 40 per cento di cento.
2025-05-29 22:51:01,413 - INFO - joeynmt.training - Example #1
2025-05-29 22:51:01,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:51:01,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:51:01,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'stato', 'il', 'di@@', 'st@@', 'ur@@', 'b@@', 'o', 'non', 'è', 'il', 'di@@', 'mostr@@', 'o', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'di@@', 'mostr@@', 'o', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:51:01,414 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:51:01,414 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:51:01,414 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la prima cosa che non è stato il disturbo non è il dimostro che non c<unk> è il dimostro del ghiaccio.
2025-05-29 22:51:01,414 - INFO - joeynmt.training - Example #2
2025-05-29 22:51:01,415 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:51:01,415 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:51:01,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:51:01,415 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:51:01,415 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:51:01,415 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è il cuore artico, il cuore artico.
2025-05-29 22:51:01,415 - INFO - joeynmt.training - Example #3
2025-05-29 22:51:01,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:51:01,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:51:01,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'en@@', 'so', 'che', 'la', 'gente', 'si', 'ri@@', 'du@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'nel', 'm@@', 'ezz@@', 'o', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 22:51:01,416 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:51:01,416 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:51:01,416 - INFO - joeynmt.training - 	Hypothesis: Penso che la gente si riduce in inverno nel mezzo di un po<unk> .
2025-05-29 22:51:01,416 - INFO - joeynmt.training - Example #4
2025-05-29 22:51:01,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:51:01,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:51:01,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:51:01,417 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:51:01,417 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:51:01,417 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un disegno di un disegno di un disegno di disegno negli ultimi 25 anni.
2025-05-29 22:51:04,797 - INFO - joeynmt.training - Epoch   8, Step:    82100, Batch Loss:     1.689117, Batch Acc: 0.494971, Tokens per Sec:    18837, Lr: 0.000300
2025-05-29 22:51:08,159 - INFO - joeynmt.training - Epoch   8, Step:    82200, Batch Loss:     1.645289, Batch Acc: 0.492706, Tokens per Sec:    20844, Lr: 0.000300
2025-05-29 22:51:11,540 - INFO - joeynmt.training - Epoch   8, Step:    82300, Batch Loss:     1.695978, Batch Acc: 0.502455, Tokens per Sec:    21033, Lr: 0.000300
2025-05-29 22:51:14,928 - INFO - joeynmt.training - Epoch   8, Step:    82400, Batch Loss:     1.797116, Batch Acc: 0.493255, Tokens per Sec:    20768, Lr: 0.000300
2025-05-29 22:51:18,312 - INFO - joeynmt.training - Epoch   8, Step:    82500, Batch Loss:     1.570659, Batch Acc: 0.489444, Tokens per Sec:    20817, Lr: 0.000300
2025-05-29 22:51:18,313 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:51:18,313 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:51:26,475 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.96, acc:   0.52, generation: 8.1505[sec], evaluation: 0.0000[sec]
2025-05-29 22:51:26,475 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:51:27,005 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/80500.ckpt
2025-05-29 22:51:27,028 - INFO - joeynmt.training - Example #0
2025-05-29 22:51:27,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:51:27,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:51:27,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'sc@@', 'o@@', 'pr@@', 'ire', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'è', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'che', 'av@@', 'evo', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'av@@', 'evo', 'fatto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'per', 'ri@@', 'p@@', 'et@@', 'iti@@', '.', '</s>']
2025-05-29 22:51:27,030 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:51:27,030 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:51:27,030 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per scoprire che la ghiaccia, che la ghiaccia, che è il 40 per cento di anni che avevo tre milioni di anni di anni che avevo fatto per il 40 per cento di anni per ripetiti.
2025-05-29 22:51:27,030 - INFO - joeynmt.training - Example #1
2025-05-29 22:51:27,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:51:27,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:51:27,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'grande', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'problema', 'che', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:51:27,031 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:51:27,031 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:51:27,031 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più grande che non è abbastanza forte perché non c<unk> è il problema che non è la Dicke del ghiaccio.
2025-05-29 22:51:27,031 - INFO - joeynmt.training - Example #2
2025-05-29 22:51:27,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:51:27,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:51:27,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'c@@', 'las@@', 'se', 'di', 'un', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:51:27,032 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:51:27,032 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:51:27,032 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il cuore di classe di un sistema di climatico globale.
2025-05-29 22:51:27,032 - INFO - joeynmt.training - Example #3
2025-05-29 22:51:27,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:51:27,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:51:27,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'es@@', 'ce', 'a', 'v@@', 'ento', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:51:27,032 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:51:27,032 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:51:27,033 - INFO - joeynmt.training - 	Hypothesis: Si riesce a vento in inverno e in inverno in inverno.
2025-05-29 22:51:27,033 - INFO - joeynmt.training - Example #4
2025-05-29 22:51:27,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:51:27,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:51:27,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'ho', 'mostr@@', 'ato', 'è', 'una', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:51:27,033 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:51:27,033 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:51:27,033 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi ho mostrato è una diapositiva che è successo negli ultimi 25 anni.
2025-05-29 22:51:30,450 - INFO - joeynmt.training - Epoch   8, Step:    82600, Batch Loss:     1.730483, Batch Acc: 0.492174, Tokens per Sec:    18360, Lr: 0.000300
2025-05-29 22:51:33,862 - INFO - joeynmt.training - Epoch   8, Step:    82700, Batch Loss:     1.583572, Batch Acc: 0.487677, Tokens per Sec:    20671, Lr: 0.000300
2025-05-29 22:51:37,265 - INFO - joeynmt.training - Epoch   8, Step:    82800, Batch Loss:     1.708731, Batch Acc: 0.496403, Tokens per Sec:    20754, Lr: 0.000300
2025-05-29 22:51:40,647 - INFO - joeynmt.training - Epoch   8, Step:    82900, Batch Loss:     1.639118, Batch Acc: 0.495753, Tokens per Sec:    20755, Lr: 0.000300
2025-05-29 22:51:44,050 - INFO - joeynmt.training - Epoch   8, Step:    83000, Batch Loss:     1.662255, Batch Acc: 0.495960, Tokens per Sec:    20811, Lr: 0.000300
2025-05-29 22:51:44,050 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:51:44,050 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:51:52,936 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.97, acc:   0.52, generation: 8.8765[sec], evaluation: 0.0000[sec]
2025-05-29 22:51:53,289 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/80000.ckpt
2025-05-29 22:51:53,314 - INFO - joeynmt.training - Example #0
2025-05-29 22:51:53,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:51:53,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:51:53,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'c@@', 'ento', 'di', 's@@', 'ott@@', 'om@@', 'ar@@', 'ini', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'è', 'stata', 'chiam@@', 'ata', '<unk>', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', ',', 'il', '4@@', '0@@', '%', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:51:53,316 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:51:53,316 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:51:53,316 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due diapositive per cento di sottomarini che la ghiaccia, che è stata chiamata <unk> ghiaccia, che ha avuto il 480 per cento di anni, il 40% di cento.
2025-05-29 22:51:53,316 - INFO - joeynmt.training - Example #1
2025-05-29 22:51:53,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:51:53,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:51:53,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'amente', 'la', 'cosa', 'più', 'importante', 'è', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'd@@', 'ell@@', '<unk>', 'E@@', 'is@@', 'es@@', '.', '</s>']
2025-05-29 22:51:53,317 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:51:53,317 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:51:53,317 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente la cosa più importante è che non c<unk> è il Dicke non è il Dicke non è abbastanza forte dell<unk> Eises.
2025-05-29 22:51:53,317 - INFO - joeynmt.training - Example #2
2025-05-29 22:51:53,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:51:53,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:51:53,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:51:53,318 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:51:53,318 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:51:53,318 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio che è il cuore del nostro sistema climatico globale.
2025-05-29 22:51:53,318 - INFO - joeynmt.training - Example #3
2025-05-29 22:51:53,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:51:53,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:51:53,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'os@@', 'siamo', 'cres@@', 'ci@@', 'uti', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'p@@', 'et@@', 'r@@', 'ol@@', 'i@@', '.', '</s>']
2025-05-29 22:51:53,319 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:51:53,319 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:51:53,319 - INFO - joeynmt.training - 	Hypothesis: Possiamo cresciuti in inverno, e si ripetroli.
2025-05-29 22:51:53,319 - INFO - joeynmt.training - Example #4
2025-05-29 22:51:53,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:51:53,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:51:53,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'ta', 'di@@', 'apos@@', 'iti@@', 've', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:51:53,320 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:51:53,320 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:51:53,320 - INFO - joeynmt.training - 	Hypothesis: La prossima dita diapositive che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 22:51:56,738 - INFO - joeynmt.training - Epoch   8, Step:    83100, Batch Loss:     1.610088, Batch Acc: 0.493233, Tokens per Sec:    18839, Lr: 0.000300
2025-05-29 22:52:00,131 - INFO - joeynmt.training - Epoch   8, Step:    83200, Batch Loss:     1.619073, Batch Acc: 0.494808, Tokens per Sec:    20551, Lr: 0.000300
2025-05-29 22:52:03,522 - INFO - joeynmt.training - Epoch   8, Step:    83300, Batch Loss:     1.780851, Batch Acc: 0.496964, Tokens per Sec:    20460, Lr: 0.000300
2025-05-29 22:52:06,919 - INFO - joeynmt.training - Epoch   8, Step:    83400, Batch Loss:     1.531955, Batch Acc: 0.493306, Tokens per Sec:    20827, Lr: 0.000300
2025-05-29 22:52:10,268 - INFO - joeynmt.training - Epoch   8, Step:    83500, Batch Loss:     1.865121, Batch Acc: 0.492085, Tokens per Sec:    21336, Lr: 0.000300
2025-05-29 22:52:10,269 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:52:10,269 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:52:18,628 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   4.99, acc:   0.52, generation: 8.3475[sec], evaluation: 0.0000[sec]
2025-05-29 22:52:19,013 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/81500.ckpt
2025-05-29 22:52:19,039 - INFO - joeynmt.training - Example #0
2025-05-29 22:52:19,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:52:19,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:52:19,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'sc@@', 'or@@', 'so', 'qu@@', 'ei', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 's@@', 'fi@@', 'da', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'in@@', 'segn@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'il', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', 'di', 'm@@', 'e@@', '.', '</s>']
2025-05-29 22:52:19,040 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:52:19,040 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:52:19,040 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno scorso quei due anni per cento di sfida artico, che l<unk> articolo che ha avuto per tre milioni di anni che avevano insegnato per tre milioni di anni che avevano il 48% dei più grandi di me.
2025-05-29 22:52:19,040 - INFO - joeynmt.training - Example #1
2025-05-29 22:52:19,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:52:19,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:52:19,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'c@@', '<unk>', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ec@@', 'chi@@', 'o@@', '.', '</s>']
2025-05-29 22:52:19,041 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:52:19,041 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:52:19,041 - INFO - joeynmt.training - 	Hypothesis: Ma non c<unk> è abbastanza forte abbastanza forte di questo problema, perché non c<unk> è il dell<unk> orecchio.
2025-05-29 22:52:19,041 - INFO - joeynmt.training - Example #2
2025-05-29 22:52:19,041 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:52:19,041 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:52:19,041 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'un', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:52:19,042 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:52:19,042 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:52:19,042 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiacciaio di ghiacciaio di un sistema globale.
2025-05-29 22:52:19,042 - INFO - joeynmt.training - Example #3
2025-05-29 22:52:19,042 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:52:19,042 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:52:19,042 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'p@@', 'et@@', 'ut@@', 'a@@', '.', '</s>']
2025-05-29 22:52:19,043 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:52:19,043 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:52:19,043 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno, e si ripetuta.
2025-05-29 22:52:19,043 - INFO - joeynmt.training - Example #4
2025-05-29 22:52:19,043 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:52:19,043 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:52:19,043 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'qu@@', 'asi', 'di', 'qu@@', 'ei', 'due', 'anni', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:52:19,043 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:52:19,044 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:52:19,044 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di quasi di quei due anni è successo negli ultimi 25 anni.
2025-05-29 22:52:22,433 - INFO - joeynmt.training - Epoch   8, Step:    83600, Batch Loss:     1.498227, Batch Acc: 0.491007, Tokens per Sec:    19073, Lr: 0.000300
2025-05-29 22:52:25,790 - INFO - joeynmt.training - Epoch   8, Step:    83700, Batch Loss:     1.750010, Batch Acc: 0.487587, Tokens per Sec:    21090, Lr: 0.000300
2025-05-29 22:52:29,138 - INFO - joeynmt.training - Epoch   8, Step:    83800, Batch Loss:     1.634021, Batch Acc: 0.497195, Tokens per Sec:    20716, Lr: 0.000300
2025-05-29 22:52:32,509 - INFO - joeynmt.training - Epoch   8, Step:    83900, Batch Loss:     1.775406, Batch Acc: 0.491629, Tokens per Sec:    21324, Lr: 0.000300
2025-05-29 22:52:35,882 - INFO - joeynmt.training - Epoch   8, Step:    84000, Batch Loss:     1.949736, Batch Acc: 0.488870, Tokens per Sec:    21511, Lr: 0.000300
2025-05-29 22:52:35,883 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:52:35,883 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:52:44,613 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.96, acc:   0.52, generation: 8.7232[sec], evaluation: 0.0000[sec]
2025-05-29 22:52:44,614 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:52:45,118 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/82000.ckpt
2025-05-29 22:52:45,138 - INFO - joeynmt.training - Example #0
2025-05-29 22:52:45,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:52:45,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:52:45,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'ire', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'per', 'la', 'qu@@', 'ale', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'la', 'qu@@', 'ale', 'per', 'il', '4@@', '0@@', '%', 'dei', 'mo@@', 'di', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:52:45,140 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:52:45,140 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:52:45,140 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per conseguire le ghiaccio, che l<unk> articolo che ha avuto per la quale per tre milioni di anni che avevano la quale per il 40% dei modi per 40 per cento di cento.
2025-05-29 22:52:45,140 - INFO - joeynmt.training - Example #1
2025-05-29 22:52:45,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:52:45,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:52:45,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'un', 'problema', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'è', 'un', 'problema', 'che', 'non', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 22:52:45,140 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:52:45,140 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:52:45,141 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte la prima cosa che non è un problema speciale che non è un problema che non mostra il dell<unk> isola.
2025-05-29 22:52:45,141 - INFO - joeynmt.training - Example #2
2025-05-29 22:52:45,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:52:45,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:52:45,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', 'mo', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:52:45,141 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:52:45,141 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:52:45,141 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiacciaio di ghiaccio, il cuore del nostro climassimo globale.
2025-05-29 22:52:45,142 - INFO - joeynmt.training - Example #3
2025-05-29 22:52:45,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:52:45,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:52:45,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ri@@', 'ma', 'si', 'è', 'ri@@', 'ma@@', 'sto', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 'm@@', 'om@@', 'in@@', 'o@@', '.', '</s>']
2025-05-29 22:52:45,142 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:52:45,142 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:52:45,142 - INFO - joeynmt.training - 	Hypothesis: Prima si è rimasto in inverno e in un momino.
2025-05-29 22:52:45,142 - INFO - joeynmt.training - Example #4
2025-05-29 22:52:45,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:52:45,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:52:45,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'co', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:52:45,143 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:52:45,143 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:52:45,143 - INFO - joeynmt.training - 	Hypothesis: Il prossimo dico che vi mostro è un disegno di un disegno di quei 25 anni.
2025-05-29 22:52:48,524 - INFO - joeynmt.training - Epoch   8, Step:    84100, Batch Loss:     1.583661, Batch Acc: 0.498047, Tokens per Sec:    18006, Lr: 0.000300
2025-05-29 22:52:51,891 - INFO - joeynmt.training - Epoch   8, Step:    84200, Batch Loss:     1.721358, Batch Acc: 0.491956, Tokens per Sec:    21419, Lr: 0.000300
2025-05-29 22:52:55,238 - INFO - joeynmt.training - Epoch   8, Step:    84300, Batch Loss:     1.656447, Batch Acc: 0.495688, Tokens per Sec:    21449, Lr: 0.000300
2025-05-29 22:52:58,588 - INFO - joeynmt.training - Epoch   8, Step:    84400, Batch Loss:     1.761776, Batch Acc: 0.495538, Tokens per Sec:    21621, Lr: 0.000300
2025-05-29 22:53:01,931 - INFO - joeynmt.training - Epoch   8, Step:    84500, Batch Loss:     1.690508, Batch Acc: 0.500754, Tokens per Sec:    20829, Lr: 0.000300
2025-05-29 22:53:01,932 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:53:01,932 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:53:10,086 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.96, acc:   0.52, generation: 8.1426[sec], evaluation: 0.0000[sec]
2025-05-29 22:53:10,483 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/83500.ckpt
2025-05-29 22:53:10,508 - INFO - joeynmt.training - Example #0
2025-05-29 22:53:10,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:53:10,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:53:10,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've@@', ',', 'per', 'essere', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'per', 'la', 'prima', 'vol@@', 't@@', 'a@@', ',', 'il', '4@@', '8@@', '%', 'di', 'questi', 'due', 'mili@@', 'ar@@', 'di', 'di', 'anni', 'che', 'ha', 'l@@', '<unk>', '4@@', '0@@', '<unk>', '.', '</s>']
2025-05-29 22:53:10,509 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:53:10,509 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:53:10,509 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso l<unk> anno scorso di queste due diapositive, per essere che l<unk> articolo che l<unk> articolo che ha avuto per la prima volta, il 48% di questi due miliardi di anni che ha l<unk> 40<unk> .
2025-05-29 22:53:10,509 - INFO - joeynmt.training - Example #1
2025-05-29 22:53:10,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:53:10,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:53:10,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'l@@', '<unk>', 'in@@', 'st@@', 'all@@', 'are', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:53:10,510 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:53:10,510 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:53:10,510 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza l<unk> installare la capacità di questo problema, perché non mostra il dell<unk> ghiaccio.
2025-05-29 22:53:10,510 - INFO - joeynmt.training - Example #2
2025-05-29 22:53:10,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:53:10,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:53:10,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:53:10,511 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:53:10,511 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:53:10,511 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccia, il cuore del nostro climatico globale.
2025-05-29 22:53:10,511 - INFO - joeynmt.training - Example #3
2025-05-29 22:53:10,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:53:10,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:53:10,512 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:53:10,512 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:53:10,512 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:53:10,512 - INFO - joeynmt.training - 	Hypothesis: E si può essere in inverno, in inverno.
2025-05-29 22:53:10,512 - INFO - joeynmt.training - Example #4
2025-05-29 22:53:10,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:53:10,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:53:10,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'fi@@', 'da', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'seg@@', 'na', 'di', 'di@@', 'seg@@', 'no', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:53:10,513 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:53:10,513 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:53:10,513 - INFO - joeynmt.training - 	Hypothesis: La prossima sfida che vi mostrerò è una disegna di disegno che è successo negli ultimi 25 anni.
2025-05-29 22:53:13,880 - INFO - joeynmt.training - Epoch   8, Step:    84600, Batch Loss:     1.669261, Batch Acc: 0.488684, Tokens per Sec:    18541, Lr: 0.000300
2025-05-29 22:53:17,278 - INFO - joeynmt.training - Epoch   8, Step:    84700, Batch Loss:     1.746052, Batch Acc: 0.500270, Tokens per Sec:    21291, Lr: 0.000300
2025-05-29 22:53:20,669 - INFO - joeynmt.training - Epoch   8, Step:    84800, Batch Loss:     1.651753, Batch Acc: 0.497889, Tokens per Sec:    21590, Lr: 0.000300
2025-05-29 22:53:24,063 - INFO - joeynmt.training - Epoch   8, Step:    84900, Batch Loss:     1.703727, Batch Acc: 0.498592, Tokens per Sec:    20717, Lr: 0.000300
2025-05-29 22:53:27,459 - INFO - joeynmt.training - Epoch   8, Step:    85000, Batch Loss:     1.612621, Batch Acc: 0.491607, Tokens per Sec:    21375, Lr: 0.000300
2025-05-29 22:53:27,459 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:53:27,459 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:53:36,628 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.94, acc:   0.52, generation: 9.1614[sec], evaluation: 0.0000[sec]
2025-05-29 22:53:36,628 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:53:37,151 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/81000.ckpt
2025-05-29 22:53:37,173 - INFO - joeynmt.training - Example #0
2025-05-29 22:53:37,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:53:37,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:53:37,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'etti@@', 'man@@', 'e', 'per', 'vedere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'che', 'la', 'ar@@', 'c@@', 'a@@', ',', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'ott@@', 'op@@', 'or@@', 'zion@@', 'e@@', '.', '</s>']
2025-05-29 22:53:37,174 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:53:37,174 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:53:37,174 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due settimane per vedere che la ghiaccio, che la ghiaccio è che la arca, che ha avuto per tre milioni di anni che avevano avuto per tre milioni di anni 40 per cento di anni di 40 per cento di sottoporzione.
2025-05-29 22:53:37,175 - INFO - joeynmt.training - Example #1
2025-05-29 22:53:37,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:53:37,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:53:37,175 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'amente', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:53:37,175 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:53:37,175 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:53:37,176 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente la capacità di questo problema speciale che non c<unk> è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 22:53:37,176 - INFO - joeynmt.training - Example #2
2025-05-29 22:53:37,176 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:53:37,176 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:53:37,176 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'il', 'cu@@', 'ore', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:53:37,176 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:53:37,176 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:53:37,177 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccio è il cuore di ghiaccio globale.
2025-05-29 22:53:37,177 - INFO - joeynmt.training - Example #3
2025-05-29 22:53:37,177 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:53:37,177 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:53:37,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'ri@@', 'dur@@', 're', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'es@@', 'ce', 'a', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 22:53:37,177 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:53:37,177 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:53:37,177 - INFO - joeynmt.training - 	Hypothesis: Si può ridurre in inverno, e si riesce a sommergibile.
2025-05-29 22:53:37,177 - INFO - joeynmt.training - Example #4
2025-05-29 22:53:37,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:53:37,178 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:53:37,178 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'co', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'una', 'ri@@', 'pres@@', 'a', 'di', 'tem@@', 'po@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:53:37,178 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:53:37,178 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:53:37,178 - INFO - joeynmt.training - 	Hypothesis: Il prossimo dico di dimostrarvi è una ripresa di tempo, che è successo negli ultimi 25 anni.
2025-05-29 22:53:40,578 - INFO - joeynmt.training - Epoch   8, Step:    85100, Batch Loss:     1.781888, Batch Acc: 0.501069, Tokens per Sec:    17884, Lr: 0.000300
2025-05-29 22:53:43,970 - INFO - joeynmt.training - Epoch   8, Step:    85200, Batch Loss:     1.896026, Batch Acc: 0.497501, Tokens per Sec:    20410, Lr: 0.000300
2025-05-29 22:53:47,342 - INFO - joeynmt.training - Epoch   8, Step:    85300, Batch Loss:     1.586741, Batch Acc: 0.493360, Tokens per Sec:    20710, Lr: 0.000300
2025-05-29 22:53:50,712 - INFO - joeynmt.training - Epoch   8, Step:    85400, Batch Loss:     1.760805, Batch Acc: 0.494935, Tokens per Sec:    20542, Lr: 0.000300
2025-05-29 22:53:54,100 - INFO - joeynmt.training - Epoch   8, Step:    85500, Batch Loss:     1.729546, Batch Acc: 0.491303, Tokens per Sec:    21180, Lr: 0.000300
2025-05-29 22:53:54,100 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:53:54,100 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:54:03,817 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   4.98, acc:   0.52, generation: 9.7031[sec], evaluation: 0.0000[sec]
2025-05-29 22:54:03,828 - INFO - joeynmt.training - Example #0
2025-05-29 22:54:03,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:54:03,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:54:03,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'che', 'le', 'persone', 'che', 'hanno', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'il', '4@@', '8', 'pa@@', 'esi', 'per', 'c@@', 'ento', 'di', 'anni', 'che', 'av@@', 'evano', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:54:03,830 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:54:03,830 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:54:03,830 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno scorso che l<unk> anno scorso che l<unk> articolo che l<unk> articolo che le ghiaccio è che le persone che hanno avuto per tre milioni di anni che avevano il 48 paesi per cento di anni che avevano il 40 per cento di cento di cento.
2025-05-29 22:54:03,830 - INFO - joeynmt.training - Example #1
2025-05-29 22:54:03,830 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:54:03,830 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:54:03,830 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'es@@', 'ce', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'ale', 'perché', 'non', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'po@@', '<unk>', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 'pi@@', 'ù@@', ',', 'e', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'un', 'problema', 'di', 's@@', 'ac@@', 'co', 'di', 's@@', 'an@@', 'gu@@', 'e@@', '.', '</s>']
2025-05-29 22:54:03,831 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:54:03,831 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:54:03,831 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la prima cosa che esce la popolazione di questo problema speciale perché non mostra il Dicke del ghiaccio del ghiaccio del ghiaccio di ghiaccio di ghiaccio di un pezzo di ghiaccio di ghiaccio di un po<unk> di ghiaccio che è stato un po<unk> di più, e la popolazione di un problema di sacco di sangue.
2025-05-29 22:54:03,831 - INFO - joeynmt.training - Example #2
2025-05-29 22:54:03,831 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:54:03,831 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:54:03,831 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'il', 'cu@@', 'ore', 'd@@', 'ell@@', '<unk>', 'al@@', 'to', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:54:03,832 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:54:03,832 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:54:03,832 - INFO - joeynmt.training - 	Hypothesis: In certo senso è la ghiaccio di ghiaccio che è il cuore dell<unk> alto climatico globale.
2025-05-29 22:54:03,832 - INFO - joeynmt.training - Example #3
2025-05-29 22:54:03,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:54:03,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:54:03,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'vel@@', 'a', 'nel', 'm@@', 'ezz@@', 'o@@', '.', '</s>']
2025-05-29 22:54:03,832 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:54:03,832 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:54:03,833 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e si rivela nel mezzo.
2025-05-29 22:54:03,833 - INFO - joeynmt.training - Example #4
2025-05-29 22:54:03,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:54:03,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:54:03,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'qu@@', 'ad@@', 'ro', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:54:03,833 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:54:03,833 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:54:03,834 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è un disegno di un disegno di un quadro di quale è successo negli ultimi 25 anni.
2025-05-29 22:54:07,256 - INFO - joeynmt.training - Epoch   8, Step:    85600, Batch Loss:     1.673804, Batch Acc: 0.496458, Tokens per Sec:    21308, Lr: 0.000300
2025-05-29 22:54:07,803 - INFO - joeynmt.training - Epoch   8: total training loss 17922.78
2025-05-29 22:54:07,804 - INFO - joeynmt.training - EPOCH 9
2025-05-29 22:54:10,679 - INFO - joeynmt.training - Epoch   9, Step:    85700, Batch Loss:     1.599847, Batch Acc: 0.508462, Tokens per Sec:    21319, Lr: 0.000300
2025-05-29 22:54:14,075 - INFO - joeynmt.training - Epoch   9, Step:    85800, Batch Loss:     1.514512, Batch Acc: 0.507321, Tokens per Sec:    20702, Lr: 0.000300
2025-05-29 22:54:17,426 - INFO - joeynmt.training - Epoch   9, Step:    85900, Batch Loss:     1.694890, Batch Acc: 0.510207, Tokens per Sec:    20940, Lr: 0.000300
2025-05-29 22:54:20,808 - INFO - joeynmt.training - Epoch   9, Step:    86000, Batch Loss:     1.760366, Batch Acc: 0.508351, Tokens per Sec:    20998, Lr: 0.000300
2025-05-29 22:54:20,809 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:54:20,809 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:54:28,858 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.96, acc:   0.52, generation: 8.0409[sec], evaluation: 0.0000[sec]
2025-05-29 22:54:29,210 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/83000.ckpt
2025-05-29 22:54:29,237 - INFO - joeynmt.training - Example #0
2025-05-29 22:54:29,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:54:29,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:54:29,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'etti@@', 'man@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'un', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'questi', 'due', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:54:29,238 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:54:29,238 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:54:29,238 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due settimane per dimostrare che l<unk> articolo che l<unk> articolo che l<unk> articolo che ha avuto tre milioni di anni ha avuto un 48 per cento di 48 ore per cento di 48 ore per cento di cento di questi due anni.
2025-05-29 22:54:29,238 - INFO - joeynmt.training - Example #1
2025-05-29 22:54:29,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:54:29,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:54:29,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'es@@', 'ce', 'a', 'sp@@', 'av@@', 'ent@@', 'os@@', 'a', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'a@@', '.', '</s>']
2025-05-29 22:54:29,239 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:54:29,239 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:54:29,239 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che esce a spaventosa questo problema, perché non mostra il dell<unk> ora.
2025-05-29 22:54:29,239 - INFO - joeynmt.training - Example #2
2025-05-29 22:54:29,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:54:29,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:54:29,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:54:29,240 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:54:29,240 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:54:29,240 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico del nostro sistema climatico sistema climatico del nostro sistema climatico globale.
2025-05-29 22:54:29,240 - INFO - joeynmt.training - Example #3
2025-05-29 22:54:29,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:54:29,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:54:29,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'sp@@', 'ost@@', 'a', 'in', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:54:29,241 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:54:29,241 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:54:29,241 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno, e si sposta in estate.
2025-05-29 22:54:29,241 - INFO - joeynmt.training - Example #4
2025-05-29 22:54:29,241 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:54:29,241 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:54:29,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'di@@', 'seg@@', 'na', 'di', 'fr@@', 'on@@', 'te', 'a', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:54:29,242 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:54:29,242 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:54:29,242 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimensione di disegna di fronte a quello che è successo negli ultimi 25 anni.
2025-05-29 22:54:32,652 - INFO - joeynmt.training - Epoch   9, Step:    86100, Batch Loss:     1.674032, Batch Acc: 0.504001, Tokens per Sec:    18487, Lr: 0.000300
2025-05-29 22:54:36,058 - INFO - joeynmt.training - Epoch   9, Step:    86200, Batch Loss:     1.832540, Batch Acc: 0.501619, Tokens per Sec:    21582, Lr: 0.000300
2025-05-29 22:54:39,441 - INFO - joeynmt.training - Epoch   9, Step:    86300, Batch Loss:     1.542043, Batch Acc: 0.504466, Tokens per Sec:    20391, Lr: 0.000300
2025-05-29 22:54:42,810 - INFO - joeynmt.training - Epoch   9, Step:    86400, Batch Loss:     1.578071, Batch Acc: 0.507946, Tokens per Sec:    20004, Lr: 0.000300
2025-05-29 22:54:46,181 - INFO - joeynmt.training - Epoch   9, Step:    86500, Batch Loss:     1.631863, Batch Acc: 0.505291, Tokens per Sec:    21063, Lr: 0.000300
2025-05-29 22:54:46,181 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:54:46,181 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:54:54,421 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.95, acc:   0.52, generation: 8.2328[sec], evaluation: 0.0000[sec]
2025-05-29 22:54:54,763 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/82500.ckpt
2025-05-29 22:54:54,786 - INFO - joeynmt.training - Example #0
2025-05-29 22:54:54,787 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:54:54,787 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:54:54,787 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'en@@', 'z@@', 'a@@', ',', 'per', 'vedere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '8@@', '%', 'dei', 'v@@', 'et@@', 'ro@@', ',', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '8', 'per', 'c@@', 'ento', 'ento', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'per', 'c@@', 'ento', 'del', '4@@', '0', 'per', 'c@@', 'ento', 'del', '4@@', '0@@', '<unk>', '.', '</s>']
2025-05-29 22:54:54,788 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:54:54,788 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:54:54,788 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per conseguenza, per vedere che la ghiaccia, che la ghiaccia, che ha avuto il 48% dei vetro, per il 40 per cento dei 48 per cento ento per il 40 per cento per cento del 40 per cento del 40<unk> .
2025-05-29 22:54:54,788 - INFO - joeynmt.training - Example #1
2025-05-29 22:54:54,788 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:54:54,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:54:54,788 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'res@@', 'pon@@', 's@@', 'abil@@', 'ità', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'di@@', 'mostr@@', 'ato', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:54:54,789 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:54:54,789 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:54:54,789 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la responsabilità di questo problema, perché non è il dimostrato che non è il Dicke del ghiaccio.
2025-05-29 22:54:54,789 - INFO - joeynmt.training - Example #2
2025-05-29 22:54:54,789 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:54:54,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:54:54,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:54:54,790 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:54:54,790 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:54:54,790 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> artico del ghiaccio artico del nostro sistema climatico globale.
2025-05-29 22:54:54,790 - INFO - joeynmt.training - Example #3
2025-05-29 22:54:54,790 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:54:54,790 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:54:54,790 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'in', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:54:54,790 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:54:54,790 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:54:54,791 - INFO - joeynmt.training - 	Hypothesis: Si può essere in inverno, e si rivela in estate.
2025-05-29 22:54:54,791 - INFO - joeynmt.training - Example #4
2025-05-29 22:54:54,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:54:54,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:54:54,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'apos@@', 'iti@@', 'vo', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ale', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:54:54,791 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:54:54,791 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:54:54,792 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostrerò è una dimensione di disegno di quale negli ultimi 25 anni.
2025-05-29 22:54:58,124 - INFO - joeynmt.training - Epoch   9, Step:    86600, Batch Loss:     1.568574, Batch Acc: 0.499267, Tokens per Sec:    18987, Lr: 0.000300
2025-05-29 22:55:01,505 - INFO - joeynmt.training - Epoch   9, Step:    86700, Batch Loss:     1.621660, Batch Acc: 0.505944, Tokens per Sec:    21151, Lr: 0.000300
2025-05-29 22:55:04,892 - INFO - joeynmt.training - Epoch   9, Step:    86800, Batch Loss:     1.651662, Batch Acc: 0.496396, Tokens per Sec:    20779, Lr: 0.000300
2025-05-29 22:55:08,286 - INFO - joeynmt.training - Epoch   9, Step:    86900, Batch Loss:     1.598208, Batch Acc: 0.506239, Tokens per Sec:    21255, Lr: 0.000300
2025-05-29 22:55:11,678 - INFO - joeynmt.training - Epoch   9, Step:    87000, Batch Loss:     1.571578, Batch Acc: 0.497405, Tokens per Sec:    21142, Lr: 0.000300
2025-05-29 22:55:11,678 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:55:11,678 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:55:20,332 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.95, acc:   0.52, generation: 8.6459[sec], evaluation: 0.0000[sec]
2025-05-29 22:55:20,678 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/84500.ckpt
2025-05-29 22:55:20,696 - INFO - joeynmt.training - Example #0
2025-05-29 22:55:20,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:55:20,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:55:20,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ica', 'è', 'che', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'un', '4@@', '8', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:55:20,697 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:55:20,697 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:55:20,697 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso che ho mostrato questi due diapositive per vedere che l<unk> anno scorso, che l<unk> artica è che il ghiaccio, che ha avuto per tre milioni di anni ha avuto un 48 per cento.
2025-05-29 22:55:20,697 - INFO - joeynmt.training - Example #1
2025-05-29 22:55:20,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:55:20,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:55:20,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'ris@@', 'post@@', 'a', 'di', 'questa', 'part@@', 'icol@@', 'are', 'è', 'la', 'cosa', 'che', 'non', 'è', 'un', 'problema', 'di', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'a@@', '.', '</s>']
2025-05-29 22:55:20,698 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:55:20,698 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:55:20,698 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la risposta di questa particolare è la cosa che non è un problema di problema, perché non è il dell<unk> ora.
2025-05-29 22:55:20,698 - INFO - joeynmt.training - Example #2
2025-05-29 22:55:20,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:55:20,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:55:20,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'or@@', 'ig@@', 'ine', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:55:20,699 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:55:20,699 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:55:20,699 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> origine artico del nostro sistema climatico sistema di climatico.
2025-05-29 22:55:20,699 - INFO - joeynmt.training - Example #3
2025-05-29 22:55:20,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:55:20,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:55:20,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'essere', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'sp@@', 'or@@', 'ti@@', 'va', 'nel', 'l@@', 'ett@@', 'o@@', '.', '</s>']
2025-05-29 22:55:20,700 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:55:20,700 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:55:20,700 - INFO - joeynmt.training - 	Hypothesis: Si può essere in inverno, e si sportiva nel letto.
2025-05-29 22:55:20,700 - INFO - joeynmt.training - Example #4
2025-05-29 22:55:20,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:55:20,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:55:20,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'seg@@', 'na', 'di', 'di@@', 'seg@@', 'no', 'di', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:55:20,700 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:55:20,701 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:55:20,701 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una disegna di disegno di cosa è successo negli ultimi 25 anni.
2025-05-29 22:55:24,089 - INFO - joeynmt.training - Epoch   9, Step:    87100, Batch Loss:     1.647379, Batch Acc: 0.505212, Tokens per Sec:    19023, Lr: 0.000300
2025-05-29 22:55:27,488 - INFO - joeynmt.training - Epoch   9, Step:    87200, Batch Loss:     1.995587, Batch Acc: 0.507868, Tokens per Sec:    20909, Lr: 0.000300
2025-05-29 22:55:30,881 - INFO - joeynmt.training - Epoch   9, Step:    87300, Batch Loss:     1.694550, Batch Acc: 0.499677, Tokens per Sec:    20973, Lr: 0.000300
2025-05-29 22:55:34,264 - INFO - joeynmt.training - Epoch   9, Step:    87400, Batch Loss:     1.523828, Batch Acc: 0.506769, Tokens per Sec:    21120, Lr: 0.000300
2025-05-29 22:55:37,658 - INFO - joeynmt.training - Epoch   9, Step:    87500, Batch Loss:     1.566074, Batch Acc: 0.498140, Tokens per Sec:    21234, Lr: 0.000300
2025-05-29 22:55:37,658 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:55:37,658 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:55:45,967 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.53, generation: 8.2974[sec], evaluation: 0.0000[sec]
2025-05-29 22:55:45,967 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:55:46,578 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/84000.ckpt
2025-05-29 22:55:46,603 - INFO - joeynmt.training - Example #0
2025-05-29 22:55:46,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:55:46,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:55:46,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', ',', 'per', 'vedere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'chiam@@', 'ato', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 's@@', 'ott@@', 'op@@', 'ost@@', 'a', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'del', '4@@', '8@@', '%', 'dei', 'v@@', 'ant@@', 'ag@@', 'gi', 'di', 's@@', 'ott@@', 'o@@', '.', '</s>']
2025-05-29 22:55:46,604 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:55:46,605 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:55:46,605 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositi, per vedere che la ghiaccia, che l<unk> articolo che ha chiamato il ghiaccio di ghiaccio di sottoposta per il 48 per cento del 48% dei vantaggi di sotto.
2025-05-29 22:55:46,605 - INFO - joeynmt.training - Example #1
2025-05-29 22:55:46,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:55:46,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:55:46,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'n@@', 'ell@@', '<unk>', 'in@@', 'st@@', 'all@@', 'azione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'ol@@', 'a@@', '.', '</s>']
2025-05-29 22:55:46,605 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:55:46,606 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:55:46,606 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più nell<unk> installazione di questo problema, perché non è il dell<unk> isola.
2025-05-29 22:55:46,606 - INFO - joeynmt.training - Example #2
2025-05-29 22:55:46,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:55:46,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:55:46,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:55:46,606 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:55:46,606 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:55:46,607 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico del nostro sistema climatico globale.
2025-05-29 22:55:46,607 - INFO - joeynmt.training - Example #3
2025-05-29 22:55:46,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:55:46,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:55:46,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'può', 'sp@@', 'os@@', 'are', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'in', 'est@@', 'at@@', 'a@@', '.', '</s>']
2025-05-29 22:55:46,607 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:55:46,607 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:55:46,607 - INFO - joeynmt.training - 	Hypothesis: Si può sposare in inverno, e si rivela in estata.
2025-05-29 22:55:46,607 - INFO - joeynmt.training - Example #4
2025-05-29 22:55:46,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:55:46,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:55:46,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:55:46,608 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:55:46,608 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:55:46,608 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di quale è successo negli ultimi 25 anni.
2025-05-29 22:55:50,014 - INFO - joeynmt.training - Epoch   9, Step:    87600, Batch Loss:     1.665169, Batch Acc: 0.498516, Tokens per Sec:    17235, Lr: 0.000300
2025-05-29 22:55:53,392 - INFO - joeynmt.training - Epoch   9, Step:    87700, Batch Loss:     1.613091, Batch Acc: 0.493811, Tokens per Sec:    20364, Lr: 0.000300
2025-05-29 22:55:56,779 - INFO - joeynmt.training - Epoch   9, Step:    87800, Batch Loss:     1.629672, Batch Acc: 0.505144, Tokens per Sec:    20809, Lr: 0.000300
2025-05-29 22:56:00,171 - INFO - joeynmt.training - Epoch   9, Step:    87900, Batch Loss:     2.147440, Batch Acc: 0.496289, Tokens per Sec:    21061, Lr: 0.000300
2025-05-29 22:56:03,545 - INFO - joeynmt.training - Epoch   9, Step:    88000, Batch Loss:     1.755081, Batch Acc: 0.497823, Tokens per Sec:    20627, Lr: 0.000300
2025-05-29 22:56:03,546 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:56:03,546 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:56:11,295 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.97, acc:   0.52, generation: 7.7384[sec], evaluation: 0.0000[sec]
2025-05-29 22:56:11,305 - INFO - joeynmt.training - Example #0
2025-05-29 22:56:11,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:56:11,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:56:11,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'i', 'ar@@', 't@@', 'ic@@', 'i@@', 'p@@', 'ati@@', ',', 'che', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'un', '4@@', '8@@', '0@@', '%', 'di', 'questi', 'sono', 'stati', 'in', '4@@', '8@@', '0@@', '<unk>', '.', '</s>']
2025-05-29 22:56:11,306 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:56:11,306 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:56:11,306 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per vedere questi due diapositive che l<unk> articolo che i articipati, che ha avuto tre milioni di anni che avevano un 480% di questi sono stati in 480<unk> .
2025-05-29 22:56:11,306 - INFO - joeynmt.training - Example #1
2025-05-29 22:56:11,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:56:11,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:56:11,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'cres@@', 'c@@', 'ita', 'di', 'questo', 'problema', 'è', 'il', 'problema', 'di', 'questo', 'problema', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'ic@@', 'chi@@', 'o@@', '.', '</s>']
2025-05-29 22:56:11,307 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:56:11,307 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:56:11,307 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la crescita di questo problema è il problema di questo problema speciale che non c<unk> è il dell<unk> icchio.
2025-05-29 22:56:11,307 - INFO - joeynmt.training - Example #2
2025-05-29 22:56:11,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:56:11,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:56:11,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'ar@@', 't@@', 'ico', 'che', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:56:11,308 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:56:11,308 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:56:11,308 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiacciaio artico che il cuore del nostro climatico globale.
2025-05-29 22:56:11,309 - INFO - joeynmt.training - Example #3
2025-05-29 22:56:11,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:56:11,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:56:11,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 'v@@', 'ento', 'in@@', 'ver@@', 't@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:56:11,309 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:56:11,309 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:56:11,309 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e in un vento invertico.
2025-05-29 22:56:11,309 - INFO - joeynmt.training - Example #4
2025-05-29 22:56:11,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:56:11,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:56:11,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'apos@@', 'iti@@', 'vo', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'di@@', 'mostr@@', 'azione', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:56:11,310 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:56:11,310 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:56:11,310 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostro è una dimostrazione di dimostrazione che è successo negli ultimi 25 anni.
2025-05-29 22:56:14,682 - INFO - joeynmt.training - Epoch   9, Step:    88100, Batch Loss:     1.510896, Batch Acc: 0.506584, Tokens per Sec:    20345, Lr: 0.000300
2025-05-29 22:56:18,014 - INFO - joeynmt.training - Epoch   9, Step:    88200, Batch Loss:     1.714857, Batch Acc: 0.501259, Tokens per Sec:    21106, Lr: 0.000300
2025-05-29 22:56:21,345 - INFO - joeynmt.training - Epoch   9, Step:    88300, Batch Loss:     1.764753, Batch Acc: 0.500000, Tokens per Sec:    20841, Lr: 0.000300
2025-05-29 22:56:24,695 - INFO - joeynmt.training - Epoch   9, Step:    88400, Batch Loss:     1.581530, Batch Acc: 0.505376, Tokens per Sec:    20941, Lr: 0.000300
2025-05-29 22:56:28,053 - INFO - joeynmt.training - Epoch   9, Step:    88500, Batch Loss:     1.747901, Batch Acc: 0.505634, Tokens per Sec:    22422, Lr: 0.000300
2025-05-29 22:56:28,053 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:56:28,053 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:56:36,585 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.93, acc:   0.52, generation: 8.5231[sec], evaluation: 0.0000[sec]
2025-05-29 22:56:36,889 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/86000.ckpt
2025-05-29 22:56:36,907 - INFO - joeynmt.training - Example #0
2025-05-29 22:56:36,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:56:36,908 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:56:36,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'v@@', 'inc@@', 'ere', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'i', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'hanno', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'hanno', 'av@@', 'uto', 'un', '4@@', '8@@', '%', 'dei', 'più', 'gran@@', 'di', 'di', 'più', 'di', '4@@', '8', 'pa@@', 'esi', 'per', 'c@@', 'ento', 'di', 'questi', 'sono', 'st@@', 'ate', 'per', 'ri@@', 'fer@@', 'im@@', 'enti', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'del', '4@@', '8@@', '<unk>', '.', '</s>']
2025-05-29 22:56:36,908 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:56:36,909 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:56:36,909 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per convincere che i ghiaccia, che i artici, che hanno avuto per tre milioni di anni hanno avuto un 48% dei più grandi di più di 48 paesi per cento di questi sono state per riferimenti di 48 per cento del 48<unk> .
2025-05-29 22:56:36,909 - INFO - joeynmt.training - Example #1
2025-05-29 22:56:36,909 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:56:36,909 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:56:36,909 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'da', 'una', 's@@', 'itu@@', 'azione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:56:36,909 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:56:36,909 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:56:36,909 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte da una situazione di questo problema, perché non c<unk> è il dell<unk> origine del ghiaccio.
2025-05-29 22:56:36,909 - INFO - joeynmt.training - Example #2
2025-05-29 22:56:36,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:56:36,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:56:36,910 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:56:36,910 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:56:36,910 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:56:36,910 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccia, il ghiaccio globale del nostro sistema climatico globale.
2025-05-29 22:56:36,910 - INFO - joeynmt.training - Example #3
2025-05-29 22:56:36,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:56:36,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:56:36,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', '.', '</s>']
2025-05-29 22:56:36,911 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:56:36,911 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:56:36,911 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno e in inverno e in inverno e in un certo senso.
2025-05-29 22:56:36,911 - INFO - joeynmt.training - Example #4
2025-05-29 22:56:36,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:56:36,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:56:36,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'co', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'ri@@', 'pres@@', 'e', 'di', 'di@@', 'seg@@', 'no', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:56:36,912 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:56:36,912 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:56:36,912 - INFO - joeynmt.training - 	Hypothesis: Il prossimo dico che vi mostro è una riprese di disegno di quello che è successo negli ultimi 25 anni.
2025-05-29 22:56:40,319 - INFO - joeynmt.training - Epoch   9, Step:    88600, Batch Loss:     1.642917, Batch Acc: 0.502710, Tokens per Sec:    18979, Lr: 0.000300
2025-05-29 22:56:43,681 - INFO - joeynmt.training - Epoch   9, Step:    88700, Batch Loss:     1.704254, Batch Acc: 0.496418, Tokens per Sec:    20851, Lr: 0.000300
2025-05-29 22:56:47,059 - INFO - joeynmt.training - Epoch   9, Step:    88800, Batch Loss:     1.440562, Batch Acc: 0.491652, Tokens per Sec:    20415, Lr: 0.000300
2025-05-29 22:56:50,455 - INFO - joeynmt.training - Epoch   9, Step:    88900, Batch Loss:     1.705901, Batch Acc: 0.505231, Tokens per Sec:    21650, Lr: 0.000300
2025-05-29 22:56:53,843 - INFO - joeynmt.training - Epoch   9, Step:    89000, Batch Loss:     1.726944, Batch Acc: 0.504577, Tokens per Sec:    20448, Lr: 0.000300
2025-05-29 22:56:53,844 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:56:53,844 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:57:02,715 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.52, generation: 8.8593[sec], evaluation: 0.0000[sec]
2025-05-29 22:57:03,103 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/87000.ckpt
2025-05-29 22:57:03,126 - INFO - joeynmt.training - Example #0
2025-05-29 22:57:03,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:57:03,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:57:03,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'ha', 'fatto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'fatto', 'per', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:57:03,127 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:57:03,127 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:57:03,127 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno ho mostrato queste due diapositive per vedere che l<unk> anno scorso che l<unk> articolo che ha fatto per tre milioni di anni che ha fatto per tre milioni di anni che avevano fatto per 48 per cento di 48 ore per cento.
2025-05-29 22:57:03,128 - INFO - joeynmt.training - Example #1
2025-05-29 22:57:03,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:57:03,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:57:03,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'ti@@', ',', 'l@@', '<unk>', 'es@@', 'pres@@', 'sione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:57:03,128 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:57:03,128 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:57:03,128 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forti, l<unk> espressione di questo particolare problema, perché non c<unk> è il Dicke del ghiaccio.
2025-05-29 22:57:03,128 - INFO - joeynmt.training - Example #2
2025-05-29 22:57:03,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:57:03,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:57:03,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:57:03,129 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:57:03,129 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:57:03,129 - INFO - joeynmt.training - 	Hypothesis: In certo senso è la ghiaccia, il cuore artico del nostro sistema globale.
2025-05-29 22:57:03,129 - INFO - joeynmt.training - Example #3
2025-05-29 22:57:03,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:57:03,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:57:03,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'vel@@', 'a', 'n@@', 'ell@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:57:03,130 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:57:03,130 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:57:03,130 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e si rivela nell<unk> estate.
2025-05-29 22:57:03,130 - INFO - joeynmt.training - Example #4
2025-05-29 22:57:03,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:57:03,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:57:03,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'apos@@', 'iti@@', 'v@@', 'a@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:57:03,131 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:57:03,131 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:57:03,131 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una diapositiva, che è successo negli ultimi 25 anni.
2025-05-29 22:57:06,523 - INFO - joeynmt.training - Epoch   9, Step:    89100, Batch Loss:     1.711155, Batch Acc: 0.498402, Tokens per Sec:    17918, Lr: 0.000300
2025-05-29 22:57:09,901 - INFO - joeynmt.training - Epoch   9, Step:    89200, Batch Loss:     1.707754, Batch Acc: 0.502175, Tokens per Sec:    21036, Lr: 0.000300
2025-05-29 22:57:13,281 - INFO - joeynmt.training - Epoch   9, Step:    89300, Batch Loss:     1.740448, Batch Acc: 0.500684, Tokens per Sec:    21412, Lr: 0.000300
2025-05-29 22:57:16,660 - INFO - joeynmt.training - Epoch   9, Step:    89400, Batch Loss:     1.815119, Batch Acc: 0.504679, Tokens per Sec:    20686, Lr: 0.000300
2025-05-29 22:57:20,039 - INFO - joeynmt.training - Epoch   9, Step:    89500, Batch Loss:     1.744100, Batch Acc: 0.503299, Tokens per Sec:    20772, Lr: 0.000300
2025-05-29 22:57:20,039 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:57:20,039 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:57:27,774 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.94, acc:   0.52, generation: 7.7236[sec], evaluation: 0.0000[sec]
2025-05-29 22:57:28,126 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/86500.ckpt
2025-05-29 22:57:28,146 - INFO - joeynmt.training - Example #0
2025-05-29 22:57:28,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:57:28,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:57:28,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'li@@', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'il', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'la', 'maggi@@', 'or', 'parte', 'delle', 'persone', 'che', 'hanno', 'av@@', 'uto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'degli', 'St@@', 'ati', 'Un@@', 'iti', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:57:28,147 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:57:28,147 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:57:28,147 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due slidiapositive per vedere che il ghiaccio, che l<unk> articolo che ha avuto per tre milioni di anni la maggior parte delle persone che hanno avuto per il 40 per cento degli Stati Uniti per cento.
2025-05-29 22:57:28,147 - INFO - joeynmt.training - Example #1
2025-05-29 22:57:28,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:57:28,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:57:28,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'pot@@', 'er@@', 'e@@', ',', 'la', 'prima', 'volta', 'che', 'non', 'si', 'è', 'ri@@', 'vel@@', 'ato', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:57:28,148 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:57:28,148 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:57:28,148 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po<unk> di potere, la prima volta che non si è rivelato il dell<unk> origine di questo particolare problema, perché non c<unk> è il dell<unk> origine del ghiaccio.
2025-05-29 22:57:28,148 - INFO - joeynmt.training - Example #2
2025-05-29 22:57:28,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:57:28,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:57:28,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'un', 'sistema', 'di', 'p@@', 'es@@', 'o', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:57:28,149 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:57:28,149 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:57:28,149 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiacciaio di un sistema di peso globale.
2025-05-29 22:57:28,149 - INFO - joeynmt.training - Example #3
2025-05-29 22:57:28,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:57:28,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:57:28,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'nel', 'v@@', 'ento', 'dei', 'v@@', 'enti', 'e', 'si', 'ri@@', 'vel@@', 'a', 'n@@', 'ell@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:57:28,150 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:57:28,150 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:57:28,150 - INFO - joeynmt.training - 	Hypothesis: Si cresce nel vento dei venti e si rivela nell<unk> estate.
2025-05-29 22:57:28,150 - INFO - joeynmt.training - Example #4
2025-05-29 22:57:28,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:57:28,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:57:28,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'co', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'di@@', 'seg@@', 'no', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:57:28,151 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:57:28,151 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:57:28,151 - INFO - joeynmt.training - 	Hypothesis: Il prossimo dico che vi mostrerò è una dimostrazione di disegno negli ultimi 25 anni.
2025-05-29 22:57:31,557 - INFO - joeynmt.training - Epoch   9, Step:    89600, Batch Loss:     1.645475, Batch Acc: 0.500508, Tokens per Sec:    19008, Lr: 0.000300
2025-05-29 22:57:34,972 - INFO - joeynmt.training - Epoch   9, Step:    89700, Batch Loss:     1.659670, Batch Acc: 0.503684, Tokens per Sec:    21305, Lr: 0.000300
2025-05-29 22:57:38,361 - INFO - joeynmt.training - Epoch   9, Step:    89800, Batch Loss:     1.598714, Batch Acc: 0.504419, Tokens per Sec:    21045, Lr: 0.000300
2025-05-29 22:57:41,755 - INFO - joeynmt.training - Epoch   9, Step:    89900, Batch Loss:     1.609490, Batch Acc: 0.505014, Tokens per Sec:    20983, Lr: 0.000300
2025-05-29 22:57:45,147 - INFO - joeynmt.training - Epoch   9, Step:    90000, Batch Loss:     1.661617, Batch Acc: 0.494103, Tokens per Sec:    20796, Lr: 0.000300
2025-05-29 22:57:45,148 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:57:45,148 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:57:54,340 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.94, acc:   0.52, generation: 9.1807[sec], evaluation: 0.0000[sec]
2025-05-29 22:57:54,353 - INFO - joeynmt.training - Example #0
2025-05-29 22:57:54,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:57:54,354 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:57:54,354 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'cio', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'fatto', 'per', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', '1@@', '0@@', '%', 'di', 'questi', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'fare', 'questo', 'm@@', 'om@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:57:54,354 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:57:54,354 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:57:54,355 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per vedere che le ghiaccia, che le ghiaccio artico, che i ghiaccio per tre milioni di anni che avevano fatto per il 48 per cento di 48 per cento di 10% di questi sono stati in grado di fare questo momento.
2025-05-29 22:57:54,355 - INFO - joeynmt.training - Example #1
2025-05-29 22:57:54,355 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:57:54,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:57:54,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'un@@', 'at@@', 'amente', 'la', 'c@@', 'aus@@', 'a', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'i@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 22:57:54,355 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:57:54,355 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:57:54,356 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente la causa di questo particolare problemi, perché non c<unk> è il dell<unk> origine del ghiaccio del ghiaccio di ghiaccio di ghiaccia.
2025-05-29 22:57:54,356 - INFO - joeynmt.training - Example #2
2025-05-29 22:57:54,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:57:54,356 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:57:54,356 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'della', 'nostra', 'c@@', 'li@@', 'ma', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:57:54,356 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:57:54,357 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:57:54,357 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il cuore della nostra clima globale.
2025-05-29 22:57:54,357 - INFO - joeynmt.training - Example #3
2025-05-29 22:57:54,357 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:57:54,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:57:54,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'm@@', 'os@@', 'se', 'e', 'si', 'ri@@', 'man@@', 'e', 'in', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:57:54,357 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:57:54,357 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:57:54,357 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno, e si rimosse e si rimane in estate.
2025-05-29 22:57:54,358 - INFO - joeynmt.training - Example #4
2025-05-29 22:57:54,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:57:54,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:57:54,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:57:54,358 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:57:54,358 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:57:54,358 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di dimostrarvi è che è successo negli ultimi 25 anni.
2025-05-29 22:57:57,758 - INFO - joeynmt.training - Epoch   9, Step:    90100, Batch Loss:     1.528855, Batch Acc: 0.496377, Tokens per Sec:    20801, Lr: 0.000300
2025-05-29 22:58:01,148 - INFO - joeynmt.training - Epoch   9, Step:    90200, Batch Loss:     1.669405, Batch Acc: 0.495738, Tokens per Sec:    20946, Lr: 0.000300
2025-05-29 22:58:04,546 - INFO - joeynmt.training - Epoch   9, Step:    90300, Batch Loss:     1.507956, Batch Acc: 0.506876, Tokens per Sec:    21835, Lr: 0.000300
2025-05-29 22:58:07,919 - INFO - joeynmt.training - Epoch   9, Step:    90400, Batch Loss:     1.497143, Batch Acc: 0.503940, Tokens per Sec:    21003, Lr: 0.000300
2025-05-29 22:58:11,298 - INFO - joeynmt.training - Epoch   9, Step:    90500, Batch Loss:     1.916111, Batch Acc: 0.500287, Tokens per Sec:    21171, Lr: 0.000300
2025-05-29 22:58:11,299 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:58:11,299 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:58:20,498 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.52, generation: 9.1907[sec], evaluation: 0.0000[sec]
2025-05-29 22:58:20,498 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:58:21,190 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/85000.ckpt
2025-05-29 22:58:21,216 - INFO - joeynmt.training - Example #0
2025-05-29 22:58:21,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:58:21,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:58:21,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'for@@', 'z@@', 'i', 'per', 'vedere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'la', 'ar@@', 't@@', 'ic@@', 'olo', 'della', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'di', '4@@', '8', 'st@@', 'ati@@', ',', 'per', 'c@@', 'ent@@', 'o@@', ',', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questo', 't@@', 'es@@', 'su@@', 'to', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questo', 't@@', 'es@@', 'su@@', 'to', 'è', 'stato', 't@@', 'ot@@', 'ale', 'che', 'ha', 'fatto', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 's@@', 'ott@@', 'o@@', ',', 'e', 'la', 'gente', 'che', 'ha', 'fatto', 'è', 'stato', 'un', 'po@@', '<unk>', 'di', 's@@', 'fi@@', 'd@@', 'anz@@', 'a@@', '.', '</s>']
2025-05-29 22:58:21,218 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:58:21,218 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:58:21,218 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due sforzi per vedere che la ghiacciaio di ghiaccio che la articolo della artica, che ha avuto tre milioni di anni di 48 stati, per cento, il 40 percento di questo tessuto per il 40 percento di questo tessuto è stato totale che ha fatto un po<unk> di un po<unk> di sotto, e la gente che ha fatto è stato un po<unk> di sfidanza.
2025-05-29 22:58:21,218 - INFO - joeynmt.training - Example #1
2025-05-29 22:58:21,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:58:21,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:58:21,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'problema', 'è', 'il', 'problema', 'che', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'che', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'po@@', '<unk>', 'di', 'pi@@', 'ù@@', ',', 'e', 'la', 'gente', 'che', 'si', 'trov@@', 'a', 'in', 'modo', 'che', 'la', 'gente', 'si', 'è', 'sc@@', 'rit@@', 't@@', 'ore', 'di', 'un', 'po@@', '<unk>', 'di', 'pi@@', 'ù@@', ',', 'e', 'la', 'gente', 'che', 'è', 'un', 'po@@', '<unk>', 'di', 'b@@', 'an@@', 'chi', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'problema', 'che', 'si', 'è', 'abb@@', 'ast@@', 'anza']
2025-05-29 22:58:21,219 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:58:21,219 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:58:21,219 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte di questo problema è il problema che mostra il Dicke non è il Dicke che mostra il Dicke del ghiaccio che non è abbastanza forte del ghiaccio di ghiaccio di un po<unk> di più, e la gente che si trova in modo che la gente si è scrittore di un po<unk> di più, e la gente che è un po<unk> di banchi di ghiaccio di ghiaccio di un problema che si è abbastanza
2025-05-29 22:58:21,219 - INFO - joeynmt.training - Example #2
2025-05-29 22:58:21,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:58:21,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:58:21,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'si', 'è', 'ri@@', 'ma@@', 'st@@', 'ic@@', 'amente', 'il', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:58:21,220 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:58:21,220 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:58:21,220 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa di ghiaccio che si è rimasticamente il nostro sistema globale.
2025-05-29 22:58:21,220 - INFO - joeynmt.training - Example #3
2025-05-29 22:58:21,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:58:21,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:58:21,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'sta', 'ri@@', 'l@@', 'ass@@', 'ù', 'in', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:58:21,221 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:58:21,221 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:58:21,221 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e si sta rilassù in estate.
2025-05-29 22:58:21,221 - INFO - joeynmt.training - Example #4
2025-05-29 22:58:21,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:58:21,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:58:21,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'fot@@', 'o', 'di', 'una', 'di@@', 'apos@@', 'iti@@', 'va', 'di', 'un', 'di@@', 'seg@@', 'no', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:58:21,222 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:58:21,222 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:58:21,222 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una foto di una diapositiva di un disegno negli ultimi 25 anni.
2025-05-29 22:58:24,641 - INFO - joeynmt.training - Epoch   9, Step:    90600, Batch Loss:     1.521117, Batch Acc: 0.498493, Tokens per Sec:    16819, Lr: 0.000300
2025-05-29 22:58:28,034 - INFO - joeynmt.training - Epoch   9, Step:    90700, Batch Loss:     1.573254, Batch Acc: 0.497824, Tokens per Sec:    20862, Lr: 0.000300
2025-05-29 22:58:31,394 - INFO - joeynmt.training - Epoch   9, Step:    90800, Batch Loss:     1.674272, Batch Acc: 0.501362, Tokens per Sec:    20558, Lr: 0.000300
2025-05-29 22:58:34,765 - INFO - joeynmt.training - Epoch   9, Step:    90900, Batch Loss:     1.660178, Batch Acc: 0.509326, Tokens per Sec:    20438, Lr: 0.000300
2025-05-29 22:58:38,141 - INFO - joeynmt.training - Epoch   9, Step:    91000, Batch Loss:     1.688917, Batch Acc: 0.497399, Tokens per Sec:    21470, Lr: 0.000300
2025-05-29 22:58:38,142 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:58:38,142 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:58:47,085 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.89, acc:   0.52, generation: 8.9314[sec], evaluation: 0.0000[sec]
2025-05-29 22:58:47,085 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:58:47,615 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/89500.ckpt
2025-05-29 22:58:47,637 - INFO - joeynmt.training - Example #0
2025-05-29 22:58:47,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:58:47,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:58:47,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'ha', 'la', 'di@@', 'apos@@', 'iti@@', 'va', 'di', 'tre', 'milioni', 'di', 'anni', 'che', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'av@@', 'uto', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questo', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:58:47,638 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:58:47,638 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:58:47,638 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per vedere che la ghiaccia, che la ghiaccio artico che ha la diapositiva di tre milioni di anni che ha avuto tre milioni di anni di persone che hanno avuto il 40 per cento di questo 40 per cento di cento.
2025-05-29 22:58:47,638 - INFO - joeynmt.training - Example #1
2025-05-29 22:58:47,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:58:47,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:58:47,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'res@@', 'pon@@', 's@@', 'abil@@', 'ità', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'è', 'il', 'D@@', 'ic@@', 'ke', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'is@@', 'es@@', 'c@@', 'a@@', '.', '</s>']
2025-05-29 22:58:47,639 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:58:47,639 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:58:47,639 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la responsabilità di questo problema, perché non è il Dicke è il Dicke che non è il Dicke è il dell<unk> isesca.
2025-05-29 22:58:47,639 - INFO - joeynmt.training - Example #2
2025-05-29 22:58:47,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:58:47,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:58:47,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'c@@', 'li@@', 'ma', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:58:47,640 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:58:47,640 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:58:47,640 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico del nostro clima globale.
2025-05-29 22:58:47,640 - INFO - joeynmt.training - Example #3
2025-05-29 22:58:47,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:58:47,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:58:47,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'ce', 'nel', 'v@@', 'ento', 'e', 'si', 'ri@@', 'vel@@', 'a', 'n@@', 'ell@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 22:58:47,641 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:58:47,641 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:58:47,641 - INFO - joeynmt.training - 	Hypothesis: Sta cresce nel vento e si rivela nell<unk> estate.
2025-05-29 22:58:47,641 - INFO - joeynmt.training - Example #4
2025-05-29 22:58:47,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:58:47,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:58:47,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:58:47,642 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:58:47,642 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:58:47,642 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di un disegno di quale è successo negli ultimi 25 anni.
2025-05-29 22:58:51,051 - INFO - joeynmt.training - Epoch   9, Step:    91100, Batch Loss:     1.684518, Batch Acc: 0.501967, Tokens per Sec:    17816, Lr: 0.000300
2025-05-29 22:58:54,453 - INFO - joeynmt.training - Epoch   9, Step:    91200, Batch Loss:     1.673608, Batch Acc: 0.499541, Tokens per Sec:    21156, Lr: 0.000300
2025-05-29 22:58:57,812 - INFO - joeynmt.training - Epoch   9, Step:    91300, Batch Loss:     1.582103, Batch Acc: 0.502006, Tokens per Sec:    20858, Lr: 0.000300
2025-05-29 22:59:01,157 - INFO - joeynmt.training - Epoch   9, Step:    91400, Batch Loss:     1.640101, Batch Acc: 0.500385, Tokens per Sec:    20588, Lr: 0.000300
2025-05-29 22:59:04,492 - INFO - joeynmt.training - Epoch   9, Step:    91500, Batch Loss:     1.635344, Batch Acc: 0.503643, Tokens per Sec:    20951, Lr: 0.000300
2025-05-29 22:59:04,493 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:59:04,493 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:59:13,441 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.52, generation: 8.9367[sec], evaluation: 0.0000[sec]
2025-05-29 22:59:13,837 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/88500.ckpt
2025-05-29 22:59:13,864 - INFO - joeynmt.training - Example #0
2025-05-29 22:59:13,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:59:13,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:59:13,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'la', 'gente', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'la', 'gente', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'la', 'c@@', 'aus@@', 'a', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 22:59:13,866 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:59:13,866 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:59:13,866 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per vedere che la gente artica, che la gente artica, che ha avuto per tre milioni di anni la causa di tre milioni di anni per il 48% di questi 48 stati.
2025-05-29 22:59:13,866 - INFO - joeynmt.training - Example #1
2025-05-29 22:59:13,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:59:13,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:59:13,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'res@@', 'pon@@', 's@@', 'abil@@', 'ità', 'di', 'questo', 'problema', 'in', 'questo', 'problema', 'in', 'cui', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:59:13,867 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:59:13,867 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:59:13,867 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza abbastanza forte la responsabilità di questo problema in questo problema in cui non è il Dicke del ghiaccio che non è la Dicke del ghiaccio del ghiaccio di ghiaccio di ghiaccio.
2025-05-29 22:59:13,867 - INFO - joeynmt.training - Example #2
2025-05-29 22:59:13,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:59:13,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:59:13,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 22:59:13,868 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:59:13,868 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:59:13,868 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il cuore del nostro climatico globale.
2025-05-29 22:59:13,868 - INFO - joeynmt.training - Example #3
2025-05-29 22:59:13,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:59:13,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:59:13,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'vel@@', 'a', 'il', 'v@@', 'ento', 'di', 'un', 'po@@', '<unk>', 'di', 'pi@@', 'ù@@', '.', '</s>']
2025-05-29 22:59:13,868 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:59:13,868 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:59:13,869 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno e si rivela il vento di un po<unk> di più.
2025-05-29 22:59:13,869 - INFO - joeynmt.training - Example #4
2025-05-29 22:59:13,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:59:13,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:59:13,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:59:13,869 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:59:13,869 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:59:13,869 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di quello che è successo negli ultimi 25 anni.
2025-05-29 22:59:17,297 - INFO - joeynmt.training - Epoch   9, Step:    91600, Batch Loss:     1.535672, Batch Acc: 0.501754, Tokens per Sec:    18344, Lr: 0.000300
2025-05-29 22:59:20,697 - INFO - joeynmt.training - Epoch   9, Step:    91700, Batch Loss:     1.581234, Batch Acc: 0.502080, Tokens per Sec:    21291, Lr: 0.000300
2025-05-29 22:59:24,079 - INFO - joeynmt.training - Epoch   9, Step:    91800, Batch Loss:     1.518743, Batch Acc: 0.496789, Tokens per Sec:    20632, Lr: 0.000300
2025-05-29 22:59:27,457 - INFO - joeynmt.training - Epoch   9, Step:    91900, Batch Loss:     1.611304, Batch Acc: 0.500991, Tokens per Sec:    20475, Lr: 0.000300
2025-05-29 22:59:30,832 - INFO - joeynmt.training - Epoch   9, Step:    92000, Batch Loss:     1.820831, Batch Acc: 0.502217, Tokens per Sec:    21051, Lr: 0.000300
2025-05-29 22:59:30,832 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:59:30,833 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:59:38,601 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.89, acc:   0.53, generation: 7.7610[sec], evaluation: 0.0000[sec]
2025-05-29 22:59:38,938 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/89000.ckpt
2025-05-29 22:59:38,961 - INFO - joeynmt.training - Example #0
2025-05-29 22:59:38,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 22:59:38,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 22:59:38,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'guard@@', 'are', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'è', 'stato', 'in@@', 'tr@@', 'ap@@', 'pol@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'av@@', 'evano', 'l@@', '<unk>', 'al@@', 'im@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 22:59:38,962 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:59:38,962 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 22:59:38,962 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per guardare le ghiaccia, che l<unk> articolo che è stato intrappolato per tre milioni di anni di anni che avevano l<unk> alimento.
2025-05-29 22:59:38,962 - INFO - joeynmt.training - Example #1
2025-05-29 22:59:38,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 22:59:38,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 22:59:38,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'abb@@', 'ast@@', 'anza', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'è', 'il', 'problema', 'di', 'questo', 'problema', 'di', 'part@@', 'icol@@', 'are', 'questo', 'problema', 'è', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 22:59:38,963 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:59:38,963 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 22:59:38,963 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza abbastanza abbastanza la prima cosa che è il problema di questo problema di particolare questo problema è che non è il Dicke è il Dicke del ghiaccio.
2025-05-29 22:59:38,963 - INFO - joeynmt.training - Example #2
2025-05-29 22:59:38,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 22:59:38,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 22:59:38,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'un', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 22:59:38,964 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:59:38,964 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 22:59:38,964 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiacciaio di ghiacciaio di un sistema di climatico.
2025-05-29 22:59:38,964 - INFO - joeynmt.training - Example #3
2025-05-29 22:59:38,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:59:38,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 22:59:38,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'v@@', 'eg@@', 'li@@', 'ano', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 22:59:38,965 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:59:38,965 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 22:59:38,965 - INFO - joeynmt.training - 	Hypothesis: Si svegliano in inverno e in inverno.
2025-05-29 22:59:38,965 - INFO - joeynmt.training - Example #4
2025-05-29 22:59:38,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 22:59:38,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 22:59:38,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'un', 'di@@', 'seg@@', 'no', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 22:59:38,966 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:59:38,966 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 22:59:38,966 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimensione di un disegno degli ultimi 25 anni.
2025-05-29 22:59:42,330 - INFO - joeynmt.training - Epoch   9, Step:    92100, Batch Loss:     1.723456, Batch Acc: 0.494448, Tokens per Sec:    18386, Lr: 0.000300
2025-05-29 22:59:45,727 - INFO - joeynmt.training - Epoch   9, Step:    92200, Batch Loss:     1.912504, Batch Acc: 0.506871, Tokens per Sec:    21472, Lr: 0.000300
2025-05-29 22:59:49,109 - INFO - joeynmt.training - Epoch   9, Step:    92300, Batch Loss:     1.575669, Batch Acc: 0.498802, Tokens per Sec:    20737, Lr: 0.000300
2025-05-29 22:59:52,497 - INFO - joeynmt.training - Epoch   9, Step:    92400, Batch Loss:     1.639452, Batch Acc: 0.499307, Tokens per Sec:    21086, Lr: 0.000300
2025-05-29 22:59:55,876 - INFO - joeynmt.training - Epoch   9, Step:    92500, Batch Loss:     1.710698, Batch Acc: 0.496324, Tokens per Sec:    20937, Lr: 0.000300
2025-05-29 22:59:55,876 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:59:55,876 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:00:04,646 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.89, acc:   0.53, generation: 8.7589[sec], evaluation: 0.0000[sec]
2025-05-29 23:00:05,002 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/91500.ckpt
2025-05-29 23:00:05,027 - INFO - joeynmt.training - Example #0
2025-05-29 23:00:05,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:00:05,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:00:05,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'inter@@', 'a', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 's@@', 'otto', 'il', '4@@', '8@@', ',', 'per', 'circa', '4@@', '8@@', '%', 'di', 'questi', 'due', 'mili@@', 'on@@', 'i@@', ',', 'per', 'il', '4@@', '8@@', '%', 'dei', 'm@@', 'oti@@', 'vi', 'per', '.', '</s>']
2025-05-29 23:00:05,028 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:00:05,028 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:00:05,028 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso che l<unk> anno scorso di queste due diapositive per vedere che la ghiaccia, che l<unk> intera popolazione di tre milioni di anni di anni di sotto il 48, per circa 48% di questi due milioni, per il 48% dei motivi per .
2025-05-29 23:00:05,028 - INFO - joeynmt.training - Example #1
2025-05-29 23:00:05,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:00:05,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:00:05,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'abb@@', 'ast@@', 'anza', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'che', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'un', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 23:00:05,029 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:00:05,029 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:00:05,029 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza abbastanza abbastanza la popolazione di questo problema, perché non è il Dicke non è il Dicke che mostra il Dicke non è un ghiacciaio di ghiaccia.
2025-05-29 23:00:05,029 - INFO - joeynmt.training - Example #2
2025-05-29 23:00:05,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:00:05,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:00:05,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'un', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:00:05,030 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:00:05,030 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:00:05,030 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa di ghiacciaio di un sistema di climatico globale del nostro climatico globale.
2025-05-29 23:00:05,030 - INFO - joeynmt.training - Example #3
2025-05-29 23:00:05,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:00:05,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:00:05,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'p@@', 'et@@', 'ut@@', 'am@@', 'ent@@', 'e@@', '.', '</s>']
2025-05-29 23:00:05,031 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:00:05,031 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:00:05,031 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e ripetutamente.
2025-05-29 23:00:05,031 - INFO - joeynmt.training - Example #4
2025-05-29 23:00:05,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:00:05,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:00:05,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'ta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'seg@@', 'no', 'di', 'un', 'peri@@', 'o@@', 'do', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:00:05,032 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:00:05,032 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:00:05,032 - INFO - joeynmt.training - 	Hypothesis: La prossima dita che vi mostrerò è un segno di un periodo di quello che è successo negli ultimi 25 anni.
2025-05-29 23:00:08,333 - INFO - joeynmt.training - Epoch   9, Step:    92600, Batch Loss:     1.649521, Batch Acc: 0.505279, Tokens per Sec:    19325, Lr: 0.000300
2025-05-29 23:00:11,602 - INFO - joeynmt.training - Epoch   9, Step:    92700, Batch Loss:     1.892272, Batch Acc: 0.495659, Tokens per Sec:    21920, Lr: 0.000300
2025-05-29 23:00:14,864 - INFO - joeynmt.training - Epoch   9, Step:    92800, Batch Loss:     1.569817, Batch Acc: 0.504912, Tokens per Sec:    21719, Lr: 0.000300
2025-05-29 23:00:18,140 - INFO - joeynmt.training - Epoch   9, Step:    92900, Batch Loss:     1.700769, Batch Acc: 0.501976, Tokens per Sec:    22331, Lr: 0.000300
2025-05-29 23:00:21,414 - INFO - joeynmt.training - Epoch   9, Step:    93000, Batch Loss:     1.655572, Batch Acc: 0.505481, Tokens per Sec:    22156, Lr: 0.000300
2025-05-29 23:00:21,415 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:00:21,415 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:00:30,340 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.88, acc:   0.53, generation: 8.9137[sec], evaluation: 0.0000[sec]
2025-05-29 23:00:30,341 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:00:30,930 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/87500.ckpt
2025-05-29 23:00:30,961 - INFO - joeynmt.training - Example #0
2025-05-29 23:00:30,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:00:30,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:00:30,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'st@@', 'anti', 'per', 'guard@@', 'are', 'questi', 'due', 'di@@', 'st@@', 'anti', 'per', 'con@@', 'segu@@', 'enze', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'di', 's@@', 'otto', 'il', '4@@', '8@@', '%', 'di', 'anni', 'per', 'ri@@', 'l@@', 'ev@@', 'are', 'il', '4@@', '8@@', '%', 'del', '4@@', '8@@', '%', 'dei', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:00:30,962 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:00:30,962 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:00:30,962 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due distanti per guardare questi due distanti per conseguenze che le ghiacciate che per tre milioni di anni che avevano tre milioni di anni che avevano avuto tre milioni di anni di sotto il 48% di anni per rilevare il 48% del 48% dei cento.
2025-05-29 23:00:30,962 - INFO - joeynmt.training - Example #1
2025-05-29 23:00:30,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:00:30,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:00:30,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'problema', 'di', 's@@', 'ott@@', 'op@@', 'ost@@', 'o', 'che', 'non', 'è', 'un', 'problema', 'di', 'questo', 'problema', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'al@@', 'b@@', 'a', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:00:30,963 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:00:30,963 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:00:30,963 - INFO - joeynmt.training - 	Hypothesis: Ma non è un problema di sottoposto che non è un problema di questo problema è il dell<unk> alba che non è il Dicke del ghiaccio.
2025-05-29 23:00:30,963 - INFO - joeynmt.training - Example #2
2025-05-29 23:00:30,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:00:30,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:00:30,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'm@@', 'as@@', 'si@@', 'mo', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:00:30,964 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:00:30,964 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:00:30,964 - INFO - joeynmt.training - 	Hypothesis: In certo senso è la ghiacciaio di ghiaccio, il cuore del nostro climassimo globale.
2025-05-29 23:00:30,964 - INFO - joeynmt.training - Example #3
2025-05-29 23:00:30,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:00:30,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:00:30,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'vel@@', 'a', 'il', 'm@@', 'as@@', 'si@@', 'mo', 'e', 'ri@@', 'l@@', 'ass@@', 'e@@', '.', '</s>']
2025-05-29 23:00:30,965 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:00:30,965 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:00:30,965 - INFO - joeynmt.training - 	Hypothesis: Sta crescita in inverno e si rivela il massimo e rilasse.
2025-05-29 23:00:30,965 - INFO - joeynmt.training - Example #4
2025-05-29 23:00:30,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:00:30,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:00:30,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 're@@', 'cu@@', 'per@@', 'o', 'di', 'qu@@', 'ei', 'due', 'anni', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:00:30,966 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:00:30,966 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:00:30,966 - INFO - joeynmt.training - 	Hypothesis: La diapositiva che vi mostrerò è un disegno di un recupero di quei due anni è successo negli ultimi 25 anni.
2025-05-29 23:00:34,357 - INFO - joeynmt.training - Epoch   9, Step:    93100, Batch Loss:     1.631240, Batch Acc: 0.501847, Tokens per Sec:    17186, Lr: 0.000300
2025-05-29 23:00:37,718 - INFO - joeynmt.training - Epoch   9, Step:    93200, Batch Loss:     1.519864, Batch Acc: 0.499501, Tokens per Sec:    21489, Lr: 0.000300
2025-05-29 23:00:41,064 - INFO - joeynmt.training - Epoch   9, Step:    93300, Batch Loss:     1.711130, Batch Acc: 0.496696, Tokens per Sec:    20406, Lr: 0.000300
2025-05-29 23:00:44,438 - INFO - joeynmt.training - Epoch   9, Step:    93400, Batch Loss:     1.656189, Batch Acc: 0.502611, Tokens per Sec:    21065, Lr: 0.000300
2025-05-29 23:00:47,821 - INFO - joeynmt.training - Epoch   9, Step:    93500, Batch Loss:     1.569454, Batch Acc: 0.494833, Tokens per Sec:    21314, Lr: 0.000300
2025-05-29 23:00:47,822 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:00:47,822 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:00:56,251 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.89, acc:   0.53, generation: 8.4183[sec], evaluation: 0.0000[sec]
2025-05-29 23:00:56,661 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/90500.ckpt
2025-05-29 23:00:56,688 - INFO - joeynmt.training - Example #0
2025-05-29 23:00:56,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:00:56,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:00:56,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'men@@', 'si@@', 'oni', 'per', 'con@@', 'si@@', 'der@@', 'are', 'che', 'le', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'le', 'ar@@', 't@@', 'ic@@', 'olo', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'st@@', 'ati@@', '.', '</s>']
2025-05-29 23:00:56,689 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:00:56,689 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:00:56,689 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso, ho mostrato questi due dimensioni per considerare che le articolo artico, che le articolo per tre milioni di anni di anni che hanno avuto tre milioni di anni di anni di anni di 48 stati.
2025-05-29 23:00:56,689 - INFO - joeynmt.training - Example #1
2025-05-29 23:00:56,690 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:00:56,690 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:00:56,690 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'succ@@', 'esso', 'è', 'che', 'la', 'not@@', 'te', 'è', 'che', 'la', 'd@@', 'ell@@', '<unk>', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'mostr@@', 'a', 'la', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', '.', '</s>']
2025-05-29 23:00:56,690 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:00:56,690 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:00:56,690 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che è successo è che la notte è che la dell<unk> icke del ghiaccio che mostra la dell<unk> origine del ghiaccio di ghiaccia.
2025-05-29 23:00:56,690 - INFO - joeynmt.training - Example #2
2025-05-29 23:00:56,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:00:56,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:00:56,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'c@@', 'li@@', 'ma', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:00:56,691 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:00:56,691 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:00:56,691 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il cuore di clima globale.
2025-05-29 23:00:56,691 - INFO - joeynmt.training - Example #3
2025-05-29 23:00:56,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:00:56,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:00:56,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'es@@', 'ce', 'a', 'sp@@', 'ost@@', 'ar@@', 'si@@', '.', '</s>']
2025-05-29 23:00:56,692 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:00:56,692 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:00:56,692 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno e si riesce a spostarsi.
2025-05-29 23:00:56,692 - INFO - joeynmt.training - Example #4
2025-05-29 23:00:56,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:00:56,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:00:56,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'con@@', 'f@@', 'e@@', 'zion@@', 'ata', 'in', 'questo', 'modo', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:00:56,693 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:00:56,693 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:00:56,693 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una confezionata in questo modo negli ultimi 25 anni.
2025-05-29 23:01:00,085 - INFO - joeynmt.training - Epoch   9, Step:    93600, Batch Loss:     1.558054, Batch Acc: 0.501681, Tokens per Sec:    18477, Lr: 0.000300
2025-05-29 23:01:03,459 - INFO - joeynmt.training - Epoch   9, Step:    93700, Batch Loss:     1.816464, Batch Acc: 0.504863, Tokens per Sec:    21089, Lr: 0.000300
2025-05-29 23:01:06,837 - INFO - joeynmt.training - Epoch   9, Step:    93800, Batch Loss:     1.739033, Batch Acc: 0.504400, Tokens per Sec:    20862, Lr: 0.000300
2025-05-29 23:01:10,221 - INFO - joeynmt.training - Epoch   9, Step:    93900, Batch Loss:     1.604739, Batch Acc: 0.498555, Tokens per Sec:    21685, Lr: 0.000300
2025-05-29 23:01:13,597 - INFO - joeynmt.training - Epoch   9, Step:    94000, Batch Loss:     1.777968, Batch Acc: 0.501249, Tokens per Sec:    20990, Lr: 0.000300
2025-05-29 23:01:13,598 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:01:13,598 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:01:22,501 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.89, acc:   0.52, generation: 8.8910[sec], evaluation: 0.0000[sec]
2025-05-29 23:01:22,513 - INFO - joeynmt.training - Example #0
2025-05-29 23:01:22,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:01:22,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:01:22,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'sc@@', 'ar@@', 'ic@@', 'are', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'di@@', 'st@@', 'anza', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:01:22,514 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:01:22,514 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:01:22,514 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per scaricare che le ghiaccio, che le ghiaccio, che per tre milioni di anni di persone che hanno tre milioni di anni di anni di distanza di 48 per cento di cento.
2025-05-29 23:01:22,515 - INFO - joeynmt.training - Example #1
2025-05-29 23:01:22,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:01:22,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:01:22,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'perché', 'non', 'è', 'un', 'problema', 'che', 'non', 'è', 'un', 'problema', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:01:22,515 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:01:22,515 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:01:22,516 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, ma non è abbastanza forte, perché non è un problema che non è un problema di ghiaccio.
2025-05-29 23:01:22,516 - INFO - joeynmt.training - Example #2
2025-05-29 23:01:22,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:01:22,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:01:22,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 23:01:22,516 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:01:22,516 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:01:22,517 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore artico.
2025-05-29 23:01:22,517 - INFO - joeynmt.training - Example #3
2025-05-29 23:01:22,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:01:22,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:01:22,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'n@@', 'ell@@', '<unk>', 'est@@', 'i@@', 'gi@@', 'o@@', '.', '</s>']
2025-05-29 23:01:22,517 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:01:22,517 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:01:22,517 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno, e si rivela nell<unk> estigio.
2025-05-29 23:01:22,518 - INFO - joeynmt.training - Example #4
2025-05-29 23:01:22,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:01:22,518 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:01:22,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'chi@@', 'ar@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:01:22,518 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:01:22,518 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:01:22,518 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dichiarazione di un disegno di cosa è successo negli ultimi 25 anni.
2025-05-29 23:01:25,914 - INFO - joeynmt.training - Epoch   9, Step:    94100, Batch Loss:     1.622023, Batch Acc: 0.499247, Tokens per Sec:    20618, Lr: 0.000300
2025-05-29 23:01:29,294 - INFO - joeynmt.training - Epoch   9, Step:    94200, Batch Loss:     1.530307, Batch Acc: 0.496924, Tokens per Sec:    20448, Lr: 0.000300
2025-05-29 23:01:32,697 - INFO - joeynmt.training - Epoch   9, Step:    94300, Batch Loss:     2.106876, Batch Acc: 0.498275, Tokens per Sec:    21219, Lr: 0.000300
2025-05-29 23:01:36,070 - INFO - joeynmt.training - Epoch   9, Step:    94400, Batch Loss:     1.725093, Batch Acc: 0.497527, Tokens per Sec:    20984, Lr: 0.000300
2025-05-29 23:01:39,454 - INFO - joeynmt.training - Epoch   9, Step:    94500, Batch Loss:     1.754893, Batch Acc: 0.496377, Tokens per Sec:    20682, Lr: 0.000300
2025-05-29 23:01:39,454 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:01:39,455 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:01:48,269 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.89, acc:   0.53, generation: 8.8029[sec], evaluation: 0.0000[sec]
2025-05-29 23:01:48,280 - INFO - joeynmt.training - Example #0
2025-05-29 23:01:48,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:01:48,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:01:48,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'anno', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'dur@@', 're', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'che', 'ha', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 's@@', 'ott@@', 'om@@', 'ar@@', 'in@@', 'o@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'quest@@', 'o@@', '.', '</s>']
2025-05-29 23:01:48,282 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:01:48,282 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:01:48,282 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso anno queste due diapositive per condurre il 40 per cento articolo artico che l<unk> articolo artico che ha tre milioni di anni di anni che ha avuto tre milioni di anni di anni di sottomarino, il 40 per cento di questo.
2025-05-29 23:01:48,282 - INFO - joeynmt.training - Example #1
2025-05-29 23:01:48,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:01:48,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:01:48,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'for@@', 'te@@', ',', 'perché', 'non', 'è', 'un', 'problema', 'spe@@', 'ci@@', 'ale', 'che', 'non', 'ci', 'mostr@@', 'a', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'ci', 'mostr@@', 'a', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'si', 'è', 'ri@@', 'vel@@', 'ato', 'a', 'di@@', 'sp@@', 'os@@', 'iti@@', 'vi', 'e', 'la', 'di@@', 'men@@', 'sione', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'e', 'la', 'maggi@@', 'or', 'parte', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'e', 'la', 'maggi@@', 'or', 'parte', 'delle', 'persone', 'che', 'hanno', 'fatto', 'per', 'la', 'prima', 'volta', 'che', 'si', 'ri@@', 'vel@@', 'a', 'la', 'maggi@@', 'or', 'parte', 'delle', 'persone', 'che', 'hanno', 'fatto', 'per', 'la', 'maggi@@', 'or', 'parte', 'delle', 'persone', 'che', 'hanno', 'fatto', 'per', 'il', 'g@@']
2025-05-29 23:01:48,283 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:01:48,283 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:01:48,283 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più forte, perché non è un problema speciale che non ci mostra la Dicke del ghiaccio che ci mostra la Dicke del ghiaccio che si è rivelato a dispositivi e la dimensione di ghiaccia, e la maggior parte di ghiaccia, e la maggior parte delle persone che hanno fatto per la prima volta che si rivela la maggior parte delle persone che hanno fatto per la maggior parte delle persone che hanno fatto per il g
2025-05-29 23:01:48,283 - INFO - joeynmt.training - Example #2
2025-05-29 23:01:48,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:01:48,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:01:48,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'olo', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:01:48,284 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:01:48,284 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:01:48,284 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il cuore articolo globale del nostro sistema globale.
2025-05-29 23:01:48,284 - INFO - joeynmt.training - Example #3
2025-05-29 23:01:48,284 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:01:48,284 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:01:48,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'du@@', 'ce', 'a', 'v@@', 'inc@@', 'ere', 'la', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 23:01:48,285 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:01:48,285 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:01:48,285 - INFO - joeynmt.training - 	Hypothesis: Sta cresce in inverno e si riduce a vincere la sommergibile.
2025-05-29 23:01:48,285 - INFO - joeynmt.training - Example #4
2025-05-29 23:01:48,285 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:01:48,285 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:01:48,285 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', 'due', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:01:48,286 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:01:48,286 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:01:48,286 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è un disegno di quei due anni.
2025-05-29 23:01:51,682 - INFO - joeynmt.training - Epoch   9, Step:    94600, Batch Loss:     1.674895, Batch Acc: 0.499008, Tokens per Sec:    20831, Lr: 0.000300
2025-05-29 23:01:55,091 - INFO - joeynmt.training - Epoch   9, Step:    94700, Batch Loss:     1.693537, Batch Acc: 0.498844, Tokens per Sec:    20689, Lr: 0.000300
2025-05-29 23:01:58,473 - INFO - joeynmt.training - Epoch   9, Step:    94800, Batch Loss:     1.572748, Batch Acc: 0.501387, Tokens per Sec:    21011, Lr: 0.000300
2025-05-29 23:02:01,852 - INFO - joeynmt.training - Epoch   9, Step:    94900, Batch Loss:     1.778433, Batch Acc: 0.502117, Tokens per Sec:    20489, Lr: 0.000300
2025-05-29 23:02:05,242 - INFO - joeynmt.training - Epoch   9, Step:    95000, Batch Loss:     1.737015, Batch Acc: 0.501239, Tokens per Sec:    21077, Lr: 0.000300
2025-05-29 23:02:05,242 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:02:05,242 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:02:13,328 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.88, acc:   0.53, generation: 8.0745[sec], evaluation: 0.0000[sec]
2025-05-29 23:02:13,328 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:02:13,950 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/93500.ckpt
2025-05-29 23:02:13,978 - INFO - joeynmt.training - Example #0
2025-05-29 23:02:13,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:02:13,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:02:13,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'a@@', 'f@@', 'ici', 'che', 'hanno', 'pres@@', 'o', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'av@@', 'evano', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'dei', '4@@', '8', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:02:13,979 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:02:13,979 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:02:13,980 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per ridurre che l<unk> articolo artica, che l<unk> artafici che hanno preso tre milioni di anni di anni che avevano tre milioni di anni di anni di 48 per cento dei 48 percento di cento.
2025-05-29 23:02:13,980 - INFO - joeynmt.training - Example #1
2025-05-29 23:02:13,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:02:13,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:02:13,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'più', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'ale', 'che', 'non', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'ale', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:02:13,980 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:02:13,980 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:02:13,981 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa più forte di questo problema, perché non c<unk> è il dell<unk> originale che non mostra il dell<unk> originale del ghiaccio.
2025-05-29 23:02:13,981 - INFO - joeynmt.training - Example #2
2025-05-29 23:02:13,981 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:02:13,981 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:02:13,981 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'il', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:02:13,981 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:02:13,981 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:02:13,981 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore articolo, il nostro sistema globale.
2025-05-29 23:02:13,982 - INFO - joeynmt.training - Example #3
2025-05-29 23:02:13,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:02:13,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:02:13,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'p@@', 'et@@', 'ut@@', 'am@@', 'ent@@', 'e@@', '.', '</s>']
2025-05-29 23:02:13,982 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:02:13,982 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:02:13,982 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e ripetutamente.
2025-05-29 23:02:13,982 - INFO - joeynmt.training - Example #4
2025-05-29 23:02:13,983 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:02:13,983 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:02:13,983 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cosa', 'di', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'asi', 'cosa', 'succ@@', 'ede', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:02:13,983 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:02:13,983 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:02:13,983 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una cosa di disegno di quasi cosa succede negli ultimi 25 anni.
2025-05-29 23:02:17,375 - INFO - joeynmt.training - Epoch   9, Step:    95100, Batch Loss:     1.610734, Batch Acc: 0.503897, Tokens per Sec:    17563, Lr: 0.000300
2025-05-29 23:02:20,738 - INFO - joeynmt.training - Epoch   9, Step:    95200, Batch Loss:     1.657193, Batch Acc: 0.499604, Tokens per Sec:    21031, Lr: 0.000300
2025-05-29 23:02:24,114 - INFO - joeynmt.training - Epoch   9, Step:    95300, Batch Loss:     1.539139, Batch Acc: 0.496886, Tokens per Sec:    21654, Lr: 0.000300
2025-05-29 23:02:27,463 - INFO - joeynmt.training - Epoch   9, Step:    95400, Batch Loss:     1.677309, Batch Acc: 0.495521, Tokens per Sec:    21605, Lr: 0.000300
2025-05-29 23:02:30,824 - INFO - joeynmt.training - Epoch   9, Step:    95500, Batch Loss:     1.691063, Batch Acc: 0.493139, Tokens per Sec:    21083, Lr: 0.000300
2025-05-29 23:02:30,824 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:02:30,825 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:02:39,530 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.52, generation: 8.6940[sec], evaluation: 0.0000[sec]
2025-05-29 23:02:39,536 - INFO - joeynmt.training - Example #0
2025-05-29 23:02:39,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:02:39,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:02:39,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'il', '4@@', '8@@', '%', 'di', 'questi', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'fare', 'un', 'p@@', 'ezz@@', 'o', 'di', 'anni', 'per', 'il', '4@@', '8@@', '%', 'dei', 'di@@', 'st@@', 'anti', 'di', 'questi', 's@@', 'ott@@', 'op@@', 'ost@@', 'i', 'a', 's@@', 'ott@@', 'op@@', 'ost@@', 'i', 'a', 's@@', 'ott@@', 'op@@', 'ost@@', 'i', 'a', 's@@', 'ott@@', 'op@@', 'ost@@', 'i', 'a', 's@@', 'ott@@', 'op@@', 'ost@@', 'i', 'a', 'c@@', 'aus@@', 'a', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so', 'di', 'un', 'po@@', '<unk>', 'di', 'come', 'il', '4@@', '8@@', '%', 'delle']
2025-05-29 23:02:39,537 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:02:39,537 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:02:39,537 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per vedere che la ghiaccia, che l<unk> articolo che l<unk> articolo che ha il 48% di questi sono stati in grado di fare un pezzo di anni per il 48% dei distanti di questi sottoposti a sottoposti a sottoposti a sottoposti a sottoposti a causa di un certo senso di un certo senso di un po<unk> di come il 48% delle
2025-05-29 23:02:39,537 - INFO - joeynmt.training - Example #1
2025-05-29 23:02:39,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:02:39,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:02:39,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'ci', 'mostr@@', 'a', 'il', 'problema', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:02:39,537 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:02:39,537 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:02:39,537 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la popolazione di questo problema, perché non ci mostra il problema del ghiaccio del ghiaccio del ghiaccio del ghiaccio.
2025-05-29 23:02:39,537 - INFO - joeynmt.training - Example #2
2025-05-29 23:02:39,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:02:39,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:02:39,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'mon@@', 'd@@', 'o@@', '.', '</s>']
2025-05-29 23:02:39,537 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:02:39,538 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:02:39,538 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo, il cuore artico, il cuore mondo.
2025-05-29 23:02:39,538 - INFO - joeynmt.training - Example #3
2025-05-29 23:02:39,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:02:39,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:02:39,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'nel', 'v@@', 'ento', 'della', 's@@', 'om@@', 'mer@@', 'gi@@', 'bi@@', 'le@@', '.', '</s>']
2025-05-29 23:02:39,538 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:02:39,538 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:02:39,538 - INFO - joeynmt.training - 	Hypothesis: Si cresce nel vento della sommergibile.
2025-05-29 23:02:39,538 - INFO - joeynmt.training - Example #4
2025-05-29 23:02:39,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:02:39,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:02:39,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'o', 'è', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:02:39,538 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:02:39,538 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:02:39,538 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una cosa che vi mostro è quello che è successo negli ultimi 25 anni.
2025-05-29 23:02:42,939 - INFO - joeynmt.training - Epoch   9, Step:    95600, Batch Loss:     1.791478, Batch Acc: 0.499826, Tokens per Sec:    21058, Lr: 0.000300
2025-05-29 23:02:46,278 - INFO - joeynmt.training - Epoch   9, Step:    95700, Batch Loss:     1.661237, Batch Acc: 0.508522, Tokens per Sec:    20513, Lr: 0.000300
2025-05-29 23:02:49,661 - INFO - joeynmt.training - Epoch   9, Step:    95800, Batch Loss:     1.783976, Batch Acc: 0.500226, Tokens per Sec:    21569, Lr: 0.000300
2025-05-29 23:02:53,015 - INFO - joeynmt.training - Epoch   9, Step:    95900, Batch Loss:     1.872774, Batch Acc: 0.502783, Tokens per Sec:    20788, Lr: 0.000300
2025-05-29 23:02:56,387 - INFO - joeynmt.training - Epoch   9, Step:    96000, Batch Loss:     1.717582, Batch Acc: 0.502149, Tokens per Sec:    21191, Lr: 0.000300
2025-05-29 23:02:56,387 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:02:56,387 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:03:04,704 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.86, acc:   0.53, generation: 8.3097[sec], evaluation: 0.0000[sec]
2025-05-29 23:03:04,705 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:03:05,237 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/92000.ckpt
2025-05-29 23:03:05,263 - INFO - joeynmt.training - Example #0
2025-05-29 23:03:05,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:03:05,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:03:05,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'ec@@', 'ol@@', 'i', 'per', 'con@@', 'segu@@', 'enza', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '8@@', '%', 'di', 'anni', 'che', 'è', 'stato', 'ri@@', 'm@@', 'esso', 'di', 'un', '4@@', '8', 'st@@', 'ati@@', ',', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:03:05,264 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:03:05,264 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:03:05,264 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due secoli per conseguenza di ghiaccio, che l<unk> artico che l<unk> artico che ha avuto il 48% di anni che è stato rimesso di un 48 stati, per il 40 per cento di anni.
2025-05-29 23:03:05,264 - INFO - joeynmt.training - Example #1
2025-05-29 23:03:05,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:03:05,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:03:05,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'spe@@', 'ci@@', 'ale', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'e', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', '.', '</s>']
2025-05-29 23:03:05,265 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:03:05,265 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:03:05,265 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la popolazione di questo speciale speciale perché non è il Dicke del ghiaccio mostra il ghiaccio del ghiaccio del ghiaccio del ghiaccio che mostra il ghiaccio di ghiaccio, e non è abbastanza forte.
2025-05-29 23:03:05,265 - INFO - joeynmt.training - Example #2
2025-05-29 23:03:05,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:03:05,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:03:05,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'che', 'il', 'cu@@', 'ore', 'd@@', 'ell@@', '<unk>', 'ag@@', 'ente', 'd@@', 'ell@@', '<unk>', 'ag@@', 'ente', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:03:05,266 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:03:05,266 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:03:05,266 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> artico che il cuore dell<unk> agente dell<unk> agente globale.
2025-05-29 23:03:05,266 - INFO - joeynmt.training - Example #3
2025-05-29 23:03:05,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:03:05,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:03:05,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'v@@', 'eg@@', 'li@@', 'ano', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'l@@', 'ass@@', 'e@@', '.', '</s>']
2025-05-29 23:03:05,267 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:03:05,267 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:03:05,267 - INFO - joeynmt.training - 	Hypothesis: Si svegliano in inverno e rilasse.
2025-05-29 23:03:05,267 - INFO - joeynmt.training - Example #4
2025-05-29 23:03:05,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:03:05,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:03:05,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'qu@@', 'ale', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:03:05,268 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:03:05,268 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:03:05,268 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò è una dimostrazione di un pezzo di quale negli ultimi 25 anni.
2025-05-29 23:03:08,675 - INFO - joeynmt.training - Epoch   9, Step:    96100, Batch Loss:     1.664403, Batch Acc: 0.497333, Tokens per Sec:    17708, Lr: 0.000300
2025-05-29 23:03:12,066 - INFO - joeynmt.training - Epoch   9, Step:    96200, Batch Loss:     1.704898, Batch Acc: 0.496950, Tokens per Sec:    20650, Lr: 0.000300
2025-05-29 23:03:15,435 - INFO - joeynmt.training - Epoch   9, Step:    96300, Batch Loss:     1.671403, Batch Acc: 0.503759, Tokens per Sec:    20536, Lr: 0.000300
2025-05-29 23:03:16,732 - INFO - joeynmt.training - Epoch   9: total training loss 17741.99
2025-05-29 23:03:16,733 - INFO - joeynmt.training - EPOCH 10
2025-05-29 23:03:18,818 - INFO - joeynmt.training - Epoch  10, Step:    96400, Batch Loss:     1.522670, Batch Acc: 0.516410, Tokens per Sec:    20673, Lr: 0.000300
2025-05-29 23:03:22,201 - INFO - joeynmt.training - Epoch  10, Step:    96500, Batch Loss:     1.829655, Batch Acc: 0.516816, Tokens per Sec:    21032, Lr: 0.000300
2025-05-29 23:03:22,201 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:03:22,201 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:03:30,705 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.86, acc:   0.53, generation: 8.4897[sec], evaluation: 0.0000[sec]
2025-05-29 23:03:30,705 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:03:31,303 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/92500.ckpt
2025-05-29 23:03:31,330 - INFO - joeynmt.training - Example #0
2025-05-29 23:03:31,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:03:31,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:03:31,330 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'etti@@', 'man@@', 'e', 'per', 'con@@', 'segu@@', 'ire', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'per', 'il', '4@@', '8@@', '%', 'di', 'questi', 'due', '4@@', '8', 'stati', 'in', 'gra@@', 'do', 'di', 'ri@@', 'fl@@', 'ett@@', 'ori', 'di', 'in@@', 'tor@@', 'no', 'al', '4@@', '8@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'm@@', 'es@@', 'i@@', '.', '</s>']
2025-05-29 23:03:31,331 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:03:31,331 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:03:31,331 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due settimane per conseguire che l<unk> articolo artico, che l<unk> articolo che ha avuto per il 48% di questi due 48 stati in grado di riflettori di intorno al 480% di questi due anni per il 40% di questi due mesi.
2025-05-29 23:03:31,331 - INFO - joeynmt.training - Example #1
2025-05-29 23:03:31,332 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:03:31,332 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:03:31,332 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'au@@', 'ra', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'spe@@', 'ci@@', 'al@@', 'e@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:03:31,332 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:03:31,332 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:03:31,332 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la paura di questo speciale speciale, perché non è il Dicke del ghiaccio.
2025-05-29 23:03:31,332 - INFO - joeynmt.training - Example #2
2025-05-29 23:03:31,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:03:31,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:03:31,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:03:31,333 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:03:31,333 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:03:31,333 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore del nostro sistema climatico globale.
2025-05-29 23:03:31,333 - INFO - joeynmt.training - Example #3
2025-05-29 23:03:31,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:03:31,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:03:31,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'p@@', 'et@@', 'ere', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:03:31,334 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:03:31,334 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:03:31,334 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e ripetere in inverno.
2025-05-29 23:03:31,334 - INFO - joeynmt.training - Example #4
2025-05-29 23:03:31,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:03:31,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:03:31,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'pros@@', 'si@@', 'mo', '2@@', '5', 'an@@', 'ni@@', ',', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cosa', 'di', 'cui', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:03:31,335 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:03:31,335 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:03:31,335 - INFO - joeynmt.training - 	Hypothesis: Il prossimo prossimo 25 anni, che vi mostrerò una cosa di cui è successo negli ultimi 25 anni.
2025-05-29 23:03:34,716 - INFO - joeynmt.training - Epoch  10, Step:    96600, Batch Loss:     1.622018, Batch Acc: 0.506984, Tokens per Sec:    17476, Lr: 0.000300
2025-05-29 23:03:38,085 - INFO - joeynmt.training - Epoch  10, Step:    96700, Batch Loss:     1.518978, Batch Acc: 0.523078, Tokens per Sec:    21232, Lr: 0.000300
2025-05-29 23:03:41,463 - INFO - joeynmt.training - Epoch  10, Step:    96800, Batch Loss:     1.633994, Batch Acc: 0.519046, Tokens per Sec:    21145, Lr: 0.000300
2025-05-29 23:03:44,834 - INFO - joeynmt.training - Epoch  10, Step:    96900, Batch Loss:     1.603616, Batch Acc: 0.508949, Tokens per Sec:    20990, Lr: 0.000300
2025-05-29 23:03:48,180 - INFO - joeynmt.training - Epoch  10, Step:    97000, Batch Loss:     1.690620, Batch Acc: 0.511444, Tokens per Sec:    21524, Lr: 0.000300
2025-05-29 23:03:48,181 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:03:48,181 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:03:56,396 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.87, acc:   0.53, generation: 8.2040[sec], evaluation: 0.0000[sec]
2025-05-29 23:03:56,798 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/91000.ckpt
2025-05-29 23:03:56,824 - INFO - joeynmt.training - Example #0
2025-05-29 23:03:56,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:03:56,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:03:56,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'li@@', 'de', 'per', 'essere', 'un', 'po@@', '<unk>', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'ha', 'av@@', 'uto', 'la', 'qu@@', 'ale', 'per', 'la', 'qu@@', 'ale', 'per', 'il', '4@@', '0@@', '%', 'di', 'anni', 'per', 'la', 'per@@', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:03:56,826 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:03:56,826 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:03:56,826 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due slide per essere un po<unk> di ghiaccio, che l<unk> articolo che ha avuto la ghiaccia, che ha avuto la quale per la quale per il 40% di anni per la percento.
2025-05-29 23:03:56,826 - INFO - joeynmt.training - Example #1
2025-05-29 23:03:56,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:03:56,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:03:56,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:03:56,827 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:03:56,827 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:03:56,827 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la capacità di questo particolare problemi perché non c<unk> è il Dicke del ghiaccio del ghiaccio.
2025-05-29 23:03:56,827 - INFO - joeynmt.training - Example #2
2025-05-29 23:03:56,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:03:56,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:03:56,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'il', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 23:03:56,828 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:03:56,828 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:03:56,828 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiacciaio di ghiaccio, il nostro sistema di climatico.
2025-05-29 23:03:56,828 - INFO - joeynmt.training - Example #3
2025-05-29 23:03:56,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:03:56,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:03:56,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'ri@@', 'es@@', 'ce', 'a', 'ri@@', 'p@@', 'et@@', 'er@@', 'a@@', '.', '</s>']
2025-05-29 23:03:56,828 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:03:56,829 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:03:56,829 - INFO - joeynmt.training - 	Hypothesis: E si cresce in inverno, e riesce a ripetera.
2025-05-29 23:03:56,829 - INFO - joeynmt.training - Example #4
2025-05-29 23:03:56,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:03:56,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:03:56,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'qu@@', 'asi', 's@@', 'om@@', 'ig@@', 'li@@', 'anza', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:03:56,829 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:03:56,829 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:03:56,830 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò è una dimostrazione di quasi somiglianza di quello che è successo negli ultimi 25 anni.
2025-05-29 23:04:00,234 - INFO - joeynmt.training - Epoch  10, Step:    97100, Batch Loss:     1.577702, Batch Acc: 0.508924, Tokens per Sec:    17957, Lr: 0.000300
2025-05-29 23:04:03,619 - INFO - joeynmt.training - Epoch  10, Step:    97200, Batch Loss:     1.555615, Batch Acc: 0.507997, Tokens per Sec:    21030, Lr: 0.000300
2025-05-29 23:04:06,977 - INFO - joeynmt.training - Epoch  10, Step:    97300, Batch Loss:     1.602026, Batch Acc: 0.507538, Tokens per Sec:    20805, Lr: 0.000300
2025-05-29 23:04:10,352 - INFO - joeynmt.training - Epoch  10, Step:    97400, Batch Loss:     1.706458, Batch Acc: 0.506645, Tokens per Sec:    20916, Lr: 0.000300
2025-05-29 23:04:13,710 - INFO - joeynmt.training - Epoch  10, Step:    97500, Batch Loss:     2.001063, Batch Acc: 0.506737, Tokens per Sec:    21247, Lr: 0.000300
2025-05-29 23:04:13,711 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:04:13,711 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:04:22,291 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.88, acc:   0.53, generation: 8.5682[sec], evaluation: 0.0000[sec]
2025-05-29 23:04:22,300 - INFO - joeynmt.training - Example #0
2025-05-29 23:04:22,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:04:22,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:04:22,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'li@@', 'de', 'per', 'ri@@', 'dur@@', 're', 'il', '4@@', '0@@', '%', 'di', 'questi', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ati', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'è', 'stato', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'av@@', 'evano', 'fatto', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', ',', 'e', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'la', 'prima', 'volta', 'per', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'di', 'vi@@', 'vere', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'la', 'loro', 'è', 'stata', 'una', 'cosa', 'che', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 't@@', 'as@@', 'so', 'di']
2025-05-29 23:04:22,302 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:04:22,302 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:04:22,302 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso che ho mostrato questi due slide per ridurre il 40% di questi ghiacciati artici, che è stato l<unk> articolo di tre milioni di anni di anni che avevano fatto per il 40 per cento di anni, e il 40% di questi due anni per la prima volta per il 40% di questi due anni per cento di questi due anni di vivere in un certo senso, e la loro è stata una cosa che si tratta di un po<unk> di un tasso di
2025-05-29 23:04:22,302 - INFO - joeynmt.training - Example #1
2025-05-29 23:04:22,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:04:22,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:04:22,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:04:22,303 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:04:22,303 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:04:22,303 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte di questo problema, perché non è il Dicke del ghiaccio del ghiaccio del ghiaccio.
2025-05-29 23:04:22,303 - INFO - joeynmt.training - Example #2
2025-05-29 23:04:22,303 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:04:22,303 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:04:22,303 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', 'per', 'il', 'nostro', 'sistema', 'glob@@', 'ale', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'e', 'la', 'nostra', 'c@@', 'aus@@', 'a', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'la', 'nostra', 'mente', 'è', 'la', 'nostra', 'c@@', 'aus@@', 'a', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'la', 'nostra', 'mente', 'è', 'la', 'nostra', 'c@@', 'aus@@', 'a', 'di', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'e', 'la', 'nostra', 'es@@', 'peri@@', 'enza', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'a@@', '.', '</s>']
2025-05-29 23:04:22,304 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:04:22,304 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:04:22,304 - INFO - joeynmt.training - 	Hypothesis: In certo senso, la ghiaccio è l<unk> artica, il cuore globale del nostro sistema globale del sistema globale del sistema globale del sistema globale del sistema globale per il nostro sistema globale di climatico globale e la nostra causa di un certo senso, e la nostra mente è la nostra causa di un certo senso, e la nostra mente è la nostra causa di un certo senso, e la nostra esperienza di climatica.
2025-05-29 23:04:22,304 - INFO - joeynmt.training - Example #3
2025-05-29 23:04:22,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:04:22,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:04:22,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'est@@', 'at@@', 'a@@', '.', '</s>']
2025-05-29 23:04:22,304 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:04:22,305 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:04:22,305 - INFO - joeynmt.training - 	Hypothesis: E si sta crescendo in inverno e l<unk> estata.
2025-05-29 23:04:22,305 - INFO - joeynmt.training - Example #4
2025-05-29 23:04:22,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:04:22,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:04:22,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ale', 'sia', 'sia', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:04:22,305 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:04:22,305 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:04:22,306 - INFO - joeynmt.training - 	Hypothesis: Il prossimo slide che vi mostrerò è una disegno di quale sia sia successo negli ultimi 25 anni.
2025-05-29 23:04:25,661 - INFO - joeynmt.training - Epoch  10, Step:    97600, Batch Loss:     1.410518, Batch Acc: 0.513160, Tokens per Sec:    21786, Lr: 0.000300
2025-05-29 23:04:29,033 - INFO - joeynmt.training - Epoch  10, Step:    97700, Batch Loss:     1.682506, Batch Acc: 0.516433, Tokens per Sec:    21181, Lr: 0.000300
2025-05-29 23:04:32,413 - INFO - joeynmt.training - Epoch  10, Step:    97800, Batch Loss:     1.630077, Batch Acc: 0.511147, Tokens per Sec:    21332, Lr: 0.000300
2025-05-29 23:04:35,766 - INFO - joeynmt.training - Epoch  10, Step:    97900, Batch Loss:     1.676888, Batch Acc: 0.514624, Tokens per Sec:    20843, Lr: 0.000300
2025-05-29 23:04:39,125 - INFO - joeynmt.training - Epoch  10, Step:    98000, Batch Loss:     1.630880, Batch Acc: 0.498679, Tokens per Sec:    21077, Lr: 0.000300
2025-05-29 23:04:39,125 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:04:39,125 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:04:46,948 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.86, acc:   0.53, generation: 7.8115[sec], evaluation: 0.0000[sec]
2025-05-29 23:04:46,948 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:04:47,532 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/93000.ckpt
2025-05-29 23:04:47,560 - INFO - joeynmt.training - Example #0
2025-05-29 23:04:47,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:04:47,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:04:47,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'le', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'che', 'i', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'ha', 'chiam@@', 'ato', 'i', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', ',', 'per', 'la', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', ',', 'per', 'la', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:04:47,561 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:04:47,561 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:04:47,562 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per vedere che le articolo artico che i artici, che ha chiamato i tre milioni di anni di anni di 40 per cento, per la 40 per cento di anni, per la 40 per cento di cento.
2025-05-29 23:04:47,562 - INFO - joeynmt.training - Example #1
2025-05-29 23:04:47,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:04:47,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:04:47,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:04:47,562 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:04:47,562 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:04:47,563 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte di questo problema, perché non è il Dicke del ghiaccio è che non è il Dicke del ghiaccio del ghiaccio.
2025-05-29 23:04:47,563 - INFO - joeynmt.training - Example #2
2025-05-29 23:04:47,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:04:47,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:04:47,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'd@@', 'ell@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'del', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:04:47,563 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:04:47,564 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:04:47,564 - INFO - joeynmt.training - 	Hypothesis: In certo senso è la causa dell<unk> articolo del nostro sistema globale.
2025-05-29 23:04:47,564 - INFO - joeynmt.training - Example #3
2025-05-29 23:04:47,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:04:47,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:04:47,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sta', 'cres@@', 'c@@', 'endo', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'l@@', 'ev@@', 'at@@', 'or@@', 'i@@', '.', '</s>']
2025-05-29 23:04:47,564 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:04:47,564 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:04:47,564 - INFO - joeynmt.training - 	Hypothesis: Si sta crescendo in inverno e rilevatori.
2025-05-29 23:04:47,565 - INFO - joeynmt.training - Example #4
2025-05-29 23:04:47,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:04:47,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:04:47,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'di@@', 'seg@@', 'no', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:04:47,565 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:04:47,565 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:04:47,565 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un disegno di disegno negli ultimi 25 anni.
2025-05-29 23:04:50,936 - INFO - joeynmt.training - Epoch  10, Step:    98100, Batch Loss:     1.691973, Batch Acc: 0.504668, Tokens per Sec:    17543, Lr: 0.000300
2025-05-29 23:04:54,263 - INFO - joeynmt.training - Epoch  10, Step:    98200, Batch Loss:     1.466421, Batch Acc: 0.504093, Tokens per Sec:    21228, Lr: 0.000300
2025-05-29 23:04:57,624 - INFO - joeynmt.training - Epoch  10, Step:    98300, Batch Loss:     1.614726, Batch Acc: 0.508949, Tokens per Sec:    20947, Lr: 0.000300
2025-05-29 23:05:00,996 - INFO - joeynmt.training - Epoch  10, Step:    98400, Batch Loss:     1.658561, Batch Acc: 0.510741, Tokens per Sec:    20853, Lr: 0.000300
2025-05-29 23:05:04,378 - INFO - joeynmt.training - Epoch  10, Step:    98500, Batch Loss:     1.552211, Batch Acc: 0.504056, Tokens per Sec:    21184, Lr: 0.000300
2025-05-29 23:05:04,379 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:05:04,379 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:05:12,683 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.53, generation: 8.2932[sec], evaluation: 0.0000[sec]
2025-05-29 23:05:12,684 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:05:13,289 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/95000.ckpt
2025-05-29 23:05:13,309 - INFO - joeynmt.training - Example #0
2025-05-29 23:05:13,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:05:13,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:05:13,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'di', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'le', 'persone', 'si', 'sono', 'ri@@', 'ma@@', 'st@@', 'i', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'chiam@@', 'ato', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'hanno', 'av@@', 'uto', 'per', 'ri@@', 'dur@@', 're', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:05:13,310 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:05:13,310 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:05:13,310 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso di queste due diapositive per vedere che le persone si sono rimasti che l<unk> articolo che ha chiamato il ghiaccio di tre milioni di anni di persone che hanno avuto per ridurre il 40 per cento di anni.
2025-05-29 23:05:13,310 - INFO - joeynmt.training - Example #1
2025-05-29 23:05:13,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:05:13,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:05:13,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'cosa', 'che', 'è', 'la', 'p@@', 'au@@', 'ra', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'em@@', 'i@@', ',', 'perché', 'non', 'ci', 'mostr@@', 'a', 'i', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:05:13,311 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:05:13,311 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:05:13,311 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la cosa che è la paura di questo particolare problemi, perché non ci mostra i dell<unk> origine del ghiaccio.
2025-05-29 23:05:13,311 - INFO - joeynmt.training - Example #2
2025-05-29 23:05:13,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:05:13,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:05:13,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:05:13,312 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:05:13,312 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:05:13,312 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico, il cuore del nostro sistema climatico globale.
2025-05-29 23:05:13,312 - INFO - joeynmt.training - Example #3
2025-05-29 23:05:13,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:05:13,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:05:13,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'l@@', 'ev@@', 'at@@', 'a@@', '.', '</s>']
2025-05-29 23:05:13,313 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:05:13,313 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:05:13,313 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e rilevata.
2025-05-29 23:05:13,313 - INFO - joeynmt.training - Example #4
2025-05-29 23:05:13,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:05:13,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:05:13,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'men@@', 'sione', 'di', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:05:13,314 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:05:13,314 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:05:13,314 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimensione di diapositiva che è successo negli ultimi 25 anni.
2025-05-29 23:05:16,718 - INFO - joeynmt.training - Epoch  10, Step:    98600, Batch Loss:     1.708406, Batch Acc: 0.507074, Tokens per Sec:    17782, Lr: 0.000300
2025-05-29 23:05:20,096 - INFO - joeynmt.training - Epoch  10, Step:    98700, Batch Loss:     1.436310, Batch Acc: 0.507677, Tokens per Sec:    21159, Lr: 0.000300
2025-05-29 23:05:23,481 - INFO - joeynmt.training - Epoch  10, Step:    98800, Batch Loss:     1.452252, Batch Acc: 0.507026, Tokens per Sec:    20946, Lr: 0.000300
2025-05-29 23:05:26,838 - INFO - joeynmt.training - Epoch  10, Step:    98900, Batch Loss:     1.459800, Batch Acc: 0.505574, Tokens per Sec:    20711, Lr: 0.000300
2025-05-29 23:05:30,187 - INFO - joeynmt.training - Epoch  10, Step:    99000, Batch Loss:     1.471861, Batch Acc: 0.501649, Tokens per Sec:    21103, Lr: 0.000300
2025-05-29 23:05:30,188 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:05:30,188 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:05:38,712 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.86, acc:   0.53, generation: 8.5133[sec], evaluation: 0.0000[sec]
2025-05-29 23:05:39,126 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/97000.ckpt
2025-05-29 23:05:39,152 - INFO - joeynmt.training - Example #0
2025-05-29 23:05:39,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:05:39,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:05:39,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'che', 'ha', 'in@@', 'segn@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'e', 'il', '4@@', '8@@', '%', 'di', 'an@@', 'ni@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'della', 'c@@', 'ent@@', 'u@@', 'ale', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'della', 'c@@', 'ent@@', 'u@@', 'ale', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'della', 'loro', 'es@@', 'ist@@', 'en@@', 'z@@', 'a@@', '.', '</s>']
2025-05-29 23:05:39,153 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:05:39,153 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:05:39,153 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per ridurre che l<unk> anno scorso che l<unk> articolo artico che ha insegnato per tre milioni di anni di anni e il 48% di anni, per tre milioni di anni per il 40 per cento della centuale per il 40 per cento della centuale per il 40 per cento della loro esistenza.
2025-05-29 23:05:39,153 - INFO - joeynmt.training - Example #1
2025-05-29 23:05:39,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:05:39,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:05:39,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'perché', 'non', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'ale', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:05:39,154 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:05:39,154 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:05:39,154 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte di questo particolare problemi di questo particolare problemi di questo speciale perché non mostra il dell<unk> originale del ghiaccio.
2025-05-29 23:05:39,154 - INFO - joeynmt.training - Example #2
2025-05-29 23:05:39,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:05:39,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:05:39,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sen@@', 'so', 'di', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:05:39,155 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:05:39,155 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:05:39,155 - INFO - joeynmt.training - 	Hypothesis: In un senso di senso è l<unk> articolo artico cuore artico del nostro sistema climatico globale.
2025-05-29 23:05:39,155 - INFO - joeynmt.training - Example #3
2025-05-29 23:05:39,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:05:39,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:05:39,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'sp@@', 'ost@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:05:39,156 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:05:39,156 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:05:39,156 - INFO - joeynmt.training - 	Hypothesis: Sta crescita in inverno, e si sposta in inverno.
2025-05-29 23:05:39,156 - INFO - joeynmt.training - Example #4
2025-05-29 23:05:39,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:05:39,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:05:39,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ale', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:05:39,157 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:05:39,157 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:05:39,157 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un disegno di quale negli ultimi 25 anni.
2025-05-29 23:05:42,542 - INFO - joeynmt.training - Epoch  10, Step:    99100, Batch Loss:     1.751101, Batch Acc: 0.501430, Tokens per Sec:    17992, Lr: 0.000300
2025-05-29 23:05:45,918 - INFO - joeynmt.training - Epoch  10, Step:    99200, Batch Loss:     1.888796, Batch Acc: 0.507471, Tokens per Sec:    21276, Lr: 0.000300
2025-05-29 23:05:49,298 - INFO - joeynmt.training - Epoch  10, Step:    99300, Batch Loss:     1.493099, Batch Acc: 0.506414, Tokens per Sec:    20951, Lr: 0.000300
2025-05-29 23:05:52,665 - INFO - joeynmt.training - Epoch  10, Step:    99400, Batch Loss:     1.795453, Batch Acc: 0.509721, Tokens per Sec:    21575, Lr: 0.000300
2025-05-29 23:05:55,977 - INFO - joeynmt.training - Epoch  10, Step:    99500, Batch Loss:     1.710464, Batch Acc: 0.510793, Tokens per Sec:    20721, Lr: 0.000300
2025-05-29 23:05:55,977 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:05:55,977 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:06:05,000 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.85, acc:   0.53, generation: 9.0117[sec], evaluation: 0.0000[sec]
2025-05-29 23:06:05,398 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/96000.ckpt
2025-05-29 23:06:05,423 - INFO - joeynmt.training - Example #0
2025-05-29 23:06:05,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:06:05,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:06:05,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'man@@', 'ere', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'di', 's@@', 'otto', 'i', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'della', 'p@@', 'op@@', 'ol@@', 'azi@@', 'on@@', 'e@@', '.', '</s>']
2025-05-29 23:06:05,425 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:06:05,425 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:06:05,425 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per rimanere per ridurre che l<unk> articolo che l<unk> articolo che ha avuto tre milioni di anni di sotto i 48 per cento di anni, il 40 per cento di 40 per cento della popolazione.
2025-05-29 23:06:05,425 - INFO - joeynmt.training - Example #1
2025-05-29 23:06:05,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:06:05,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:06:05,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'è', 'il', 'D@@', 'ic@@', 'ke', 'è', 'che', 'non', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'è', 'che', 'non', 'mostr@@', 'a', 'il', 'D@@', 'ic@@', 'ke', 'è', 'un', 'po@@', '<unk>', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'e', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', '.', '</s>']
2025-05-29 23:06:05,426 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:06:05,426 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:06:05,426 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la prima cosa che è il Dicke è che non mostra il Dicke del ghiaccio del ghiaccio del ghiaccio che mostra il ghiaccio è che non mostra il Dicke è un po<unk> di ghiaccio che non è abbastanza forte di questo problema, e non è abbastanza forte abbastanza forte di questo problema, e non è abbastanza forte.
2025-05-29 23:06:05,426 - INFO - joeynmt.training - Example #2
2025-05-29 23:06:05,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:06:05,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:06:05,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:06:05,427 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:06:05,427 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:06:05,427 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico del nostro sistema climatico globale.
2025-05-29 23:06:05,427 - INFO - joeynmt.training - Example #3
2025-05-29 23:06:05,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:06:05,427 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:06:05,427 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'chi@@', 'est@@', 'o@@', '.', '</s>']
2025-05-29 23:06:05,427 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:06:05,427 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:06:05,428 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e richiesto.
2025-05-29 23:06:05,428 - INFO - joeynmt.training - Example #4
2025-05-29 23:06:05,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:06:05,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:06:05,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ei', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:06:05,428 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:06:05,428 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:06:05,428 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è un disegno di quei che è successo negli ultimi 25 anni.
2025-05-29 23:06:08,793 - INFO - joeynmt.training - Epoch  10, Step:    99600, Batch Loss:     1.701574, Batch Acc: 0.507929, Tokens per Sec:    18176, Lr: 0.000300
2025-05-29 23:06:12,149 - INFO - joeynmt.training - Epoch  10, Step:    99700, Batch Loss:     1.911923, Batch Acc: 0.506902, Tokens per Sec:    21289, Lr: 0.000300
2025-05-29 23:06:15,496 - INFO - joeynmt.training - Epoch  10, Step:    99800, Batch Loss:     1.651766, Batch Acc: 0.506644, Tokens per Sec:    21117, Lr: 0.000300
2025-05-29 23:06:18,840 - INFO - joeynmt.training - Epoch  10, Step:    99900, Batch Loss:     1.507898, Batch Acc: 0.505710, Tokens per Sec:    20880, Lr: 0.000300
2025-05-29 23:06:22,161 - INFO - joeynmt.training - Epoch  10, Step:   100000, Batch Loss:     1.915677, Batch Acc: 0.498966, Tokens per Sec:    20240, Lr: 0.000300
2025-05-29 23:06:22,162 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:06:22,162 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:06:29,928 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.88, acc:   0.53, generation: 7.7555[sec], evaluation: 0.0000[sec]
2025-05-29 23:06:29,949 - INFO - joeynmt.training - Example #0
2025-05-29 23:06:29,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:06:29,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:06:29,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'tre', 'milioni', 'di', 'anni', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'anni', 'di', 'cui', 'il', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'anni', 'di', 'cui', 'il', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:06:29,950 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:06:29,950 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:06:29,950 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per ridurre che l<unk> articolo che l<unk> articolo che ha tre milioni di anni di ghiaccio di anni di cui il 48 per cento di anni di cui il 40 per cento.
2025-05-29 23:06:29,950 - INFO - joeynmt.training - Example #1
2025-05-29 23:06:29,950 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:06:29,950 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:06:29,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'probl@@', 'emi', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'che', 'non', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'pi@@', 'ù@@', '.', '</s>']
2025-05-29 23:06:29,951 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:06:29,951 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:06:29,951 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la popolazione di questo particolare problemi di questo particolare è che non mostra il dell<unk> origine del ghiaccio che non è il dell<unk> origine di ghiaccio che non è un po<unk> di più.
2025-05-29 23:06:29,951 - INFO - joeynmt.training - Example #2
2025-05-29 23:06:29,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:06:29,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:06:29,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'd@@', 'ell@@', '<unk>', 'in@@', 'gr@@', 'esso', 'di', 'un', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:06:29,952 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:06:29,952 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:06:29,952 - INFO - joeynmt.training - 	Hypothesis: In certo senso è l<unk> artico, il cuore dell<unk> ingresso di un sistema globale.
2025-05-29 23:06:29,952 - INFO - joeynmt.training - Example #3
2025-05-29 23:06:29,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:06:29,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:06:29,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'è', 'sp@@', 'ost@@', 'ata', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:06:29,953 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:06:29,953 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:06:29,953 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno, e si è spostata in inverno.
2025-05-29 23:06:29,953 - INFO - joeynmt.training - Example #4
2025-05-29 23:06:29,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:06:29,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:06:29,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'st@@', 'anza', 'di', 'qu@@', 'ant@@', 'ità', 'di', 'di', 'qu@@', 'at@@', 'tro', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:06:29,954 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:06:29,954 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:06:29,954 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una distanza di quantità di di quattro anni.
2025-05-29 23:06:33,338 - INFO - joeynmt.training - Epoch  10, Step:   100100, Batch Loss:     1.714103, Batch Acc: 0.508042, Tokens per Sec:    21340, Lr: 0.000300
2025-05-29 23:06:36,719 - INFO - joeynmt.training - Epoch  10, Step:   100200, Batch Loss:     1.716358, Batch Acc: 0.512193, Tokens per Sec:    20502, Lr: 0.000300
2025-05-29 23:06:40,091 - INFO - joeynmt.training - Epoch  10, Step:   100300, Batch Loss:     1.586692, Batch Acc: 0.501251, Tokens per Sec:    21218, Lr: 0.000300
2025-05-29 23:06:43,437 - INFO - joeynmt.training - Epoch  10, Step:   100400, Batch Loss:     1.722391, Batch Acc: 0.506033, Tokens per Sec:    21260, Lr: 0.000300
2025-05-29 23:06:46,787 - INFO - joeynmt.training - Epoch  10, Step:   100500, Batch Loss:     1.532643, Batch Acc: 0.506717, Tokens per Sec:    20916, Lr: 0.000300
2025-05-29 23:06:46,788 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:06:46,788 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:06:55,513 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.86, acc:   0.53, generation: 8.7139[sec], evaluation: 0.0000[sec]
2025-05-29 23:06:55,524 - INFO - joeynmt.training - Example #0
2025-05-29 23:06:55,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:06:55,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:06:55,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 's@@', 'li@@', 'de', 'per', 'ri@@', 'dur@@', 're', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'che', 'l@@', '<unk>', 'inter@@', 'a', 'p@@', 'et@@', 'r@@', 'ol@@', 'i@@', 'a@@', ',', 'che', 'ha', 'chiam@@', 'ato', '4@@', '8', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'av@@', 'evano', 'tre', 'milioni', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'an@@', 'ni@@', ',', 'il', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:06:55,526 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:06:55,526 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:06:55,526 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso che ho mostrato queste due slide per ridurre che le ghiacciate che l<unk> intera petrolia, che ha chiamato 48 milioni di anni di anni che avevano tre milioni di anni di 40 per cento di anni, il 40 per cento.
2025-05-29 23:06:55,526 - INFO - joeynmt.training - Example #1
2025-05-29 23:06:55,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:06:55,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:06:55,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'lo', 'si', 'tr@@', 'at@@', 'ta', 'di', 'un', 'problema', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'problema', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:06:55,526 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:06:55,527 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:06:55,527 - INFO - joeynmt.training - 	Hypothesis: Ma non lo si tratta di un problema di questo problema, perché non c<unk> è il problema di questo problema, perché non c<unk> è il Dicke del ghiaccio.
2025-05-29 23:06:55,527 - INFO - joeynmt.training - Example #2
2025-05-29 23:06:55,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:06:55,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:06:55,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'ale', 'del', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:06:55,527 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:06:55,528 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:06:55,528 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> originale del cuore artico, il cuore del nostro sistema climatico globale.
2025-05-29 23:06:55,528 - INFO - joeynmt.training - Example #3
2025-05-29 23:06:55,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:06:55,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:06:55,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no@@', ',', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:06:55,528 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:06:55,528 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:06:55,529 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno, in inverno.
2025-05-29 23:06:55,529 - INFO - joeynmt.training - Example #4
2025-05-29 23:06:55,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:06:55,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:06:55,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'st@@', 'anza', 'di', 'di@@', 'seg@@', 'no', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:06:55,529 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:06:55,529 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:06:55,529 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una distanza di disegno negli ultimi 25 anni.
2025-05-29 23:06:58,870 - INFO - joeynmt.training - Epoch  10, Step:   100600, Batch Loss:     1.650918, Batch Acc: 0.503082, Tokens per Sec:    20979, Lr: 0.000300
2025-05-29 23:07:02,198 - INFO - joeynmt.training - Epoch  10, Step:   100700, Batch Loss:     1.762975, Batch Acc: 0.502518, Tokens per Sec:    21430, Lr: 0.000300
2025-05-29 23:07:05,510 - INFO - joeynmt.training - Epoch  10, Step:   100800, Batch Loss:     1.583325, Batch Acc: 0.504100, Tokens per Sec:    21286, Lr: 0.000300
2025-05-29 23:07:08,838 - INFO - joeynmt.training - Epoch  10, Step:   100900, Batch Loss:     1.799481, Batch Acc: 0.499751, Tokens per Sec:    21151, Lr: 0.000300
2025-05-29 23:07:12,197 - INFO - joeynmt.training - Epoch  10, Step:   101000, Batch Loss:     1.646446, Batch Acc: 0.508832, Tokens per Sec:    21106, Lr: 0.000300
2025-05-29 23:07:12,197 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:07:12,197 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:07:21,844 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.53, generation: 9.6344[sec], evaluation: 0.0000[sec]
2025-05-29 23:07:21,845 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:07:22,393 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/96500.ckpt
2025-05-29 23:07:22,420 - INFO - joeynmt.training - Example #0
2025-05-29 23:07:22,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:07:22,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:07:22,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'ar@@', 't@@', 'ic@@', 'amente', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ai', 'a', 'tre', 'milioni', 'di', 'anni', 'di', 'l@@', '<unk>', '4@@', '8@@', ',', 'e', 'il', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', '4@@', '8@@', '0@@', '%', 'di', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'il', '4@@', '0@@', '%', 'di', 'un', 'po@@', '<unk>', '.', '</s>']
2025-05-29 23:07:22,422 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:07:22,422 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:07:22,422 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per vedere che le ghiacciate articamente che le ghiacciai a tre milioni di anni di l<unk> 48, e il 480 per cento di anni di 40 per cento di un 480% di questi due diapositive per il 40% di un po<unk> .
2025-05-29 23:07:22,422 - INFO - joeynmt.training - Example #1
2025-05-29 23:07:22,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:07:22,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:07:22,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'ti@@', ',', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'perché', 'non', 'c@@', '<unk>', 'è', 'il', 'd@@', 'ic@@', 'chi@@', 'ar@@', 'o', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'in', 'modo', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'per', 'il', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', '.', '</s>']
2025-05-29 23:07:22,423 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:07:22,423 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:07:22,423 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forti, la prima cosa che non è abbastanza forte perché non c<unk> è il dicchiaro del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio in modo che non è abbastanza forte, ma non è abbastanza forte per il motivo per cui non è abbastanza forte, ma non è abbastanza forte.
2025-05-29 23:07:22,423 - INFO - joeynmt.training - Example #2
2025-05-29 23:07:22,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:07:22,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:07:22,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:07:22,424 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:07:22,424 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:07:22,424 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il cuore di climatico del nostro sistema climatico globale.
2025-05-29 23:07:22,424 - INFO - joeynmt.training - Example #3
2025-05-29 23:07:22,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:07:22,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:07:22,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:07:22,425 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:07:22,425 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:07:22,425 - INFO - joeynmt.training - 	Hypothesis: E si cresce in inverno, e si rivela in inverno.
2025-05-29 23:07:22,425 - INFO - joeynmt.training - Example #4
2025-05-29 23:07:22,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:07:22,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:07:22,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:07:22,426 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:07:22,426 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:07:22,426 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 23:07:25,803 - INFO - joeynmt.training - Epoch  10, Step:   101100, Batch Loss:     1.714499, Batch Acc: 0.509159, Tokens per Sec:    17696, Lr: 0.000300
2025-05-29 23:07:29,151 - INFO - joeynmt.training - Epoch  10, Step:   101200, Batch Loss:     1.602186, Batch Acc: 0.498863, Tokens per Sec:    20621, Lr: 0.000300
2025-05-29 23:07:32,522 - INFO - joeynmt.training - Epoch  10, Step:   101300, Batch Loss:     1.739508, Batch Acc: 0.502906, Tokens per Sec:    20936, Lr: 0.000300
2025-05-29 23:07:35,893 - INFO - joeynmt.training - Epoch  10, Step:   101400, Batch Loss:     1.818367, Batch Acc: 0.501462, Tokens per Sec:    21609, Lr: 0.000300
2025-05-29 23:07:39,256 - INFO - joeynmt.training - Epoch  10, Step:   101500, Batch Loss:     1.615457, Batch Acc: 0.508022, Tokens per Sec:    21298, Lr: 0.000300
2025-05-29 23:07:39,257 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:07:39,257 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:07:47,735 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.83, acc:   0.53, generation: 8.4671[sec], evaluation: 0.0000[sec]
2025-05-29 23:07:47,735 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:07:48,246 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/98000.ckpt
2025-05-29 23:07:48,273 - INFO - joeynmt.training - Example #0
2025-05-29 23:07:48,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:07:48,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:07:48,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'ire', 'le', 'di@@', 'apos@@', 'iti@@', 've', 'che', 'le', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ico', 'che', 'ha', 'chiam@@', 'ato', 'i', '4@@', '8', 'anni', 'di', 'questi', '4@@', '8', 'anni', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', '4@@', '8', 'ore', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'un', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'di', 'questi', 'due', 'anni', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'di', '1@@', '0@@', '0@@', '.', '</s>']
2025-05-29 23:07:48,274 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:07:48,274 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:07:48,274 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per conseguire le diapositive che le articolo artico che ha chiamato i 48 anni di questi 48 anni di 48 per cento di 48 per cento di 48 per cento di 48 ore per cento di 40 per cento di un 48 per cento di questi due anni di questi due anni di 40 percento di questi due anni di 100.
2025-05-29 23:07:48,274 - INFO - joeynmt.training - Example #1
2025-05-29 23:07:48,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:07:48,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:07:48,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'al@@', 'im@@', 'ent@@', 'o@@', ',', 'perché', 'non', 'è', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'ine', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'p@@', 'al@@', 'mo', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'e', 'la', 'cosa', 'più', 'importante', 'è', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', '.', '</s>']
2025-05-29 23:07:48,275 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:07:48,275 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:07:48,275 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che è il dell<unk> alimento, perché non è il dell<unk> origine del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di un palmo di ghiaccio, e la cosa più importante è che non è abbastanza forte.
2025-05-29 23:07:48,275 - INFO - joeynmt.training - Example #2
2025-05-29 23:07:48,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:07:48,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:07:48,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:07:48,276 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:07:48,276 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:07:48,276 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il ghiaccio artico, il nostro sistema climatico globale.
2025-05-29 23:07:48,276 - INFO - joeynmt.training - Example #3
2025-05-29 23:07:48,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:07:48,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:07:48,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sp@@', 'ost@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'du@@', 'ce', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:07:48,277 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:07:48,277 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:07:48,277 - INFO - joeynmt.training - 	Hypothesis: Si sposta in inverno, e si riduce in inverno.
2025-05-29 23:07:48,277 - INFO - joeynmt.training - Example #4
2025-05-29 23:07:48,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:07:48,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:07:48,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:07:48,277 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:07:48,277 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:07:48,277 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una dimostrazione di quale è successo negli ultimi 25 anni.
2025-05-29 23:07:51,658 - INFO - joeynmt.training - Epoch  10, Step:   101600, Batch Loss:     1.570125, Batch Acc: 0.503978, Tokens per Sec:    17946, Lr: 0.000300
2025-05-29 23:07:55,034 - INFO - joeynmt.training - Epoch  10, Step:   101700, Batch Loss:     1.769622, Batch Acc: 0.509573, Tokens per Sec:    20938, Lr: 0.000300
2025-05-29 23:07:58,414 - INFO - joeynmt.training - Epoch  10, Step:   101800, Batch Loss:     1.629183, Batch Acc: 0.514355, Tokens per Sec:    21512, Lr: 0.000300
2025-05-29 23:08:01,749 - INFO - joeynmt.training - Epoch  10, Step:   101900, Batch Loss:     1.691156, Batch Acc: 0.512842, Tokens per Sec:    20956, Lr: 0.000300
2025-05-29 23:08:05,100 - INFO - joeynmt.training - Epoch  10, Step:   102000, Batch Loss:     1.506152, Batch Acc: 0.508078, Tokens per Sec:    21341, Lr: 0.000300
2025-05-29 23:08:05,100 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:08:05,100 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:08:14,353 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.53, generation: 9.2401[sec], evaluation: 0.0000[sec]
2025-05-29 23:08:14,763 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/99000.ckpt
2025-05-29 23:08:14,791 - INFO - joeynmt.training - Example #0
2025-05-29 23:08:14,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:08:14,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:08:14,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'vedere', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'chiam@@', 'ato', 'il', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'dei', 'più', 'al@@', 'ti', 'del', '4@@', '8', 'per', 'c@@', 'ento', 'dei', 'più', 'al@@', 'ti', 'di', '4@@', '8', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:08:14,792 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:08:14,792 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:08:14,792 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per vedere che l<unk> articolo artico, che l<unk> articolo che ha chiamato il 480 per cento dei più alti del 48 per cento dei più alti di 48 per cento di cento.
2025-05-29 23:08:14,792 - INFO - joeynmt.training - Example #1
2025-05-29 23:08:14,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:08:14,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:08:14,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'la', 'prima', 'cosa', 'che', 'mostr@@', 'a', 'questo', 'part@@', 'icol@@', 'ar@@', 'e@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'k@@', ',', 'e', 'non', 'mostr@@', 'a', 'il', 'd@@', 'ell@@', '<unk>', 'or@@', 'ig@@', 'in@@', 'ale', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', '.', '</s>']
2025-05-29 23:08:14,793 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:08:14,793 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:08:14,793 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo particolare è la prima cosa che mostra questo particolare, perché non è il Dick, e non mostra il dell<unk> originale del ghiaccio del ghiaccio che non è abbastanza forte.
2025-05-29 23:08:14,793 - INFO - joeynmt.training - Example #2
2025-05-29 23:08:14,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:08:14,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:08:14,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:08:14,794 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:08:14,794 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:08:14,794 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> artico, il cuore artico del sistema climatico globale.
2025-05-29 23:08:14,794 - INFO - joeynmt.training - Example #3
2025-05-29 23:08:14,794 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:08:14,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:08:14,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'es@@', 'ce', 'a', 'sc@@', 'u@@', 'ola', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 23:08:14,795 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:08:14,795 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:08:14,795 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e si riesce a scuola in inverno e l<unk> estate.
2025-05-29 23:08:14,795 - INFO - joeynmt.training - Example #4
2025-05-29 23:08:14,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:08:14,795 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:08:14,795 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'm@@', 'em@@', 'or@@', 'ia', 'di', 'tem@@', 'po@@', ',', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:08:14,796 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:08:14,796 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:08:14,796 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una memoria di tempo, che è successo negli ultimi 25 anni.
2025-05-29 23:08:18,180 - INFO - joeynmt.training - Epoch  10, Step:   102100, Batch Loss:     1.571470, Batch Acc: 0.510273, Tokens per Sec:    18850, Lr: 0.000300
2025-05-29 23:08:21,549 - INFO - joeynmt.training - Epoch  10, Step:   102200, Batch Loss:     1.495370, Batch Acc: 0.506388, Tokens per Sec:    21590, Lr: 0.000300
2025-05-29 23:08:24,890 - INFO - joeynmt.training - Epoch  10, Step:   102300, Batch Loss:     1.742801, Batch Acc: 0.502562, Tokens per Sec:    20569, Lr: 0.000300
2025-05-29 23:08:28,245 - INFO - joeynmt.training - Epoch  10, Step:   102400, Batch Loss:     1.662875, Batch Acc: 0.504393, Tokens per Sec:    20831, Lr: 0.000300
2025-05-29 23:08:31,588 - INFO - joeynmt.training - Epoch  10, Step:   102500, Batch Loss:     1.577434, Batch Acc: 0.508518, Tokens per Sec:    20938, Lr: 0.000300
2025-05-29 23:08:31,588 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:08:31,588 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:08:40,085 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.85, acc:   0.53, generation: 8.4857[sec], evaluation: 0.0000[sec]
2025-05-29 23:08:40,096 - INFO - joeynmt.training - Example #0
2025-05-29 23:08:40,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:08:40,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:08:40,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'li@@', 'de', 'per', 'ri@@', 'dur@@', 're', 'che', 'i', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'i', 'n@@', 'on@@', 'ost@@', 'ante', 'gli', 'anni', 'di', 'questi', 'sono', 'stati', 'in', 'gra@@', 'do', 'di', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', 'il', '4@@', '8@@', ',', 'per', 'il', '4@@', '8@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:08:40,097 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:08:40,097 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:08:40,097 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due slide per ridurre che i ghiaccio, che i nonostante gli anni di questi sono stati in grado di tre milioni di anni che hanno avuto il 48, per il 480 per cento.
2025-05-29 23:08:40,097 - INFO - joeynmt.training - Example #1
2025-05-29 23:08:40,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:08:40,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:08:40,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'p@@', 'ell@@', 'u@@', 'di@@', 'tà', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'un', 'po@@', '<unk>', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'p@@', 'ezz@@', 'o', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 's@@', 'é', 'st@@', 'essi@@', '.', '</s>']
2025-05-29 23:08:40,098 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:08:40,098 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:08:40,098 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte la pelludità di questo problema, perché non è un po<unk> di ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di un pezzo di ghiaccio di sé stessi.
2025-05-29 23:08:40,098 - INFO - joeynmt.training - Example #2
2025-05-29 23:08:40,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:08:40,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:08:40,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'cal@@', 'am@@', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:08:40,099 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:08:40,099 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:08:40,099 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> calamartico, il cuore artico, il nostro sistema climatico globale.
2025-05-29 23:08:40,099 - INFO - joeynmt.training - Example #3
2025-05-29 23:08:40,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:08:40,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:08:40,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'p@@', 'et@@', 'ere', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 23:08:40,100 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:08:40,100 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:08:40,100 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e ripetere in inverno e l<unk> estate.
2025-05-29 23:08:40,100 - INFO - joeynmt.training - Example #4
2025-05-29 23:08:40,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:08:40,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:08:40,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'apos@@', 'iti@@', 'vo', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:08:40,101 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:08:40,101 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:08:40,101 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostrerò è una cosa che è successo negli ultimi 25 anni.
2025-05-29 23:08:43,468 - INFO - joeynmt.training - Epoch  10, Step:   102600, Batch Loss:     1.569069, Batch Acc: 0.502741, Tokens per Sec:    21302, Lr: 0.000300
2025-05-29 23:08:46,839 - INFO - joeynmt.training - Epoch  10, Step:   102700, Batch Loss:     1.900256, Batch Acc: 0.509484, Tokens per Sec:    20996, Lr: 0.000300
2025-05-29 23:08:50,222 - INFO - joeynmt.training - Epoch  10, Step:   102800, Batch Loss:     1.482266, Batch Acc: 0.507411, Tokens per Sec:    21361, Lr: 0.000300
2025-05-29 23:08:53,606 - INFO - joeynmt.training - Epoch  10, Step:   102900, Batch Loss:     1.664475, Batch Acc: 0.502659, Tokens per Sec:    22294, Lr: 0.000300
2025-05-29 23:08:56,971 - INFO - joeynmt.training - Epoch  10, Step:   103000, Batch Loss:     1.607248, Batch Acc: 0.503677, Tokens per Sec:    21297, Lr: 0.000300
2025-05-29 23:08:56,972 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:08:56,972 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:09:05,623 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.82, acc:   0.53, generation: 8.6401[sec], evaluation: 0.0000[sec]
2025-05-29 23:09:05,623 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:09:06,314 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/99500.ckpt
2025-05-29 23:09:06,339 - INFO - joeynmt.training - Example #0
2025-05-29 23:09:06,340 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:09:06,340 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:09:06,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'sc@@', 'ar@@', 'ab@@', 'oc@@', 'chi@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'sono', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', 'il', '4@@', '8@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:09:06,340 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:09:06,340 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:09:06,341 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive per scarabocchi, che le ghiacciate artici, che sono i tre milioni di anni che hanno avuto il 480 per cento.
2025-05-29 23:09:06,341 - INFO - joeynmt.training - Example #1
2025-05-29 23:09:06,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:09:06,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:09:06,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'essere', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'è', 'il', 'D@@', 'ic@@', 'ke', 'non', 'è', 'un', 'problema', 'spe@@', 'ci@@', 'ale', 'perché', 'non', 'è', 'un', 'problema', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:09:06,341 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:09:06,341 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:09:06,341 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di essere abbastanza la prima cosa che è il Dicke non è un problema speciale perché non è un problema di ghiaccio.
2025-05-29 23:09:06,341 - INFO - joeynmt.training - Example #2
2025-05-29 23:09:06,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:09:06,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:09:06,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'ar@@', 't@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 23:09:06,342 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:09:06,342 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:09:06,342 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> articolo artico.
2025-05-29 23:09:06,342 - INFO - joeynmt.training - Example #3
2025-05-29 23:09:06,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:09:06,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:09:06,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'cres@@', 'ce', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'ri@@', 'vel@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:09:06,343 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:09:06,343 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:09:06,343 - INFO - joeynmt.training - 	Hypothesis: Si cresce in inverno e si rivela in inverno.
2025-05-29 23:09:06,343 - INFO - joeynmt.training - Example #4
2025-05-29 23:09:06,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:09:06,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:09:06,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:09:06,344 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:09:06,344 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:09:06,344 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una cosa che è successo negli ultimi 25 anni.
2025-05-29 23:09:09,694 - INFO - joeynmt.training - Epoch  10, Step:   103100, Batch Loss:     1.681498, Batch Acc: 0.504615, Tokens per Sec:    17514, Lr: 0.000300
2025-05-29 23:09:13,030 - INFO - joeynmt.training - Epoch  10, Step:   103200, Batch Loss:     1.491960, Batch Acc: 0.504565, Tokens per Sec:    20098, Lr: 0.000300
2025-05-29 23:09:16,361 - INFO - joeynmt.training - Epoch  10, Step:   103300, Batch Loss:     1.660593, Batch Acc: 0.499828, Tokens per Sec:    21010, Lr: 0.000300
2025-05-29 23:09:19,705 - INFO - joeynmt.training - Epoch  10, Step:   103400, Batch Loss:     1.649101, Batch Acc: 0.504024, Tokens per Sec:    21223, Lr: 0.000300
2025-05-29 23:09:23,049 - INFO - joeynmt.training - Epoch  10, Step:   103500, Batch Loss:     1.664618, Batch Acc: 0.506730, Tokens per Sec:    20689, Lr: 0.000300
2025-05-29 23:09:23,049 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:09:23,049 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:09:31,391 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.85, acc:   0.53, generation: 8.3310[sec], evaluation: 0.0000[sec]
2025-05-29 23:09:31,405 - INFO - joeynmt.training - Example #0
2025-05-29 23:09:31,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:09:31,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:09:31,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'ri@@', 'dur@@', 're', 'che', 'l@@', '<unk>', 'inter@@', 'a', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ico', 'che', 'ha', 'av@@', 'uto', 'il', '4@@', '8@@', '0@@', '%', 'di', 'questi', 'due', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'av@@', 'uto', 'il', '4@@', '8@@', '%', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:09:31,406 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:09:31,406 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:09:31,406 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due diapositive per ridurre che l<unk> intera ghiaccio, che l<unk> artico che ha avuto il 480% di questi due milioni di anni che avevano avuto il 48% di cento.
2025-05-29 23:09:31,406 - INFO - joeynmt.training - Example #1
2025-05-29 23:09:31,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:09:31,407 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:09:31,407 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'la', 'prima', 'cosa', 'che', 'è', 'la', 'prima', 'cosa', 'che', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'p@@', 'op@@', 'ol@@', 'are', 'il', 'di@@', 'v@@', 'ario', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'sol@@', 'i@@', 'di@@', 'o', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'un', 'po@@', '<unk>', 'di', 'un', 'po@@', '<unk>', 'di', 'sol@@', 'ito', 'di', 'e', 'non', 'ci', 'sono', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', '.', '</s>']
2025-05-29 23:09:31,407 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:09:31,407 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:09:31,408 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza la prima cosa che è la prima cosa che è il Dicke del ghiaccio di ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di popolare il divario del ghiaccio di un po<unk> di un po<unk> di un po<unk> di un po<unk> di solidio di ghiaccio di un po<unk> di un po<unk> di solito di e non ci sono abbastanza forte.
2025-05-29 23:09:31,408 - INFO - joeynmt.training - Example #2
2025-05-29 23:09:31,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:09:31,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:09:31,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'inter@@', 'fac@@', 'cia', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:09:31,409 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:09:31,409 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:09:31,409 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> interfaccia artica, il cuore del nostro sistema climatico globale.
2025-05-29 23:09:31,409 - INFO - joeynmt.training - Example #3
2025-05-29 23:09:31,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:09:31,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:09:31,409 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sp@@', 'ost@@', 'a', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'l@@', 'ass@@', 'e@@', '.', '</s>']
2025-05-29 23:09:31,410 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:09:31,410 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:09:31,410 - INFO - joeynmt.training - 	Hypothesis: Si sposta in inverno e rilasse.
2025-05-29 23:09:31,410 - INFO - joeynmt.training - Example #4
2025-05-29 23:09:31,410 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:09:31,410 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:09:31,410 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 't@@', 'ore', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'f@@', 'es@@', 'a', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'un', 'cer@@', 'to', 'punto', 'di', 'vi@@', 'sta', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:09:31,411 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:09:31,411 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:09:31,411 - INFO - joeynmt.training - 	Hypothesis: La prossima ditore che vi mostrerò è una difesa di un disegno di un certo punto di vista che è successo negli ultimi 25 anni.
2025-05-29 23:09:34,747 - INFO - joeynmt.training - Epoch  10, Step:   103600, Batch Loss:     1.784104, Batch Acc: 0.503410, Tokens per Sec:    20980, Lr: 0.000300
2025-05-29 23:09:38,081 - INFO - joeynmt.training - Epoch  10, Step:   103700, Batch Loss:     1.724706, Batch Acc: 0.506003, Tokens per Sec:    21268, Lr: 0.000300
2025-05-29 23:09:41,412 - INFO - joeynmt.training - Epoch  10, Step:   103800, Batch Loss:     1.512686, Batch Acc: 0.506186, Tokens per Sec:    20794, Lr: 0.000300
2025-05-29 23:09:44,761 - INFO - joeynmt.training - Epoch  10, Step:   103900, Batch Loss:     1.546453, Batch Acc: 0.502818, Tokens per Sec:    21464, Lr: 0.000300
2025-05-29 23:09:48,138 - INFO - joeynmt.training - Epoch  10, Step:   104000, Batch Loss:     1.564992, Batch Acc: 0.500690, Tokens per Sec:    21251, Lr: 0.000300
2025-05-29 23:09:48,138 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:09:48,138 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:09:56,524 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.83, acc:   0.53, generation: 8.3743[sec], evaluation: 0.0000[sec]
2025-05-29 23:09:56,930 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/98500.ckpt
2025-05-29 23:09:56,956 - INFO - joeynmt.training - Example #0
2025-05-29 23:09:56,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:09:56,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:09:56,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'segu@@', 'enze', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'l@@', '<unk>', 'ar@@', 't@@', 'ic@@', 'olo', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'av@@', 'uto', 'per', 'il', '4@@', '0@@', '%', 'di', 'questi', 'due', 'anni', 'che', 'av@@', 'evano', 'l@@', '<unk>', '4@@', '0@@', '<unk>', '.', '</s>']
2025-05-29 23:09:56,957 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:09:56,957 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:09:56,957 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso che ho mostrato queste due diapositive per diapositive per conseguenze artici, che l<unk> articolo che ha avuto per tre milioni di anni che avevano avuto per il 40% di questi due anni che avevano l<unk> 40<unk> .
2025-05-29 23:09:56,957 - INFO - joeynmt.training - Example #1
2025-05-29 23:09:56,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:09:56,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:09:56,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'la', 'prima', 'cosa', 'che', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:09:56,958 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:09:56,958 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:09:56,958 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che la prima cosa che è il Dicke del ghiaccio che non è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 23:09:56,958 - INFO - joeynmt.training - Example #2
2025-05-29 23:09:56,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:09:56,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:09:56,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'l@@', '<unk>', 'or@@', 'ig@@', 'ine', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:09:56,959 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:09:56,959 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:09:56,959 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è l<unk> origine artico, il cuore del nostro sistema climatico globale.
2025-05-29 23:09:56,959 - INFO - joeynmt.training - Example #3
2025-05-29 23:09:56,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:09:56,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:09:56,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sp@@', 'ost@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'in', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 23:09:56,960 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:09:56,960 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:09:56,960 - INFO - joeynmt.training - 	Hypothesis: Si sposta in inverno, e si rivela in estate.
2025-05-29 23:09:56,960 - INFO - joeynmt.training - Example #4
2025-05-29 23:09:56,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:09:56,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:09:56,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pros@@', 'si@@', 'mo', 'di@@', 'f@@', 'es@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'sp@@', 'ec@@', 'ie', 'di', 'di@@', 'mostr@@', 'azione', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:09:56,961 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:09:56,961 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:09:56,961 - INFO - joeynmt.training - 	Hypothesis: Il prossimo difesa che vi mostrerò è una specie di dimostrazione che è successo negli ultimi 25 anni.
2025-05-29 23:10:00,365 - INFO - joeynmt.training - Epoch  10, Step:   104100, Batch Loss:     1.681337, Batch Acc: 0.508399, Tokens per Sec:    19223, Lr: 0.000300
2025-05-29 23:10:03,699 - INFO - joeynmt.training - Epoch  10, Step:   104200, Batch Loss:     1.427471, Batch Acc: 0.499449, Tokens per Sec:    20685, Lr: 0.000300
2025-05-29 23:10:07,037 - INFO - joeynmt.training - Epoch  10, Step:   104300, Batch Loss:     1.625432, Batch Acc: 0.498522, Tokens per Sec:    21190, Lr: 0.000300
2025-05-29 23:10:10,346 - INFO - joeynmt.training - Epoch  10, Step:   104400, Batch Loss:     1.767558, Batch Acc: 0.496720, Tokens per Sec:    21382, Lr: 0.000300
2025-05-29 23:10:13,658 - INFO - joeynmt.training - Epoch  10, Step:   104500, Batch Loss:     1.664416, Batch Acc: 0.509820, Tokens per Sec:    21822, Lr: 0.000300
2025-05-29 23:10:13,658 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:10:13,658 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:10:21,853 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.83, acc:   0.53, generation: 8.1839[sec], evaluation: 0.0000[sec]
2025-05-29 23:10:22,309 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/102000.ckpt
2025-05-29 23:10:22,418 - INFO - joeynmt.training - Example #0
2025-05-29 23:10:22,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:10:22,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:10:22,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'abbiamo', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'con@@', 'dur@@', 're', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'icol@@', 'o@@', ',', 'che', 'ha', 'chiam@@', 'ato', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'icol@@', 't@@', 'ica', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'questi', 'due', 'milioni', 'di', 'anni', 'di', 'questi', '4@@', '8', 'pa@@', 'esi', 'che', 'av@@', 'evano', 'il', '4@@', '0', 'per', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:10:22,420 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:10:22,420 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:10:22,420 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso abbiamo mostrato queste due diapositive per condurre che la ghiaccio articolo, che ha chiamato la ghiaccio articoltica per tre milioni di anni di questi due milioni di anni di questi 48 paesi che avevano il 40 per cento.
2025-05-29 23:10:22,420 - INFO - joeynmt.training - Example #1
2025-05-29 23:10:22,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:10:22,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:10:22,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:10:22,421 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:10:22,421 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:10:22,421 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte di questo particolare è la causa di questo particolare è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio.
2025-05-29 23:10:22,421 - INFO - joeynmt.training - Example #2
2025-05-29 23:10:22,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:10:22,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:10:22,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:10:22,422 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:10:22,422 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:10:22,422 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa artica, il cuore artico del nostro sistema climatico globale.
2025-05-29 23:10:22,422 - INFO - joeynmt.training - Example #3
2025-05-29 23:10:22,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:10:22,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:10:22,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sp@@', 'ost@@', 'a', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'est@@', 'ate', 'in', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 23:10:22,422 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:10:22,423 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:10:22,423 - INFO - joeynmt.training - 	Hypothesis: Si sposta in inverno e in inverno e l<unk> estate in estate.
2025-05-29 23:10:22,423 - INFO - joeynmt.training - Example #4
2025-05-29 23:10:22,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:10:22,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:10:22,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'delle', 'cose', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:10:22,423 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:10:22,423 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:10:22,424 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una delle cose che vi mostrerò è successo negli ultimi 25 anni.
2025-05-29 23:10:25,833 - INFO - joeynmt.training - Epoch  10, Step:   104600, Batch Loss:     1.674231, Batch Acc: 0.496663, Tokens per Sec:    18341, Lr: 0.000300
2025-05-29 23:10:29,217 - INFO - joeynmt.training - Epoch  10, Step:   104700, Batch Loss:     1.506958, Batch Acc: 0.503113, Tokens per Sec:    21220, Lr: 0.000300
2025-05-29 23:10:32,588 - INFO - joeynmt.training - Epoch  10, Step:   104800, Batch Loss:     1.552473, Batch Acc: 0.504347, Tokens per Sec:    21156, Lr: 0.000300
2025-05-29 23:10:35,961 - INFO - joeynmt.training - Epoch  10, Step:   104900, Batch Loss:     1.739735, Batch Acc: 0.502251, Tokens per Sec:    21479, Lr: 0.000300
2025-05-29 23:10:39,330 - INFO - joeynmt.training - Epoch  10, Step:   105000, Batch Loss:     1.599425, Batch Acc: 0.504860, Tokens per Sec:    20799, Lr: 0.000300
2025-05-29 23:10:39,331 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:10:39,331 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:10:48,933 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.80, acc:   0.53, generation: 9.5902[sec], evaluation: 0.0000[sec]
2025-05-29 23:10:48,934 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:10:49,534 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/101000.ckpt
2025-05-29 23:10:49,561 - INFO - joeynmt.training - Example #0
2025-05-29 23:10:49,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:10:49,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:10:49,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've@@', ',', 'per', 'ri@@', 'dur@@', 're', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'che', 'ha', 'in@@', 'contr@@', 'ato', 'i', 'tr@@', 'e@@', ',', 'che', 'ha', 'fatto', 'un', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', 'ulti@@', 'mi', 'tre', 'milioni', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:10:49,563 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:10:49,563 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:10:49,563 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive, per ridurre che la ghiaccia, che la ghiaccia, che ha incontrato i tre, che ha fatto un 480 per cento di questi ultimi tre milioni di anni di 40 per cento di cento.
2025-05-29 23:10:49,563 - INFO - joeynmt.training - Example #1
2025-05-29 23:10:49,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:10:49,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:10:49,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'problema', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'che', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:10:49,564 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:10:49,564 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:10:49,564 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo problema di questo particolare è che non è la Dicke non è la Dicke del ghiaccio del ghiaccio.
2025-05-29 23:10:49,564 - INFO - joeynmt.training - Example #2
2025-05-29 23:10:49,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:10:49,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:10:49,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', 'io', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'nostro', 'sistema', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:10:49,565 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:10:49,565 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:10:49,565 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiacciaio di ghiaccia, il nostro sistema globale.
2025-05-29 23:10:49,565 - INFO - joeynmt.training - Example #3
2025-05-29 23:10:49,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:10:49,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:10:49,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'es@@', 'ce', 'a', 'sc@@', 'u@@', 'ola', 'e', 't@@', 'ar@@', 'di@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 23:10:49,566 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:10:49,566 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:10:49,566 - INFO - joeynmt.training - 	Hypothesis: Si riesce a scuola e tardi, e si rivela estate.
2025-05-29 23:10:49,566 - INFO - joeynmt.training - Example #4
2025-05-29 23:10:49,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:10:49,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:10:49,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'sp@@', 'ec@@', 'ie', 'di', 'qu@@', 'ant@@', 'ità', 'di', 'cui', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:10:49,567 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:10:49,567 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:10:49,567 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una specie di quantità di cui è successo negli ultimi 25 anni.
2025-05-29 23:10:52,928 - INFO - joeynmt.training - Epoch  10, Step:   105100, Batch Loss:     1.587655, Batch Acc: 0.509338, Tokens per Sec:    17241, Lr: 0.000300
2025-05-29 23:10:56,296 - INFO - joeynmt.training - Epoch  10, Step:   105200, Batch Loss:     1.494068, Batch Acc: 0.505328, Tokens per Sec:    21013, Lr: 0.000300
2025-05-29 23:10:59,642 - INFO - joeynmt.training - Epoch  10, Step:   105300, Batch Loss:     1.724560, Batch Acc: 0.503207, Tokens per Sec:    21020, Lr: 0.000300
2025-05-29 23:11:02,991 - INFO - joeynmt.training - Epoch  10, Step:   105400, Batch Loss:     1.718590, Batch Acc: 0.499986, Tokens per Sec:    21492, Lr: 0.000300
2025-05-29 23:11:06,339 - INFO - joeynmt.training - Epoch  10, Step:   105500, Batch Loss:     1.693193, Batch Acc: 0.504662, Tokens per Sec:    21117, Lr: 0.000300
2025-05-29 23:11:06,340 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:11:06,340 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:11:14,660 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.82, acc:   0.53, generation: 8.3125[sec], evaluation: 0.0000[sec]
2025-05-29 23:11:14,998 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/104500.ckpt
2025-05-29 23:11:15,022 - INFO - joeynmt.training - Example #0
2025-05-29 23:11:15,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:11:15,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:11:15,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'apos@@', 'iti@@', 've@@', ',', 'per', 'sc@@', 'or@@', 'r@@', 'ere', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ico', 'che', 'ha', 'av@@', 'uto', 'tre', 'milioni', 'di', 'anni', 'la', 'più', 'grande', 'del', '4@@', '8@@', '%', 'di', 'anni', 'ha', 'av@@', 'uto', 'un', '4@@', '8@@', '%', 'di', '1@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'di', 'questi', 'sono', 'c@@', 'r@@', 'oll@@', 'i', 'di', '4@@', '0', 'per@@', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:11:15,023 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:11:15,023 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:11:15,023 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato queste due diapositive, per scorrere che la ghiaccio artico che la ghiaccio artico che ha avuto tre milioni di anni la più grande del 48% di anni ha avuto un 48% di 10% del 40% di questi sono crolli di 40 percento.
2025-05-29 23:11:15,023 - INFO - joeynmt.training - Example #1
2025-05-29 23:11:15,024 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:11:15,024 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:11:15,024 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'p@@', 'op@@', 'ol@@', 'azione', 'di', 'questo', 'spe@@', 'ci@@', 'ale', 'di', 'questo', 'part@@', 'icol@@', 'are', 'è', 'che', 'non', 'è', 'il', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'questo', 'problema', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'g@@', 'over@@', 'n@@', 'ati@@', 'vo', 'di', 'questo', 'problema', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'tipo', 'di', 'probl@@', 'em@@', 'a@@', '.', '</s>']
2025-05-29 23:11:15,024 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:11:15,024 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:11:15,024 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di popolazione di questo speciale di questo particolare è che non è il Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio del ghiaccio di questo problema di ghiaccio che non è abbastanza forte di governativo di questo problema di ghiaccio che non è abbastanza forte di questo tipo di problema.
2025-05-29 23:11:15,024 - INFO - joeynmt.training - Example #2
2025-05-29 23:11:15,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:11:15,025 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:11:15,025 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'g@@', 'hi@@', 'ac@@', 'cia', 'ar@@', 't@@', 'ico', 'il', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:11:15,025 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:11:15,025 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:11:15,025 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa della ghiaccia artico il nostro climatico globale.
2025-05-29 23:11:15,025 - INFO - joeynmt.training - Example #3
2025-05-29 23:11:15,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:11:15,025 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:11:15,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sp@@', 'ost@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', ',', 'e', 'si', 'ri@@', 'vel@@', 'a', 'il', 'm@@', 'oti@@', 'vo', 'per', 'cui', 'si', 'trov@@', 'a', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:11:15,026 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:11:15,026 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:11:15,026 - INFO - joeynmt.training - 	Hypothesis: Si sposta in inverno, e si rivela il motivo per cui si trova in inverno.
2025-05-29 23:11:15,026 - INFO - joeynmt.training - Example #4
2025-05-29 23:11:15,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:11:15,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:11:15,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:11:15,027 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:11:15,027 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:11:15,027 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una dimostrazione di un disegno di quale è successo negli ultimi 25 anni.
2025-05-29 23:11:18,325 - INFO - joeynmt.training - Epoch  10, Step:   105600, Batch Loss:     1.536706, Batch Acc: 0.508134, Tokens per Sec:    19007, Lr: 0.000300
2025-05-29 23:11:21,661 - INFO - joeynmt.training - Epoch  10, Step:   105700, Batch Loss:     1.571937, Batch Acc: 0.508106, Tokens per Sec:    21159, Lr: 0.000300
2025-05-29 23:11:24,987 - INFO - joeynmt.training - Epoch  10, Step:   105800, Batch Loss:     1.599416, Batch Acc: 0.504725, Tokens per Sec:    21161, Lr: 0.000300
2025-05-29 23:11:28,298 - INFO - joeynmt.training - Epoch  10, Step:   105900, Batch Loss:     1.368093, Batch Acc: 0.502956, Tokens per Sec:    21110, Lr: 0.000300
2025-05-29 23:11:31,594 - INFO - joeynmt.training - Epoch  10, Step:   106000, Batch Loss:     1.563419, Batch Acc: 0.503617, Tokens per Sec:    21519, Lr: 0.000300
2025-05-29 23:11:31,595 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:11:31,595 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:11:39,556 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.81, acc:   0.53, generation: 7.9505[sec], evaluation: 0.0000[sec]
2025-05-29 23:11:39,918 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/101500.ckpt
2025-05-29 23:11:39,942 - INFO - joeynmt.training - Example #0
2025-05-29 23:11:39,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:11:39,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:11:39,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'li@@', 'de@@', ',', 'per', 'con@@', 'si@@', 'der@@', 'are', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'ate', 'ar@@', 't@@', 'ic@@', 'i@@', ',', 'che', 'è', 'stato', 'in@@', 'contr@@', 'o', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'ha', 'in@@', 'segn@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'ha', 'fatto', 'è', 'c@@', 'aus@@', 'ato', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'del', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'di', 's@@', 'ott@@', 'o@@', '.', '</s>']
2025-05-29 23:11:39,943 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:11:39,943 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:11:39,943 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due slide, per considerare che le ghiacciate artici, che è stato incontro tre milioni di anni di anni che ha insegnato per tre milioni di anni di anni che ha fatto è causato il 40 per cento del 40 per cento di anni di sotto.
2025-05-29 23:11:39,943 - INFO - joeynmt.training - Example #1
2025-05-29 23:11:39,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:11:39,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:11:39,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'stato', 'in@@', 't@@', 'eg@@', 'r@@', 'ato', 'a', 'questo', 'problema', 'spe@@', 'ci@@', 'ale', 'per', 'il', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.', '</s>']
2025-05-29 23:11:39,944 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:11:39,944 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:11:39,944 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte, la prima cosa che è stato integrato a questo problema speciale per il ghiaccio di ghiaccio.
2025-05-29 23:11:39,944 - INFO - joeynmt.training - Example #2
2025-05-29 23:11:39,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:11:39,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:11:39,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sen@@', 'so', 'di', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'della', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'mon@@', 'di@@', 'al@@', 'e@@', '.', '</s>']
2025-05-29 23:11:39,945 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:11:39,945 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:11:39,945 - INFO - joeynmt.training - 	Hypothesis: In un senso di senso è la causa della ghiaccia, il cuore mondiale.
2025-05-29 23:11:39,945 - INFO - joeynmt.training - Example #3
2025-05-29 23:11:39,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:11:39,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:11:39,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'in', 'in@@', 'ver@@', 'no', 'e', 'in', 'in@@', 'ver@@', 'no@@', '.', '</s>']
2025-05-29 23:11:39,945 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:11:39,946 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:11:39,946 - INFO - joeynmt.training - 	Hypothesis: Sta crescita in inverno e in inverno.
2025-05-29 23:11:39,946 - INFO - joeynmt.training - Example #4
2025-05-29 23:11:39,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:11:39,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:11:39,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'sp@@', 'ec@@', 'ie', 'di', 'di@@', 'mostr@@', 'azione', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:11:39,946 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:11:39,946 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:11:39,947 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una specie di dimostrazione che è successo negli ultimi 25 anni.
2025-05-29 23:11:43,240 - INFO - joeynmt.training - Epoch  10, Step:   106100, Batch Loss:     1.611705, Batch Acc: 0.498613, Tokens per Sec:    19182, Lr: 0.000300
2025-05-29 23:11:46,528 - INFO - joeynmt.training - Epoch  10, Step:   106200, Batch Loss:     1.597481, Batch Acc: 0.504886, Tokens per Sec:    21727, Lr: 0.000300
2025-05-29 23:11:49,810 - INFO - joeynmt.training - Epoch  10, Step:   106300, Batch Loss:     1.673637, Batch Acc: 0.498575, Tokens per Sec:    21822, Lr: 0.000300
2025-05-29 23:11:53,098 - INFO - joeynmt.training - Epoch  10, Step:   106400, Batch Loss:     1.571054, Batch Acc: 0.501993, Tokens per Sec:    21829, Lr: 0.000300
2025-05-29 23:11:56,375 - INFO - joeynmt.training - Epoch  10, Step:   106500, Batch Loss:     1.601540, Batch Acc: 0.504807, Tokens per Sec:    21683, Lr: 0.000300
2025-05-29 23:11:56,376 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:11:56,376 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:12:03,806 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.82, acc:   0.53, generation: 7.4231[sec], evaluation: 0.0000[sec]
2025-05-29 23:12:04,274 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/104000.ckpt
2025-05-29 23:12:04,298 - INFO - joeynmt.training - Example #0
2025-05-29 23:12:04,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:12:04,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:12:04,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'li@@', 'de@@', ',', 'per', 'sc@@', 'o@@', 'pr@@', 'ire', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'che', 'è', 'stato', 'in@@', 'tr@@', 'ap@@', 'pol@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'si', 'è', 'ri@@', 'vel@@', 'ato', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'che', 'è', 'stato', 'in@@', 'cor@@', 'aggi@@', 'ato', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'anni', 'di', 'pi@@', 'ù@@', '.', '</s>']
2025-05-29 23:12:04,299 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:12:04,299 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:12:04,299 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso ho mostrato questi due slide, per scoprire che le ghiaccio artico, che è stato intrappolato per tre milioni di anni di anni che si è rivelato per tre milioni di anni di anni che è stato incoraggiato per il 40 per cento di anni di 40 per cento di anni di più.
2025-05-29 23:12:04,299 - INFO - joeynmt.training - Example #1
2025-05-29 23:12:04,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:12:04,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:12:04,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'ti@@', ',', 'la', 'prima', 'cosa', 'che', 'è', 'la', 'prima', 'cosa', 'che', 'è', 'che', 'mostr@@', 'a', 'questo', 'part@@', 'icol@@', 'are', 'è', 'che', 'non', 'è', 'la', 'D@@', 'ic@@', 'ke', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'del', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'e', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'che', 'non', 'si', 'può', 'essere', 'un', 'po@@', '<unk>', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'non', 'si', 'può', 'essere', 'un', 'po@@', '<unk>', 'di', 'g@@', 'hi@@', 'ac@@', 'cio', 'che', 'è', 'stato', 'in@@', 'contr@@', 'ato', 'per', 'la', 'prima', 'vol@@', 't@@', 'a@@', '.', '</s>']
2025-05-29 23:12:04,300 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:12:04,300 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:12:04,300 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forti, la prima cosa che è la prima cosa che è che mostra questo particolare è che non è la Dicke del ghiaccio del ghiaccio del ghiaccio del ghiaccio di ghiaccio di ghiaccio, e non è abbastanza che non si può essere un po<unk> di ghiaccio che non si può essere un po<unk> di ghiaccio che è stato incontrato per la prima volta.
2025-05-29 23:12:04,300 - INFO - joeynmt.training - Example #2
2025-05-29 23:12:04,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:12:04,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:12:04,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'il', 'cu@@', 'ore', 'd@@', 'ell@@', '<unk>', 'al@@', 'to', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 23:12:04,301 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:12:04,301 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:12:04,301 - INFO - joeynmt.training - 	Hypothesis: In certo senso è la causa artica, il cuore dell<unk> alto del nostro sistema climatico.
2025-05-29 23:12:04,301 - INFO - joeynmt.training - Example #3
2025-05-29 23:12:04,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:12:04,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:12:04,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'ri@@', 'vel@@', 'a', 'e', 'si', 'ri@@', 'vol@@', 'u@@', 'zion@@', 'e@@', '.', '</s>']
2025-05-29 23:12:04,302 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:12:04,302 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:12:04,302 - INFO - joeynmt.training - 	Hypothesis: Si rivela e si rivoluzione.
2025-05-29 23:12:04,302 - INFO - joeynmt.training - Example #4
2025-05-29 23:12:04,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:12:04,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:12:04,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'di@@', 'apos@@', 'iti@@', 'va', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'mostr@@', 'azione', 'di', 'un', 'di@@', 'seg@@', 'no', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:12:04,303 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:12:04,303 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:12:04,303 - INFO - joeynmt.training - 	Hypothesis: La diapositiva che vi mostrerò è una dimostrazione di un disegno di quale è successo negli ultimi 25 anni.
2025-05-29 23:12:07,586 - INFO - joeynmt.training - Epoch  10, Step:   106600, Batch Loss:     1.655287, Batch Acc: 0.501828, Tokens per Sec:    18307, Lr: 0.000300
2025-05-29 23:12:10,905 - INFO - joeynmt.training - Epoch  10, Step:   106700, Batch Loss:     1.583482, Batch Acc: 0.506393, Tokens per Sec:    21808, Lr: 0.000300
2025-05-29 23:12:14,278 - INFO - joeynmt.training - Epoch  10, Step:   106800, Batch Loss:     1.570826, Batch Acc: 0.502982, Tokens per Sec:    21227, Lr: 0.000300
2025-05-29 23:12:17,649 - INFO - joeynmt.training - Epoch  10, Step:   106900, Batch Loss:     1.610185, Batch Acc: 0.501993, Tokens per Sec:    21295, Lr: 0.000300
2025-05-29 23:12:21,010 - INFO - joeynmt.training - Epoch  10, Step:   107000, Batch Loss:     1.677362, Batch Acc: 0.502985, Tokens per Sec:    21190, Lr: 0.000300
2025-05-29 23:12:21,010 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:12:21,010 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:12:28,802 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.80, acc:   0.53, generation: 7.7815[sec], evaluation: 0.0000[sec]
2025-05-29 23:12:29,209 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/105500.ckpt
2025-05-29 23:12:29,235 - INFO - joeynmt.training - Example #0
2025-05-29 23:12:29,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't@@', ',', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en@@', ',', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e@@', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Milli@@', 'onen', 'Jahre', 'die', 'Gr@@', 'ö@@', 's@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'h@@', 'att@@', 'e@@', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:12:29,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', "'@@", 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ic@@', 'a@@', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'si@@', 'oni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i@@', ',', 'si', 'è', 'ri@@', 'str@@', 'et@@', 'ta', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 23:12:29,236 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '<unk>', 'anno', 'sc@@', 'or@@', 'so@@', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 's@@', 'li@@', 'de@@', ',', 'per', 'ri@@', 'dur@@', 're', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'le', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', ',', 'che', 'è', 'stato', 'in@@', 'vent@@', 'ato', 'per', 'il', '4@@', '8', 'st@@', 'at@@', 'o@@', ',', 'il', '4@@', '8@@', ',', 'per', '4@@', '8', 'per@@', 'c@@', 'ento', 'degli', 'St@@', 'ati', 'Un@@', 'iti', 'per', '4@@', '0', 'per@@', 'c@@', 'ento', 'del', '4@@', '0', 'per@@', 'c@@', 'ento', 'del', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ent@@', 'o@@', '.', '</s>']
2025-05-29 23:12:29,237 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:12:29,237 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 23:12:29,237 - INFO - joeynmt.training - 	Hypothesis: L<unk> anno scorso, ho mostrato questi due slide, per ridurre il 40 percento di ghiaccio, che le ghiaccio, che è stato inventato per il 48 stato, il 48, per 48 percento degli Stati Uniti per 40 percento del 40 percento del 40 percento di cento.
2025-05-29 23:12:29,237 - INFO - joeynmt.training - Example #1
2025-05-29 23:12:29,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'üc@@', 'kt', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'ha@@', 'f@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Probl@@', 'em@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ic@@', 'ke', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't@@', '.']
2025-05-29 23:12:29,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'a@@', 'via', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'ac@@', 'ci@@', 'o@@', '.']
2025-05-29 23:12:29,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'prima', 'cosa', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'probl@@', 'em@@', 'a@@', ',', 'perché', 'non', 'è', 'il', 'D@@', 'ic@@', 'k@@', '.', '</s>']
2025-05-29 23:12:29,238 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:12:29,238 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 23:12:29,238 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la prima cosa che non è abbastanza forte di questo problema, perché non è il Dick.
2025-05-29 23:12:29,238 - INFO - joeynmt.training - Example #2
2025-05-29 23:12:29,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'm@@', 'as@@', 'yst@@', 'em@@', 's@@', '.']
2025-05-29 23:12:29,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'ar@@', 't@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 'sen@@', 'so@@', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'al@@', 'e@@', '.']
2025-05-29 23:12:29,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'ac@@', 'cio', 'ar@@', 't@@', 'ic@@', 'o@@', ',', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 23:12:29,239 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:12:29,239 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 23:12:29,239 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccio artico, il cuore artico.
2025-05-29 23:12:29,239 - INFO - joeynmt.training - Example #3
2025-05-29 23:12:29,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:12:29,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'an@@', 'de', 'd@@', "'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', 'd@@', "'@@", 'est@@', 'at@@', 'e@@', '.']
2025-05-29 23:12:29,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'cres@@', 'c@@', 'ita', 'in', 'in@@', 'ver@@', 'no', 'e', 'ri@@', 'p@@', 'et@@', 'ere', 'in', 'in@@', 'ver@@', 'no', 'e', 'l@@', '<unk>', 'est@@', 'at@@', 'e@@', '.', '</s>']
2025-05-29 23:12:29,240 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:12:29,240 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 23:12:29,240 - INFO - joeynmt.training - 	Hypothesis: Sta crescita in inverno e ripetere in inverno e l<unk> estate.
2025-05-29 23:12:29,240 - INFO - joeynmt.training - Example #4
2025-05-29 23:12:29,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e@@', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passiert', 'ist@@', '.']
2025-05-29 23:12:29,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sar@@', 'à', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.']
2025-05-29 23:12:29,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'co', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'delle', 'di@@', 'men@@', 'si@@', 'oni', 'di', 'qu@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'an@@', 'ni@@', '.', '</s>']
2025-05-29 23:12:29,241 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:12:29,241 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 23:12:29,241 - INFO - joeynmt.training - 	Hypothesis: La prossima dico che vi mostrerò è una delle dimensioni di quale è successo negli ultimi 25 anni.
2025-05-29 23:12:31,243 - INFO - joeynmt.training - Epoch  10: total training loss 17560.77
2025-05-29 23:12:31,243 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-29 23:12:31,243 - INFO - joeynmt.training - Best validation result (greedy) at step   105000:   4.80 ppl.
2025-05-29 23:12:31,278 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 23:12:31,329 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 23:12:31,421 - INFO - joeynmt.helpers - Load model from /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/105000.ckpt.
2025-05-29 23:12:31,440 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	loss_function=None)
2025-05-29 23:12:31,450 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-29 23:12:31,450 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:12:31,450 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:13:13,652 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 42.1971[sec], evaluation: 0.0000[sec]
2025-05-29 23:13:13,658 - INFO - joeynmt.prediction - Translations saved to: /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/00105000.hyps.dev.
2025-05-29 23:13:13,658 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-29 23:13:13,659 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:13:13,659 - INFO - joeynmt.prediction - Predicting 1567 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:14:15,465 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 61.7995[sec], evaluation: 0.0000[sec]
2025-05-29 23:14:15,471 - INFO - joeynmt.prediction - Translations saved to: /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/00105000.hyps.test.
