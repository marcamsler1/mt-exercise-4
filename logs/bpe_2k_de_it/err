2025-05-27 19:02:17,084 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                           cfg.name : bpe_2k_de_it
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                     cfg.data.train : data/bpe_2k/train.bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                       cfg.data.dev : data/bpe_2k/dev.bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                      cfg.data.test : data/bpe_2k/test.bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : subword_models/2k/bpe_2k.joint_vocab
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : subword_models/2k/bpe_2k.codes
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-27 19:02:17,085 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/bpe_2k_de_it
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-27 19:02:17,086 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-27 19:02:17,087 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-27 19:02:17,087 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-27 19:02:17,087 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-27 19:02:17,087 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-27 19:02:17,225 - INFO - joeynmt.data - Building tokenizer...
2025-05-27 19:02:17,236 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 19:02:17,236 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-27 19:02:17,236 - INFO - joeynmt.data - Loading train set...
2025-05-27 19:02:17,426 - INFO - joeynmt.data - Building vocabulary...
2025-05-27 19:02:17,459 - INFO - joeynmt.data - Loading dev set...
2025-05-27 19:02:17,464 - INFO - joeynmt.data - Loading test set...
2025-05-27 19:02:17,470 - INFO - joeynmt.data - Data loaded.
2025-05-27 19:02:17,470 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 19:02:17,470 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=923, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 19:02:17,470 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1567, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-27 19:02:17,471 - INFO - joeynmt.data - First training example:
	[SRC] J@@ @@@ @ etzt er@@ @@@ @ inn@@ @@@ @ ern Sie sich , wir unter@@ @@@ @ su@@ @@@ @ chen G@@ @@@ @ ene .
	[TRG] R@@ @@@ @ ic@@ @@@ @ ord@@ @@@ @ ate che noi an@@ @@@ @ al@@ @@@ @ i@@ @@@ @ z@@ @@@ @ zi@@ @@@ @ amo i gen@@ @@@ @ i .
2025-05-27 19:02:17,471 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ! (5) # (6) $ (7) % (8) &#9@@ (9) &@@
2025-05-27 19:02:17,471 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ! (5) # (6) $ (7) % (8) &#9@@ (9) &@@
2025-05-27 19:02:17,471 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2000
2025-05-27 19:02:17,471 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2000
2025-05-27 19:02:17,478 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-27 19:02:17,547 - INFO - joeynmt.model - Enc-dec model built.
2025-05-27 19:02:17,555 - INFO - joeynmt.model - Total params: 3411200
2025-05-27 19:02:17,556 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-27 19:02:19,714 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
/home/user/amsler/joeynmt/joeynmt/training.py:117: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(enabled=self.fp16)
2025-05-27 19:02:19,715 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-27 19:02:19,716 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-27 19:02:19,716 - INFO - joeynmt.training - EPOCH 1
2025-05-27 19:02:24,072 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     2.375705, Batch Acc: 0.431204, Tokens per Sec:    18396, Lr: 0.000300
2025-05-27 19:02:27,460 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.060086, Batch Acc: 0.479482, Tokens per Sec:    23769, Lr: 0.000300
2025-05-27 19:02:30,860 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.021719, Batch Acc: 0.493525, Tokens per Sec:    23355, Lr: 0.000300
2025-05-27 19:02:34,250 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.171319, Batch Acc: 0.495307, Tokens per Sec:    22977, Lr: 0.000300
2025-05-27 19:02:37,673 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.043835, Batch Acc: 0.498460, Tokens per Sec:    23345, Lr: 0.000300
2025-05-27 19:02:37,674 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:02:37,675 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:30, 29.38it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:20, 44.15it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:19, 44.48it/s]Predicting...:   6%|▌         | 56/923 [00:01<00:16, 51.42it/s]Predicting...:   8%|▊         | 72/923 [00:01<00:16, 51.74it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:14, 58.10it/s]Predicting...:  11%|█▏        | 104/923 [00:02<00:15, 52.32it/s]Predicting...:  13%|█▎        | 121/923 [00:02<00:11, 67.34it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 44.12it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 46.78it/s]Predicting...:  17%|█▋        | 160/923 [00:03<00:14, 51.21it/s]Predicting...:  20%|██        | 185/923 [00:03<00:12, 59.62it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:12, 58.60it/s]Predicting...:  23%|██▎       | 211/923 [00:04<00:12, 56.05it/s]Predicting...:  24%|██▍       | 224/923 [00:04<00:12, 57.00it/s]Predicting...:  25%|██▌       | 235/923 [00:04<00:13, 51.15it/s]Predicting...:  27%|██▋       | 249/923 [00:04<00:11, 56.63it/s]Predicting...:  28%|██▊       | 258/923 [00:05<00:18, 35.93it/s]Predicting...:  29%|██▉       | 267/923 [00:05<00:18, 35.61it/s]Predicting...:  30%|███       | 277/923 [00:05<00:16, 38.38it/s]Predicting...:  31%|███▏      | 289/923 [00:06<00:18, 34.05it/s]Predicting...:  33%|███▎      | 302/923 [00:06<00:15, 39.58it/s]Predicting...:  34%|███▍      | 314/923 [00:06<00:16, 35.91it/s]Predicting...:  35%|███▌      | 327/923 [00:07<00:14, 41.30it/s]Predicting...:  37%|███▋      | 337/923 [00:07<00:13, 43.17it/s]Predicting...:  38%|███▊      | 347/923 [00:07<00:17, 33.87it/s]Predicting...:  39%|███▉      | 361/923 [00:07<00:14, 38.54it/s]Predicting...:  41%|████      | 379/923 [00:08<00:11, 47.71it/s]Predicting...:  43%|████▎     | 393/923 [00:08<00:10, 48.46it/s]Predicting...:  44%|████▍     | 408/923 [00:08<00:09, 54.84it/s]Predicting...:  46%|████▌     | 424/923 [00:09<00:11, 44.24it/s]Predicting...:  48%|████▊     | 441/923 [00:09<00:10, 46.34it/s]Predicting...:  49%|████▉     | 455/923 [00:09<00:10, 45.34it/s]Predicting...:  51%|█████     | 469/923 [00:10<00:10, 44.90it/s]Predicting...:  52%|█████▏    | 480/923 [00:10<00:09, 46.38it/s]Predicting...:  54%|█████▎    | 494/923 [00:10<00:09, 45.35it/s]Predicting...:  54%|█████▍    | 503/923 [00:10<00:09, 44.87it/s]Predicting...:  56%|█████▌    | 517/923 [00:11<00:09, 44.35it/s]Predicting...:  58%|█████▊    | 531/923 [00:11<00:08, 43.77it/s]Predicting...:  59%|█████▊    | 540/923 [00:11<00:08, 44.14it/s]Predicting...:  59%|█████▉    | 548/923 [00:12<00:10, 35.37it/s]Predicting...:  60%|██████    | 556/923 [00:12<00:15, 24.37it/s]Predicting...:  62%|██████▏   | 568/923 [00:13<00:13, 27.27it/s]Predicting...:  63%|██████▎   | 580/923 [00:13<00:11, 29.03it/s]Predicting...:  64%|██████▎   | 587/923 [00:14<00:16, 20.81it/s]Predicting...:  65%|██████▍   | 596/923 [00:14<00:13, 24.36it/s]Predicting...:  66%|██████▌   | 605/923 [00:14<00:13, 24.10it/s]Predicting...:  67%|██████▋   | 618/923 [00:15<00:11, 27.70it/s]Predicting...:  68%|██████▊   | 630/923 [00:15<00:09, 30.90it/s]Predicting...:  69%|██████▉   | 639/923 [00:15<00:08, 33.67it/s]Predicting...:  70%|███████   | 647/923 [00:15<00:09, 29.23it/s]Predicting...:  71%|███████   | 653/923 [00:16<00:09, 29.34it/s]Predicting...:  72%|███████▏  | 661/923 [00:16<00:09, 26.45it/s]Predicting...:  73%|███████▎  | 671/923 [00:17<00:10, 24.05it/s]Predicting...:  73%|███████▎  | 678/923 [00:17<00:10, 22.40it/s]Predicting...:  74%|███████▍  | 687/923 [00:17<00:10, 22.71it/s]Predicting...:  75%|███████▌  | 696/923 [00:18<00:10, 22.53it/s]Predicting...:  77%|███████▋  | 708/923 [00:18<00:08, 25.58it/s]Predicting...:  78%|███████▊  | 717/923 [00:19<00:09, 21.73it/s]Predicting...:  79%|███████▉  | 729/923 [00:19<00:07, 24.75it/s]Predicting...:  80%|████████  | 742/923 [00:19<00:06, 29.66it/s]Predicting...:  81%|████████  | 749/923 [00:20<00:08, 21.12it/s]Predicting...:  82%|████████▏ | 759/923 [00:20<00:06, 25.37it/s]Predicting...:  84%|████████▍ | 774/923 [00:21<00:04, 30.63it/s]Predicting...:  85%|████████▌ | 786/923 [00:21<00:03, 35.65it/s]Predicting...:  87%|████████▋ | 800/923 [00:21<00:02, 42.55it/s]Predicting...:  88%|████████▊ | 815/923 [00:21<00:02, 52.99it/s]Predicting...:  90%|████████▉ | 827/923 [00:21<00:01, 50.64it/s]Predicting...:  90%|█████████ | 835/923 [00:22<00:02, 29.57it/s]Predicting...:  92%|█████████▏| 850/923 [00:22<00:01, 37.47it/s]Predicting...:  93%|█████████▎| 862/923 [00:23<00:01, 34.86it/s]Predicting...:  95%|█████████▌| 878/923 [00:23<00:01, 40.93it/s]Predicting...:  97%|█████████▋| 892/923 [00:23<00:00, 47.22it/s]Predicting...:  98%|█████████▊| 908/923 [00:23<00:00, 55.99it/s]Predicting...: 100%|██████████| 923/923 [00:23<00:00, 64.43it/s]Predicting...: 100%|██████████| 923/923 [00:23<00:00, 38.53it/s]
2025-05-27 19:03:01,651 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.30, acc:   0.50, generation: 23.9608[sec], evaluation: 0.0000[sec]
2025-05-27 19:03:01,652 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:03:02,128 - INFO - joeynmt.training - Example #0
2025-05-27 19:03:02,130 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:03:02,130 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:03:02,130 - INFO - joeynmt.training - 	Hypothesis: E è è la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la e .
2025-05-27 19:03:02,130 - INFO - joeynmt.training - Example #1
2025-05-27 19:03:02,131 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:03:02,131 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:03:02,132 - INFO - joeynmt.training - 	Hypothesis: E è è è è è la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la e .
2025-05-27 19:03:02,132 - INFO - joeynmt.training - Example #2
2025-05-27 19:03:02,133 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:03:02,133 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:03:02,133 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la .
2025-05-27 19:03:02,133 - INFO - joeynmt.training - Example #3
2025-05-27 19:03:02,133 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:03:02,134 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:03:02,134 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è la la la la la la la la la la e .
2025-05-27 19:03:02,134 - INFO - joeynmt.training - Example #4
2025-05-27 19:03:02,134 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:03:02,135 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:03:02,135 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la .
2025-05-27 19:03:05,652 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.020925, Batch Acc: 0.498667, Tokens per Sec:    20252, Lr: 0.000300
2025-05-27 19:03:09,207 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     1.892585, Batch Acc: 0.500728, Tokens per Sec:    22214, Lr: 0.000300
2025-05-27 19:03:12,700 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     1.863940, Batch Acc: 0.498636, Tokens per Sec:    22887, Lr: 0.000300
2025-05-27 19:03:16,146 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     1.925505, Batch Acc: 0.497653, Tokens per Sec:    23062, Lr: 0.000300
2025-05-27 19:03:19,568 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     1.982655, Batch Acc: 0.501826, Tokens per Sec:    22809, Lr: 0.000300
2025-05-27 19:03:19,569 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:03:19,569 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 58.94it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 75.92it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 90.55it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 99.80it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 111.21it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 107.91it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 114.26it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 127.89it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:18, 41.04it/s] Predicting...:  17%|█▋        | 160/923 [00:02<00:16, 45.69it/s]Predicting...:  20%|██        | 185/923 [00:02<00:11, 61.75it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 72.90it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 65.39it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:13, 49.17it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:12, 54.98it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:16, 40.05it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:18, 35.61it/s]Predicting...:  30%|███       | 277/923 [00:05<00:21, 29.57it/s]Predicting...:  31%|███▏      | 289/923 [00:05<00:25, 24.98it/s]Predicting...:  33%|███▎      | 302/923 [00:06<00:21, 28.93it/s]Predicting...:  34%|███▍      | 314/923 [00:06<00:21, 28.91it/s]Predicting...:  35%|███▌      | 327/923 [00:06<00:18, 32.59it/s]Predicting...:  37%|███▋      | 337/923 [00:07<00:17, 34.07it/s]Predicting...:  38%|███▊      | 347/923 [00:07<00:15, 38.18it/s]Predicting...:  39%|███▉      | 361/923 [00:07<00:12, 46.83it/s]Predicting...:  41%|████      | 379/923 [00:07<00:09, 54.41it/s]Predicting...:  43%|████▎     | 393/923 [00:07<00:08, 59.52it/s]Predicting...:  44%|████▍     | 408/923 [00:08<00:08, 62.02it/s]Predicting...:  46%|████▌     | 424/923 [00:08<00:07, 64.12it/s]Predicting...:  48%|████▊     | 441/923 [00:08<00:06, 71.62it/s]Predicting...:  49%|████▉     | 455/923 [00:08<00:06, 72.40it/s]Predicting...:  51%|█████     | 469/923 [00:08<00:06, 72.20it/s]Predicting...:  52%|█████▏    | 480/923 [00:09<00:06, 69.75it/s]Predicting...:  54%|█████▎    | 494/923 [00:09<00:05, 75.02it/s]Predicting...:  54%|█████▍    | 503/923 [00:09<00:09, 43.54it/s]Predicting...:  56%|█████▌    | 517/923 [00:09<00:07, 52.08it/s]Predicting...:  58%|█████▊    | 531/923 [00:10<00:06, 63.32it/s]Predicting...:  59%|█████▊    | 540/923 [00:10<00:07, 53.51it/s]Predicting...:  59%|█████▉    | 548/923 [00:10<00:07, 49.45it/s]Predicting...:  60%|██████    | 556/923 [00:11<00:12, 28.57it/s]Predicting...:  62%|██████▏   | 568/923 [00:12<00:17, 20.60it/s]Predicting...:  63%|██████▎   | 580/923 [00:12<00:14, 23.45it/s]Predicting...:  64%|██████▎   | 587/923 [00:12<00:13, 25.13it/s]Predicting...:  65%|██████▍   | 596/923 [00:12<00:12, 26.38it/s]Predicting...:  66%|██████▌   | 605/923 [00:13<00:10, 30.07it/s]Predicting...:  67%|██████▋   | 618/923 [00:13<00:09, 32.11it/s]Predicting...:  68%|██████▊   | 630/923 [00:13<00:09, 32.40it/s]Predicting...:  69%|██████▉   | 639/923 [00:14<00:10, 27.71it/s]Predicting...:  70%|███████   | 647/923 [00:14<00:09, 29.28it/s]Predicting...:  71%|███████   | 653/923 [00:15<00:12, 21.10it/s]Predicting...:  72%|███████▏  | 661/923 [00:15<00:15, 16.97it/s]Predicting...:  73%|███████▎  | 671/923 [00:16<00:13, 18.17it/s]Predicting...:  73%|███████▎  | 678/923 [00:16<00:11, 21.06it/s]Predicting...:  74%|███████▍  | 687/923 [00:16<00:09, 25.84it/s]Predicting...:  75%|███████▌  | 696/923 [00:16<00:07, 29.99it/s]Predicting...:  77%|███████▋  | 708/923 [00:16<00:05, 37.55it/s]Predicting...:  78%|███████▊  | 717/923 [00:17<00:05, 37.41it/s]Predicting...:  79%|███████▉  | 729/923 [00:17<00:04, 40.88it/s]Predicting...:  80%|████████  | 742/923 [00:17<00:03, 51.19it/s]Predicting...:  81%|████████  | 749/923 [00:17<00:03, 50.97it/s]Predicting...:  82%|████████▏ | 759/923 [00:18<00:03, 43.44it/s]Predicting...:  84%|████████▍ | 774/923 [00:18<00:02, 53.63it/s]Predicting...:  85%|████████▌ | 786/923 [00:18<00:02, 56.12it/s]Predicting...:  87%|████████▋ | 800/923 [00:18<00:02, 57.00it/s]Predicting...:  88%|████████▊ | 815/923 [00:18<00:01, 67.93it/s]Predicting...:  90%|████████▉ | 827/923 [00:18<00:01, 70.61it/s]Predicting...:  90%|█████████ | 835/923 [00:19<00:02, 36.81it/s]Predicting...:  93%|█████████▎| 862/923 [00:20<00:01, 42.88it/s]Predicting...:  95%|█████████▌| 878/923 [00:20<00:00, 54.46it/s]Predicting...:  97%|█████████▋| 892/923 [00:20<00:00, 63.83it/s]Predicting...:  98%|█████████▊| 908/923 [00:20<00:00, 70.63it/s]Predicting...: 100%|██████████| 923/923 [00:20<00:00, 44.85it/s]
2025-05-27 19:03:40,158 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.04, acc:   0.50, generation: 20.5790[sec], evaluation: 0.0000[sec]
2025-05-27 19:03:40,159 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:03:40,643 - INFO - joeynmt.training - Example #0
2025-05-27 19:03:40,644 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:03:40,644 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:03:40,644 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è è la la m<unk> @ o , , , , , , , , la s<unk> @ o , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , la la la la la la la la la la la la la la la la la la la la la la la la la la la s<unk> @ o , , , , , , , la la .
2025-05-27 19:03:40,644 - INFO - joeynmt.training - Example #1
2025-05-27 19:03:40,645 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:03:40,645 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:03:40,645 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è la la la m<unk> @ o , la s<unk> @ o .
2025-05-27 19:03:40,646 - INFO - joeynmt.training - Example #2
2025-05-27 19:03:40,646 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:03:40,647 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:03:40,647 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è la m<unk> @ a , , , , la la la m<unk> @ a .
2025-05-27 19:03:40,647 - INFO - joeynmt.training - Example #3
2025-05-27 19:03:40,647 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:03:40,647 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:03:40,648 - INFO - joeynmt.training - 	Hypothesis: E la m<unk> @ o , la m<unk> @ o , la m<unk> @ o .
2025-05-27 19:03:40,648 - INFO - joeynmt.training - Example #4
2025-05-27 19:03:40,648 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:03:40,649 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:03:40,649 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è , , , , , , , , , la .
2025-05-27 19:03:43,974 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     1.986058, Batch Acc: 0.504054, Tokens per Sec:    20755, Lr: 0.000300
2025-05-27 19:03:47,299 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     1.910730, Batch Acc: 0.501730, Tokens per Sec:    23653, Lr: 0.000300
2025-05-27 19:03:50,554 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     1.947831, Batch Acc: 0.505690, Tokens per Sec:    24389, Lr: 0.000300
2025-05-27 19:03:53,785 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     1.876700, Batch Acc: 0.502200, Tokens per Sec:    25053, Lr: 0.000300
2025-05-27 19:03:57,035 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     1.945475, Batch Acc: 0.503745, Tokens per Sec:    25022, Lr: 0.000300
2025-05-27 19:03:57,035 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:03:57,035 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:23, 38.53it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:16, 54.59it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 77.13it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 103.45it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 110.76it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 108.18it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 91.29it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 41.97it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 48.82it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 49.58it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 71.70it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:10, 68.03it/s]Predicting...:  23%|██▎       | 211/923 [00:03<00:10, 70.76it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 64.65it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 60.38it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:12, 55.52it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:11, 55.67it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:17, 36.89it/s]Predicting...:  30%|███       | 277/923 [00:04<00:15, 42.37it/s]Predicting...:  31%|███▏      | 289/923 [00:05<00:20, 31.08it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:15, 40.03it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:16, 36.80it/s]Predicting...:  35%|███▌      | 327/923 [00:06<00:14, 41.69it/s]Predicting...:  37%|███▋      | 337/923 [00:06<00:12, 45.18it/s]Predicting...:  38%|███▊      | 347/923 [00:06<00:16, 35.61it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:13, 41.57it/s]Predicting...:  41%|████      | 379/923 [00:07<00:09, 55.89it/s]Predicting...:  44%|████▍     | 408/923 [00:07<00:06, 78.90it/s]Predicting...:  46%|████▌     | 424/923 [00:07<00:05, 88.00it/s]Predicting...:  48%|████▊     | 441/923 [00:07<00:05, 93.86it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:04, 104.61it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:04, 105.09it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:04, 92.30it/s] Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 75.27it/s]Predicting...:  59%|█████▊    | 540/923 [00:09<00:07, 49.42it/s]Predicting...:  59%|█████▉    | 548/923 [00:09<00:08, 44.90it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:12, 30.23it/s]Predicting...:  62%|██████▏   | 568/923 [00:10<00:10, 34.26it/s]Predicting...:  63%|██████▎   | 580/923 [00:10<00:09, 34.53it/s]Predicting...:  64%|██████▎   | 587/923 [00:10<00:11, 29.49it/s]Predicting...:  65%|██████▍   | 596/923 [00:11<00:10, 32.36it/s]Predicting...:  66%|██████▌   | 605/923 [00:11<00:08, 37.51it/s]Predicting...:  67%|██████▋   | 618/923 [00:11<00:06, 45.68it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:05, 54.29it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:06, 46.07it/s]Predicting...:  70%|███████   | 647/923 [00:12<00:07, 38.38it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:11, 23.53it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:09, 28.43it/s]Predicting...:  73%|███████▎  | 671/923 [00:13<00:07, 32.81it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:06, 35.07it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:06, 37.48it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:06, 35.44it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:06, 35.12it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:05, 37.13it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:04, 42.00it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 40.03it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:06, 25.37it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:05, 32.04it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:04, 36.88it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 53.70it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:02, 53.09it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 51.05it/s]Predicting...:  90%|█████████ | 835/923 [00:17<00:01, 46.08it/s]Predicting...:  92%|█████████▏| 850/923 [00:17<00:01, 54.90it/s]Predicting...:  93%|█████████▎| 862/923 [00:17<00:00, 61.44it/s]Predicting...:  95%|█████████▌| 878/923 [00:17<00:00, 62.22it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 70.39it/s]Predicting...:  98%|█████████▊| 908/923 [00:18<00:00, 66.82it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 73.71it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 50.81it/s]
2025-05-27 19:04:15,214 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.92, acc:   0.51, generation: 18.1670[sec], evaluation: 0.0000[sec]
2025-05-27 19:04:15,215 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:04:15,736 - INFO - joeynmt.training - Example #0
2025-05-27 19:04:15,738 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:04:15,738 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:04:15,738 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è che è che è che è è è è , che è , la mondo , che la mondo , che la mondo , che la mondo , che è , che la mondo , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , la mondo .
2025-05-27 19:04:15,738 - INFO - joeynmt.training - Example #1
2025-05-27 19:04:15,739 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:04:15,739 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:04:15,739 - INFO - joeynmt.training - 	Hypothesis: E non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-27 19:04:15,739 - INFO - joeynmt.training - Example #2
2025-05-27 19:04:15,740 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:04:15,740 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:04:15,740 - INFO - joeynmt.training - 	Hypothesis: Il mondo , è è è è è è è è è è è è è è , è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è .
2025-05-27 19:04:15,740 - INFO - joeynmt.training - Example #3
2025-05-27 19:04:15,741 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:04:15,741 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:04:15,741 - INFO - joeynmt.training - 	Hypothesis: C<unk> @ a , e la mondo , e la mondo , e la mondo , e la mondo .
2025-05-27 19:04:15,741 - INFO - joeynmt.training - Example #4
2025-05-27 19:04:15,742 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:04:15,742 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:04:15,742 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è .
2025-05-27 19:04:19,202 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     1.902544, Batch Acc: 0.505508, Tokens per Sec:    20085, Lr: 0.000300
2025-05-27 19:04:22,616 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     1.960353, Batch Acc: 0.508130, Tokens per Sec:    23664, Lr: 0.000300
2025-05-27 19:04:26,012 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     1.942113, Batch Acc: 0.504558, Tokens per Sec:    23427, Lr: 0.000300
2025-05-27 19:04:29,391 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     1.928912, Batch Acc: 0.507378, Tokens per Sec:    22848, Lr: 0.000300
2025-05-27 19:04:32,778 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     1.947224, Batch Acc: 0.508230, Tokens per Sec:    23594, Lr: 0.000300
2025-05-27 19:04:32,779 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:04:32,779 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:24, 37.04it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:14, 60.74it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 78.33it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 88.28it/s]Predicting...:   8%|▊         | 72/923 [00:01<00:12, 70.02it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:10, 77.61it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 86.69it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:10, 76.20it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:26, 29.55it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:22, 35.13it/s]Predicting...:  17%|█▋        | 160/923 [00:03<00:19, 38.19it/s]Predicting...:  20%|██        | 185/923 [00:03<00:12, 57.81it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:12, 57.92it/s]Predicting...:  23%|██▎       | 211/923 [00:04<00:16, 42.35it/s]Predicting...:  24%|██▍       | 224/923 [00:04<00:13, 50.28it/s]Predicting...:  25%|██▌       | 235/923 [00:04<00:15, 43.75it/s]Predicting...:  27%|██▋       | 249/923 [00:04<00:14, 46.48it/s]Predicting...:  28%|██▊       | 258/923 [00:05<00:15, 43.55it/s]Predicting...:  29%|██▉       | 267/923 [00:05<00:16, 39.19it/s]Predicting...:  30%|███       | 277/923 [00:05<00:20, 31.40it/s]Predicting...:  31%|███▏      | 289/923 [00:06<00:23, 26.89it/s]Predicting...:  33%|███▎      | 302/923 [00:06<00:20, 29.86it/s]Predicting...:  34%|███▍      | 314/923 [00:07<00:20, 30.21it/s]Predicting...:  35%|███▌      | 327/923 [00:07<00:16, 35.58it/s]Predicting...:  37%|███▋      | 337/923 [00:07<00:18, 31.44it/s]Predicting...:  38%|███▊      | 347/923 [00:08<00:20, 28.51it/s]Predicting...:  39%|███▉      | 361/923 [00:08<00:17, 32.36it/s]Predicting...:  41%|████      | 379/923 [00:08<00:12, 42.58it/s]Predicting...:  43%|████▎     | 393/923 [00:09<00:10, 52.26it/s]Predicting...:  44%|████▍     | 408/923 [00:09<00:08, 63.10it/s]Predicting...:  46%|████▌     | 424/923 [00:09<00:10, 48.80it/s]Predicting...:  49%|████▉     | 455/923 [00:09<00:06, 70.23it/s]Predicting...:  51%|█████     | 469/923 [00:10<00:07, 62.81it/s]Predicting...:  52%|█████▏    | 480/923 [00:10<00:06, 64.92it/s]Predicting...:  54%|█████▎    | 494/923 [00:10<00:07, 58.22it/s]Predicting...:  54%|█████▍    | 503/923 [00:10<00:08, 48.19it/s]Predicting...:  56%|█████▌    | 517/923 [00:11<00:07, 53.09it/s]Predicting...:  58%|█████▊    | 531/923 [00:11<00:06, 58.82it/s]Predicting...:  59%|█████▊    | 540/923 [00:11<00:08, 45.09it/s]Predicting...:  59%|█████▉    | 548/923 [00:12<00:09, 37.51it/s]Predicting...:  60%|██████    | 556/923 [00:12<00:09, 37.52it/s]Predicting...:  62%|██████▏   | 568/923 [00:12<00:08, 40.11it/s]Predicting...:  63%|██████▎   | 580/923 [00:12<00:06, 50.77it/s]Predicting...:  64%|██████▎   | 587/923 [00:12<00:07, 43.72it/s]Predicting...:  65%|██████▍   | 596/923 [00:13<00:08, 40.33it/s]Predicting...:  66%|██████▌   | 605/923 [00:13<00:07, 45.10it/s]Predicting...:  67%|██████▋   | 618/923 [00:13<00:07, 42.88it/s]Predicting...:  68%|██████▊   | 630/923 [00:14<00:09, 32.32it/s]Predicting...:  69%|██████▉   | 639/923 [00:14<00:08, 34.96it/s]Predicting...:  70%|███████   | 647/923 [00:14<00:07, 36.45it/s]Predicting...:  71%|███████   | 653/923 [00:14<00:08, 30.26it/s]Predicting...:  72%|███████▏  | 661/923 [00:15<00:08, 30.19it/s]Predicting...:  73%|███████▎  | 671/923 [00:15<00:07, 32.83it/s]Predicting...:  73%|███████▎  | 678/923 [00:15<00:07, 31.85it/s]Predicting...:  74%|███████▍  | 687/923 [00:15<00:06, 35.04it/s]Predicting...:  75%|███████▌  | 696/923 [00:16<00:06, 33.56it/s]Predicting...:  77%|███████▋  | 708/923 [00:16<00:06, 33.57it/s]Predicting...:  78%|███████▊  | 717/923 [00:16<00:05, 34.46it/s]Predicting...:  79%|███████▉  | 729/923 [00:17<00:05, 34.35it/s]Predicting...:  80%|████████  | 742/923 [00:17<00:05, 35.23it/s]Predicting...:  81%|████████  | 749/923 [00:17<00:05, 33.11it/s]Predicting...:  82%|████████▏ | 759/923 [00:18<00:05, 27.44it/s]Predicting...:  84%|████████▍ | 774/923 [00:18<00:04, 32.98it/s]Predicting...:  85%|████████▌ | 786/923 [00:18<00:03, 41.22it/s]Predicting...:  87%|████████▋ | 800/923 [00:18<00:02, 44.63it/s]Predicting...:  88%|████████▊ | 815/923 [00:19<00:02, 46.78it/s]Predicting...:  90%|████████▉ | 827/923 [00:19<00:02, 42.09it/s]Predicting...:  90%|█████████ | 835/923 [00:19<00:02, 32.29it/s]Predicting...:  92%|█████████▏| 850/923 [00:20<00:01, 37.18it/s]Predicting...:  93%|█████████▎| 862/923 [00:20<00:01, 33.23it/s]Predicting...:  95%|█████████▌| 878/923 [00:20<00:01, 40.26it/s]Predicting...:  97%|█████████▋| 892/923 [00:21<00:00, 42.13it/s]Predicting...:  98%|█████████▊| 908/923 [00:21<00:00, 47.97it/s]Predicting...: 100%|██████████| 923/923 [00:21<00:00, 58.32it/s]Predicting...: 100%|██████████| 923/923 [00:21<00:00, 42.65it/s]
2025-05-27 19:04:54,429 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.75, acc:   0.51, generation: 21.6406[sec], evaluation: 0.0000[sec]
2025-05-27 19:04:54,430 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:04:54,921 - INFO - joeynmt.training - Example #0
2025-05-27 19:04:54,923 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:04:54,923 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:04:54,923 - INFO - joeynmt.training - 	Hypothesis: E ho ho ho ho ho ho un mio mio mio mio mio mio mio mio mio mio mio mondo , e la m<unk> @ o , e il mondo , e la mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo , e il mondo .
2025-05-27 19:04:54,923 - INFO - joeynmt.training - Example #1
2025-05-27 19:04:54,924 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:04:54,924 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:04:54,924 - INFO - joeynmt.training - 	Hypothesis: Ma non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non la mondo <unk> @ o .
2025-05-27 19:04:54,924 - INFO - joeynmt.training - Example #2
2025-05-27 19:04:54,925 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:04:54,925 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:04:54,925 - INFO - joeynmt.training - 	Hypothesis: E è un p<unk> @ o , è un p<unk> @ o , è un p<unk> @ o , è un p<unk> @ o , è un p<unk> @ o , è un p<unk> @ o , è un p<unk> @ o .
2025-05-27 19:04:54,925 - INFO - joeynmt.training - Example #3
2025-05-27 19:04:54,926 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:04:54,926 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:04:54,926 - INFO - joeynmt.training - 	Hypothesis: C<unk> @ e la s<unk> @ o , e il mio mio mio mio mio m<unk> @ o , e il mio m<unk> @ o .
2025-05-27 19:04:54,926 - INFO - joeynmt.training - Example #4
2025-05-27 19:04:54,927 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:04:54,927 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:04:54,927 - INFO - joeynmt.training - 	Hypothesis: E ho ho ho ho ho ho un mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio m<unk> @ o .
2025-05-27 19:04:58,297 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     1.972605, Batch Acc: 0.510490, Tokens per Sec:    20709, Lr: 0.000300
2025-05-27 19:05:01,669 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     1.915320, Batch Acc: 0.509307, Tokens per Sec:    22818, Lr: 0.000300
2025-05-27 19:05:05,047 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     1.915236, Batch Acc: 0.510479, Tokens per Sec:    23274, Lr: 0.000300
2025-05-27 19:05:08,446 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     1.875664, Batch Acc: 0.510589, Tokens per Sec:    23552, Lr: 0.000300
2025-05-27 19:05:11,819 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     1.883425, Batch Acc: 0.510943, Tokens per Sec:    22910, Lr: 0.000300
2025-05-27 19:05:11,820 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:05:11,820 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 84.17it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 109.95it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 83.45it/s] Predicting...:   8%|▊         | 72/923 [00:00<00:09, 90.46it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 85.03it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 98.25it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 104.07it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:23, 34.08it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:20, 38.42it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 48.21it/s]Predicting...:  20%|██        | 185/923 [00:03<00:12, 57.88it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:11, 65.27it/s]Predicting...:  23%|██▎       | 211/923 [00:03<00:14, 50.77it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:15, 45.48it/s]Predicting...:  25%|██▌       | 235/923 [00:04<00:15, 44.74it/s]Predicting...:  27%|██▋       | 249/923 [00:04<00:15, 44.26it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:17, 38.41it/s]Predicting...:  29%|██▉       | 267/923 [00:05<00:16, 40.18it/s]Predicting...:  30%|███       | 277/923 [00:05<00:19, 33.96it/s]Predicting...:  31%|███▏      | 289/923 [00:05<00:16, 39.01it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:16, 38.40it/s]Predicting...:  34%|███▍      | 314/923 [00:06<00:13, 43.74it/s]Predicting...:  35%|███▌      | 327/923 [00:06<00:11, 50.82it/s]Predicting...:  37%|███▋      | 337/923 [00:06<00:11, 51.30it/s]Predicting...:  38%|███▊      | 347/923 [00:06<00:10, 52.69it/s]Predicting...:  39%|███▉      | 361/923 [00:07<00:11, 48.66it/s]Predicting...:  41%|████      | 379/923 [00:07<00:08, 61.13it/s]Predicting...:  43%|████▎     | 393/923 [00:07<00:07, 69.49it/s]Predicting...:  44%|████▍     | 408/923 [00:07<00:06, 80.41it/s]Predicting...:  46%|████▌     | 424/923 [00:07<00:07, 67.30it/s]Predicting...:  48%|████▊     | 441/923 [00:07<00:05, 83.30it/s]Predicting...:  49%|████▉     | 455/923 [00:08<00:05, 88.70it/s]Predicting...:  51%|█████     | 469/923 [00:08<00:04, 93.72it/s]Predicting...:  52%|█████▏    | 480/923 [00:08<00:05, 86.80it/s]Predicting...:  54%|█████▎    | 494/923 [00:08<00:05, 85.21it/s]Predicting...:  56%|█████▌    | 517/923 [00:09<00:06, 59.81it/s]Predicting...:  58%|█████▊    | 531/923 [00:09<00:06, 62.34it/s]Predicting...:  59%|█████▊    | 540/923 [00:09<00:06, 58.70it/s]Predicting...:  59%|█████▉    | 548/923 [00:09<00:07, 51.45it/s]Predicting...:  60%|██████    | 556/923 [00:10<00:12, 29.93it/s]Predicting...:  62%|██████▏   | 568/923 [00:10<00:10, 33.83it/s]Predicting...:  63%|██████▎   | 580/923 [00:10<00:10, 34.07it/s]Predicting...:  64%|██████▎   | 587/923 [00:11<00:09, 33.66it/s]Predicting...:  65%|██████▍   | 596/923 [00:11<00:09, 36.24it/s]Predicting...:  66%|██████▌   | 605/923 [00:11<00:08, 39.17it/s]Predicting...:  67%|██████▋   | 618/923 [00:11<00:06, 47.37it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:05, 50.57it/s]Predicting...:  69%|██████▉   | 639/923 [00:12<00:05, 49.43it/s]Predicting...:  70%|███████   | 647/923 [00:12<00:05, 46.40it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:08, 33.08it/s]Predicting...:  72%|███████▏  | 661/923 [00:13<00:10, 25.05it/s]Predicting...:  73%|███████▎  | 671/923 [00:13<00:10, 23.21it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:09, 24.54it/s]Predicting...:  74%|███████▍  | 687/923 [00:14<00:08, 28.75it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:08, 27.84it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:06, 31.34it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:05, 35.18it/s]Predicting...:  79%|███████▉  | 729/923 [00:15<00:04, 42.82it/s]Predicting...:  80%|████████  | 742/923 [00:15<00:03, 48.53it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:03, 45.67it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:03, 45.77it/s]Predicting...:  84%|████████▍ | 774/923 [00:16<00:03, 45.44it/s]Predicting...:  85%|████████▌ | 786/923 [00:16<00:02, 50.84it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 50.18it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:02, 53.43it/s]Predicting...:  90%|████████▉ | 827/923 [00:17<00:02, 44.65it/s]Predicting...:  90%|█████████ | 835/923 [00:17<00:03, 27.51it/s]Predicting...:  92%|█████████▏| 850/923 [00:18<00:02, 32.52it/s]Predicting...:  93%|█████████▎| 862/923 [00:18<00:02, 29.66it/s]Predicting...:  95%|█████████▌| 878/923 [00:18<00:01, 39.13it/s]Predicting...:  97%|█████████▋| 892/923 [00:19<00:00, 45.35it/s]Predicting...:  98%|█████████▊| 908/923 [00:19<00:00, 49.17it/s]Predicting...: 100%|██████████| 923/923 [00:19<00:00, 56.94it/s]Predicting...: 100%|██████████| 923/923 [00:19<00:00, 47.41it/s]
2025-05-27 19:05:31,303 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.63, acc:   0.51, generation: 19.4690[sec], evaluation: 0.0000[sec]
2025-05-27 19:05:31,304 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:05:31,842 - INFO - joeynmt.training - Example #0
2025-05-27 19:05:31,844 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:05:31,844 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:05:31,844 - INFO - joeynmt.training - 	Hypothesis: E questo , se , se , se se , se , se se se se , se se se se se , ma , ma , ma , ma , ma , ma , che la , che la , che la , che la , che la , che la , che la , che la , che la , che la .
2025-05-27 19:05:31,844 - INFO - joeynmt.training - Example #1
2025-05-27 19:05:31,845 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:05:31,845 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:05:31,845 - INFO - joeynmt.training - 	Hypothesis: Ma non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non è una .
2025-05-27 19:05:31,845 - INFO - joeynmt.training - Example #2
2025-05-27 19:05:31,846 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:05:31,846 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:05:31,847 - INFO - joeynmt.training - 	Hypothesis: È un p<unk> @ a , è un p<unk> @ a , è una p<unk> @ o , la sua p<unk> @ a , la sua p<unk> @ a , la sua p<unk> @ a , la .
2025-05-27 19:05:31,847 - INFO - joeynmt.training - Example #3
2025-05-27 19:05:31,847 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:05:31,847 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:05:31,847 - INFO - joeynmt.training - 	Hypothesis: Non sono sono sono sono un p<unk> @ a , e i e i m<unk> @ o , e e e e , e e e e e e e e e e e e e e e e .
2025-05-27 19:05:31,848 - INFO - joeynmt.training - Example #4
2025-05-27 19:05:31,848 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:05:31,848 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:05:31,848 - INFO - joeynmt.training - 	Hypothesis: E è un mio cosa è un altro , è un po &apos; cosa è un po &apos; un po &apos; un po &apos; un po &apos; un altro , ma , ma , ma , ma , ma , ma , ma , ma , ma , ma , ma .
2025-05-27 19:05:35,255 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     1.863181, Batch Acc: 0.511785, Tokens per Sec:    20048, Lr: 0.000300
2025-05-27 19:05:38,647 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     1.853239, Batch Acc: 0.515497, Tokens per Sec:    23459, Lr: 0.000300
2025-05-27 19:05:42,051 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     1.879747, Batch Acc: 0.515161, Tokens per Sec:    24180, Lr: 0.000300
2025-05-27 19:05:45,424 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     1.856018, Batch Acc: 0.515862, Tokens per Sec:    24220, Lr: 0.000300
2025-05-27 19:05:48,809 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     1.795134, Batch Acc: 0.520147, Tokens per Sec:    23341, Lr: 0.000300
2025-05-27 19:05:48,809 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:05:48,809 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:25, 35.61it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:14, 59.74it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:17, 51.61it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:13, 64.31it/s]Predicting...:   8%|▊         | 72/923 [00:01<00:14, 59.11it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:14, 57.38it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:13, 60.14it/s]Predicting...:  13%|█▎        | 121/923 [00:02<00:13, 60.15it/s]Predicting...:  15%|█▍        | 134/923 [00:03<00:28, 27.82it/s]Predicting...:  16%|█▌        | 146/923 [00:03<00:26, 28.78it/s]Predicting...:  17%|█▋        | 160/923 [00:03<00:23, 32.59it/s]Predicting...:  20%|██        | 185/923 [00:04<00:17, 43.31it/s]Predicting...:  22%|██▏       | 201/923 [00:04<00:15, 46.19it/s]Predicting...:  23%|██▎       | 211/923 [00:04<00:14, 49.42it/s]Predicting...:  24%|██▍       | 224/923 [00:04<00:13, 53.70it/s]Predicting...:  25%|██▌       | 235/923 [00:05<00:16, 41.20it/s]Predicting...:  27%|██▋       | 249/923 [00:05<00:16, 41.76it/s]Predicting...:  28%|██▊       | 258/923 [00:05<00:15, 42.37it/s]Predicting...:  29%|██▉       | 267/923 [00:06<00:21, 30.90it/s]Predicting...:  30%|███       | 277/923 [00:06<00:19, 33.44it/s]Predicting...:  31%|███▏      | 289/923 [00:07<00:23, 27.44it/s]Predicting...:  33%|███▎      | 302/923 [00:07<00:20, 30.63it/s]Predicting...:  34%|███▍      | 314/923 [00:07<00:19, 30.65it/s]Predicting...:  35%|███▌      | 327/923 [00:08<00:15, 37.54it/s]Predicting...:  37%|███▋      | 337/923 [00:08<00:14, 39.62it/s]Predicting...:  38%|███▊      | 347/923 [00:08<00:12, 44.83it/s]Predicting...:  39%|███▉      | 361/923 [00:08<00:12, 44.13it/s]Predicting...:  41%|████      | 379/923 [00:09<00:10, 52.04it/s]Predicting...:  43%|████▎     | 393/923 [00:09<00:08, 62.62it/s]Predicting...:  44%|████▍     | 408/923 [00:09<00:08, 57.41it/s]Predicting...:  46%|████▌     | 424/923 [00:09<00:10, 46.32it/s]Predicting...:  48%|████▊     | 441/923 [00:10<00:09, 48.61it/s]Predicting...:  49%|████▉     | 455/923 [00:10<00:07, 58.70it/s]Predicting...:  51%|█████     | 469/923 [00:10<00:06, 66.29it/s]Predicting...:  52%|█████▏    | 480/923 [00:10<00:06, 71.35it/s]Predicting...:  54%|█████▎    | 494/923 [00:10<00:06, 65.04it/s]Predicting...:  54%|█████▍    | 503/923 [00:11<00:09, 42.10it/s]Predicting...:  56%|█████▌    | 517/923 [00:11<00:09, 43.13it/s]Predicting...:  58%|█████▊    | 531/923 [00:12<00:08, 43.60it/s]Predicting...:  59%|█████▊    | 540/923 [00:12<00:08, 45.53it/s]Predicting...:  59%|█████▉    | 548/923 [00:12<00:08, 44.80it/s]Predicting...:  60%|██████    | 556/923 [00:12<00:07, 46.93it/s]Predicting...:  62%|██████▏   | 568/923 [00:13<00:13, 25.79it/s]Predicting...:  63%|██████▎   | 580/923 [00:13<00:12, 28.24it/s]Predicting...:  64%|██████▎   | 587/923 [00:14<00:17, 19.33it/s]Predicting...:  65%|██████▍   | 596/923 [00:15<00:17, 18.23it/s]Predicting...:  66%|██████▌   | 605/923 [00:15<00:13, 22.85it/s]Predicting...:  67%|██████▋   | 618/923 [00:15<00:11, 27.06it/s]Predicting...:  68%|██████▊   | 630/923 [00:16<00:11, 24.85it/s]Predicting...:  69%|██████▉   | 639/923 [00:16<00:09, 28.85it/s]Predicting...:  70%|███████   | 647/923 [00:16<00:12, 22.73it/s]Predicting...:  71%|███████   | 653/923 [00:17<00:16, 16.09it/s]Predicting...:  72%|███████▏  | 661/923 [00:18<00:17, 14.92it/s]Predicting...:  73%|███████▎  | 671/923 [00:18<00:15, 16.64it/s]Predicting...:  73%|███████▎  | 678/923 [00:19<00:16, 14.42it/s]Predicting...:  74%|███████▍  | 687/923 [00:19<00:15, 15.57it/s]Predicting...:  75%|███████▌  | 696/923 [00:21<00:19, 11.45it/s]Predicting...:  77%|███████▋  | 708/923 [00:21<00:12, 16.85it/s]Predicting...:  78%|███████▊  | 717/923 [00:21<00:09, 20.66it/s]Predicting...:  79%|███████▉  | 729/923 [00:21<00:07, 25.86it/s]Predicting...:  80%|████████  | 742/923 [00:22<00:06, 28.91it/s]Predicting...:  81%|████████  | 749/923 [00:22<00:08, 21.10it/s]Predicting...:  82%|████████▏ | 759/923 [00:23<00:07, 20.67it/s]Predicting...:  84%|████████▍ | 774/923 [00:23<00:05, 28.76it/s]Predicting...:  85%|████████▌ | 786/923 [00:23<00:04, 30.14it/s]Predicting...:  87%|████████▋ | 800/923 [00:24<00:03, 35.34it/s]Predicting...:  88%|████████▊ | 815/923 [00:24<00:02, 42.48it/s]Predicting...:  90%|████████▉ | 827/923 [00:24<00:02, 39.50it/s]Predicting...:  90%|█████████ | 835/923 [00:24<00:02, 41.67it/s]Predicting...:  92%|█████████▏| 850/923 [00:25<00:01, 47.07it/s]Predicting...:  93%|█████████▎| 862/923 [00:25<00:01, 51.07it/s]Predicting...:  95%|█████████▌| 878/923 [00:25<00:00, 58.90it/s]Predicting...:  97%|█████████▋| 892/923 [00:25<00:00, 61.27it/s]Predicting...:  98%|█████████▊| 908/923 [00:25<00:00, 70.75it/s]Predicting...: 100%|██████████| 923/923 [00:25<00:00, 77.15it/s]Predicting...: 100%|██████████| 923/923 [00:25<00:00, 35.57it/s]
2025-05-27 19:06:14,774 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.26, acc:   0.52, generation: 25.9496[sec], evaluation: 0.0000[sec]
2025-05-27 19:06:14,775 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:06:15,245 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/500.ckpt
2025-05-27 19:06:15,268 - INFO - joeynmt.training - Example #0
2025-05-27 19:06:15,269 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:06:15,269 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:06:15,269 - INFO - joeynmt.training - 	Hypothesis: E questo è che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che av<unk> @ rebbe che la mia f<unk> @ or<unk> @ i<unk> @ ato che che che la sua sua sua sua sua sua sua sua sua sua sua sua sua , che la sua sua sua sua sua sua sua f<unk> @ i<unk> @ i<unk> @ i di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di persone che la sua sua sua sua sua sua sua c<unk> @ are .
2025-05-27 19:06:15,269 - INFO - joeynmt.training - Example #1
2025-05-27 19:06:15,270 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:06:15,270 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:06:15,270 - INFO - joeynmt.training - 	Hypothesis: Ma non è una cosa non è una cosa non non non non non non non non non non non non non non non non non non non non non non non non non è una cosa non è una cosa non è una cosa non è una cosa non è una cosa che non è una cosa non non non non non non non è un po a un po i<unk> @ are .
2025-05-27 19:06:15,270 - INFO - joeynmt.training - Example #2
2025-05-27 19:06:15,271 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:06:15,271 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:06:15,271 - INFO - joeynmt.training - 	Hypothesis: La sua sua sua sua sua sua sua è una b<unk> @ i<unk> @ a è una b<unk> @ i<unk> @ a , la sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua .
2025-05-27 19:06:15,271 - INFO - joeynmt.training - Example #3
2025-05-27 19:06:15,272 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:06:15,272 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:06:15,272 - INFO - joeynmt.training - 	Hypothesis: E se av<unk> @ ete un p<unk> @ o<unk> @ o<unk> @ o<unk> @ o<unk> @ i<unk> @ o e .
2025-05-27 19:06:15,272 - INFO - joeynmt.training - Example #4
2025-05-27 19:06:15,273 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:06:15,273 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:06:15,273 - INFO - joeynmt.training - 	Hypothesis: La mia mia mia mia mia mia mia mia mia mia mia mia mia mia cosa che è una cosa che la mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia f<unk> @ at<unk> @ at<unk> @ i<unk> @ ato .
2025-05-27 19:06:18,694 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     1.818535, Batch Acc: 0.520575, Tokens per Sec:    20446, Lr: 0.000300
2025-05-27 19:06:22,111 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     1.876826, Batch Acc: 0.522271, Tokens per Sec:    23532, Lr: 0.000300
2025-05-27 19:06:25,495 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     1.760885, Batch Acc: 0.525896, Tokens per Sec:    23075, Lr: 0.000300
2025-05-27 19:06:28,891 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     1.814273, Batch Acc: 0.530121, Tokens per Sec:    23221, Lr: 0.000300
2025-05-27 19:06:32,291 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     1.756444, Batch Acc: 0.531600, Tokens per Sec:    23160, Lr: 0.000300
2025-05-27 19:06:32,292 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:06:32,292 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 88.03it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:06, 127.02it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 140.65it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:05, 143.91it/s]Predicting...:  13%|█▎        | 121/923 [00:00<00:05, 148.00it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 45.94it/s] Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 53.32it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 71.80it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:08, 83.87it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 79.55it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:07, 85.97it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:08, 73.18it/s]Predicting...:  30%|███       | 277/923 [00:03<00:08, 73.94it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:08, 76.65it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:07, 84.38it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:06, 88.04it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:06, 90.16it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:07, 80.85it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 77.16it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 82.47it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 101.79it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 99.22it/s] Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 106.48it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 106.18it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 116.46it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 113.42it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:03, 114.60it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 102.82it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 89.36it/s] Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 95.99it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:04, 76.45it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:08, 43.45it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:08, 41.30it/s]Predicting...:  64%|██████▎   | 587/923 [00:07<00:08, 39.39it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:07, 41.00it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 44.17it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 53.80it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 57.75it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 55.40it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 53.71it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 43.52it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 41.91it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:05, 47.75it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:07, 31.03it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:09, 25.34it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:08, 27.95it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:05, 38.11it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:05, 39.12it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 46.11it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 56.17it/s]Predicting...:  81%|████████  | 749/923 [00:11<00:03, 51.94it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:02, 55.21it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:01, 78.89it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 100.87it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:00, 98.22it/s] Predicting...:  92%|█████████▏| 850/923 [00:12<00:00, 94.47it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 92.84it/s]Predicting...:  95%|█████████▌| 878/923 [00:12<00:00, 105.55it/s]Predicting...:  98%|█████████▊| 908/923 [00:12<00:00, 120.68it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 71.55it/s] 
2025-05-27 19:06:45,205 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.54, generation: 12.9012[sec], evaluation: 0.0000[sec]
2025-05-27 19:06:45,205 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:06:45,801 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/1000.ckpt
2025-05-27 19:06:45,816 - INFO - joeynmt.training - Example #0
2025-05-27 19:06:45,818 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:06:45,818 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:06:45,818 - INFO - joeynmt.training - 	Hypothesis: E ho detto che ho detto che ho detto che ho detto che ho detto che ho detto che ho detto che av<unk> @ ete , sono le persone che ha detto che av<unk> @ ete , che i m<unk> @ ec<unk> @ i<unk> @ enti che si si av<unk> @ ete , che i sono sono 1<unk> @ 0 , sono sono sono 1<unk> @ 0 anni , e i sono sono sono 1<unk> @ 0 , per 1<unk> @ 00 anni , sono 1<unk> @ 0 , sono 1<unk> @ 00 anni .
2025-05-27 19:06:45,818 - INFO - joeynmt.training - Example #1
2025-05-27 19:06:45,819 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:06:45,819 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:06:45,819 - INFO - joeynmt.training - 	Hypothesis: Ma non si si si si si si si si si si si si s<unk> @ ent<unk> @ ale , non si si si si si si si si si si si si si si si s<unk> @ ent<unk> @ ale , non si si si si si .
2025-05-27 19:06:45,819 - INFO - joeynmt.training - Example #2
2025-05-27 19:06:45,819 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Hypothesis: La parte di questo è il nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro pa<unk> @ ic<unk> @ ica , è il mondo .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - Example #3
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ i , e si si si si si si si si s<unk> @ ent<unk> @ ato .
2025-05-27 19:06:45,820 - INFO - joeynmt.training - Example #4
2025-05-27 19:06:45,821 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:06:45,821 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:06:45,821 - INFO - joeynmt.training - 	Hypothesis: La prima , se ho detto che ho detto che ho detto che ho detto che la mia mia mia mia parte di un po &apos; è che si si si si si si av<unk> @ ete .
2025-05-27 19:06:49,183 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     1.725436, Batch Acc: 0.537382, Tokens per Sec:    20325, Lr: 0.000300
2025-05-27 19:06:52,611 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     1.689029, Batch Acc: 0.542396, Tokens per Sec:    23321, Lr: 0.000300
2025-05-27 19:06:56,034 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     1.685906, Batch Acc: 0.546390, Tokens per Sec:    23076, Lr: 0.000300
2025-05-27 19:06:59,450 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     1.645360, Batch Acc: 0.549287, Tokens per Sec:    22848, Lr: 0.000300
2025-05-27 19:07:02,894 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     1.601819, Batch Acc: 0.551824, Tokens per Sec:    23033, Lr: 0.000300
2025-05-27 19:07:02,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:07:02,895 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 84.11it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 103.42it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 97.15it/s] Predicting...:   6%|▌         | 56/923 [00:00<00:08, 99.10it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 110.11it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 119.55it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 108.24it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 120.26it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:17, 45.52it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 50.76it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 60.98it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 88.78it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 97.94it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.20it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 77.09it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:13, 47.00it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 47.67it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:18, 35.12it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:14, 41.59it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:13, 45.83it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:11, 52.75it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 55.49it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 54.18it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 65.02it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 92.24it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 96.65it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 90.32it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 95.42it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 92.71it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 93.34it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.58it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 83.34it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:05, 70.58it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 79.72it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 90.13it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 59.63it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:10, 34.03it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:10, 35.04it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:09, 35.76it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 30.62it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:13, 24.18it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:11, 27.06it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:09, 33.73it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 37.33it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 35.72it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 35.75it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:09, 28.62it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:09, 28.46it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:07, 33.70it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 27.37it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 29.02it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:15, 15.07it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:10, 21.46it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:08, 23.04it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:06, 30.25it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 39.60it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:05, 34.12it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 36.35it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 49.10it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:03, 42.18it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 50.58it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 59.51it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 63.65it/s]Predicting...:  90%|█████████ | 835/923 [00:17<00:02, 33.27it/s]Predicting...:  92%|█████████▏| 850/923 [00:17<00:01, 45.13it/s]Predicting...:  93%|█████████▎| 862/923 [00:17<00:01, 50.84it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 76.74it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 82.99it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 51.65it/s]
2025-05-27 19:07:20,778 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.56, generation: 17.8701[sec], evaluation: 0.0000[sec]
2025-05-27 19:07:20,779 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:07:21,472 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/1500.ckpt
2025-05-27 19:07:21,496 - INFO - joeynmt.training - Example #0
2025-05-27 19:07:21,497 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:07:21,498 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:07:21,498 - INFO - joeynmt.training - 	Hypothesis: E ho detto che ho detto , ho detto che ho detto , mi sono stato stato stato stato di c<unk> @ ento di ri<unk> @ vol<unk> @ ere la c<unk> @ ur<unk> @ i , che la nostra nostra nostra nostra nostra c<unk> @ ult<unk> @ ura che la nostra nostra s<unk> @ ett<unk> @ azione di persone che hanno ri<unk> @ vol<unk> @ u<unk> @ ppo di di di persone che la nostra s<unk> @ es<unk> @ peri<unk> @ enza di 1<unk> @ 0<unk> @ 0<unk> @ 0 .
2025-05-27 19:07:21,498 - INFO - joeynmt.training - Example #1
2025-05-27 19:07:21,499 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:07:21,499 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:07:21,499 - INFO - joeynmt.training - 	Hypothesis: Ma non è la nostra vita , non non non è la nostra vita , non è la nostra cosa che la nostra nostra vita , non è la nostra vita , non è la nostra cosa non è la nostra vita .
2025-05-27 19:07:21,499 - INFO - joeynmt.training - Example #2
2025-05-27 19:07:21,500 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:07:21,500 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:07:21,500 - INFO - joeynmt.training - 	Hypothesis: E la nostra nostra nostra c<unk> @ ur<unk> @ ale , è la la c<unk> @ ur<unk> @ i , la nostra nostra c<unk> @ ur<unk> @ ale , la la con<unk> @ si<unk> @ m<unk> @ esso .
2025-05-27 19:07:21,500 - INFO - joeynmt.training - Example #3
2025-05-27 19:07:21,501 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:07:21,501 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:07:21,501 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ i miei miei miei miei miei miei miei p<unk> @ es<unk> @ ist<unk> @ a .
2025-05-27 19:07:21,501 - INFO - joeynmt.training - Example #4
2025-05-27 19:07:21,502 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:07:21,502 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:07:21,502 - INFO - joeynmt.training - 	Hypothesis: La cosa che mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi sono sono un po &apos; di un po &apos; di c<unk> @ ento di s<unk> @ etti<unk> @ vo .
2025-05-27 19:07:24,942 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     1.634318, Batch Acc: 0.552202, Tokens per Sec:    18982, Lr: 0.000300
2025-05-27 19:07:28,369 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     1.645152, Batch Acc: 0.556187, Tokens per Sec:    23316, Lr: 0.000300
2025-05-27 19:07:31,768 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     1.622139, Batch Acc: 0.558895, Tokens per Sec:    23667, Lr: 0.000300
2025-05-27 19:07:35,164 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     1.614781, Batch Acc: 0.560197, Tokens per Sec:    22735, Lr: 0.000300
2025-05-27 19:07:38,566 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     1.600858, Batch Acc: 0.561609, Tokens per Sec:    23440, Lr: 0.000300
2025-05-27 19:07:38,567 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:07:38,567 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 78.64it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 91.57it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 93.62it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 96.97it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 101.32it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 112.72it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 114.38it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 119.29it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:17, 44.22it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:17, 43.73it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 52.12it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 71.43it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 80.71it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 67.84it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 62.16it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 64.05it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 53.69it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 47.12it/s]Predicting...:  30%|███       | 277/923 [00:04<00:18, 35.67it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:17, 36.80it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:14, 42.26it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:12, 47.89it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:11, 54.10it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 54.10it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:12, 44.88it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:12, 44.06it/s]Predicting...:  41%|████      | 379/923 [00:06<00:08, 61.29it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:07, 68.71it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 75.60it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 82.13it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 89.97it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:05, 88.77it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 68.59it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 63.35it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:06, 69.56it/s]Predicting...:  54%|█████▍    | 503/923 [00:08<00:07, 54.79it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:06, 65.96it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 71.32it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 61.32it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 47.73it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:08, 42.11it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:10, 32.90it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:08, 40.90it/s]Predicting...:  64%|██████▎   | 587/923 [00:10<00:08, 37.83it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:09, 35.76it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:08, 37.16it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:08, 36.62it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:07, 37.52it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 37.36it/s]Predicting...:  70%|███████   | 647/923 [00:12<00:10, 25.36it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:10, 24.91it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:13, 19.91it/s]Predicting...:  73%|███████▎  | 671/923 [00:13<00:10, 24.42it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:09, 24.64it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:08, 27.90it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:08, 28.05it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:06, 33.25it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:08, 25.62it/s]Predicting...:  79%|███████▉  | 729/923 [00:15<00:06, 27.99it/s]Predicting...:  80%|████████  | 742/923 [00:15<00:04, 36.23it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:05, 33.31it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 33.20it/s]Predicting...:  84%|████████▍ | 774/923 [00:16<00:03, 37.75it/s]Predicting...:  85%|████████▌ | 786/923 [00:16<00:03, 36.04it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 47.38it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 58.47it/s]Predicting...:  90%|████████▉ | 827/923 [00:17<00:01, 64.90it/s]Predicting...:  92%|█████████▏| 850/923 [00:17<00:01, 59.54it/s]Predicting...:  93%|█████████▎| 862/923 [00:17<00:01, 57.17it/s]Predicting...:  95%|█████████▌| 878/923 [00:17<00:00, 70.78it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 78.17it/s]Predicting...:  98%|█████████▊| 908/923 [00:18<00:00, 89.96it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 50.97it/s]
2025-05-27 19:07:56,686 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.74, acc:   0.56, generation: 18.1104[sec], evaluation: 0.0000[sec]
2025-05-27 19:07:56,687 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:07:57,131 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/2000.ckpt
2025-05-27 19:07:57,154 - INFO - joeynmt.training - Example #0
2025-05-27 19:07:57,156 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:07:57,156 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:07:57,156 - INFO - joeynmt.training - 	Hypothesis: E ho fatto che ho fatto che ho fatto che ho fatto che ho fatto fatto il mio p<unk> @ op<unk> @ ol<unk> @ i , che le nostr<unk> @ e s<unk> @ etti<unk> @ man<unk> @ a di c<unk> @ ento di 1<unk> @ 00 % di persone che hanno fatto che hanno sc<unk> @ u<unk> @ te le persone che hanno sc<unk> @ u<unk> @ ppo di persone che hanno fatto di 1<unk> @ 00 % di doll<unk> @ ari .
2025-05-27 19:07:57,156 - INFO - joeynmt.training - Example #1
2025-05-27 19:07:57,157 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:07:57,157 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:07:57,157 - INFO - joeynmt.training - 	Hypothesis: Ma non è il mio p<unk> @ op<unk> @ po non è il p<unk> @ op<unk> @ po , che non si ri<unk> @ guar<unk> @ da un po &apos; di c<unk> @ ult<unk> @ ura , non è che non si ri<unk> @ guar<unk> @ da un po &apos; di c<unk> @ aus<unk> @ a .
2025-05-27 19:07:57,157 - INFO - joeynmt.training - Example #2
2025-05-27 19:07:57,158 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:07:57,158 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:07:57,158 - INFO - joeynmt.training - 	Hypothesis: Il nostro nostro nostro nostro c<unk> @ ult<unk> @ ura è il c<unk> @ ur<unk> @ ale è il nostro c<unk> @ ult<unk> @ ura di c<unk> @ ur<unk> @ ale , che si ri<unk> @ guar<unk> @ da un p<unk> @ op<unk> @ po .
2025-05-27 19:07:57,158 - INFO - joeynmt.training - Example #3
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ i i m<unk> @ eg<unk> @ gi<unk> @ o , e la m<unk> @ ezz<unk> @ o .
2025-05-27 19:07:57,159 - INFO - joeynmt.training - Example #4
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:07:57,159 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:07:57,160 - INFO - joeynmt.training - 	Hypothesis: La prima volta che ho fatto che ho fatto che ho fatto che ho fatto un po &apos; di anni fa , è un po &apos; di anni &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; &apos; anni .
2025-05-27 19:08:00,457 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:     1.587359, Batch Acc: 0.564328, Tokens per Sec:    21004, Lr: 0.000300
2025-05-27 19:08:03,876 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:     1.644898, Batch Acc: 0.563259, Tokens per Sec:    23845, Lr: 0.000300
2025-05-27 19:08:07,253 - INFO - joeynmt.training - Epoch   1, Step:     4800, Batch Loss:     1.577929, Batch Acc: 0.564450, Tokens per Sec:    23436, Lr: 0.000300
2025-05-27 19:08:10,657 - INFO - joeynmt.training - Epoch   1, Step:     4900, Batch Loss:     1.524483, Batch Acc: 0.565920, Tokens per Sec:    23798, Lr: 0.000300
2025-05-27 19:08:14,013 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:     1.512671, Batch Acc: 0.568500, Tokens per Sec:    23260, Lr: 0.000300
2025-05-27 19:08:14,014 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:08:14,014 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 73.70it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 92.10it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 93.47it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 106.52it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 110.65it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 121.46it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 115.67it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 118.47it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:20, 37.99it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:17, 43.81it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 53.42it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 76.12it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 84.68it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 80.03it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:12, 54.57it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:13, 50.94it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:16, 40.70it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:16, 40.62it/s]Predicting...:  30%|███       | 277/923 [00:04<00:18, 35.25it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:15, 42.22it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:13, 46.81it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 51.55it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 59.27it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 56.98it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 52.49it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:09, 56.91it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 74.38it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 82.57it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 84.60it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 93.48it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 97.69it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 96.18it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 73.38it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 71.29it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 76.26it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 64.13it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 74.63it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:04, 83.60it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:05, 62.91it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:06, 56.42it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:06, 55.43it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 65.69it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:05, 56.89it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:06, 48.26it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 55.13it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 56.78it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 45.96it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 42.28it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:06, 40.76it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 37.03it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 39.70it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:10, 22.32it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 26.23it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 27.27it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 35.69it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.45it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 45.40it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 54.95it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:03, 44.16it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 44.01it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 52.85it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 59.98it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 69.41it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 80.34it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 80.05it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 45.46it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 51.02it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 61.97it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 68.86it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 77.85it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.42it/s]
2025-05-27 19:08:29,827 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.55, acc:   0.57, generation: 15.8006[sec], evaluation: 0.0000[sec]
2025-05-27 19:08:29,828 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:08:30,353 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/2500.ckpt
2025-05-27 19:08:30,372 - INFO - joeynmt.training - Example #0
2025-05-27 19:08:30,374 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:08:30,374 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:08:30,374 - INFO - joeynmt.training - 	Hypothesis: Per cui ho inizi<unk> @ ato a fare un po &apos; di anni , ho inizi<unk> @ ato a sc<unk> @ u<unk> @ ola , le persone che hanno sc<unk> @ u<unk> @ ola che che che la nostra s<unk> @ an<unk> @ ze che che che la nostra s<unk> @ per<unk> @ f<unk> @ anno , le nostr<unk> @ e i nostri mili<unk> @ ar<unk> @ di di di anni , per le persone che hanno sc<unk> @ u<unk> @ ola di anni .
2025-05-27 19:08:30,374 - INFO - joeynmt.training - Example #1
2025-05-27 19:08:30,375 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:08:30,375 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:08:30,375 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che la nostra cosa che la nostra cosa che non è che non è che non si può essere essere in<unk> @ forma<unk> @ zione di cui non si può essere essere in<unk> @ forma<unk> @ zione .
2025-05-27 19:08:30,375 - INFO - joeynmt.training - Example #2
2025-05-27 19:08:30,376 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:08:30,376 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:08:30,376 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el prim<unk> @ o è che è il nostro problema è è il nostro modo di in<unk> @ f<unk> @ ig<unk> @ n è il mondo .
2025-05-27 19:08:30,376 - INFO - joeynmt.training - Example #3
2025-05-27 19:08:30,377 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:08:30,377 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:08:30,377 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ ogli<unk> @ o che si può essere un po &apos; di s<unk> @ ec<unk> @ olo .
2025-05-27 19:08:30,377 - INFO - joeynmt.training - Example #4
2025-05-27 19:08:30,378 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:08:30,378 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:08:30,378 - INFO - joeynmt.training - 	Hypothesis: Per cui ho fatto un po &apos; di un po &apos; di anni , è che ho fatto un po &apos; anni fa , è che è che è che la mia anni .
2025-05-27 19:08:33,788 - INFO - joeynmt.training - Epoch   1, Step:     5100, Batch Loss:     1.489514, Batch Acc: 0.570389, Tokens per Sec:    20015, Lr: 0.000300
2025-05-27 19:08:37,161 - INFO - joeynmt.training - Epoch   1, Step:     5200, Batch Loss:     1.489687, Batch Acc: 0.569565, Tokens per Sec:    23715, Lr: 0.000300
2025-05-27 19:08:40,543 - INFO - joeynmt.training - Epoch   1, Step:     5300, Batch Loss:     1.433503, Batch Acc: 0.574029, Tokens per Sec:    23623, Lr: 0.000300
2025-05-27 19:08:43,893 - INFO - joeynmt.training - Epoch   1, Step:     5400, Batch Loss:     1.506775, Batch Acc: 0.574157, Tokens per Sec:    23204, Lr: 0.000300
2025-05-27 19:08:47,249 - INFO - joeynmt.training - Epoch   1, Step:     5500, Batch Loss:     1.494792, Batch Acc: 0.575532, Tokens per Sec:    22934, Lr: 0.000300
2025-05-27 19:08:47,249 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:08:47,249 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 72.22it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 86.33it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:12, 70.83it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:15, 57.55it/s]Predicting...:   8%|▊         | 72/923 [00:01<00:11, 72.03it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 85.82it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 87.26it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 100.53it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:13, 56.84it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 59.49it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 65.94it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 90.39it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 95.47it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 82.70it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 82.52it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:07, 87.70it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 55.25it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 59.42it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:10, 63.03it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:08, 69.82it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 69.87it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.07it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 59.17it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 60.59it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 68.03it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 89.29it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 88.92it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 97.99it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 103.30it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 82.71it/s] Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 69.55it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:06, 74.35it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 65.83it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 74.60it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:08, 47.42it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:07, 57.71it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:06, 62.36it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 59.56it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:08, 43.24it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 44.75it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 45.72it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:06, 50.50it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:06, 50.94it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:06, 51.07it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 59.28it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 55.38it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 51.46it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 39.88it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:06, 39.36it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:10, 25.56it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 31.98it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.28it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.94it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 35.26it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:04, 47.18it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 31.73it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:05, 38.65it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:04, 39.23it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 40.46it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 43.85it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 54.96it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 65.11it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 79.55it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 69.64it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 73.60it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 70.10it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 50.81it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 74.35it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 84.90it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 61.46it/s]
2025-05-27 19:09:02,277 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.41, acc:   0.58, generation: 15.0193[sec], evaluation: 0.0000[sec]
2025-05-27 19:09:02,278 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:09:02,786 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/3000.ckpt
2025-05-27 19:09:02,808 - INFO - joeynmt.training - Example #0
2025-05-27 19:09:02,809 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:09:02,809 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:09:02,809 - INFO - joeynmt.training - 	Hypothesis: Per cui ho inizi<unk> @ ato a fare questo è il mio prim<unk> @ o di cui ho sc<unk> @ rit<unk> @ to che si ri<unk> @ vol<unk> @ are il mondo , la c<unk> @ ult<unk> @ ur<unk> @ g<unk> @ over<unk> @ no , che si ri<unk> @ vol<unk> @ o 2<unk> @ 5 anni , e abbiamo bisogno di un mili<unk> @ ar<unk> @ di di doll<unk> @ ari , e ho fatto il mondo , per il 19<unk> @ 1<unk> @ 00 milioni di doll<unk> @ ari .
2025-05-27 19:09:02,809 - INFO - joeynmt.training - Example #1
2025-05-27 19:09:02,810 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:09:02,810 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:09:02,810 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa non è la maggi<unk> @ or parte della nostra vita , la cosa non è la maggi<unk> @ or parte della nostra c<unk> @ ult<unk> @ ura , non è la nostra cosa che non è la nostra cosa non non è la maggi<unk> @ or parte della vita .
2025-05-27 19:09:02,810 - INFO - joeynmt.training - Example #2
2025-05-27 19:09:02,811 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:09:02,811 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:09:02,811 - INFO - joeynmt.training - 	Hypothesis: Il mio prim<unk> @ o è la c<unk> @ ult<unk> @ ura è la c<unk> @ ult<unk> @ ura è la c<unk> @ ura della nostra c<unk> @ ura .
2025-05-27 19:09:02,811 - INFO - joeynmt.training - Example #3
2025-05-27 19:09:02,812 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:09:02,812 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:09:02,812 - INFO - joeynmt.training - 	Hypothesis: E poi si tr<unk> @ at<unk> @ ta e la b<unk> @ att<unk> @ a e la f<unk> @ att<unk> @ a .
2025-05-27 19:09:02,812 - INFO - joeynmt.training - Example #4
2025-05-27 19:09:02,813 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:09:02,813 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:09:02,813 - INFO - joeynmt.training - 	Hypothesis: La prima volta che ho fatto il mio prim<unk> @ o è una cosa che è una cosa che è una cosa che è una cosa è una cosa che è una cosa che è una cosa che è una cosa che è una cosa che è una cosa che è un po &apos; 8<unk> @ 0 anni .
2025-05-27 19:09:06,136 - INFO - joeynmt.training - Epoch   1, Step:     5600, Batch Loss:     1.487764, Batch Acc: 0.577287, Tokens per Sec:    20049, Lr: 0.000300
2025-05-27 19:09:09,533 - INFO - joeynmt.training - Epoch   1, Step:     5700, Batch Loss:     1.430234, Batch Acc: 0.580687, Tokens per Sec:    22876, Lr: 0.000300
2025-05-27 19:09:12,909 - INFO - joeynmt.training - Epoch   1, Step:     5800, Batch Loss:     1.507910, Batch Acc: 0.581922, Tokens per Sec:    23185, Lr: 0.000300
2025-05-27 19:09:16,297 - INFO - joeynmt.training - Epoch   1, Step:     5900, Batch Loss:     1.493704, Batch Acc: 0.581970, Tokens per Sec:    24002, Lr: 0.000300
2025-05-27 19:09:19,669 - INFO - joeynmt.training - Epoch   1, Step:     6000, Batch Loss:     1.352775, Batch Acc: 0.583851, Tokens per Sec:    24345, Lr: 0.000300
2025-05-27 19:09:19,670 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:09:19,670 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 76.77it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 86.83it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 83.22it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 89.55it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 93.70it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 104.14it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 108.21it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:09, 80.22it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 63.15it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:10, 70.59it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 91.79it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 95.01it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 72.37it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:10, 66.39it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 73.60it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 57.12it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:13, 48.64it/s]Predicting...:  30%|███       | 277/923 [00:03<00:13, 47.97it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 51.51it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 62.06it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 64.50it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 68.92it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 64.72it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 61.01it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 70.52it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 90.46it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 95.87it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 95.47it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 93.84it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 101.29it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 98.34it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 95.42it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 84.27it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 82.34it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 61.83it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 69.17it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 79.03it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 60.19it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:08, 46.15it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 41.42it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.83it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.17it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 43.51it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 43.15it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 40.03it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 47.36it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 45.61it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 43.20it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 34.68it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 30.15it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 29.93it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 32.62it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.30it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 31.99it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 28.62it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 36.98it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.16it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 47.19it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 59.08it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 45.51it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 55.38it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 55.54it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:02, 58.31it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 68.81it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 74.46it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 64.79it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.72it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 75.45it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 80.67it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 113.40it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 62.10it/s] 
2025-05-27 19:09:34,543 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.27, acc:   0.59, generation: 14.8648[sec], evaluation: 0.0000[sec]
2025-05-27 19:09:34,544 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:09:35,019 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/3500.ckpt
2025-05-27 19:09:35,044 - INFO - joeynmt.training - Example #0
2025-05-27 19:09:35,045 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:09:35,045 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:09:35,046 - INFO - joeynmt.training - 	Hypothesis: E ho fatto che ho fatto , ho fatto che ho fatto , ho fatto che ho fatto il prim<unk> @ o di cui ho fatto che av<unk> @ uto il m<unk> @ ett<unk> @ ore , che la s<unk> @ itu<unk> @ azione di cui i nostri milioni di anni , che i nostri milioni di anni , che av<unk> @ evano 1<unk> @ 00 milioni di anni , che hanno fatto che av<unk> @ uto il 1<unk> @ 00 milioni di anni , che av<unk> @ evano 1<unk> @ 00 milioni di anni .
2025-05-27 19:09:35,046 - INFO - joeynmt.training - Example #1
2025-05-27 19:09:35,047 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:09:35,047 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:09:35,047 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa non è che non è la ris<unk> @ ult<unk> @ ura che la ris<unk> @ ult<unk> @ ura di questo modo di questo modo di questo modo di questo modo di questo modo di ri<unk> @ guar<unk> @ do di questo modo di più più di più di cui non è la nostra s<unk> @ itu<unk> @ azione .
2025-05-27 19:09:35,047 - INFO - joeynmt.training - Example #2
2025-05-27 19:09:35,048 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:09:35,048 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:09:35,048 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el c<unk> @ entr<unk> @ o è il fatto è il ris<unk> @ ult<unk> @ ato è il nostro in<unk> @ f<unk> @ ico , il nostro cervello di c<unk> @ entr<unk> @ o di c<unk> @ entr<unk> @ o .
2025-05-27 19:09:35,048 - INFO - joeynmt.training - Example #3
2025-05-27 19:09:35,048 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:09:35,049 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:09:35,049 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , e si trov<unk> @ a a a a , e poi si trov<unk> @ a .
2025-05-27 19:09:35,049 - INFO - joeynmt.training - Example #4
2025-05-27 19:09:35,049 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:09:35,049 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:09:35,050 - INFO - joeynmt.training - 	Hypothesis: La cosa che ho fatto , il mio p<unk> @ ezz<unk> @ o , è che ho fatto che è una cosa che è che è una cosa che è una cosa che è che è stato stato il prim<unk> @ o di anni .
2025-05-27 19:09:38,471 - INFO - joeynmt.training - Epoch   1, Step:     6100, Batch Loss:     1.509397, Batch Acc: 0.586169, Tokens per Sec:    20109, Lr: 0.000300
2025-05-27 19:09:41,874 - INFO - joeynmt.training - Epoch   1, Step:     6200, Batch Loss:     1.477101, Batch Acc: 0.586691, Tokens per Sec:    23683, Lr: 0.000300
2025-05-27 19:09:45,263 - INFO - joeynmt.training - Epoch   1, Step:     6300, Batch Loss:     1.387346, Batch Acc: 0.587745, Tokens per Sec:    23525, Lr: 0.000300
2025-05-27 19:09:48,643 - INFO - joeynmt.training - Epoch   1, Step:     6400, Batch Loss:     1.500510, Batch Acc: 0.586706, Tokens per Sec:    23642, Lr: 0.000300
2025-05-27 19:09:52,040 - INFO - joeynmt.training - Epoch   1, Step:     6500, Batch Loss:     1.375237, Batch Acc: 0.588201, Tokens per Sec:    23624, Lr: 0.000300
2025-05-27 19:09:52,040 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:09:52,040 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 85.02it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 95.98it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 90.86it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 93.93it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:11, 74.37it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 85.25it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:12, 64.61it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:10, 79.83it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 53.17it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 57.42it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 90.94it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 87.82it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:08, 79.96it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.31it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 72.07it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 80.82it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:09, 70.78it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 58.65it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 57.57it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 55.62it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 63.29it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 63.29it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 67.52it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 62.46it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 61.87it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 67.91it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 87.82it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 93.01it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 75.42it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 84.98it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 98.48it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 98.96it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 82.18it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 79.71it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 89.49it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 74.91it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 84.34it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 61.37it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 48.60it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 55.58it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 33.18it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.50it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 42.38it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 43.33it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 38.22it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:08, 33.41it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 33.53it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 32.17it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.11it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.68it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 33.65it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 32.26it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 41.90it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.34it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 43.04it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:04, 41.79it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.52it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 39.30it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 52.29it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 58.45it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 70.63it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 64.81it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 69.88it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 57.84it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 70.54it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 57.05it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 79.69it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 98.51it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.53it/s]
2025-05-27 19:10:07,298 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.15, acc:   0.59, generation: 15.2492[sec], evaluation: 0.0000[sec]
2025-05-27 19:10:07,299 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:10:07,776 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/4000.ckpt
2025-05-27 19:10:07,794 - INFO - joeynmt.training - Example #0
2025-05-27 19:10:07,795 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:10:07,795 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:10:07,795 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , ho fatto che ho fatto , ho fatto , ho fatto che ho fatto che ho fatto che il m<unk> @ esso di fare il m<unk> @ esso di 1<unk> @ 5 anni , il mondo , il modo che la maggi<unk> @ or parte di anni , che il giorno , il giorno , il giorno , per 1<unk> @ 5 anni .
2025-05-27 19:10:07,795 - INFO - joeynmt.training - Example #1
2025-05-27 19:10:07,796 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:10:07,796 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:10:07,796 - INFO - joeynmt.training - 	Hypothesis: Ma questo è la cosa non è la maggi<unk> @ or parte di questo non è la maggi<unk> @ or parte del nostro modo di questa tecnologia , il problema di questa è la gente non è la maggi<unk> @ or parte di cui non è la gente non è il problema di questo problema .
2025-05-27 19:10:07,796 - INFO - joeynmt.training - Example #2
2025-05-27 19:10:07,797 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:10:07,797 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:10:07,797 - INFO - joeynmt.training - 	Hypothesis: In realtà , la maggi<unk> @ or parte di questa è la c<unk> @ ur<unk> @ ezza di c<unk> @ ur<unk> @ i<unk> @ os<unk> @ a , la nostra c<unk> @ ult<unk> @ ura .
2025-05-27 19:10:07,797 - INFO - joeynmt.training - Example #3
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta e la b<unk> @ an<unk> @ ta e e la b<unk> @ an<unk> @ ta .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - Example #4
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:10:07,798 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o è stato un po &apos; di cui ho fatto che ho fatto una cosa che è che è stata una cosa che è stata una cosa che è che è stata una cosa che è stata stata una cosa che è stata più più anni .
2025-05-27 19:10:11,158 - INFO - joeynmt.training - Epoch   1, Step:     6600, Batch Loss:     1.378398, Batch Acc: 0.589312, Tokens per Sec:    20684, Lr: 0.000300
2025-05-27 19:10:14,554 - INFO - joeynmt.training - Epoch   1, Step:     6700, Batch Loss:     1.457967, Batch Acc: 0.590939, Tokens per Sec:    23483, Lr: 0.000300
2025-05-27 19:10:17,970 - INFO - joeynmt.training - Epoch   1, Step:     6800, Batch Loss:     1.477306, Batch Acc: 0.591351, Tokens per Sec:    23387, Lr: 0.000300
2025-05-27 19:10:21,360 - INFO - joeynmt.training - Epoch   1, Step:     6900, Batch Loss:     1.499579, Batch Acc: 0.594163, Tokens per Sec:    23174, Lr: 0.000300
2025-05-27 19:10:24,740 - INFO - joeynmt.training - Epoch   1, Step:     7000, Batch Loss:     1.277357, Batch Acc: 0.593569, Tokens per Sec:    23395, Lr: 0.000300
2025-05-27 19:10:24,740 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:10:24,741 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 72.27it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 73.60it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 84.07it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 83.17it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 90.20it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 90.74it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 91.06it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 104.94it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:22, 34.33it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:20, 38.32it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:16, 46.82it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 67.52it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:09, 77.77it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:11, 62.34it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:12, 55.53it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 61.36it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:14, 44.48it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:16, 39.59it/s]Predicting...:  30%|███       | 277/923 [00:04<00:16, 39.54it/s]Predicting...:  31%|███▏      | 289/923 [00:05<00:17, 35.68it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:17, 36.15it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:15, 40.57it/s]Predicting...:  35%|███▌      | 327/923 [00:06<00:13, 43.37it/s]Predicting...:  37%|███▋      | 337/923 [00:06<00:15, 38.64it/s]Predicting...:  38%|███▊      | 347/923 [00:06<00:13, 43.90it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:11, 48.37it/s]Predicting...:  41%|████      | 379/923 [00:07<00:08, 66.52it/s]Predicting...:  43%|████▎     | 393/923 [00:07<00:06, 78.53it/s]Predicting...:  44%|████▍     | 408/923 [00:07<00:05, 89.41it/s]Predicting...:  46%|████▌     | 424/923 [00:07<00:05, 94.01it/s]Predicting...:  48%|████▊     | 441/923 [00:07<00:04, 106.36it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:04, 100.16it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:04, 106.44it/s]Predicting...:  54%|█████▎    | 494/923 [00:08<00:04, 105.54it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:04, 92.20it/s] Predicting...:  58%|█████▊    | 531/923 [00:08<00:04, 94.62it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:05, 73.88it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:06, 54.90it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:05, 58.51it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:07, 44.15it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:07, 43.45it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 43.50it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 41.04it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:06, 40.96it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:09, 30.42it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:13, 20.35it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:11, 22.08it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:09, 25.92it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:12, 19.62it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:10, 22.86it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:09, 23.13it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:06, 31.90it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:06, 31.20it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:05, 38.51it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 50.65it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:03, 45.08it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:02, 51.57it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 50.58it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 58.84it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 69.26it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 71.49it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 45.53it/s]Predicting...:  93%|█████████▎| 862/923 [00:17<00:01, 39.45it/s]Predicting...:  95%|█████████▌| 878/923 [00:17<00:00, 51.47it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 51.66it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 64.58it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 51.43it/s]
2025-05-27 19:10:42,696 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.40, ppl:   4.07, acc:   0.60, generation: 17.9460[sec], evaluation: 0.0000[sec]
2025-05-27 19:10:42,696 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:10:43,179 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/4500.ckpt
2025-05-27 19:10:43,202 - INFO - joeynmt.training - Example #0
2025-05-27 19:10:43,203 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:10:43,203 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:10:43,203 - INFO - joeynmt.training - 	Hypothesis: E ho visto che ho visto che ho visto che ho fatto che ho fatto il mondo , che ho fatto che la prima volta , che la gente si ha fatto che la gente si ha fatto che la gente che la gente che la c<unk> @ ult<unk> @ ura di 1<unk> @ 00 milioni di doll<unk> @ ari , che hanno 1<unk> @ 00 anni , e il 1<unk> @ 5 anni , che hanno 1<unk> @ 00 anni , che ha 1<unk> @ 5 anni .
2025-05-27 19:10:43,203 - INFO - joeynmt.training - Example #1
2025-05-27 19:10:43,204 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:10:43,204 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:10:43,204 - INFO - joeynmt.training - 	Hypothesis: Ma questo punto , non è che non è la gente non è la prima volta che non è la c<unk> @ ult<unk> @ ura di questa tecnologia , che non è la gente non è la c<unk> @ ult<unk> @ ura di questa tecnologia .
2025-05-27 19:10:43,204 - INFO - joeynmt.training - Example #2
2025-05-27 19:10:43,205 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:10:43,205 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:10:43,205 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el modo di cui la tecnologia è la nostra sp<unk> @ ec<unk> @ ie è il nostro in<unk> @ f<unk> @ ico , la nostra soci<unk> @ età di in<unk> @ f<unk> @ am<unk> @ ig<unk> @ lia .
2025-05-27 19:10:43,205 - INFO - joeynmt.training - Example #3
2025-05-27 19:10:43,206 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:10:43,206 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:10:43,206 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un po &apos; di l<unk> @ ì , e poi si tr<unk> @ at<unk> @ ta .
2025-05-27 19:10:43,206 - INFO - joeynmt.training - Example #4
2025-05-27 19:10:43,207 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:10:43,207 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:10:43,207 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o che vi mostr<unk> @ er<unk> @ ò che vi mostr<unk> @ a che vi mostr<unk> @ a a una cosa che ha un anno anno di 1<unk> @ 00 anni .
2025-05-27 19:10:46,523 - INFO - joeynmt.training - Epoch   1, Step:     7100, Batch Loss:     1.472641, Batch Acc: 0.592737, Tokens per Sec:    20730, Lr: 0.000300
2025-05-27 19:10:49,847 - INFO - joeynmt.training - Epoch   1, Step:     7200, Batch Loss:     1.423405, Batch Acc: 0.596922, Tokens per Sec:    24645, Lr: 0.000300
2025-05-27 19:10:53,163 - INFO - joeynmt.training - Epoch   1, Step:     7300, Batch Loss:     1.456144, Batch Acc: 0.593800, Tokens per Sec:    24285, Lr: 0.000300
2025-05-27 19:10:56,447 - INFO - joeynmt.training - Epoch   1, Step:     7400, Batch Loss:     1.442577, Batch Acc: 0.596320, Tokens per Sec:    24105, Lr: 0.000300
2025-05-27 19:10:59,760 - INFO - joeynmt.training - Epoch   1, Step:     7500, Batch Loss:     1.375107, Batch Acc: 0.601157, Tokens per Sec:    23701, Lr: 0.000300
2025-05-27 19:10:59,761 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:10:59,761 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 84.30it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 97.98it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 86.14it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 96.28it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 104.25it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 112.81it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 109.27it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:08, 91.55it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 65.20it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:10, 73.92it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 94.44it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 101.47it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 80.98it/s] Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 77.42it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 85.76it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:09, 67.55it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 63.80it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 62.68it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 69.74it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 84.53it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:07, 77.35it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 75.36it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 82.12it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 104.22it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 110.89it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:03, 120.66it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 108.87it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 103.08it/s]Predicting...:  52%|█████▏    | 480/923 [00:05<00:04, 89.88it/s] Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 96.91it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 88.87it/s]Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 84.79it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:07, 47.78it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 48.71it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:07, 45.74it/s]Predicting...:  64%|██████▎   | 587/923 [00:07<00:07, 43.08it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:07, 44.87it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 44.08it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 54.17it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 54.40it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 51.19it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:06, 45.98it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 39.84it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 36.97it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 40.59it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 38.70it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:05, 41.25it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 35.14it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 45.67it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:04, 43.34it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 53.17it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:02, 67.10it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:02, 56.96it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 69.47it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:01, 76.46it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 99.07it/s]Predicting...:  90%|█████████ | 835/923 [00:12<00:01, 84.58it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 71.26it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 88.46it/s]Predicting...:  98%|█████████▊| 908/923 [00:12<00:00, 95.69it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 71.65it/s]
2025-05-27 19:11:12,652 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.01, acc:   0.60, generation: 12.8832[sec], evaluation: 0.0000[sec]
2025-05-27 19:11:12,653 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:11:13,118 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/5000.ckpt
2025-05-27 19:11:13,141 - INFO - joeynmt.training - Example #0
2025-05-27 19:11:13,142 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:11:13,142 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:11:13,142 - INFO - joeynmt.training - 	Hypothesis: E &apos; la prima volta che ho sc<unk> @ oper<unk> @ to questo , ho sc<unk> @ oper<unk> @ to che la s<unk> @ itu<unk> @ azione di cui la s<unk> @ itu<unk> @ azione , che la sci<unk> @ enza di persone che i bambini sono 1<unk> @ 00 milioni di persone che hanno sc<unk> @ oper<unk> @ to il 1<unk> @ 8<unk> @ 0 anni , che ho av<unk> @ uto il 19<unk> @ 8<unk> @ 0 anni , che ho sc<unk> @ oper<unk> @ to .
2025-05-27 19:11:13,143 - INFO - joeynmt.training - Example #1
2025-05-27 19:11:13,143 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:11:13,144 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:11:13,144 - INFO - joeynmt.training - 	Hypothesis: Ma questo è il problema non è la cosa non è la s<unk> @ itu<unk> @ azione di cui non è la s<unk> @ itu<unk> @ azione di questo problema .
2025-05-27 19:11:13,144 - INFO - joeynmt.training - Example #2
2025-05-27 19:11:13,144 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Hypothesis: In realtà , la parte è la parte è la c<unk> @ ult<unk> @ ura è la tecnologia del mondo è la nostra soci<unk> @ età di in<unk> @ f<unk> @ ar .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - Example #3
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:11:13,145 - INFO - joeynmt.training - 	Hypothesis: C<unk> @ &apos; è la cosa è stato stato stato stato il suo f<unk> @ ut<unk> @ uro e la di<unk> @ sp<unk> @ ec<unk> @ ie .
2025-05-27 19:11:13,146 - INFO - joeynmt.training - Example #4
2025-05-27 19:11:13,146 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:11:13,146 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:11:13,146 - INFO - joeynmt.training - 	Hypothesis: La prima volta che ho fatto che la prima volta è una cosa che vi mostr<unk> @ a che vi mostr<unk> @ a che una volta è una volta che è stato di anni fa .
2025-05-27 19:11:16,453 - INFO - joeynmt.training - Epoch   1, Step:     7600, Batch Loss:     1.305449, Batch Acc: 0.601382, Tokens per Sec:    20870, Lr: 0.000300
2025-05-27 19:11:19,718 - INFO - joeynmt.training - Epoch   1, Step:     7700, Batch Loss:     1.453135, Batch Acc: 0.598884, Tokens per Sec:    23018, Lr: 0.000300
2025-05-27 19:11:23,080 - INFO - joeynmt.training - Epoch   1, Step:     7800, Batch Loss:     1.317912, Batch Acc: 0.599982, Tokens per Sec:    23596, Lr: 0.000300
2025-05-27 19:11:25,389 - INFO - joeynmt.training - Epoch   1: total training loss 13370.39
2025-05-27 19:11:25,390 - INFO - joeynmt.training - EPOCH 2
2025-05-27 19:11:26,376 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     1.373097, Batch Acc: 0.598649, Tokens per Sec:    24358, Lr: 0.000300
2025-05-27 19:11:29,666 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     1.339123, Batch Acc: 0.602712, Tokens per Sec:    24280, Lr: 0.000300
2025-05-27 19:11:29,666 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:11:29,666 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 80.45it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 105.69it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 120.81it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 118.70it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 130.34it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 137.73it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 131.70it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:08, 95.72it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 65.38it/s]Predicting...:  20%|██        | 185/923 [00:01<00:08, 89.87it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 98.81it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 71.00it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:12, 56.16it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 64.36it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 56.66it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 51.43it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 53.07it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 54.34it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 62.59it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.41it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.47it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:12, 48.69it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:13, 42.33it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 51.54it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 78.11it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 87.53it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 88.01it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 101.82it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:03, 113.68it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 96.47it/s] Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 79.22it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 83.52it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:05, 66.67it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 53.24it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 59.56it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 45.50it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 43.34it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 51.46it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.61it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 41.46it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 41.01it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:11, 23.58it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:10, 24.56it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 28.97it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 28.58it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:09, 25.58it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:15, 14.79it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:10, 20.94it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:08, 24.21it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:06, 31.31it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:04, 39.70it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 36.91it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 38.69it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 50.08it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 54.44it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 55.91it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 69.08it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 71.19it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 56.42it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 69.79it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 48.07it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 54.26it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 61.04it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 75.06it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.55it/s]
2025-05-27 19:11:46,001 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.96, acc:   0.60, generation: 16.3238[sec], evaluation: 0.0000[sec]
2025-05-27 19:11:46,001 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:11:46,604 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/5500.ckpt
2025-05-27 19:11:46,626 - INFO - joeynmt.training - Example #0
2025-05-27 19:11:46,628 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:11:46,628 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:11:46,628 - INFO - joeynmt.training - 	Hypothesis: E ho fatto , ho fatto , ho fatto , ho fatto , che ho fatto , che la c<unk> @ ent<unk> @ u<unk> @ zione , che la con<unk> @ si<unk> @ der<unk> @ na che la c<unk> @ a<unk> @ ia di anni , che la c<unk> @ ent<unk> @ u<unk> @ zione , che ha fatto di 1<unk> @ 5 anni , che hanno 1<unk> @ 5 anni , che ha fatto di 1<unk> @ 5 anni .
2025-05-27 19:11:46,628 - INFO - joeynmt.training - Example #1
2025-05-27 19:11:46,629 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:11:46,629 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:11:46,629 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa che non è il p<unk> @ es<unk> @ peri<unk> @ enza , non è il des<unk> @ ig<unk> @ n di questo , che non è il problema di questo tipo di di di c<unk> @ aus<unk> @ a di questo non è il problema di c<unk> @ aus<unk> @ a di un problema .
2025-05-27 19:11:46,629 - INFO - joeynmt.training - Example #2
2025-05-27 19:11:46,630 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:11:46,630 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:11:46,630 - INFO - joeynmt.training - 	Hypothesis: In realtà , è il p<unk> @ es<unk> @ ist<unk> @ a è il nostro s<unk> @ an<unk> @ co di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a .
2025-05-27 19:11:46,630 - INFO - joeynmt.training - Example #3
2025-05-27 19:11:46,631 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:11:46,631 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:11:46,631 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ e<unk> @ dete il suo f<unk> @ ig<unk> @ lio .
2025-05-27 19:11:46,631 - INFO - joeynmt.training - Example #4
2025-05-27 19:11:46,632 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:11:46,632 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:11:46,632 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o anno , ho fatto che ho fatto , è un po &apos; di c<unk> @ aus<unk> @ a di anni fa , è un anno di anni fa .
2025-05-27 19:11:49,964 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     1.401587, Batch Acc: 0.604006, Tokens per Sec:    20096, Lr: 0.000300
2025-05-27 19:11:53,295 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     1.330742, Batch Acc: 0.603558, Tokens per Sec:    23212, Lr: 0.000300
2025-05-27 19:11:56,565 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     1.358879, Batch Acc: 0.605823, Tokens per Sec:    23195, Lr: 0.000300
2025-05-27 19:11:59,868 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     1.373996, Batch Acc: 0.609356, Tokens per Sec:    23893, Lr: 0.000300
2025-05-27 19:12:03,178 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     1.267296, Batch Acc: 0.610134, Tokens per Sec:    24660, Lr: 0.000300
2025-05-27 19:12:03,178 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:12:03,178 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 86.10it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 111.45it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:06, 130.67it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 135.76it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:05, 141.45it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 129.37it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:08, 98.89it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:10, 72.57it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:09, 82.45it/s]Predicting...:  20%|██        | 185/923 [00:01<00:06, 107.29it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:06, 103.33it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 98.61it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 94.69it/s]Predicting...:  29%|██▉       | 267/923 [00:02<00:08, 74.61it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 71.67it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:09, 69.84it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 75.17it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:07, 78.51it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 75.50it/s]Predicting...:  38%|███▊      | 347/923 [00:03<00:07, 77.57it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 81.79it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 99.14it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 102.49it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 112.03it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 111.37it/s]Predicting...:  49%|████▉     | 455/923 [00:04<00:03, 126.16it/s]Predicting...:  52%|█████▏    | 480/923 [00:04<00:03, 119.41it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:03, 117.70it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 96.71it/s] Predicting...:  59%|█████▊    | 540/923 [00:05<00:04, 92.14it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:05, 69.72it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:06, 53.53it/s]Predicting...:  63%|██████▎   | 580/923 [00:06<00:05, 59.67it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:06, 52.48it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:06, 47.35it/s]Predicting...:  67%|██████▋   | 618/923 [00:07<00:05, 55.81it/s]Predicting...:  68%|██████▊   | 630/923 [00:07<00:05, 56.84it/s]Predicting...:  69%|██████▉   | 639/923 [00:07<00:05, 53.89it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 50.67it/s]Predicting...:  71%|███████   | 653/923 [00:08<00:06, 40.39it/s]Predicting...:  72%|███████▏  | 661/923 [00:08<00:06, 41.13it/s]Predicting...:  73%|███████▎  | 671/923 [00:08<00:05, 44.94it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:07, 32.60it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:06, 37.42it/s]Predicting...:  75%|███████▌  | 696/923 [00:09<00:06, 32.94it/s]Predicting...:  77%|███████▋  | 708/923 [00:09<00:04, 43.18it/s]Predicting...:  78%|███████▊  | 717/923 [00:09<00:04, 44.70it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 51.99it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:02, 65.27it/s]Predicting...:  82%|████████▏ | 759/923 [00:10<00:02, 71.28it/s]Predicting...:  84%|████████▍ | 774/923 [00:10<00:01, 76.67it/s]Predicting...:  85%|████████▌ | 786/923 [00:10<00:01, 78.99it/s]Predicting...:  87%|████████▋ | 800/923 [00:10<00:01, 85.00it/s]Predicting...:  88%|████████▊ | 815/923 [00:10<00:01, 93.64it/s]Predicting...:  90%|████████▉ | 827/923 [00:11<00:01, 92.92it/s]Predicting...:  92%|█████████▏| 850/923 [00:11<00:00, 78.65it/s]Predicting...:  93%|█████████▎| 862/923 [00:11<00:00, 72.66it/s]Predicting...:  95%|█████████▌| 878/923 [00:11<00:00, 85.84it/s]Predicting...:  97%|█████████▋| 892/923 [00:11<00:00, 93.97it/s]Predicting...: 100%|██████████| 923/923 [00:11<00:00, 124.34it/s]Predicting...: 100%|██████████| 923/923 [00:11<00:00, 77.02it/s] 
2025-05-27 19:12:15,171 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.90, acc:   0.61, generation: 11.9842[sec], evaluation: 0.0000[sec]
2025-05-27 19:12:15,171 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:12:15,661 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/6000.ckpt
2025-05-27 19:12:15,684 - INFO - joeynmt.training - Example #0
2025-05-27 19:12:15,685 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:12:15,685 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:12:15,685 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho fatto che ho fatto questi due due anni , ho fatto questi due due anni , ho inizi<unk> @ ato a lavor<unk> @ are per creare un anno di 1<unk> @ 00 milioni di anni , che si è stato stato il mondo , che il 1<unk> @ 00 milioni di anni , che si è stato stato il 1<unk> @ 8<unk> @ 0 , che hanno inizi<unk> @ ato a 1<unk> @ 8<unk> @ 0 , che ho inizi<unk> @ ato a 1<unk> @ 8<unk> @ 0 .
2025-05-27 19:12:15,685 - INFO - joeynmt.training - Example #1
2025-05-27 19:12:15,686 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:12:15,686 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:12:15,686 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa non è il punto di vi<unk> @ sta , non è la maggi<unk> @ or parte del mondo non è la m<unk> @ ess<unk> @ a di questo tipo di lavoro .
2025-05-27 19:12:15,686 - INFO - joeynmt.training - Example #2
2025-05-27 19:12:15,687 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:12:15,687 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:12:15,687 - INFO - joeynmt.training - 	Hypothesis: In eff<unk> @ etti , il m<unk> @ ezz<unk> @ o è il fatto di un in<unk> @ f<unk> @ ut<unk> @ uro è il nostro modo di cui il nostro cor<unk> @ so del nostro cor<unk> @ so .
2025-05-27 19:12:15,687 - INFO - joeynmt.training - Example #3
2025-05-27 19:12:15,688 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:12:15,688 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:12:15,688 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di ri<unk> @ vol<unk> @ are e poi il suo f<unk> @ ut<unk> @ uro .
2025-05-27 19:12:15,688 - INFO - joeynmt.training - Example #4
2025-05-27 19:12:15,689 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:12:15,689 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:12:15,689 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o è stato il prim<unk> @ o di voi , vi mostr<unk> @ o una cosa che vi mostr<unk> @ a che è stato stato un ulti<unk> @ mo di anni fa .
2025-05-27 19:12:19,004 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     1.287003, Batch Acc: 0.609028, Tokens per Sec:    20939, Lr: 0.000300
2025-05-27 19:12:22,302 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     1.340498, Batch Acc: 0.610428, Tokens per Sec:    24716, Lr: 0.000300
2025-05-27 19:12:25,629 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     1.419819, Batch Acc: 0.608334, Tokens per Sec:    23879, Lr: 0.000300
2025-05-27 19:12:28,943 - INFO - joeynmt.training - Epoch   2, Step:     8900, Batch Loss:     1.523959, Batch Acc: 0.610898, Tokens per Sec:    25195, Lr: 0.000300
2025-05-27 19:12:32,219 - INFO - joeynmt.training - Epoch   2, Step:     9000, Batch Loss:     1.357627, Batch Acc: 0.610646, Tokens per Sec:    23665, Lr: 0.000300
2025-05-27 19:12:32,219 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:12:32,220 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:09, 95.39it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:07, 113.46it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 119.65it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 124.27it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 133.99it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:07, 112.26it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:09, 85.31it/s] Predicting...:  17%|█▋        | 160/923 [00:01<00:08, 91.25it/s]Predicting...:  20%|██        | 185/923 [00:01<00:06, 112.15it/s]Predicting...:  23%|██▎       | 211/923 [00:01<00:06, 108.16it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:06, 105.35it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 91.03it/s] Predicting...:  29%|██▉       | 267/923 [00:02<00:09, 70.30it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 67.74it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:09, 64.32it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 71.24it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 71.16it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:08, 73.92it/s]Predicting...:  37%|███▋      | 337/923 [00:03<00:08, 69.48it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 68.54it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 81.84it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 103.41it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:04, 110.63it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 115.18it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 105.59it/s]Predicting...:  48%|████▊     | 441/923 [00:04<00:04, 114.87it/s]Predicting...:  49%|████▉     | 455/923 [00:04<00:03, 119.56it/s]Predicting...:  51%|█████     | 469/923 [00:04<00:03, 118.94it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:03, 109.82it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 88.28it/s] Predicting...:  59%|█████▊    | 540/923 [00:05<00:04, 90.32it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:06, 60.98it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:06, 56.52it/s]Predicting...:  63%|██████▎   | 580/923 [00:06<00:05, 63.75it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:07, 43.09it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:07, 43.78it/s]Predicting...:  67%|██████▋   | 618/923 [00:07<00:05, 50.86it/s]Predicting...:  68%|██████▊   | 630/923 [00:07<00:05, 53.74it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 49.85it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 47.96it/s]Predicting...:  71%|███████   | 653/923 [00:08<00:06, 39.25it/s]Predicting...:  72%|███████▏  | 661/923 [00:08<00:06, 38.35it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 40.31it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:07, 30.94it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:07, 33.02it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:08, 26.06it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:06, 35.27it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:05, 36.13it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:04, 42.29it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:03, 48.72it/s]Predicting...:  81%|████████  | 749/923 [00:11<00:04, 39.25it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 42.23it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 54.51it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:02, 58.44it/s]Predicting...:  87%|████████▋ | 800/923 [00:11<00:01, 66.98it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 74.11it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 73.04it/s]Predicting...:  90%|█████████ | 835/923 [00:12<00:01, 52.95it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:01, 64.96it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 61.35it/s]Predicting...:  95%|█████████▌| 878/923 [00:12<00:00, 76.93it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 76.15it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 87.42it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 68.86it/s]
2025-05-27 19:12:45,638 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.35, ppl:   3.84, acc:   0.61, generation: 13.4040[sec], evaluation: 0.0000[sec]
2025-05-27 19:12:45,639 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:12:46,194 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/6500.ckpt
2025-05-27 19:12:46,219 - INFO - joeynmt.training - Example #0
2025-05-27 19:12:46,221 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:12:46,221 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:12:46,221 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho fatto che ho fatto , ho fatto , ho fatto che ho fatto , per la prima volta , per la prima volta , per la prima volta , per la prima volta che la c<unk> @ ult<unk> @ ura , che la con<unk> @ fer<unk> @ enza , che l&apos; anno , che l&apos; anno , che ho inizi<unk> @ ato a 1<unk> @ 6 milioni di doll<unk> @ ari , che ho inizi<unk> @ ato a 1<unk> @ 6 milioni di anni , che ho fatto il 9<unk> @ 0 .
2025-05-27 19:12:46,221 - INFO - joeynmt.training - Example #1
2025-05-27 19:12:46,222 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:12:46,222 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:12:46,222 - INFO - joeynmt.training - 	Hypothesis: Ma non è il modo di cui non è il cambi<unk> @ amento non è il cambi<unk> @ amento non è il cambi<unk> @ amento della nostra soci<unk> @ età non è il cambi<unk> @ amento della soci<unk> @ età .
2025-05-27 19:12:46,222 - INFO - joeynmt.training - Example #2
2025-05-27 19:12:46,223 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:12:46,223 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:12:46,223 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el m<unk> @ oti<unk> @ vo è il m<unk> @ oti<unk> @ vo è che la nostra soci<unk> @ età è la nostra soci<unk> @ età della nostra soci<unk> @ età .
2025-05-27 19:12:46,223 - INFO - joeynmt.training - Example #3
2025-05-27 19:12:46,224 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:12:46,224 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:12:46,224 - INFO - joeynmt.training - 	Hypothesis: H<unk> @ a s<unk> @ ent<unk> @ ito , e il p<unk> @ es<unk> @ o , e si è stato s<unk> @ otto .
2025-05-27 19:12:46,224 - INFO - joeynmt.training - Example #4
2025-05-27 19:12:46,225 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:12:46,225 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:12:46,225 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che la prima cosa che ho fatto , è un po &apos; di m<unk> @ oti<unk> @ vo che è una cosa che è stata una cosa che è stata stata una cosa che è stata stata stata una cosa che è stato stato stato stato stato stato il prim<unk> @ o ulti<unk> @ mo .
2025-05-27 19:12:49,646 - INFO - joeynmt.training - Epoch   2, Step:     9100, Batch Loss:     1.278527, Batch Acc: 0.610051, Tokens per Sec:    19362, Lr: 0.000300
2025-05-27 19:12:53,024 - INFO - joeynmt.training - Epoch   2, Step:     9200, Batch Loss:     1.314478, Batch Acc: 0.613638, Tokens per Sec:    23504, Lr: 0.000300
2025-05-27 19:12:56,387 - INFO - joeynmt.training - Epoch   2, Step:     9300, Batch Loss:     1.304136, Batch Acc: 0.612477, Tokens per Sec:    22975, Lr: 0.000300
2025-05-27 19:12:59,763 - INFO - joeynmt.training - Epoch   2, Step:     9400, Batch Loss:     1.483722, Batch Acc: 0.610910, Tokens per Sec:    23398, Lr: 0.000300
2025-05-27 19:13:03,161 - INFO - joeynmt.training - Epoch   2, Step:     9500, Batch Loss:     1.311440, Batch Acc: 0.614737, Tokens per Sec:    23622, Lr: 0.000300
2025-05-27 19:13:03,162 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:13:03,162 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 73.56it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.83it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 90.11it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 103.99it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 101.47it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 115.17it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 123.97it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 53.63it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 56.50it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 65.34it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 84.15it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 92.40it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 74.69it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 68.80it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 73.50it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:10, 64.76it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 55.97it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 49.81it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 45.20it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 48.97it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.08it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 65.13it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 65.17it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 60.71it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 72.09it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 96.85it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 100.99it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 102.90it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 110.20it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 107.31it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 99.29it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 87.03it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 88.24it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 62.51it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 70.56it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 76.75it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 63.92it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 53.29it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 44.50it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 38.26it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 44.92it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 35.00it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 38.72it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 41.29it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 51.21it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 54.69it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 48.73it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:05, 48.79it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:06, 42.08it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:06, 40.94it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:05, 45.86it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 37.55it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 41.31it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 34.00it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:04, 44.02it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 45.39it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 53.55it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 64.48it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 53.65it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 65.61it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 65.98it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 78.14it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 90.88it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 92.85it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:00, 87.77it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 83.71it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 96.59it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 95.97it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 108.77it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 67.22it/s] 
2025-05-27 19:13:16,901 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.34, ppl:   3.80, acc:   0.61, generation: 13.7312[sec], evaluation: 0.0000[sec]
2025-05-27 19:13:16,902 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:13:17,394 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/7000.ckpt
2025-05-27 19:13:17,410 - INFO - joeynmt.training - Example #0
2025-05-27 19:13:17,411 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:13:17,411 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:13:17,411 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho sc<unk> @ oper<unk> @ to , ho fatto , questa è la sc<unk> @ u<unk> @ ola , per c<unk> @ aus<unk> @ a di fare il m<unk> @ oti<unk> @ vo che la c<unk> @ av<unk> @ e per tre anni , che hanno inizi<unk> @ ato a 1<unk> @ 8 anni , e il 1<unk> @ 8 anni , e il 1<unk> @ 8 anni , per tre anni , per tre anni , il 1<unk> @ 8 , il 1<unk> @ 8 anni .
2025-05-27 19:13:17,411 - INFO - joeynmt.training - Example #1
2025-05-27 19:13:17,412 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:13:17,412 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:13:17,412 - INFO - joeynmt.training - 	Hypothesis: Ma non non è la s<unk> @ itu<unk> @ azione di non è la la ri<unk> @ vol<unk> @ u<unk> @ zione di questo , la nostra sp<unk> @ ec<unk> @ ie , non è la la nostra sp<unk> @ ec<unk> @ os<unk> @ ità .
2025-05-27 19:13:17,412 - INFO - joeynmt.training - Example #2
2025-05-27 19:13:17,413 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:13:17,413 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:13:17,413 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ itu<unk> @ azione è la c<unk> @ at<unk> @ ric<unk> @ e di la nostra c<unk> @ ult<unk> @ ura , la nostra c<unk> @ ult<unk> @ ura .
2025-05-27 19:13:17,413 - INFO - joeynmt.training - Example #3
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ ma , e la m<unk> @ app<unk> @ a .
2025-05-27 19:13:17,414 - INFO - joeynmt.training - Example #4
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:13:17,414 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:13:17,415 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o succ<unk> @ esso , la mia pers<unk> @ ona che vi mostr<unk> @ a una cosa che vi mostr<unk> @ a una cosa che è che è stato un pa<unk> @ ese di anni .
2025-05-27 19:13:20,774 - INFO - joeynmt.training - Epoch   2, Step:     9600, Batch Loss:     1.246672, Batch Acc: 0.614132, Tokens per Sec:    20868, Lr: 0.000300
2025-05-27 19:13:24,159 - INFO - joeynmt.training - Epoch   2, Step:     9700, Batch Loss:     1.382323, Batch Acc: 0.616143, Tokens per Sec:    23479, Lr: 0.000300
2025-05-27 19:13:27,534 - INFO - joeynmt.training - Epoch   2, Step:     9800, Batch Loss:     1.409018, Batch Acc: 0.617104, Tokens per Sec:    22402, Lr: 0.000300
2025-05-27 19:13:30,951 - INFO - joeynmt.training - Epoch   2, Step:     9900, Batch Loss:     1.277229, Batch Acc: 0.619159, Tokens per Sec:    23579, Lr: 0.000300
2025-05-27 19:13:34,356 - INFO - joeynmt.training - Epoch   2, Step:    10000, Batch Loss:     1.264566, Batch Acc: 0.619506, Tokens per Sec:    23632, Lr: 0.000300
2025-05-27 19:13:34,357 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:13:34,357 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 74.65it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 97.25it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 104.85it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 105.97it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 98.77it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:07, 105.93it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 93.66it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 102.47it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.17it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 50.63it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 59.62it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 76.26it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 83.18it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:09, 72.28it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:10, 69.28it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 62.25it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 67.86it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 53.98it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:14, 46.70it/s]Predicting...:  30%|███       | 277/923 [00:04<00:16, 39.71it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:15, 41.98it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:13, 46.02it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:12, 49.49it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:11, 54.16it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 50.98it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:12, 46.11it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 52.54it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 68.99it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:07, 69.63it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:08, 63.67it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:07, 69.25it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 77.07it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:05, 78.23it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:05, 81.58it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 71.73it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 73.63it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.06it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 71.66it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:04, 79.82it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:05, 66.88it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:06, 54.94it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 46.87it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:08, 43.43it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:06, 52.40it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:07, 42.69it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:07, 43.59it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 45.12it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:05, 52.50it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:05, 52.91it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:05, 51.00it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:05, 50.02it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 37.75it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 37.14it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 41.19it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:06, 36.13it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:05, 39.52it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 32.04it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 42.30it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 39.07it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 47.95it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 59.78it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 49.87it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 60.48it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 62.35it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 75.28it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 83.30it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 86.29it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 70.06it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 67.29it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 82.21it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 83.35it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 76.70it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.97it/s]
2025-05-27 19:13:49,507 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.32, ppl:   3.75, acc:   0.62, generation: 15.1385[sec], evaluation: 0.0000[sec]
2025-05-27 19:13:49,507 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:13:50,169 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/7500.ckpt
2025-05-27 19:13:50,191 - INFO - joeynmt.training - Example #0
2025-05-27 19:13:50,192 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:13:50,192 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:13:50,192 - INFO - joeynmt.training - 	Hypothesis: E la prima volta , ho fatto , ho fatto , ho fatto , questi due anni , ho fatto , l&apos; ho fatto che la prima volta , la prima volta che la c<unk> @ r<unk> @ os<unk> @ sa che la c<unk> @ r<unk> @ os<unk> @ sa che la c<unk> @ r<unk> @ os<unk> @ a , la c<unk> @ r<unk> @ os<unk> @ a , il 1<unk> @ 8 milioni di doll<unk> @ ari .
2025-05-27 19:13:50,192 - INFO - joeynmt.training - Example #1
2025-05-27 19:13:50,193 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:13:50,193 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:13:50,193 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa non è la s<unk> @ itu<unk> @ azione di non è la s<unk> @ itu<unk> @ azione di questo , non è la s<unk> @ itu<unk> @ azione di questo non è la s<unk> @ itu<unk> @ azione .
2025-05-27 19:13:50,193 - INFO - joeynmt.training - Example #2
2025-05-27 19:13:50,194 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:13:50,194 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:13:50,194 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ itu<unk> @ azione è la c<unk> @ at<unk> @ ura di in<unk> @ f<unk> @ am<unk> @ enti , la nostra soci<unk> @ età della nostra c<unk> @ ult<unk> @ ura .
2025-05-27 19:13:50,194 - INFO - joeynmt.training - Example #3
2025-05-27 19:13:50,195 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:13:50,195 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:13:50,195 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di tutto , e la s<unk> @ etti<unk> @ man<unk> @ a e e la tu<unk> @ a f<unk> @ am<unk> @ a .
2025-05-27 19:13:50,195 - INFO - joeynmt.training - Example #4
2025-05-27 19:13:50,196 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:13:50,196 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:13:50,196 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o è la prima volta che vi ho fatto , vi ho fatto una cosa che ho fatto , una cosa che ho fatto è stato un po &apos; di 1<unk> @ 5 anni .
2025-05-27 19:13:53,662 - INFO - joeynmt.training - Epoch   2, Step:    10100, Batch Loss:     1.313063, Batch Acc: 0.619812, Tokens per Sec:    18959, Lr: 0.000300
2025-05-27 19:13:57,128 - INFO - joeynmt.training - Epoch   2, Step:    10200, Batch Loss:     1.358874, Batch Acc: 0.619283, Tokens per Sec:    22247, Lr: 0.000300
2025-05-27 19:14:00,620 - INFO - joeynmt.training - Epoch   2, Step:    10300, Batch Loss:     1.271849, Batch Acc: 0.619530, Tokens per Sec:    22594, Lr: 0.000300
2025-05-27 19:14:04,097 - INFO - joeynmt.training - Epoch   2, Step:    10400, Batch Loss:     1.389257, Batch Acc: 0.619495, Tokens per Sec:    22746, Lr: 0.000300
2025-05-27 19:14:07,602 - INFO - joeynmt.training - Epoch   2, Step:    10500, Batch Loss:     1.324364, Batch Acc: 0.622815, Tokens per Sec:    23055, Lr: 0.000300
2025-05-27 19:14:07,602 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:14:07,603 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 67.36it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 80.17it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 87.69it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 85.43it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.64it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 102.51it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 97.57it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:10, 79.55it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 44.79it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 48.10it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 58.03it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 78.24it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.14it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 74.07it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 63.86it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 66.79it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 55.01it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 50.81it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 47.03it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.47it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:13, 44.43it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:12, 49.10it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:11, 53.31it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:12, 46.10it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:12, 45.74it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 53.51it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 68.20it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:07, 72.77it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 74.91it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 74.03it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 75.38it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:06, 72.68it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 74.72it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 68.53it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 72.39it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 55.72it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:06, 61.32it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 68.68it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 56.40it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 45.88it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:09, 39.38it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 38.67it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 47.19it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 39.80it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:07, 41.89it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:07, 43.20it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 49.48it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:05, 52.23it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:05, 48.37it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:06, 44.92it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:06, 40.25it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:06, 38.22it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 41.85it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:06, 35.77it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:05, 40.08it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:05, 38.52it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:04, 47.49it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:04, 44.65it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:03, 52.13it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:02, 63.15it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 49.49it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 61.96it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 67.32it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 78.07it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 86.75it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 85.81it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 68.67it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 58.64it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 76.84it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 87.79it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.22it/s]
2025-05-27 19:14:22,940 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.31, ppl:   3.71, acc:   0.62, generation: 15.3282[sec], evaluation: 0.0000[sec]
2025-05-27 19:14:22,941 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:14:23,569 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/8000.ckpt
2025-05-27 19:14:23,593 - INFO - joeynmt.training - Example #0
2025-05-27 19:14:23,595 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:14:23,595 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:14:23,595 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o anno , ho fatto questa è la prima volta che ho fatto questa in<unk> @ du<unk> @ stri<unk> @ a che la maggi<unk> @ or parte delle persone che i dati , la maggi<unk> @ or parte di cui i dati , la ri<unk> @ es<unk> @ c<unk> @ ita , la maggi<unk> @ or parte di tre tre milioni di persone che hanno sc<unk> @ oper<unk> @ to , il 19<unk> @ 4<unk> @ 8 milioni di anni .
2025-05-27 19:14:23,595 - INFO - joeynmt.training - Example #1
2025-05-27 19:14:23,596 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:14:23,596 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:14:23,596 - INFO - joeynmt.training - 	Hypothesis: Ma non è il problema di questo non è il problema di cui non è il problema di questo che la c<unk> @ ur<unk> @ i<unk> @ den<unk> @ za di questo problema , non è il problema di questo problema , non è il problema di questo problema .
2025-05-27 19:14:23,596 - INFO - joeynmt.training - Example #2
2025-05-27 19:14:23,597 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:14:23,597 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:14:23,597 - INFO - joeynmt.training - 	Hypothesis: In realtà è la ver<unk> @ ità di questo è il sistema di c<unk> @ arb<unk> @ ar<unk> @ o , la nostra c<unk> @ ur<unk> @ ale del nostro sistema sistema di c<unk> @ entr<unk> @ ale .
2025-05-27 19:14:23,597 - INFO - joeynmt.training - Example #3
2025-05-27 19:14:23,598 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:14:23,598 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:14:23,598 - INFO - joeynmt.training - 	Hypothesis: E &apos; stato il tr<unk> @ att<unk> @ ito e la b<unk> @ ella di p<unk> @ oco e e la c<unk> @ ur<unk> @ b<unk> @ a .
2025-05-27 19:14:23,598 - INFO - joeynmt.training - Example #4
2025-05-27 19:14:23,599 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:14:23,599 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:14:23,599 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che ho fatto è il prim<unk> @ o di voi , vi vi vi mostr<unk> @ er<unk> @ ò un pa<unk> @ io di anni fa .
2025-05-27 19:14:26,975 - INFO - joeynmt.training - Epoch   2, Step:    10600, Batch Loss:     1.374650, Batch Acc: 0.620803, Tokens per Sec:    19860, Lr: 0.000300
2025-05-27 19:14:30,406 - INFO - joeynmt.training - Epoch   2, Step:    10700, Batch Loss:     1.422705, Batch Acc: 0.619582, Tokens per Sec:    22628, Lr: 0.000300
2025-05-27 19:14:33,837 - INFO - joeynmt.training - Epoch   2, Step:    10800, Batch Loss:     1.282665, Batch Acc: 0.620323, Tokens per Sec:    22876, Lr: 0.000300
2025-05-27 19:14:37,249 - INFO - joeynmt.training - Epoch   2, Step:    10900, Batch Loss:     1.277033, Batch Acc: 0.621964, Tokens per Sec:    22516, Lr: 0.000300
2025-05-27 19:14:40,686 - INFO - joeynmt.training - Epoch   2, Step:    11000, Batch Loss:     1.345781, Batch Acc: 0.623581, Tokens per Sec:    22770, Lr: 0.000300
2025-05-27 19:14:40,686 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:14:40,687 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 78.44it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 85.30it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 93.67it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:12, 68.16it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 82.17it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:08, 95.92it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 71.67it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 87.62it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:16, 47.45it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 51.84it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 61.88it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.64it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 93.52it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.55it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 70.80it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 75.88it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:10, 61.31it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 54.89it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 53.83it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.02it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 57.35it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 60.02it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.24it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:12, 45.85it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:12, 47.58it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 60.04it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.71it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:08, 65.95it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:07, 71.67it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 71.34it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 84.38it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 94.01it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 101.34it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:04, 87.89it/s] Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.74it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 76.56it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 52.23it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 47.13it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 43.72it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.59it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 39.84it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:10, 29.83it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:12, 25.49it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:08, 34.19it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 38.78it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 40.31it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 41.48it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:11, 22.65it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:10, 24.41it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:08, 29.59it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 28.48it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 30.95it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:08, 26.81it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:07, 29.76it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 32.97it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 34.29it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 44.38it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 37.11it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 39.36it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 50.15it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 55.35it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:01, 69.60it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 75.55it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 59.54it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 57.59it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:00, 73.13it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 59.07it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 75.55it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 82.28it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 113.77it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 55.90it/s] 
2025-05-27 19:14:57,209 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.30, ppl:   3.68, acc:   0.62, generation: 16.5136[sec], evaluation: 0.0000[sec]
2025-05-27 19:14:57,210 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:14:57,840 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/8500.ckpt
2025-05-27 19:14:57,856 - INFO - joeynmt.training - Example #0
2025-05-27 19:14:57,857 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Hypothesis: E ho fatto questa sc<unk> @ oper<unk> @ a questa sc<unk> @ oper<unk> @ a , ho fatto questa s<unk> @ itu<unk> @ azione , che la s<unk> @ itu<unk> @ azione , che la con<unk> @ si<unk> @ der<unk> @ azione , che la s<unk> @ itu<unk> @ azione , che i dati , i dati che hanno fatto i m<unk> @ esso , per tre tre anni , che ho fatto , per 1<unk> @ 5 anni , che ho fatto , ho fatto fatto il 7<unk> @ 0 anni .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - Example #1
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:14:57,858 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è la s<unk> @ itu<unk> @ azione di questo non è la s<unk> @ itu<unk> @ azione di questo prog<unk> @ etto , questa è questo problema di questo problema , non è la maggi<unk> @ ore di questo problema .
2025-05-27 19:14:57,859 - INFO - joeynmt.training - Example #2
2025-05-27 19:14:57,859 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:14:57,859 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:14:57,859 - INFO - joeynmt.training - 	Hypothesis: In realtà è la s<unk> @ itu<unk> @ zione di essere in<unk> @ f<unk> @ lu<unk> @ og<unk> @ en<unk> @ o , la c<unk> @ ult<unk> @ ura della nostra c<unk> @ ult<unk> @ ura .
2025-05-27 19:14:57,860 - INFO - joeynmt.training - Example #3
2025-05-27 19:14:57,860 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:14:57,860 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:14:57,860 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , e poi si chiam<unk> @ a S<unk> @ c<unk> @ r<unk> @ om<unk> @ a .
2025-05-27 19:14:57,860 - INFO - joeynmt.training - Example #4
2025-05-27 19:14:57,861 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:14:57,861 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:14:57,861 - INFO - joeynmt.training - 	Hypothesis: Il prim<unk> @ o che ho fatto è stato stato un gr<unk> @ an s<unk> @ otto di voi , è una cosa che è stato stato stato stato stato stato sc<unk> @ oper<unk> @ to in ulti<unk> @ ma anni fa .
2025-05-27 19:15:01,276 - INFO - joeynmt.training - Epoch   2, Step:    11100, Batch Loss:     1.288755, Batch Acc: 0.625534, Tokens per Sec:    19119, Lr: 0.000300
2025-05-27 19:15:04,735 - INFO - joeynmt.training - Epoch   2, Step:    11200, Batch Loss:     1.280525, Batch Acc: 0.623022, Tokens per Sec:    23102, Lr: 0.000300
2025-05-27 19:15:08,173 - INFO - joeynmt.training - Epoch   2, Step:    11300, Batch Loss:     1.252034, Batch Acc: 0.624469, Tokens per Sec:    22730, Lr: 0.000300
2025-05-27 19:15:11,600 - INFO - joeynmt.training - Epoch   2, Step:    11400, Batch Loss:     1.246595, Batch Acc: 0.625609, Tokens per Sec:    22817, Lr: 0.000300
2025-05-27 19:15:14,968 - INFO - joeynmt.training - Epoch   2, Step:    11500, Batch Loss:     1.240937, Batch Acc: 0.626193, Tokens per Sec:    23623, Lr: 0.000300
2025-05-27 19:15:14,969 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:15:14,969 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 74.53it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 96.48it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 83.06it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 89.77it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.28it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 108.77it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 106.21it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:11, 71.60it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 57.54it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 65.11it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 89.03it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 95.42it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 70.13it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 66.82it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 74.31it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 55.92it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 53.16it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 54.15it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 59.94it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 63.45it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 62.56it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 59.28it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 56.47it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 64.95it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.40it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 90.30it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 98.01it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 97.68it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 96.15it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 100.00it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 98.51it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 90.73it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 91.74it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 74.16it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 81.94it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 51.91it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 43.41it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:10, 32.33it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:08, 38.67it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 32.59it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 32.81it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 32.85it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 41.90it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 42.85it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 42.50it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 39.12it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 33.34it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 32.73it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 37.75it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 27.86it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 31.64it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.11it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 37.66it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 39.10it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 47.62it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 57.15it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:03, 47.86it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 46.68it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 55.09it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 58.36it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 68.82it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 77.42it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 78.30it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 63.52it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 56.40it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 68.47it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 76.82it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 87.88it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.09it/s]
2025-05-27 19:15:30,342 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.29, ppl:   3.62, acc:   0.63, generation: 15.3600[sec], evaluation: 0.0000[sec]
2025-05-27 19:15:30,343 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:15:30,864 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/9000.ckpt
2025-05-27 19:15:30,887 - INFO - joeynmt.training - Example #0
2025-05-27 19:15:30,888 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:15:30,888 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:15:30,888 - INFO - joeynmt.training - 	Hypothesis: La m<unk> @ app<unk> @ a di questa fot<unk> @ o , ho fatto questa fot<unk> @ o , per la c<unk> @ ur<unk> @ ezza , che la c<unk> @ ur<unk> @ i<unk> @ va , che la c<unk> @ ur<unk> @ ezza , la c<unk> @ ur<unk> @ azione , il m<unk> @ oti<unk> @ vo , il m<unk> @ oti<unk> @ vo per tre anni , il 4<unk> @ 4<unk> @ 0 e i 4<unk> @ 0 e i 4<unk> @ 0 anni .
2025-05-27 19:15:30,889 - INFO - joeynmt.training - Example #1
2025-05-27 19:15:30,889 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:15:30,890 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:15:30,890 - INFO - joeynmt.training - 	Hypothesis: Ma questo , non è un problema di c<unk> @ ur<unk> @ i<unk> @ ente , il ris<unk> @ chio di in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ ità di questo problema , non è il problema di non è il problema di cui non è il fatto di un problema .
2025-05-27 19:15:30,890 - INFO - joeynmt.training - Example #2
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Hypothesis: In eff<unk> @ etti , la c<unk> @ a<unk> @ zza è la c<unk> @ ris<unk> @ ol<unk> @ vere il modo di essere in<unk> @ cre<unk> @ di<unk> @ to di una c<unk> @ ura di c<unk> @ li<unk> @ ma di c<unk> @ li<unk> @ ma .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - Example #3
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di s<unk> @ etti<unk> @ man<unk> @ e e di l<unk> @ ei si chiam<unk> @ a &quot; .
2025-05-27 19:15:30,891 - INFO - joeynmt.training - Example #4
2025-05-27 19:15:30,892 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:15:30,892 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:15:30,892 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ a la prima cosa che vi mostr<unk> @ a una cosa che vi mostr<unk> @ a una cosa che è una cosa che è che è stato un gr<unk> @ u<unk> @ ppo di anni .
2025-05-27 19:15:34,330 - INFO - joeynmt.training - Epoch   2, Step:    11600, Batch Loss:     1.318744, Batch Acc: 0.628237, Tokens per Sec:    20348, Lr: 0.000300
2025-05-27 19:15:37,755 - INFO - joeynmt.training - Epoch   2, Step:    11700, Batch Loss:     1.315692, Batch Acc: 0.623407, Tokens per Sec:    23674, Lr: 0.000300
2025-05-27 19:15:41,165 - INFO - joeynmt.training - Epoch   2, Step:    11800, Batch Loss:     1.257781, Batch Acc: 0.628644, Tokens per Sec:    23221, Lr: 0.000300
2025-05-27 19:15:44,572 - INFO - joeynmt.training - Epoch   2, Step:    11900, Batch Loss:     1.322094, Batch Acc: 0.629743, Tokens per Sec:    23623, Lr: 0.000300
2025-05-27 19:15:47,978 - INFO - joeynmt.training - Epoch   2, Step:    12000, Batch Loss:     1.352537, Batch Acc: 0.632918, Tokens per Sec:    23837, Lr: 0.000300
2025-05-27 19:15:47,978 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:15:47,978 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 81.35it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 81.84it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 89.50it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 98.80it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 112.68it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 113.95it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:08, 90.37it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:10, 72.15it/s]Predicting...:  20%|██        | 185/923 [00:01<00:07, 99.44it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 107.51it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 88.98it/s] Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 77.75it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:08, 82.07it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 51.66it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 52.32it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:12, 52.07it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 57.48it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 60.34it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 65.14it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:10, 57.14it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:10, 54.91it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:08, 65.49it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 85.94it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 102.98it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 108.03it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 86.86it/s] Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 94.20it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 96.09it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 88.20it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 98.94it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 71.27it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 81.77it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 57.05it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 48.17it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 54.97it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 43.96it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 45.26it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 55.05it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 54.86it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 49.49it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:05, 46.40it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 38.73it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 37.52it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 38.15it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 32.92it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 34.47it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 26.59it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:06, 33.82it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 35.24it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 46.26it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 57.23it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 45.41it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 55.24it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 59.44it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 81.57it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 81.46it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 71.70it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 61.28it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 74.79it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 76.71it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 88.42it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 65.42it/s]
2025-05-27 19:16:02,097 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.28, ppl:   3.58, acc:   0.63, generation: 14.1092[sec], evaluation: 0.0000[sec]
2025-05-27 19:16:02,097 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:16:02,702 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/9500.ckpt
2025-05-27 19:16:02,725 - INFO - joeynmt.training - Example #0
2025-05-27 19:16:02,726 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:16:02,726 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:16:02,726 - INFO - joeynmt.training - 	Hypothesis: E in questo anno , ho visto questa è la sc<unk> @ or<unk> @ sa , che la p<unk> @ an<unk> @ ca che è che il m<unk> @ ezz<unk> @ o di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di un anno , tre milioni di persone che hanno sc<unk> @ oper<unk> @ to che hanno sc<unk> @ oper<unk> @ to il 4<unk> @ 4<unk> @ 4<unk> @ 4<unk> @ 8 milioni di doll<unk> @ ari .
2025-05-27 19:16:02,726 - INFO - joeynmt.training - Example #1
2025-05-27 19:16:02,727 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:16:02,727 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:16:02,727 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa che è che non è la s<unk> @ itu<unk> @ azione , che non è la s<unk> @ itu<unk> @ azione di questo .
2025-05-27 19:16:02,727 - INFO - joeynmt.training - Example #2
2025-05-27 19:16:02,728 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:16:02,728 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:16:02,728 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà è la s<unk> @ fi<unk> @ da è la c<unk> @ aus<unk> @ a di una c<unk> @ aus<unk> @ a della c<unk> @ at<unk> @ ura .
2025-05-27 19:16:02,728 - INFO - joeynmt.training - Example #3
2025-05-27 19:16:02,729 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:16:02,729 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:16:02,729 - INFO - joeynmt.training - 	Hypothesis: V<unk> @ e<unk> @ dete , e la sc<unk> @ or<unk> @ sa e la sc<unk> @ or<unk> @ sa .
2025-05-27 19:16:02,729 - INFO - joeynmt.training - Example #4
2025-05-27 19:16:02,730 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:16:02,730 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:16:02,730 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ er<unk> @ ò la prima volta che vi mostr<unk> @ er<unk> @ ò una cosa che è succ<unk> @ esso in cui è succ<unk> @ esso .
2025-05-27 19:16:06,128 - INFO - joeynmt.training - Epoch   2, Step:    12100, Batch Loss:     1.270924, Batch Acc: 0.626987, Tokens per Sec:    20025, Lr: 0.000300
2025-05-27 19:16:09,534 - INFO - joeynmt.training - Epoch   2, Step:    12200, Batch Loss:     1.330685, Batch Acc: 0.629300, Tokens per Sec:    22922, Lr: 0.000300
2025-05-27 19:16:12,852 - INFO - joeynmt.training - Epoch   2, Step:    12300, Batch Loss:     1.254413, Batch Acc: 0.635443, Tokens per Sec:    23225, Lr: 0.000300
2025-05-27 19:16:16,171 - INFO - joeynmt.training - Epoch   2, Step:    12400, Batch Loss:     1.175360, Batch Acc: 0.630482, Tokens per Sec:    24182, Lr: 0.000300
2025-05-27 19:16:19,508 - INFO - joeynmt.training - Epoch   2, Step:    12500, Batch Loss:     1.258564, Batch Acc: 0.635196, Tokens per Sec:    24393, Lr: 0.000300
2025-05-27 19:16:19,509 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:16:19,509 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 89.41it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:06, 142.62it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:05, 143.71it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:05, 154.90it/s]Predicting...:  14%|█▍        | 127/923 [00:00<00:06, 119.40it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:08, 91.78it/s] Predicting...:  20%|██        | 185/923 [00:01<00:06, 115.22it/s]Predicting...:  23%|██▎       | 211/923 [00:01<00:06, 112.78it/s]Predicting...:  24%|██▍       | 224/923 [00:01<00:06, 109.47it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:06, 102.78it/s]Predicting...:  29%|██▉       | 267/923 [00:02<00:08, 75.58it/s] Predicting...:  30%|███       | 277/923 [00:02<00:08, 73.12it/s]Predicting...:  31%|███▏      | 289/923 [00:02<00:08, 74.64it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 75.94it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 74.80it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 79.50it/s]Predicting...:  37%|███▋      | 337/923 [00:03<00:08, 72.37it/s]Predicting...:  38%|███▊      | 347/923 [00:03<00:08, 70.11it/s]Predicting...:  39%|███▉      | 361/923 [00:03<00:06, 82.71it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:04, 115.51it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 119.93it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 115.48it/s]Predicting...:  49%|████▉     | 455/923 [00:04<00:03, 127.54it/s]Predicting...:  51%|█████     | 469/923 [00:04<00:03, 129.01it/s]Predicting...:  54%|█████▎    | 494/923 [00:04<00:04, 104.99it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 95.28it/s] Predicting...:  59%|█████▊    | 540/923 [00:05<00:04, 91.16it/s]Predicting...:  60%|██████    | 556/923 [00:05<00:05, 64.71it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:05, 64.27it/s]Predicting...:  63%|██████▎   | 580/923 [00:06<00:04, 69.80it/s]Predicting...:  65%|██████▍   | 596/923 [00:06<00:06, 51.52it/s]Predicting...:  67%|██████▋   | 618/923 [00:06<00:04, 64.27it/s]Predicting...:  68%|██████▊   | 630/923 [00:07<00:04, 63.44it/s]Predicting...:  69%|██████▉   | 639/923 [00:07<00:05, 54.44it/s]Predicting...:  70%|███████   | 647/923 [00:07<00:05, 52.86it/s]Predicting...:  71%|███████   | 653/923 [00:07<00:05, 53.00it/s]Predicting...:  72%|███████▏  | 661/923 [00:07<00:05, 48.51it/s]Predicting...:  73%|███████▎  | 671/923 [00:08<00:04, 51.50it/s]Predicting...:  73%|███████▎  | 678/923 [00:08<00:05, 44.21it/s]Predicting...:  74%|███████▍  | 687/923 [00:08<00:04, 47.33it/s]Predicting...:  75%|███████▌  | 696/923 [00:08<00:05, 40.74it/s]Predicting...:  77%|███████▋  | 708/923 [00:08<00:04, 52.65it/s]Predicting...:  78%|███████▊  | 717/923 [00:09<00:04, 48.22it/s]Predicting...:  79%|███████▉  | 729/923 [00:09<00:03, 60.90it/s]Predicting...:  80%|████████  | 742/923 [00:09<00:02, 73.99it/s]Predicting...:  82%|████████▏ | 759/923 [00:09<00:02, 56.02it/s]Predicting...:  84%|████████▍ | 774/923 [00:09<00:02, 66.69it/s]Predicting...:  85%|████████▌ | 786/923 [00:10<00:01, 70.72it/s]Predicting...:  88%|████████▊ | 815/923 [00:10<00:01, 76.81it/s]Predicting...:  90%|████████▉ | 827/923 [00:10<00:01, 80.78it/s]Predicting...:  92%|█████████▏| 850/923 [00:11<00:01, 61.51it/s]Predicting...:  93%|█████████▎| 862/923 [00:11<00:00, 63.75it/s]Predicting...:  97%|█████████▋| 892/923 [00:11<00:00, 80.21it/s]Predicting...: 100%|██████████| 923/923 [00:11<00:00, 103.62it/s]Predicting...: 100%|██████████| 923/923 [00:11<00:00, 79.66it/s] 
2025-05-27 19:16:31,105 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.27, ppl:   3.55, acc:   0.63, generation: 11.5872[sec], evaluation: 0.0000[sec]
2025-05-27 19:16:31,105 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:16:31,593 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/10000.ckpt
2025-05-27 19:16:31,610 - INFO - joeynmt.training - Example #0
2025-05-27 19:16:31,612 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:16:31,612 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:16:31,612 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho fatto questa fot<unk> @ o , ho fatto questa fot<unk> @ o , ho fatto questa fot<unk> @ o che la c<unk> @ av<unk> @ e la sc<unk> @ u<unk> @ ola che ha ri<unk> @ guar<unk> @ do che la c<unk> @ av<unk> @ e per le persone che hanno ri<unk> @ m<unk> @ ett<unk> @ amente c<unk> @ ent<unk> @ in<unk> @ a<unk> @ io , per tre anni , per la città di 1<unk> @ 8 anni .
2025-05-27 19:16:31,612 - INFO - joeynmt.training - Example #1
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il modo di in<unk> @ cre<unk> @ di<unk> @ bile che non è la con<unk> @ fer<unk> @ enza di questa in<unk> @ f<unk> @ lu<unk> @ enza non è il fatto che non è il problema di questo che non è il fatto che non è il problema .
2025-05-27 19:16:31,613 - INFO - joeynmt.training - Example #2
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:16:31,613 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà è la maggi<unk> @ or parte di un s<unk> @ ac<unk> @ co di in<unk> @ tel<unk> @ li<unk> @ gen<unk> @ za , il sistema di c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - Example #3
2025-05-27 19:16:31,614 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - 	Hypothesis: E &apos; stato in realtà , e la s<unk> @ etti<unk> @ man<unk> @ a e la b<unk> @ om<unk> @ ma .
2025-05-27 19:16:31,614 - INFO - joeynmt.training - Example #4
2025-05-27 19:16:31,615 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:16:31,615 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:16:31,615 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ o la prima volta che vi mostr<unk> @ i la prima volta che vi mostr<unk> @ a la prima volta che ha fatto .
2025-05-27 19:16:34,920 - INFO - joeynmt.training - Epoch   2, Step:    12600, Batch Loss:     1.276156, Batch Acc: 0.633897, Tokens per Sec:    20594, Lr: 0.000300
2025-05-27 19:16:38,231 - INFO - joeynmt.training - Epoch   2, Step:    12700, Batch Loss:     1.247316, Batch Acc: 0.635895, Tokens per Sec:    23852, Lr: 0.000300
2025-05-27 19:16:41,574 - INFO - joeynmt.training - Epoch   2, Step:    12800, Batch Loss:     1.289197, Batch Acc: 0.634785, Tokens per Sec:    24327, Lr: 0.000300
2025-05-27 19:16:44,879 - INFO - joeynmt.training - Epoch   2, Step:    12900, Batch Loss:     1.282854, Batch Acc: 0.632701, Tokens per Sec:    23924, Lr: 0.000300
2025-05-27 19:16:48,186 - INFO - joeynmt.training - Epoch   2, Step:    13000, Batch Loss:     1.281909, Batch Acc: 0.633186, Tokens per Sec:    23579, Lr: 0.000300
2025-05-27 19:16:48,187 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:16:48,187 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:08, 104.31it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 97.76it/s] Predicting...:   6%|▌         | 56/923 [00:00<00:06, 126.36it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:05, 146.32it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:08, 96.12it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:09, 87.21it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:10, 75.54it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.61it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:07, 90.22it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 92.26it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:09, 69.21it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:09, 74.56it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:09, 66.95it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 63.89it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 64.02it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 58.79it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 67.22it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 68.92it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 69.58it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 64.51it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 62.35it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 74.95it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:04, 109.29it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 111.62it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 107.73it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 120.47it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:03, 118.26it/s]Predicting...:  52%|█████▏    | 480/923 [00:05<00:03, 118.68it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:03, 118.18it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 87.55it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 82.42it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:05, 64.84it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:05, 61.44it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 53.80it/s]Predicting...:  64%|██████▎   | 587/923 [00:07<00:08, 40.21it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:07, 41.55it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:07, 44.42it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 54.54it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 52.16it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 47.49it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:06, 45.74it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 37.36it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 36.94it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 41.70it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 39.70it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:05, 41.36it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:05, 42.75it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:03, 54.21it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:04, 48.43it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 59.46it/s]Predicting...:  81%|████████  | 749/923 [00:10<00:02, 66.19it/s]Predicting...:  82%|████████▏ | 759/923 [00:10<00:02, 63.77it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 72.40it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:01, 75.08it/s]Predicting...:  87%|████████▋ | 800/923 [00:11<00:01, 85.71it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 96.90it/s]Predicting...:  90%|█████████ | 835/923 [00:11<00:01, 79.17it/s]Predicting...:  92%|█████████▏| 850/923 [00:11<00:00, 86.41it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 75.75it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 96.97it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 126.20it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 73.51it/s] 
2025-05-27 19:17:00,752 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.26, ppl:   3.53, acc:   0.64, generation: 12.5565[sec], evaluation: 0.0000[sec]
2025-05-27 19:17:00,752 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:17:01,412 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/10500.ckpt
2025-05-27 19:17:01,436 - INFO - joeynmt.training - Example #0
2025-05-27 19:17:01,438 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:17:01,438 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:17:01,438 - INFO - joeynmt.training - 	Hypothesis: E &apos; in<unk> @ fine , ho sc<unk> @ oper<unk> @ to questo , ho fatto che la m<unk> @ em<unk> @ br<unk> @ a che la c<unk> @ aus<unk> @ a di un ar<unk> @ g<unk> @ omento di c<unk> @ aus<unk> @ a di c<unk> @ ent<unk> @ in<unk> @ azione , per tre tre milioni di anni , per tre tre milioni di anni , per la città di circa 4<unk> @ 0 , il 1<unk> @ 8 milioni di doll<unk> @ ari .
2025-05-27 19:17:01,438 - INFO - joeynmt.training - Example #1
2025-05-27 19:17:01,439 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:17:01,439 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:17:01,439 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il problema di non è che non è la la prima cosa che la ris<unk> @ ol<unk> @ vere il problema di questo problema .
2025-05-27 19:17:01,439 - INFO - joeynmt.training - Example #2
2025-05-27 19:17:01,440 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:17:01,440 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:17:01,440 - INFO - joeynmt.training - 	Hypothesis: In realtà , la realtà è la n<unk> @ ec<unk> @ ess<unk> @ a è la c<unk> @ at<unk> @ ura del nostro sistema sistema sistema sistema di di<unk> @ ag<unk> @ n<unk> @ et<unk> @ ico .
2025-05-27 19:17:01,440 - INFO - joeynmt.training - Example #3
2025-05-27 19:17:01,441 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:17:01,441 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:17:01,441 - INFO - joeynmt.training - 	Hypothesis: E &apos; in<unk> @ tr<unk> @ ac<unk> @ ci<unk> @ ano e il p<unk> @ om<unk> @ e .
2025-05-27 19:17:01,441 - INFO - joeynmt.training - Example #4
2025-05-27 19:17:01,441 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:17:01,442 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:17:01,442 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma che vi mostr<unk> @ o la prima volta che vi mostr<unk> @ i una di una c<unk> @ ent<unk> @ u<unk> @ ale che è stata la prima volta che è stata la prima prima volta .
2025-05-27 19:17:04,865 - INFO - joeynmt.training - Epoch   2, Step:    13100, Batch Loss:     1.233199, Batch Acc: 0.637396, Tokens per Sec:    19290, Lr: 0.000300
2025-05-27 19:17:08,201 - INFO - joeynmt.training - Epoch   2, Step:    13200, Batch Loss:     1.162460, Batch Acc: 0.637399, Tokens per Sec:    23379, Lr: 0.000300
2025-05-27 19:17:11,590 - INFO - joeynmt.training - Epoch   2, Step:    13300, Batch Loss:     1.349093, Batch Acc: 0.637342, Tokens per Sec:    23965, Lr: 0.000300
2025-05-27 19:17:14,998 - INFO - joeynmt.training - Epoch   2, Step:    13400, Batch Loss:     1.283956, Batch Acc: 0.638644, Tokens per Sec:    23864, Lr: 0.000300
2025-05-27 19:17:18,418 - INFO - joeynmt.training - Epoch   2, Step:    13500, Batch Loss:     1.285493, Batch Acc: 0.638752, Tokens per Sec:    23547, Lr: 0.000300
2025-05-27 19:17:18,418 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:17:18,418 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:16, 53.58it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:13, 68.82it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 82.61it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 89.49it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 93.48it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 102.46it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 103.62it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 111.32it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:13, 57.49it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 61.92it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:10, 69.40it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 86.39it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 93.59it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 74.14it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:09, 74.31it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 78.35it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 59.26it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 51.28it/s]Predicting...:  30%|███       | 277/923 [00:03<00:13, 49.34it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.39it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 54.62it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.44it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 59.66it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:12, 47.46it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:12, 45.94it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 53.87it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 68.83it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 79.33it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 81.19it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 87.37it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 97.41it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 91.06it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 91.12it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 76.32it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 78.60it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 52.70it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 61.84it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 68.51it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 56.40it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 48.51it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 42.43it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 44.56it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.27it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 45.45it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 37.14it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 51.45it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 48.92it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 42.09it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.86it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 30.96it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 32.05it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 34.98it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.23it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 32.96it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 28.75it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 36.74it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.78it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 43.34it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 52.89it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 43.49it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 42.06it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 49.88it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 58.59it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 69.67it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 60.36it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 63.41it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 59.48it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 65.74it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 60.19it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 71.23it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 78.18it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 87.77it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.39it/s]
2025-05-27 19:17:33,974 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.25, ppl:   3.49, acc:   0.64, generation: 15.5428[sec], evaluation: 0.0000[sec]
2025-05-27 19:17:33,975 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:17:34,547 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/11000.ckpt
2025-05-27 19:17:34,569 - INFO - joeynmt.training - Example #0
2025-05-27 19:17:34,571 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:17:34,571 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:17:34,571 - INFO - joeynmt.training - 	Hypothesis: E ho fatto che ho fatto questa fot<unk> @ o , ho fatto questa fot<unk> @ o , che la p<unk> @ es<unk> @ sione di p<unk> @ es<unk> @ c<unk> @ ente , che la p<unk> @ es<unk> @ sione di tre milioni di anni , che la qu<unk> @ ale di tre milioni di anni , per tre milioni di anni , per tre milioni di anni , per tre milioni di anni , per c<unk> @ ento di anni , per c<unk> @ ento , per tre milioni di anni .
2025-05-27 19:17:34,571 - INFO - joeynmt.training - Example #1
2025-05-27 19:17:34,572 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:17:34,572 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:17:34,572 - INFO - joeynmt.training - 	Hypothesis: Ma non è una cosa che non è il problema di cui non è la n<unk> @ ec<unk> @ ess<unk> @ ità di questo problema .
2025-05-27 19:17:34,572 - INFO - joeynmt.training - Example #2
2025-05-27 19:17:34,573 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:17:34,573 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:17:34,573 - INFO - joeynmt.training - 	Hypothesis: In realtà , è il sistema è il sistema di s<unk> @ es<unk> @ im<unk> @ o è il sistema di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:17:34,573 - INFO - joeynmt.training - Example #3
2025-05-27 19:17:34,574 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:17:34,574 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:17:34,574 - INFO - joeynmt.training - 	Hypothesis: E &apos; in l<unk> @ ei s<unk> @ otto , e in gi<unk> @ ro .
2025-05-27 19:17:34,574 - INFO - joeynmt.training - Example #4
2025-05-27 19:17:34,575 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:17:34,575 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:17:34,575 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ er<unk> @ ò una cosa che vi mostr<unk> @ a una cosa che ho fatto una cosa che è una cosa che ha fatto .
2025-05-27 19:17:38,009 - INFO - joeynmt.training - Epoch   2, Step:    13600, Batch Loss:     1.268145, Batch Acc: 0.640567, Tokens per Sec:    19682, Lr: 0.000300
2025-05-27 19:17:41,448 - INFO - joeynmt.training - Epoch   2, Step:    13700, Batch Loss:     1.313471, Batch Acc: 0.639062, Tokens per Sec:    23129, Lr: 0.000300
2025-05-27 19:17:44,854 - INFO - joeynmt.training - Epoch   2, Step:    13800, Batch Loss:     1.204301, Batch Acc: 0.639151, Tokens per Sec:    23067, Lr: 0.000300
2025-05-27 19:17:48,287 - INFO - joeynmt.training - Epoch   2, Step:    13900, Batch Loss:     1.198202, Batch Acc: 0.639215, Tokens per Sec:    23524, Lr: 0.000300
2025-05-27 19:17:51,705 - INFO - joeynmt.training - Epoch   2, Step:    14000, Batch Loss:     1.249046, Batch Acc: 0.639392, Tokens per Sec:    23392, Lr: 0.000300
2025-05-27 19:17:51,705 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:17:51,705 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 77.16it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.89it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 88.93it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:13, 63.95it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:11, 73.76it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 90.44it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 87.61it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 102.83it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 53.90it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 57.87it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 67.01it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.01it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.88it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 76.31it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 71.67it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 73.24it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 58.34it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 52.49it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 50.87it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 48.77it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.84it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 53.15it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 58.26it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 50.77it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 48.16it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 55.69it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 72.50it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 77.88it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 80.52it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 78.82it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 91.23it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 80.13it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 75.70it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 63.59it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 71.67it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 55.53it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 64.66it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:06, 65.24it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 57.00it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 48.03it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 39.33it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 36.45it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:09, 36.60it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 32.30it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:11, 29.71it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:10, 30.48it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:08, 37.72it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 41.89it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.12it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 37.39it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 30.91it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 30.65it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:07, 33.93it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:07, 31.71it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:06, 36.07it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:06, 36.02it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:04, 45.15it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:04, 43.00it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:03, 50.47it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:02, 62.83it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 54.46it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 66.05it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:01, 71.05it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 81.30it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 91.50it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 85.11it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:00, 74.76it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 76.17it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 94.73it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 103.10it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.94it/s] 
2025-05-27 19:18:07,113 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.24, ppl:   3.46, acc:   0.64, generation: 15.3995[sec], evaluation: 0.0000[sec]
2025-05-27 19:18:07,114 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:18:07,602 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/11500.ckpt
2025-05-27 19:18:07,626 - INFO - joeynmt.training - Example #0
2025-05-27 19:18:07,627 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:18:07,627 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:18:07,627 - INFO - joeynmt.training - 	Hypothesis: E la fine , ho fatto questa è la mia f<unk> @ est<unk> @ a , ho mostr<unk> @ ato che la f<unk> @ ant<unk> @ as<unk> @ c<unk> @ ita , che la g<unk> @ over<unk> @ n<unk> @ on<unk> @ al<unk> @ ia di milioni di doll<unk> @ ari , che i dati per i 1<unk> @ 8 milioni di doll<unk> @ ari , che hanno av<unk> @ uto per i dati , per c<unk> @ ento di 1<unk> @ 8 milioni di doll<unk> @ ari , per c<unk> @ ento , il 4<unk> @ 0 % .
2025-05-27 19:18:07,627 - INFO - joeynmt.training - Example #1
2025-05-27 19:18:07,628 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:18:07,628 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:18:07,628 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il fatto che non è il fatto di questo non è il ris<unk> @ chio di ris<unk> @ ol<unk> @ vere questo problema di queste cose che non è il problema di questo non è il problema di questo che non è il problema di questo non è il mondo .
2025-05-27 19:18:07,628 - INFO - joeynmt.training - Example #2
2025-05-27 19:18:07,629 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:18:07,629 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:18:07,629 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ fi<unk> @ da è la s<unk> @ fi<unk> @ da è il sistema di in<unk> @ f<unk> @ lu<unk> @ og<unk> @ o del sistema di c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:18:07,629 - INFO - joeynmt.training - Example #3
2025-05-27 19:18:07,630 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:18:07,630 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:18:07,630 - INFO - joeynmt.training - 	Hypothesis: E si è in un s<unk> @ ac<unk> @ co di s<unk> @ é .
2025-05-27 19:18:07,630 - INFO - joeynmt.training - Example #4
2025-05-27 19:18:07,631 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:18:07,631 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:18:07,631 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostr<unk> @ er<unk> @ ò che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ aus<unk> @ a di questa è una cosa che è succ<unk> @ essi<unk> @ va in cin<unk> @ que anni .
2025-05-27 19:18:11,036 - INFO - joeynmt.training - Epoch   2, Step:    14100, Batch Loss:     1.259939, Batch Acc: 0.641321, Tokens per Sec:    20386, Lr: 0.000300
2025-05-27 19:18:14,430 - INFO - joeynmt.training - Epoch   2, Step:    14200, Batch Loss:     1.233723, Batch Acc: 0.643578, Tokens per Sec:    22989, Lr: 0.000300
2025-05-27 19:18:17,816 - INFO - joeynmt.training - Epoch   2, Step:    14300, Batch Loss:     1.247798, Batch Acc: 0.645113, Tokens per Sec:    23875, Lr: 0.000300
2025-05-27 19:18:21,194 - INFO - joeynmt.training - Epoch   2, Step:    14400, Batch Loss:     1.268963, Batch Acc: 0.643792, Tokens per Sec:    23719, Lr: 0.000300
2025-05-27 19:18:24,600 - INFO - joeynmt.training - Epoch   2, Step:    14500, Batch Loss:     1.158336, Batch Acc: 0.644444, Tokens per Sec:    23586, Lr: 0.000300
2025-05-27 19:18:24,600 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:18:24,601 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 70.45it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 74.19it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 81.25it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 85.49it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 93.09it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 102.97it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 102.20it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 82.46it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 46.95it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 51.81it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 61.21it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.07it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 91.99it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 76.66it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 65.97it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 73.95it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:10, 61.40it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 53.41it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 48.00it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.40it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 54.02it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.73it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 59.35it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 51.74it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 49.98it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 58.79it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 75.77it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 84.94it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 83.80it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 83.14it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 92.80it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 89.63it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 92.84it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.60it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 75.19it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 59.69it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.29it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 73.82it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 57.94it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 44.66it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 38.03it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 37.40it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 45.52it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 36.96it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 37.64it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.53it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 47.45it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:05, 50.69it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 46.03it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 43.31it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 34.96it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 33.57it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 38.87it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.68it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.24it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 31.41it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 40.12it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 38.45it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 44.77it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 54.04it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:06, 28.10it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:05, 31.48it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 40.47it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 49.79it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 61.71it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 68.26it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 71.74it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 70.76it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 67.24it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 79.92it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 81.01it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 91.46it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.75it/s]
2025-05-27 19:18:40,325 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.23, ppl:   3.42, acc:   0.65, generation: 15.7110[sec], evaluation: 0.0000[sec]
2025-05-27 19:18:40,325 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:18:40,997 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/12000.ckpt
2025-05-27 19:18:41,023 - INFO - joeynmt.training - Example #0
2025-05-27 19:18:41,024 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:18:41,024 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:18:41,025 - INFO - joeynmt.training - 	Hypothesis: E ho fatto questa parte di questi due anni , ho fatto , ho fatto questa è la p<unk> @ op<unk> @ ol<unk> @ azione per la prima volta che i dati i dati i dati in gra<unk> @ do di f<unk> @ ar s<unk> @ ì che i dati sono tre gior<unk> @ n<unk> @ ali per i tre anni , per i dati , tre tre m<unk> @ oti<unk> @ vi per i dati , tre anni , per i dati , per i dati , per i dati , per i dati , per i dati .
2025-05-27 19:18:41,025 - INFO - joeynmt.training - Example #1
2025-05-27 19:18:41,026 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:18:41,026 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:18:41,026 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa che non è che è il fatto di questo che non è il con<unk> @ si<unk> @ der<unk> @ ato di questo problema , non è il problema di questo problema .
2025-05-27 19:18:41,026 - INFO - joeynmt.training - Example #2
2025-05-27 19:18:41,027 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:18:41,027 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:18:41,027 - INFO - joeynmt.training - 	Hypothesis: In realtà , che è la s<unk> @ fi<unk> @ da è la s<unk> @ in<unk> @ azione di c<unk> @ li<unk> @ vello glob<unk> @ ale del sistema glob<unk> @ ale glob<unk> @ ale , il sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:18:41,027 - INFO - joeynmt.training - Example #3
2025-05-27 19:18:41,027 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e in realtà , e in s<unk> @ etti<unk> @ man<unk> @ a .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - Example #4
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:18:41,028 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò un pa<unk> @ io di anni fa .
2025-05-27 19:18:44,438 - INFO - joeynmt.training - Epoch   2, Step:    14600, Batch Loss:     1.406981, Batch Acc: 0.643522, Tokens per Sec:    19286, Lr: 0.000300
2025-05-27 19:18:47,853 - INFO - joeynmt.training - Epoch   2, Step:    14700, Batch Loss:     1.265407, Batch Acc: 0.644272, Tokens per Sec:    24064, Lr: 0.000300
2025-05-27 19:18:51,234 - INFO - joeynmt.training - Epoch   2, Step:    14800, Batch Loss:     1.291039, Batch Acc: 0.642656, Tokens per Sec:    23050, Lr: 0.000300
2025-05-27 19:18:54,637 - INFO - joeynmt.training - Epoch   2, Step:    14900, Batch Loss:     1.365782, Batch Acc: 0.646855, Tokens per Sec:    23338, Lr: 0.000300
2025-05-27 19:18:58,031 - INFO - joeynmt.training - Epoch   2, Step:    15000, Batch Loss:     1.359763, Batch Acc: 0.643470, Tokens per Sec:    23562, Lr: 0.000300
2025-05-27 19:18:58,031 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:18:58,031 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 66.34it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 76.09it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 78.89it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:12, 67.37it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 79.25it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 91.44it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 89.25it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:10, 76.70it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 43.11it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 48.35it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 57.97it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 82.10it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.60it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 68.71it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 62.11it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 66.91it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:13, 50.09it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:14, 45.03it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 46.22it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 44.31it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:13, 47.10it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 52.12it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 55.05it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 49.45it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 48.47it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:09, 57.95it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 74.94it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 80.60it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 83.37it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 85.06it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 94.01it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 93.81it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:04, 94.02it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 79.90it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 76.44it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 58.44it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 65.79it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 73.08it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 60.96it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 48.62it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 42.93it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:08, 40.91it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 48.46it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 33.09it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:10, 32.16it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 33.67it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 42.36it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 43.92it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 40.13it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 36.37it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:13, 19.41it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:12, 20.99it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:09, 26.09it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 24.98it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:08, 27.23it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:09, 24.87it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 33.55it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:06, 33.47it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:04, 39.98it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 49.60it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 41.04it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:03, 41.63it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:02, 50.92it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 55.13it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:01, 62.56it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 71.64it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 71.09it/s]Predicting...:  90%|█████████ | 835/923 [00:16<00:01, 49.25it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 60.05it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 58.86it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 72.98it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 75.90it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 86.24it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 54.18it/s]
2025-05-27 19:19:15,082 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.22, ppl:   3.39, acc:   0.65, generation: 17.0377[sec], evaluation: 0.0000[sec]
2025-05-27 19:19:15,083 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:19:15,676 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/12500.ckpt
2025-05-27 19:19:15,696 - INFO - joeynmt.training - Example #0
2025-05-27 19:19:15,698 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:19:15,698 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:19:15,698 - INFO - joeynmt.training - 	Hypothesis: E questo pa<unk> @ io ho fatto questa fot<unk> @ o , ho fatto questa fot<unk> @ o per mostr<unk> @ are che la m<unk> @ app<unk> @ a per i g<unk> @ am<unk> @ enti che i g<unk> @ am<unk> @ enti per i tre mili<unk> @ ar<unk> @ di di di persone per tre anni , per tre milioni di anni , per tre tre mili<unk> @ ar<unk> @ di di di anni , per per c<unk> @ ento , per tre mili<unk> @ ar<unk> @ di di di anni , per c<unk> @ ento .
2025-05-27 19:19:15,698 - INFO - joeynmt.training - Example #1
2025-05-27 19:19:15,699 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:19:15,699 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:19:15,699 - INFO - joeynmt.training - 	Hypothesis: Ma non questo non è il fatto di questo non è il fatto di questo che la con<unk> @ n<unk> @ as<unk> @ c<unk> @ ita di queste cell<unk> @ ule che non è il problema di queste cell<unk> @ ule che non è il li<unk> @ vello di in<unk> @ f<unk> @ lu<unk> @ enza .
2025-05-27 19:19:15,699 - INFO - joeynmt.training - Example #2
2025-05-27 19:19:15,700 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:19:15,700 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:19:15,700 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la s<unk> @ fi<unk> @ da è la nostra in<unk> @ f<unk> @ am<unk> @ ig<unk> @ lia di sistema soci<unk> @ ale , il sistema di c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:19:15,700 - INFO - joeynmt.training - Example #3
2025-05-27 19:19:15,701 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:19:15,701 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:19:15,701 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e il s<unk> @ ito di s<unk> @ om<unk> @ e , e in gra<unk> @ do di s<unk> @ om<unk> @ e .
2025-05-27 19:19:15,701 - INFO - joeynmt.training - Example #4
2025-05-27 19:19:15,702 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:19:15,702 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:19:15,702 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o la prima volta che vi mostr<unk> @ o una delle due anni fa , è una cosa che succ<unk> @ ede in cui la prima volta , che è succ<unk> @ esso in 2<unk> @ 5 anni fa .
2025-05-27 19:19:19,104 - INFO - joeynmt.training - Epoch   2, Step:    15100, Batch Loss:     1.179104, Batch Acc: 0.653630, Tokens per Sec:    19793, Lr: 0.000300
2025-05-27 19:19:22,498 - INFO - joeynmt.training - Epoch   2, Step:    15200, Batch Loss:     1.147978, Batch Acc: 0.647779, Tokens per Sec:    23468, Lr: 0.000300
2025-05-27 19:19:25,859 - INFO - joeynmt.training - Epoch   2, Step:    15300, Batch Loss:     1.260328, Batch Acc: 0.646384, Tokens per Sec:    23284, Lr: 0.000300
2025-05-27 19:19:29,256 - INFO - joeynmt.training - Epoch   2, Step:    15400, Batch Loss:     1.164020, Batch Acc: 0.649811, Tokens per Sec:    23582, Lr: 0.000300
2025-05-27 19:19:32,645 - INFO - joeynmt.training - Epoch   2, Step:    15500, Batch Loss:     1.152776, Batch Acc: 0.651024, Tokens per Sec:    22822, Lr: 0.000300
2025-05-27 19:19:32,645 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:19:32,645 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 80.27it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 78.28it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 78.31it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 82.04it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 89.75it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 100.92it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 103.62it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 83.04it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 44.13it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 49.55it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 59.95it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 74.11it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.12it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 68.88it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 60.60it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 68.00it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 55.39it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 51.73it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 50.52it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.44it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 50.61it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.34it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 59.29it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 55.30it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 51.90it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 60.69it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 76.61it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 81.53it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 75.50it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 83.94it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 97.63it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 100.72it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 97.74it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 90.00it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:04, 97.84it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:04, 83.33it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 81.14it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 65.12it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:06, 55.66it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 48.90it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 43.13it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.75it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 41.11it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 40.79it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 39.35it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 48.55it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.00it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.43it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.09it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:09, 29.21it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 28.15it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 32.33it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 28.25it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 32.83it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.27it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 38.68it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.22it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 44.66it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 55.28it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 40.33it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 41.83it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 43.24it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 46.00it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 58.24it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 68.36it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 71.35it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 61.49it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 56.17it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 70.38it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 79.86it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 93.86it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.83it/s]
2025-05-27 19:19:48,345 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.22, ppl:   3.37, acc:   0.65, generation: 15.6910[sec], evaluation: 0.0000[sec]
2025-05-27 19:19:48,345 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:19:48,825 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/13000.ckpt
2025-05-27 19:19:48,849 - INFO - joeynmt.training - Example #0
2025-05-27 19:19:48,850 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:19:48,851 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:19:48,851 - INFO - joeynmt.training - 	Hypothesis: La sc<unk> @ or<unk> @ sa di questi due anni , ho mostr<unk> @ ato questa fot<unk> @ ogra<unk> @ f<unk> @ ia per la sc<unk> @ al<unk> @ a per la com<unk> @ pren<unk> @ sione , che la c<unk> @ r<unk> @ oc<unk> @ c<unk> @ ina , che la c<unk> @ las<unk> @ se , per tre mili<unk> @ ar<unk> @ di di di di doll<unk> @ ari che av<unk> @ evano un gr<unk> @ u<unk> @ ppo di persone che av<unk> @ evano il 4<unk> @ 0 % .
2025-05-27 19:19:48,851 - INFO - joeynmt.training - Example #1
2025-05-27 19:19:48,851 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:19:48,852 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:19:48,852 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il modo di ri<unk> @ guar<unk> @ do , la prima volta che è la ris<unk> @ post<unk> @ a di questo problema , non è il problema di questo problema .
2025-05-27 19:19:48,852 - INFO - joeynmt.training - Example #2
2025-05-27 19:19:48,852 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:19:48,853 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:19:48,853 - INFO - joeynmt.training - 	Hypothesis: In realtà , è una s<unk> @ itu<unk> @ azione di una s<unk> @ fi<unk> @ da , la c<unk> @ ult<unk> @ ura del nostro sistema glob<unk> @ ale .
2025-05-27 19:19:48,853 - INFO - joeynmt.training - Example #3
2025-05-27 19:19:48,853 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:19:48,853 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:19:48,854 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e in realtà , e in realtà , e in s<unk> @ om<unk> @ b<unk> @ a .
2025-05-27 19:19:48,854 - INFO - joeynmt.training - Example #4
2025-05-27 19:19:48,854 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:19:48,854 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:19:48,855 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostr<unk> @ o è una cosa che vi mostr<unk> @ a una delle sc<unk> @ u<unk> @ ole che è una sc<unk> @ u<unk> @ ola di quello che è succ<unk> @ esso in circa 1<unk> @ 5 anni .
2025-05-27 19:19:52,237 - INFO - joeynmt.training - Epoch   2, Step:    15600, Batch Loss:     1.133865, Batch Acc: 0.650231, Tokens per Sec:    20804, Lr: 0.000300
2025-05-27 19:19:55,651 - INFO - joeynmt.training - Epoch   2, Step:    15700, Batch Loss:     1.312570, Batch Acc: 0.648119, Tokens per Sec:    23194, Lr: 0.000300
2025-05-27 19:19:57,169 - INFO - joeynmt.training - Epoch   2: total training loss 10139.88
2025-05-27 19:19:57,170 - INFO - joeynmt.training - EPOCH 3
2025-05-27 19:19:59,032 - INFO - joeynmt.training - Epoch   3, Step:    15800, Batch Loss:     1.239009, Batch Acc: 0.655112, Tokens per Sec:    23377, Lr: 0.000300
2025-05-27 19:20:02,405 - INFO - joeynmt.training - Epoch   3, Step:    15900, Batch Loss:     1.144844, Batch Acc: 0.657273, Tokens per Sec:    23690, Lr: 0.000300
2025-05-27 19:20:05,774 - INFO - joeynmt.training - Epoch   3, Step:    16000, Batch Loss:     1.093356, Batch Acc: 0.658668, Tokens per Sec:    23409, Lr: 0.000300
2025-05-27 19:20:05,774 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:20:05,774 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 60.10it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:19, 46.72it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:13, 63.41it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:12, 70.05it/s]Predicting...:   8%|▊         | 72/923 [00:01<00:10, 81.71it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:08, 93.48it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 93.15it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 106.04it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:16, 47.66it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 52.54it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 60.83it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 87.78it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 95.89it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 74.75it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 61.47it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 67.69it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 55.03it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 48.72it/s]Predicting...:  30%|███       | 277/923 [00:04<00:15, 42.92it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:16, 38.72it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:14, 42.47it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:13, 46.71it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:12, 49.22it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 53.03it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 57.97it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 72.18it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 79.33it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 82.95it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:09, 54.96it/s]Predicting...:  48%|████▊     | 441/923 [00:07<00:07, 65.61it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:06, 70.95it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 70.01it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:07, 62.60it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:06, 68.61it/s]Predicting...:  54%|█████▍    | 503/923 [00:08<00:07, 55.19it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:06, 63.09it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 72.33it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 58.46it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 45.68it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:09, 39.02it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:10, 32.28it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:09, 37.61it/s]Predicting...:  64%|██████▎   | 587/923 [00:10<00:12, 27.71it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:11, 29.35it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:10, 30.50it/s]Predicting...:  67%|██████▋   | 618/923 [00:11<00:07, 39.51it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:06, 43.04it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 38.99it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 35.51it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:13, 19.48it/s]Predicting...:  72%|███████▏  | 661/923 [00:13<00:13, 19.64it/s]Predicting...:  73%|███████▎  | 671/923 [00:13<00:10, 23.99it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:11, 21.30it/s]Predicting...:  74%|███████▍  | 687/923 [00:14<00:09, 24.30it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:09, 23.05it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:07, 30.44it/s]Predicting...:  78%|███████▊  | 717/923 [00:15<00:06, 31.32it/s]Predicting...:  79%|███████▉  | 729/923 [00:15<00:05, 37.97it/s]Predicting...:  80%|████████  | 742/923 [00:15<00:03, 47.34it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:05, 32.40it/s]Predicting...:  82%|████████▏ | 759/923 [00:16<00:04, 35.28it/s]Predicting...:  84%|████████▍ | 774/923 [00:16<00:03, 41.97it/s]Predicting...:  85%|████████▌ | 786/923 [00:16<00:02, 50.28it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 60.77it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 71.25it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 69.29it/s]Predicting...:  90%|█████████ | 835/923 [00:17<00:01, 46.28it/s]Predicting...:  92%|█████████▏| 850/923 [00:17<00:01, 57.70it/s]Predicting...:  93%|█████████▎| 862/923 [00:17<00:01, 40.73it/s]Predicting...:  95%|█████████▌| 878/923 [00:18<00:00, 52.08it/s]Predicting...:  97%|█████████▋| 892/923 [00:18<00:00, 60.11it/s]Predicting...:  98%|█████████▊| 908/923 [00:18<00:00, 74.52it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 50.06it/s]
2025-05-27 19:20:24,229 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.20, ppl:   3.31, acc:   0.66, generation: 18.4397[sec], evaluation: 0.0000[sec]
2025-05-27 19:20:24,230 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:20:24,782 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/13500.ckpt
2025-05-27 19:20:24,808 - INFO - joeynmt.training - Example #0
2025-05-27 19:20:24,810 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:20:24,810 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:20:24,810 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so che ho mostr<unk> @ ato a questi due anni , ho mostr<unk> @ ato che i due anni fa , i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ali che i i i i dati i mo<unk> @ di che i m<unk> @ oti<unk> @ vi per i m<unk> @ oti<unk> @ vi per i m<unk> @ oti<unk> @ vi per i anni , che i m<unk> @ oti<unk> @ vi per la città .
2025-05-27 19:20:24,810 - INFO - joeynmt.training - Example #1
2025-05-27 19:20:24,811 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:20:24,811 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:20:24,811 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il ris<unk> @ chio di non è la ris<unk> @ p<unk> @ etto a questo problema , che non è il problema di questo che non è il problema .
2025-05-27 19:20:24,811 - INFO - joeynmt.training - Example #2
2025-05-27 19:20:24,812 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:20:24,812 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:20:24,812 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ fi<unk> @ da è la str<unk> @ utt<unk> @ ura del nostro cor<unk> @ so è la c<unk> @ li<unk> @ ma del nostro sistema soci<unk> @ ale .
2025-05-27 19:20:24,812 - INFO - joeynmt.training - Example #3
2025-05-27 19:20:24,813 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:20:24,813 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:20:24,813 - INFO - joeynmt.training - 	Hypothesis: E &apos; un s<unk> @ ac<unk> @ co di s<unk> @ om<unk> @ b<unk> @ o e in un p<unk> @ ezz<unk> @ o .
2025-05-27 19:20:24,813 - INFO - joeynmt.training - Example #4
2025-05-27 19:20:24,814 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:20:24,814 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:20:24,814 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo è che vi mostr<unk> @ i che vi è un po &apos; di qu<unk> @ ale è un po &apos; di qu<unk> @ ale è che è succ<unk> @ esso in due anni .
2025-05-27 19:20:28,213 - INFO - joeynmt.training - Epoch   3, Step:    16100, Batch Loss:     1.159508, Batch Acc: 0.656295, Tokens per Sec:    20032, Lr: 0.000300
2025-05-27 19:20:31,601 - INFO - joeynmt.training - Epoch   3, Step:    16200, Batch Loss:     1.163716, Batch Acc: 0.657870, Tokens per Sec:    23294, Lr: 0.000300
2025-05-27 19:20:34,982 - INFO - joeynmt.training - Epoch   3, Step:    16300, Batch Loss:     1.201549, Batch Acc: 0.658831, Tokens per Sec:    23456, Lr: 0.000300
2025-05-27 19:20:38,330 - INFO - joeynmt.training - Epoch   3, Step:    16400, Batch Loss:     1.117826, Batch Acc: 0.658425, Tokens per Sec:    23941, Lr: 0.000300
2025-05-27 19:20:41,689 - INFO - joeynmt.training - Epoch   3, Step:    16500, Batch Loss:     1.368971, Batch Acc: 0.659029, Tokens per Sec:    23543, Lr: 0.000300
2025-05-27 19:20:41,689 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:20:41,689 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 64.29it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 73.64it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 85.08it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 86.65it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 99.41it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 102.89it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 104.68it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 83.77it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 47.06it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 50.99it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 58.92it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.33it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.05it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 78.80it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 71.40it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 72.94it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 56.91it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 52.22it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 49.60it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 48.34it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.96it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 55.98it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 59.69it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 56.13it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 50.24it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 59.48it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 78.15it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 83.65it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 85.65it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 87.94it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 79.74it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 83.31it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 87.02it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 76.75it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 75.05it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 63.15it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 72.38it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 81.18it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 61.76it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 49.21it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 46.25it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 42.66it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.00it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:07, 43.31it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:07, 41.47it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 40.68it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 49.95it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.96it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 44.23it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 42.26it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:06, 38.89it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 34.67it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 36.39it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:06, 35.34it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.50it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 33.02it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 40.47it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 38.60it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 45.91it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 54.79it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 35.58it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 38.07it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 40.47it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 46.64it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 54.80it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 68.13it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 71.10it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 55.25it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 53.60it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 67.70it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 71.00it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 79.62it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.25it/s]
2025-05-27 19:20:57,282 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.19, ppl:   3.29, acc:   0.66, generation: 15.5799[sec], evaluation: 0.0000[sec]
2025-05-27 19:20:57,282 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:20:58,007 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/14000.ckpt
2025-05-27 19:20:58,034 - INFO - joeynmt.training - Example #0
2025-05-27 19:20:58,035 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:20:58,036 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:20:58,036 - INFO - joeynmt.training - 	Hypothesis: E ho mostr<unk> @ ato a questi due milioni di anni , ho mostr<unk> @ ato a questi due milioni di anni , per cerc<unk> @ are di fare per ri<unk> @ fl<unk> @ et<unk> @ tere che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ate che il 4<unk> @ 0 milioni di anni .
2025-05-27 19:20:58,036 - INFO - joeynmt.training - Example #1
2025-05-27 19:20:58,037 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:20:58,037 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:20:58,037 - INFO - joeynmt.training - 	Hypothesis: Ma non è n<unk> @ ec<unk> @ ess<unk> @ ità di questo non è il modo di in<unk> @ cre<unk> @ di<unk> @ bile , non è il fatto di questo problema .
2025-05-27 19:20:58,037 - INFO - joeynmt.training - Example #2
2025-05-27 19:20:58,038 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:20:58,038 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:20:58,038 - INFO - joeynmt.training - 	Hypothesis: In realtà , è la s<unk> @ fi<unk> @ da è la str<unk> @ utt<unk> @ ura di g<unk> @ hi<unk> @ ac<unk> @ cio , il nostro sistema di c<unk> @ li<unk> @ ente .
2025-05-27 19:20:58,038 - INFO - joeynmt.training - Example #3
2025-05-27 19:20:58,039 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:20:58,039 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:20:58,039 - INFO - joeynmt.training - 	Hypothesis: E &apos; succ<unk> @ ede in gra<unk> @ do di in<unk> @ f<unk> @ era e s<unk> @ otto .
2025-05-27 19:20:58,039 - INFO - joeynmt.training - Example #4
2025-05-27 19:20:58,040 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:20:58,040 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:20:58,040 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma è che vi mostr<unk> @ er<unk> @ ò una delle cose che vi mostr<unk> @ er<unk> @ ò una delle sc<unk> @ el<unk> @ ta di una s<unk> @ itu<unk> @ azione .
2025-05-27 19:21:01,445 - INFO - joeynmt.training - Epoch   3, Step:    16600, Batch Loss:     1.208213, Batch Acc: 0.658889, Tokens per Sec:    19088, Lr: 0.000300
2025-05-27 19:21:04,811 - INFO - joeynmt.training - Epoch   3, Step:    16700, Batch Loss:     1.146444, Batch Acc: 0.660464, Tokens per Sec:    23415, Lr: 0.000300
2025-05-27 19:21:08,172 - INFO - joeynmt.training - Epoch   3, Step:    16800, Batch Loss:     1.167095, Batch Acc: 0.660528, Tokens per Sec:    23172, Lr: 0.000300
2025-05-27 19:21:11,556 - INFO - joeynmt.training - Epoch   3, Step:    16900, Batch Loss:     1.198058, Batch Acc: 0.663488, Tokens per Sec:    23282, Lr: 0.000300
2025-05-27 19:21:14,927 - INFO - joeynmt.training - Epoch   3, Step:    17000, Batch Loss:     1.265898, Batch Acc: 0.658818, Tokens per Sec:    23528, Lr: 0.000300
2025-05-27 19:21:14,927 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:21:14,927 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 71.74it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 98.82it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 110.98it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 113.13it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 100.56it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 121.34it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:07, 102.36it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:09, 84.37it/s] Predicting...:  17%|█▋        | 160/923 [00:01<00:08, 90.86it/s]Predicting...:  20%|██        | 185/923 [00:01<00:06, 117.08it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:06, 113.83it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:06, 104.84it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:06, 98.65it/s] Predicting...:  29%|██▉       | 267/923 [00:02<00:08, 78.35it/s]Predicting...:  30%|███       | 277/923 [00:02<00:08, 73.05it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:08, 70.76it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 76.52it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:07, 78.35it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 80.29it/s]Predicting...:  37%|███▋      | 337/923 [00:03<00:07, 76.50it/s]Predicting...:  38%|███▊      | 347/923 [00:03<00:08, 67.80it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 81.68it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 102.08it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 116.03it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 108.61it/s]Predicting...:  49%|████▉     | 455/923 [00:04<00:03, 123.75it/s]Predicting...:  51%|█████     | 469/923 [00:04<00:03, 115.26it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:03, 117.06it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:03, 108.80it/s]Predicting...:  58%|█████▊    | 531/923 [00:05<00:03, 111.03it/s]Predicting...:  59%|█████▉    | 548/923 [00:05<00:04, 79.89it/s] Predicting...:  62%|██████▏   | 568/923 [00:06<00:05, 61.11it/s]Predicting...:  63%|██████▎   | 580/923 [00:06<00:05, 64.95it/s]Predicting...:  65%|██████▍   | 596/923 [00:06<00:05, 57.26it/s]Predicting...:  66%|██████▌   | 605/923 [00:06<00:05, 56.85it/s]Predicting...:  67%|██████▋   | 618/923 [00:07<00:04, 66.34it/s]Predicting...:  68%|██████▊   | 630/923 [00:07<00:04, 66.15it/s]Predicting...:  69%|██████▉   | 639/923 [00:07<00:04, 60.12it/s]Predicting...:  70%|███████   | 647/923 [00:07<00:04, 57.15it/s]Predicting...:  72%|███████▏  | 661/923 [00:08<00:05, 47.63it/s]Predicting...:  73%|███████▎  | 671/923 [00:08<00:04, 51.33it/s]Predicting...:  73%|███████▎  | 678/923 [00:08<00:06, 38.46it/s]Predicting...:  74%|███████▍  | 687/923 [00:08<00:05, 42.14it/s]Predicting...:  75%|███████▌  | 696/923 [00:09<00:06, 37.44it/s]Predicting...:  77%|███████▋  | 708/923 [00:09<00:04, 48.77it/s]Predicting...:  78%|███████▊  | 717/923 [00:09<00:04, 46.37it/s]Predicting...:  79%|███████▉  | 729/923 [00:09<00:03, 58.04it/s]Predicting...:  80%|████████  | 742/923 [00:09<00:02, 68.53it/s]Predicting...:  82%|████████▏ | 759/923 [00:09<00:03, 54.26it/s]Predicting...:  84%|████████▍ | 774/923 [00:10<00:02, 65.19it/s]Predicting...:  87%|████████▋ | 800/923 [00:10<00:01, 84.55it/s]Predicting...:  88%|████████▊ | 815/923 [00:10<00:01, 94.77it/s]Predicting...:  90%|████████▉ | 827/923 [00:10<00:01, 94.74it/s]Predicting...:  92%|█████████▏| 850/923 [00:10<00:00, 87.84it/s]Predicting...:  93%|█████████▎| 862/923 [00:10<00:00, 84.90it/s]Predicting...:  95%|█████████▌| 878/923 [00:11<00:00, 98.72it/s]Predicting...:  97%|█████████▋| 892/923 [00:11<00:00, 98.24it/s]Predicting...: 100%|██████████| 923/923 [00:11<00:00, 130.18it/s]Predicting...: 100%|██████████| 923/923 [00:11<00:00, 81.05it/s] 
2025-05-27 19:21:26,324 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.19, ppl:   3.27, acc:   0.66, generation: 11.3884[sec], evaluation: 0.0000[sec]
2025-05-27 19:21:26,324 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:21:26,817 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/14500.ckpt
2025-05-27 19:21:26,834 - INFO - joeynmt.training - Example #0
2025-05-27 19:21:26,836 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:21:26,836 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:21:26,836 - INFO - joeynmt.training - 	Hypothesis: E l&apos; anno anno ho mostr<unk> @ ato a questa fot<unk> @ o , ho mostr<unk> @ ato che la f<unk> @ anno , per la f<unk> @ ar s<unk> @ ì che la c<unk> @ aus<unk> @ a di un gr<unk> @ u<unk> @ ppo di persone che non av<unk> @ evano visto per i tre mili<unk> @ ar<unk> @ di di di persone che hanno sc<unk> @ oper<unk> @ to per i 4<unk> @ 8 milioni di anni .
2025-05-27 19:21:26,836 - INFO - joeynmt.training - Example #1
2025-05-27 19:21:26,837 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:21:26,837 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:21:26,837 - INFO - joeynmt.training - 	Hypothesis: Ma non lo ve<unk> @ dete , non è il ris<unk> @ ult<unk> @ ato che non è il loro ris<unk> @ p<unk> @ etto a questo problema .
2025-05-27 19:21:26,837 - INFO - joeynmt.training - Example #2
2025-05-27 19:21:26,838 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:21:26,838 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:21:26,838 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la s<unk> @ fi<unk> @ da è la la stessa cosa che la cap<unk> @ ac<unk> @ ità di c<unk> @ at<unk> @ tere il nostro cor<unk> @ po .
2025-05-27 19:21:26,838 - INFO - joeynmt.training - Example #3
2025-05-27 19:21:26,839 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:21:26,839 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:21:26,839 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ à in tutto , e la m<unk> @ am<unk> @ ma e in tutto il m<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:21:26,839 - INFO - joeynmt.training - Example #4
2025-05-27 19:21:26,840 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:21:26,840 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:21:26,840 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo m<unk> @ ezz<unk> @ o che vi mostr<unk> @ a la cosa che vi è stato un po &apos; di qu<unk> @ ale è stato un po &apos; di quello che succ<unk> @ essi<unk> @ vo .
2025-05-27 19:21:30,204 - INFO - joeynmt.training - Epoch   3, Step:    17100, Batch Loss:     1.150646, Batch Acc: 0.658185, Tokens per Sec:    20171, Lr: 0.000300
2025-05-27 19:21:33,609 - INFO - joeynmt.training - Epoch   3, Step:    17200, Batch Loss:     1.318043, Batch Acc: 0.661177, Tokens per Sec:    24237, Lr: 0.000300
2025-05-27 19:21:36,988 - INFO - joeynmt.training - Epoch   3, Step:    17300, Batch Loss:     1.193127, Batch Acc: 0.661338, Tokens per Sec:    23426, Lr: 0.000300
2025-05-27 19:21:40,488 - INFO - joeynmt.training - Epoch   3, Step:    17400, Batch Loss:     1.152196, Batch Acc: 0.662607, Tokens per Sec:    23256, Lr: 0.000300
2025-05-27 19:21:43,893 - INFO - joeynmt.training - Epoch   3, Step:    17500, Batch Loss:     1.421140, Batch Acc: 0.658683, Tokens per Sec:    24250, Lr: 0.000300
2025-05-27 19:21:43,893 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:21:43,893 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 62.52it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 72.95it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 77.31it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:12, 69.41it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 78.41it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 89.65it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 94.01it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 81.65it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:13, 59.47it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:12, 62.05it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 68.97it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 92.04it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 97.35it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 71.82it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 67.93it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 71.63it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 56.24it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:13, 49.48it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 49.93it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 51.33it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.20it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.27it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.43it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 56.00it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 62.36it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.50it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 86.64it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 82.35it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:08, 56.27it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:08, 55.72it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:08, 56.35it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:07, 62.30it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:07, 62.31it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:06, 63.83it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 53.58it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:07, 57.94it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 68.49it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 61.95it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 50.43it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 40.58it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:08, 39.74it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 45.32it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 34.47it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 36.02it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:08, 35.67it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 43.60it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 42.68it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 40.18it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 37.51it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:09, 28.13it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 28.33it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:07, 32.24it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 26.26it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 28.16it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:08, 25.64it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 31.64it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 33.55it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 39.63it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 46.98it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 37.91it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 37.44it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 46.11it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 50.36it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 60.59it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 68.18it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 68.05it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 49.65it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 63.42it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 57.27it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 70.96it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 76.74it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 83.59it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 84.39it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 54.83it/s]
2025-05-27 19:22:00,741 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.17, ppl:   3.24, acc:   0.66, generation: 16.8356[sec], evaluation: 0.0000[sec]
2025-05-27 19:22:00,742 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:22:01,298 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/15000.ckpt
2025-05-27 19:22:01,321 - INFO - joeynmt.training - Example #0
2025-05-27 19:22:01,322 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:22:01,322 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:22:01,322 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato a questi due anni , ho mostr<unk> @ ato a questo p<unk> @ eg<unk> @ no per ri<unk> @ guar<unk> @ do di per la prima volta che la c<unk> @ aus<unk> @ a di tre milioni di anni , per la prima volta che la c<unk> @ aus<unk> @ a di tre mili<unk> @ ar<unk> @ di di anni , per la prima volta , per tre milioni di anni , sono stati stati stati stati stati stati stati stati stati stati stati s<unk> @ iti a 4<unk> @ 0 % .
2025-05-27 19:22:01,322 - INFO - joeynmt.training - Example #1
2025-05-27 19:22:01,323 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:22:01,323 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:22:01,324 - INFO - joeynmt.training - 	Hypothesis: Ma non è n<unk> @ ec<unk> @ ess<unk> @ ario la di<unk> @ men<unk> @ sione di ris<unk> @ ol<unk> @ vere probl<unk> @ emi di questo probl<unk> @ emi di questo probl<unk> @ emi , non è il d<unk> @ ic<unk> @ a<unk> @ io che non è il D<unk> @ ic<unk> @ a<unk> @ ci<unk> @ d<unk> @ ente .
2025-05-27 19:22:01,324 - INFO - joeynmt.training - Example #2
2025-05-27 19:22:01,324 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:22:01,324 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la s<unk> @ fi<unk> @ da è la s<unk> @ fi<unk> @ da , il nostro sistema di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - Example #3
2025-05-27 19:22:01,325 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - 	Hypothesis: E si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ p<unk> @ a e la s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:22:01,325 - INFO - joeynmt.training - Example #4
2025-05-27 19:22:01,326 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:22:01,326 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:22:01,326 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o , ho mostr<unk> @ ato a una cosa che è che è succ<unk> @ esso in cui si è trov<unk> @ ato in 2<unk> @ 5 anni .
2025-05-27 19:22:04,712 - INFO - joeynmt.training - Epoch   3, Step:    17600, Batch Loss:     1.208378, Batch Acc: 0.665078, Tokens per Sec:    19552, Lr: 0.000300
2025-05-27 19:22:08,123 - INFO - joeynmt.training - Epoch   3, Step:    17700, Batch Loss:     1.269725, Batch Acc: 0.661711, Tokens per Sec:    23612, Lr: 0.000300
2025-05-27 19:22:11,509 - INFO - joeynmt.training - Epoch   3, Step:    17800, Batch Loss:     1.157221, Batch Acc: 0.661276, Tokens per Sec:    23891, Lr: 0.000300
2025-05-27 19:22:14,875 - INFO - joeynmt.training - Epoch   3, Step:    17900, Batch Loss:     1.080647, Batch Acc: 0.662928, Tokens per Sec:    23449, Lr: 0.000300
2025-05-27 19:22:18,227 - INFO - joeynmt.training - Epoch   3, Step:    18000, Batch Loss:     0.998702, Batch Acc: 0.663932, Tokens per Sec:    23420, Lr: 0.000300
2025-05-27 19:22:18,227 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:22:18,228 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 80.38it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 82.98it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 90.90it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:13, 64.81it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 81.66it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 91.23it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 94.59it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:10, 74.40it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 65.02it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:10, 70.25it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 91.58it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 100.86it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 80.96it/s] Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 71.22it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 76.35it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 58.29it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 52.39it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 52.02it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 53.77it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 58.92it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.99it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 64.49it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 64.88it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 70.91it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 85.23it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 89.12it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 92.42it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 93.29it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:06, 76.16it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 81.68it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 84.90it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.54it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 88.98it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 77.19it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 84.29it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 58.64it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 50.16it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 44.00it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.11it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 42.67it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:09, 35.69it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.77it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.34it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.52it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 45.12it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 41.75it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 33.15it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 33.56it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 38.55it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 32.36it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.43it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:14, 15.63it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:11, 19.17it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:09, 21.93it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:06, 28.73it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:04, 37.95it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:05, 32.15it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 35.28it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 46.30it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 52.33it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 62.75it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 74.25it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.73it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 64.16it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 62.28it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 76.12it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 76.61it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 91.70it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 57.96it/s]
2025-05-27 19:22:34,164 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.17, ppl:   3.22, acc:   0.66, generation: 15.9244[sec], evaluation: 0.0000[sec]
2025-05-27 19:22:34,165 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:22:34,685 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/15500.ckpt
2025-05-27 19:22:34,705 - INFO - joeynmt.training - Example #0
2025-05-27 19:22:34,706 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:22:34,706 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:22:34,706 - INFO - joeynmt.training - 	Hypothesis: E abbiamo fatto questa sc<unk> @ or<unk> @ sa , questi due anni , ho fatto questa è la f<unk> @ ant<unk> @ ast<unk> @ ica per la c<unk> @ op<unk> @ ol<unk> @ azione per le persone che av<unk> @ evano fatto che la c<unk> @ at<unk> @ en<unk> @ a per tre tre anni , per la città per la prima volta che av<unk> @ evo tre tre tre anni .
2025-05-27 19:22:34,706 - INFO - joeynmt.training - Example #1
2025-05-27 19:22:34,707 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:22:34,707 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:22:34,707 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un problema , non è molto diff<unk> @ ic<unk> @ ile di questa con<unk> @ n<unk> @ et<unk> @ ica , non è la gente che non è il fatto .
2025-05-27 19:22:34,707 - INFO - joeynmt.training - Example #2
2025-05-27 19:22:34,708 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:22:34,708 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:22:34,708 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , è la s<unk> @ edi<unk> @ zione è la nostra c<unk> @ op<unk> @ ol<unk> @ azione di c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:22:34,708 - INFO - joeynmt.training - Example #3
2025-05-27 19:22:34,709 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:22:34,709 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:22:34,709 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ ete , in s<unk> @ é e in s<unk> @ é e in s<unk> @ om<unk> @ p<unk> @ a e .
2025-05-27 19:22:34,709 - INFO - joeynmt.training - Example #4
2025-05-27 19:22:34,710 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:22:34,710 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:22:34,710 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo pros<unk> @ si<unk> @ mo che vi mostr<unk> @ o una delle cose che è una delle cose che è stata una delle sc<unk> @ or<unk> @ me , e &apos; 2<unk> @ 5 anni .
2025-05-27 19:22:38,108 - INFO - joeynmt.training - Epoch   3, Step:    18100, Batch Loss:     1.129996, Batch Acc: 0.664604, Tokens per Sec:    19545, Lr: 0.000300
2025-05-27 19:22:41,496 - INFO - joeynmt.training - Epoch   3, Step:    18200, Batch Loss:     1.257040, Batch Acc: 0.664668, Tokens per Sec:    23188, Lr: 0.000300
2025-05-27 19:22:44,877 - INFO - joeynmt.training - Epoch   3, Step:    18300, Batch Loss:     1.154723, Batch Acc: 0.667427, Tokens per Sec:    23852, Lr: 0.000300
2025-05-27 19:22:48,213 - INFO - joeynmt.training - Epoch   3, Step:    18400, Batch Loss:     1.192705, Batch Acc: 0.665634, Tokens per Sec:    23321, Lr: 0.000300
2025-05-27 19:22:51,608 - INFO - joeynmt.training - Epoch   3, Step:    18500, Batch Loss:     1.253750, Batch Acc: 0.664483, Tokens per Sec:    23568, Lr: 0.000300
2025-05-27 19:22:51,608 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:22:51,608 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 57.55it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 72.67it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 78.91it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 90.71it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 100.78it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 115.85it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:06, 119.25it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:15, 52.66it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 53.05it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.35it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.29it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 94.83it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 82.28it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 75.87it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 56.57it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 56.06it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 55.29it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 60.46it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 65.31it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 69.46it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 59.08it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 56.43it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 69.39it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 90.02it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 97.84it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 94.46it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 91.79it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 101.88it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 102.17it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 105.13it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 81.56it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 88.33it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 65.23it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 69.38it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 63.77it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 53.60it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 44.17it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.28it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.87it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:13, 25.43it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:12, 27.22it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:11, 28.90it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:08, 37.34it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 40.05it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 37.10it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 34.62it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:10, 25.84it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:10, 26.04it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 30.32it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:11, 20.52it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:09, 24.02it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:16, 14.13it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:10, 20.28it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:09, 22.12it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:06, 28.81it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 38.27it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:05, 32.08it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 34.48it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 47.44it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 53.82it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:01, 64.59it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 74.83it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 79.02it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 60.13it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 55.90it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 68.35it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 74.05it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 102.49it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 53.98it/s] 
2025-05-27 19:23:08,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.16, ppl:   3.20, acc:   0.66, generation: 17.0995[sec], evaluation: 0.0000[sec]
2025-05-27 19:23:08,717 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:23:09,288 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/16000.ckpt
2025-05-27 19:23:09,312 - INFO - joeynmt.training - Example #0
2025-05-27 19:23:09,313 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o , per costru<unk> @ ire che i comp<unk> @ ag<unk> @ iti , che i f<unk> @ anno che il m<unk> @ oti<unk> @ vo per cui i dati , per la gr<unk> @ av<unk> @ e per la prima volta che av<unk> @ evano 4<unk> @ 0 milioni di persone che av<unk> @ evano 4<unk> @ 0 % della città .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - Example #1
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:23:09,314 - INFO - joeynmt.training - 	Hypothesis: Ma non si è in<unk> @ tr<unk> @ at<unk> @ ta di una con<unk> @ n<unk> @ et<unk> @ ta di questa in<unk> @ f<unk> @ era di questa in<unk> @ forma<unk> @ zione di questo problema .
2025-05-27 19:23:09,315 - INFO - joeynmt.training - Example #2
2025-05-27 19:23:09,315 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:23:09,315 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:23:09,315 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la s<unk> @ itu<unk> @ azione è la c<unk> @ aus<unk> @ a della nostra c<unk> @ aus<unk> @ a della nostra c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:23:09,315 - INFO - joeynmt.training - Example #3
2025-05-27 19:23:09,316 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:23:09,316 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:23:09,316 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ olo , si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ p<unk> @ a e in s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:23:09,316 - INFO - joeynmt.training - Example #4
2025-05-27 19:23:09,317 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:23:09,317 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:23:09,317 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o la cosa che ho mostr<unk> @ ato una delle cose che è che è una delle sc<unk> @ en<unk> @ a di quello che sta succ<unk> @ e<unk> @ dendo in ulti<unk> @ ma 2<unk> @ 5 anni .
2025-05-27 19:23:12,648 - INFO - joeynmt.training - Epoch   3, Step:    18600, Batch Loss:     1.135028, Batch Acc: 0.663487, Tokens per Sec:    20212, Lr: 0.000300
2025-05-27 19:23:15,996 - INFO - joeynmt.training - Epoch   3, Step:    18700, Batch Loss:     1.164630, Batch Acc: 0.666127, Tokens per Sec:    23445, Lr: 0.000300
2025-05-27 19:23:19,363 - INFO - joeynmt.training - Epoch   3, Step:    18800, Batch Loss:     1.134684, Batch Acc: 0.665665, Tokens per Sec:    24135, Lr: 0.000300
2025-05-27 19:23:22,710 - INFO - joeynmt.training - Epoch   3, Step:    18900, Batch Loss:     1.270692, Batch Acc: 0.663689, Tokens per Sec:    23552, Lr: 0.000300
2025-05-27 19:23:26,066 - INFO - joeynmt.training - Epoch   3, Step:    19000, Batch Loss:     1.190498, Batch Acc: 0.670388, Tokens per Sec:    23842, Lr: 0.000300
2025-05-27 19:23:26,066 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:23:26,066 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 81.49it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 88.38it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 101.56it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 104.69it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 112.18it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 121.89it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 114.73it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:09, 82.19it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:10, 71.42it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:09, 79.90it/s]Predicting...:  20%|██        | 185/923 [00:01<00:07, 105.02it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 110.03it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 92.65it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 84.56it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 63.66it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 61.99it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 60.60it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 65.55it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 70.63it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 73.30it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 68.80it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 58.26it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 70.39it/s]Predicting...:  41%|████      | 379/923 [00:04<00:06, 89.69it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 98.41it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:05, 97.36it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 93.68it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:06, 74.53it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:06, 77.76it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:05, 83.01it/s]Predicting...:  52%|█████▏    | 480/923 [00:05<00:05, 75.77it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 83.15it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 69.61it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 80.12it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 90.95it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:05, 68.13it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 51.87it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 56.83it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 41.75it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 41.76it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 46.28it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 49.77it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 44.19it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 41.58it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 33.88it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:08, 31.10it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 34.52it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 33.14it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 38.27it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 34.66it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 44.34it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 43.55it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 51.49it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 61.69it/s]Predicting...:  81%|████████  | 749/923 [00:11<00:03, 44.62it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 47.01it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 55.30it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 63.42it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 69.49it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 79.47it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 83.65it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 66.38it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:01, 60.65it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 72.12it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 77.25it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 89.01it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 66.24it/s]
2025-05-27 19:23:40,013 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.16, ppl:   3.19, acc:   0.67, generation: 13.9342[sec], evaluation: 0.0000[sec]
2025-05-27 19:23:40,014 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:23:40,612 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/16500.ckpt
2025-05-27 19:23:40,637 - INFO - joeynmt.training - Example #0
2025-05-27 19:23:40,638 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:23:40,638 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:23:40,638 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o di sc<unk> @ oper<unk> @ ta per creare il can<unk> @ c<unk> @ ro di g<unk> @ hi<unk> @ ac<unk> @ cio per i tre mili<unk> @ ar<unk> @ di di di persone che av<unk> @ evano tre mili<unk> @ ar<unk> @ di di di di anni , il 4<unk> @ 0 , 4<unk> @ 0 % di persone che av<unk> @ evano 4<unk> @ 0 % .
2025-05-27 19:23:40,638 - INFO - joeynmt.training - Example #1
2025-05-27 19:23:40,639 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:23:40,640 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:23:40,640 - INFO - joeynmt.training - 	Hypothesis: Ma questo non questo non è il ris<unk> @ ult<unk> @ ato di ris<unk> @ ol<unk> @ vere il ris<unk> @ ult<unk> @ ato di questi probl<unk> @ emi di questi probl<unk> @ emi di questi probl<unk> @ emi di questi probl<unk> @ emi .
2025-05-27 19:23:40,640 - INFO - joeynmt.training - Example #2
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ ella s<unk> @ ov<unk> @ ità è la s<unk> @ itu<unk> @ azione di em<unk> @ issi<unk> @ oni , il sistema di c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:23:40,641 - INFO - joeynmt.training - Example #3
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:23:40,641 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:23:40,642 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ olo , si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ p<unk> @ a e in s<unk> @ é .
2025-05-27 19:23:40,642 - INFO - joeynmt.training - Example #4
2025-05-27 19:23:40,642 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:23:40,642 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:23:40,642 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma è una cosa che vi mostr<unk> @ a che è una cosa che è che è succ<unk> @ esso in cui è succ<unk> @ esso in cui è succ<unk> @ esso in cui è succ<unk> @ esso .
2025-05-27 19:23:44,003 - INFO - joeynmt.training - Epoch   3, Step:    19100, Batch Loss:     1.155507, Batch Acc: 0.666815, Tokens per Sec:    19716, Lr: 0.000300
2025-05-27 19:23:47,329 - INFO - joeynmt.training - Epoch   3, Step:    19200, Batch Loss:     1.204934, Batch Acc: 0.665535, Tokens per Sec:    23920, Lr: 0.000300
2025-05-27 19:23:50,654 - INFO - joeynmt.training - Epoch   3, Step:    19300, Batch Loss:     1.016007, Batch Acc: 0.670112, Tokens per Sec:    24219, Lr: 0.000300
2025-05-27 19:23:54,017 - INFO - joeynmt.training - Epoch   3, Step:    19400, Batch Loss:     1.216370, Batch Acc: 0.668333, Tokens per Sec:    23920, Lr: 0.000300
2025-05-27 19:23:57,398 - INFO - joeynmt.training - Epoch   3, Step:    19500, Batch Loss:     1.282668, Batch Acc: 0.671632, Tokens per Sec:    23950, Lr: 0.000300
2025-05-27 19:23:57,399 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:23:57,399 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 77.05it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 87.22it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 87.23it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 88.25it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 83.51it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 95.64it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 98.76it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 111.10it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 54.18it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 56.94it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 65.27it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 89.73it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 97.56it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.81it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 68.73it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 74.48it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 59.66it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.63it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 52.79it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 49.67it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.93it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 58.08it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 57.26it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:10, 55.96it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.03it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 64.74it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 82.02it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 90.60it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 92.72it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:06, 78.68it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:07, 66.66it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 69.90it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:06, 71.25it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 64.10it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:06, 69.81it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 61.98it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 72.76it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 82.00it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 73.78it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 56.14it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 48.67it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 49.04it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 53.22it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 42.22it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 40.27it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 39.44it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 47.47it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.52it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 44.20it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 42.49it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:11, 22.60it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:10, 23.94it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 29.77it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 27.89it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 32.13it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.27it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:07, 29.96it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 30.68it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 38.60it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 45.86it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 34.81it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 35.65it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 44.40it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 51.10it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 61.20it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 71.13it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 75.28it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:00, 74.39it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 69.27it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 89.17it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 95.68it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 95.95it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.51it/s]
2025-05-27 19:24:13,186 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.15, ppl:   3.16, acc:   0.67, generation: 15.7750[sec], evaluation: 0.0000[sec]
2025-05-27 19:24:13,187 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:24:13,713 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/17000.ckpt
2025-05-27 19:24:13,737 - INFO - joeynmt.training - Example #0
2025-05-27 19:24:13,738 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:24:13,738 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:24:13,738 - INFO - joeynmt.training - 	Hypothesis: E la fine di cui ho mostr<unk> @ ato questa don<unk> @ na , ho mostr<unk> @ ato che la p<unk> @ es<unk> @ ca di c<unk> @ aus<unk> @ a di g<unk> @ ar<unk> @ re il g<unk> @ atto di c<unk> @ aus<unk> @ a di tre milioni di anni , che aveva tre mili<unk> @ ar<unk> @ di di di anni , per tre milioni di anni , che av<unk> @ evo 4<unk> @ 0 milioni di anni , che av<unk> @ evo 4<unk> @ 0 anni , il 4<unk> @ 0 anni , il 4<unk> @ 0 % .
2025-05-27 19:24:13,738 - INFO - joeynmt.training - Example #1
2025-05-27 19:24:13,739 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:24:13,739 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:24:13,739 - INFO - joeynmt.training - 	Hypothesis: Ma non è il fatto di un problema di cui non è la ris<unk> @ post<unk> @ a di questo problema , che non è il fatto di questo problema di questo problema , e non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:24:13,739 - INFO - joeynmt.training - Example #2
2025-05-27 19:24:13,740 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:24:13,740 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:24:13,740 - INFO - joeynmt.training - 	Hypothesis: In realtà , è il sistema di s<unk> @ é che è la c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a del nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:24:13,741 - INFO - joeynmt.training - Example #3
2025-05-27 19:24:13,741 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:24:13,741 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:24:13,741 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e il s<unk> @ ac<unk> @ co di s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:24:13,741 - INFO - joeynmt.training - Example #4
2025-05-27 19:24:13,742 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:24:13,742 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:24:13,742 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò una cosa che vi mostr<unk> @ a una cosa che è succ<unk> @ esso in cui l&apos; ulti<unk> @ mo anni .
2025-05-27 19:24:17,118 - INFO - joeynmt.training - Epoch   3, Step:    19600, Batch Loss:     1.135661, Batch Acc: 0.667354, Tokens per Sec:    20223, Lr: 0.000300
2025-05-27 19:24:20,485 - INFO - joeynmt.training - Epoch   3, Step:    19700, Batch Loss:     1.130685, Batch Acc: 0.669139, Tokens per Sec:    24155, Lr: 0.000300
2025-05-27 19:24:23,840 - INFO - joeynmt.training - Epoch   3, Step:    19800, Batch Loss:     1.155150, Batch Acc: 0.670867, Tokens per Sec:    23680, Lr: 0.000300
2025-05-27 19:24:27,193 - INFO - joeynmt.training - Epoch   3, Step:    19900, Batch Loss:     1.073417, Batch Acc: 0.670823, Tokens per Sec:    23209, Lr: 0.000300
2025-05-27 19:24:30,580 - INFO - joeynmt.training - Epoch   3, Step:    20000, Batch Loss:     1.070847, Batch Acc: 0.670837, Tokens per Sec:    23701, Lr: 0.000300
2025-05-27 19:24:30,580 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:24:30,581 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 75.29it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.09it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 82.22it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 88.00it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 97.87it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 99.99it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 96.65it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 112.47it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 49.83it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 56.21it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 67.82it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 96.45it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 104.86it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 83.91it/s] Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 61.47it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:13, 50.32it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 48.83it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 46.85it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.32it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.73it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 62.45it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 57.61it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 53.81it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 62.68it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 78.04it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 82.38it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 83.87it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 88.49it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 104.04it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 105.11it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 103.17it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 91.36it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 86.19it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 59.22it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 67.31it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 74.47it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 60.64it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 51.52it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 40.88it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 38.87it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 45.53it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 42.09it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 40.49it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 38.74it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.31it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 48.57it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 42.80it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 41.12it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.60it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 31.76it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 34.84it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 32.07it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 33.90it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.57it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 37.78it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.78it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 46.39it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 55.24it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:03, 43.86it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 43.83it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 49.47it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 54.57it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 66.06it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 73.32it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 79.56it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 65.72it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 68.37it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 82.55it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 82.45it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 90.34it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 101.36it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.66it/s] 
2025-05-27 19:24:45,810 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.14, ppl:   3.14, acc:   0.67, generation: 15.2170[sec], evaluation: 0.0000[sec]
2025-05-27 19:24:45,811 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:24:46,405 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/17500.ckpt
2025-05-27 19:24:46,433 - INFO - joeynmt.training - Example #0
2025-05-27 19:24:46,434 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:24:46,434 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:24:46,434 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato a questa fot<unk> @ o , ho mostr<unk> @ ato che la f<unk> @ ol<unk> @ ia per la f<unk> @ av<unk> @ e per i tre milioni di anni , che la c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di tre milioni di anni , per i tre milioni di anni , per i tre milioni di anni , per c<unk> @ ento , 4<unk> @ 0 milioni di anni .
2025-05-27 19:24:46,434 - INFO - joeynmt.training - Example #1
2025-05-27 19:24:46,435 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:24:46,435 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:24:46,436 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il fatto che non è stato mostr<unk> @ ato a una cosa che è il ris<unk> @ ult<unk> @ ato di questa con<unk> @ n<unk> @ es<unk> @ sione , non è il problema della de<unk> @ fin<unk> @ i<unk> @ zione .
2025-05-27 19:24:46,436 - INFO - joeynmt.training - Example #2
2025-05-27 19:24:46,436 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:24:46,437 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:24:46,437 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ f<unk> @ re<unk> @ zione è la nostra in<unk> @ t<unk> @ ura , la nostra c<unk> @ aus<unk> @ a della nostra c<unk> @ li<unk> @ mat<unk> @ ica .
2025-05-27 19:24:46,437 - INFO - joeynmt.training - Example #3
2025-05-27 19:24:46,437 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:24:46,437 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:24:46,438 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e si trov<unk> @ a in s<unk> @ om<unk> @ b<unk> @ a .
2025-05-27 19:24:46,438 - INFO - joeynmt.training - Example #4
2025-05-27 19:24:46,438 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:24:46,438 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:24:46,439 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ er<unk> @ ò la mia m<unk> @ em<unk> @ or<unk> @ ia è una c<unk> @ aus<unk> @ a di 2<unk> @ 5 anni .
2025-05-27 19:24:49,846 - INFO - joeynmt.training - Epoch   3, Step:    20100, Batch Loss:     1.146412, Batch Acc: 0.671980, Tokens per Sec:    20245, Lr: 0.000300
2025-05-27 19:24:53,204 - INFO - joeynmt.training - Epoch   3, Step:    20200, Batch Loss:     1.098671, Batch Acc: 0.672677, Tokens per Sec:    25012, Lr: 0.000300
2025-05-27 19:24:56,549 - INFO - joeynmt.training - Epoch   3, Step:    20300, Batch Loss:     1.262245, Batch Acc: 0.670158, Tokens per Sec:    23443, Lr: 0.000300
2025-05-27 19:24:59,899 - INFO - joeynmt.training - Epoch   3, Step:    20400, Batch Loss:     1.285209, Batch Acc: 0.669450, Tokens per Sec:    23707, Lr: 0.000300
2025-05-27 19:25:03,262 - INFO - joeynmt.training - Epoch   3, Step:    20500, Batch Loss:     1.240388, Batch Acc: 0.672535, Tokens per Sec:    23698, Lr: 0.000300
2025-05-27 19:25:03,263 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:25:03,263 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 83.03it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 84.24it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 99.13it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 108.01it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 113.53it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 122.82it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 112.08it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 126.56it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 60.32it/s] Predicting...:  17%|█▋        | 160/923 [00:01<00:11, 66.89it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 88.25it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 95.23it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:10, 67.43it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:11, 61.68it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 66.71it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:13, 51.06it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:13, 50.30it/s]Predicting...:  30%|███       | 277/923 [00:03<00:13, 46.89it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 44.98it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:13, 47.20it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:12, 50.64it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 54.44it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 51.20it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:12, 45.80it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 58.55it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 76.35it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 86.92it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:07, 69.06it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:07, 69.43it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 76.44it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 79.22it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 83.06it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 77.42it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 81.94it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 60.89it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.19it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 76.91it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 66.31it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 52.47it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 47.90it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 43.52it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 49.69it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 38.76it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 38.25it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.99it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.02it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 46.02it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 44.26it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 42.43it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 37.54it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 35.75it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 39.25it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 32.27it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 36.57it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 30.87it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 39.42it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 38.34it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 46.74it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 55.74it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.96it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.64it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 50.75it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 59.18it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 68.03it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 79.04it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 75.72it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 62.22it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 60.60it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 69.79it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 72.78it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 70.55it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.65it/s]
2025-05-27 19:25:18,746 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.14, ppl:   3.13, acc:   0.67, generation: 15.4740[sec], evaluation: 0.0000[sec]
2025-05-27 19:25:18,746 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:25:19,259 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/18000.ckpt
2025-05-27 19:25:19,277 - INFO - joeynmt.training - Example #0
2025-05-27 19:25:19,278 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:25:19,278 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:25:19,278 - INFO - joeynmt.training - 	Hypothesis: E ho mostr<unk> @ ato questi due m<unk> @ oni , ho mostr<unk> @ ato a che i miei f<unk> @ att<unk> @ ori per per il f<unk> @ oll<unk> @ o , per i tre milioni di m<unk> @ oti<unk> @ vi per i tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , il 4<unk> @ 0 per c<unk> @ ento .
2025-05-27 19:25:19,278 - INFO - joeynmt.training - Example #1
2025-05-27 19:25:19,279 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:25:19,279 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:25:19,279 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato il problema di in<unk> @ st<unk> @ im<unk> @ ol<unk> @ t<unk> @ ore che è stato in<unk> @ vent<unk> @ ato , non è il problema di un problema di e<unk> @ qu<unk> @ i<unk> @ li<unk> @ zz<unk> @ ato .
2025-05-27 19:25:19,279 - INFO - joeynmt.training - Example #2
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ ella s<unk> @ ett<unk> @ ore è la s<unk> @ itu<unk> @ azione di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ mento glob<unk> @ ale .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - Example #3
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e la s<unk> @ om<unk> @ p<unk> @ a e in s<unk> @ é .
2025-05-27 19:25:19,280 - INFO - joeynmt.training - Example #4
2025-05-27 19:25:19,281 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:25:19,281 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:25:19,281 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostr<unk> @ o che vi mostr<unk> @ o è che vi mostr<unk> @ o un num<unk> @ ero di due anni .
2025-05-27 19:25:22,641 - INFO - joeynmt.training - Epoch   3, Step:    20600, Batch Loss:     1.064212, Batch Acc: 0.669127, Tokens per Sec:    20354, Lr: 0.000300
2025-05-27 19:25:25,989 - INFO - joeynmt.training - Epoch   3, Step:    20700, Batch Loss:     1.135859, Batch Acc: 0.673611, Tokens per Sec:    23776, Lr: 0.000300
2025-05-27 19:25:29,338 - INFO - joeynmt.training - Epoch   3, Step:    20800, Batch Loss:     1.113295, Batch Acc: 0.674569, Tokens per Sec:    23406, Lr: 0.000300
2025-05-27 19:25:32,705 - INFO - joeynmt.training - Epoch   3, Step:    20900, Batch Loss:     1.137988, Batch Acc: 0.672831, Tokens per Sec:    24225, Lr: 0.000300
2025-05-27 19:25:36,041 - INFO - joeynmt.training - Epoch   3, Step:    21000, Batch Loss:     1.038801, Batch Acc: 0.672588, Tokens per Sec:    23635, Lr: 0.000300
2025-05-27 19:25:36,041 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:25:36,041 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 75.52it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 89.14it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 100.52it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 106.19it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 121.65it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 120.71it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 120.15it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 130.20it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 55.79it/s] Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 61.79it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 82.86it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 90.19it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 77.80it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:10, 68.55it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 71.85it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 57.71it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.05it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 53.30it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.54it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 54.30it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.26it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.99it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 60.61it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 51.94it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 64.24it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.93it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 87.76it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 92.01it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 90.59it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 100.91it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 96.92it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 101.45it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.26it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 89.09it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 73.47it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 82.57it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 56.35it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 48.26it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 44.38it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.15it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 38.74it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 39.01it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.49it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.17it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.93it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 44.86it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 39.61it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:12, 22.50it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:10, 25.08it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 30.92it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 28.21it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 33.17it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 26.87it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 35.85it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 33.99it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 43.77it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 53.98it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 43.42it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 46.65it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 62.56it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:01, 69.85it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 82.65it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 94.78it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 94.75it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 70.96it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 68.05it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 71.86it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 81.55it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 61.47it/s]
2025-05-27 19:25:51,065 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.14, ppl:   3.12, acc:   0.67, generation: 15.0149[sec], evaluation: 0.0000[sec]
2025-05-27 19:25:51,065 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:25:51,645 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/18500.ckpt
2025-05-27 19:25:51,668 - INFO - joeynmt.training - Example #0
2025-05-27 19:25:51,669 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:25:51,669 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:25:51,669 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato a che il p<unk> @ es<unk> @ ce per fare il f<unk> @ ut<unk> @ uro che il g<unk> @ hi<unk> @ ac<unk> @ cio per tre anni , la c<unk> @ aus<unk> @ a di g<unk> @ am<unk> @ be per tre anni , per c<unk> @ ento di tre anni , che av<unk> @ evo tre anni .
2025-05-27 19:25:51,669 - INFO - joeynmt.training - Example #1
2025-05-27 19:25:51,670 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:25:51,670 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:25:51,671 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po &apos; di ris<unk> @ ult<unk> @ ato che la ris<unk> @ ol<unk> @ tà di questa in<unk> @ forma<unk> @ zione , non è un problema di quello che non è il d<unk> @ ato di questo problema .
2025-05-27 19:25:51,671 - INFO - joeynmt.training - Example #2
2025-05-27 19:25:51,671 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ f<unk> @ era la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are la nostra c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - Example #3
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , nel s<unk> @ é .
2025-05-27 19:25:51,672 - INFO - joeynmt.training - Example #4
2025-05-27 19:25:51,673 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:25:51,673 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:25:51,673 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò una delle prim<unk> @ e sc<unk> @ or<unk> @ so che è quello che è succ<unk> @ esso in sc<unk> @ or<unk> @ so in cui l&apos; ulti<unk> @ 5 anni .
2025-05-27 19:25:54,860 - INFO - joeynmt.training - Epoch   3, Step:    21100, Batch Loss:     1.063454, Batch Acc: 0.674099, Tokens per Sec:    20223, Lr: 0.000300
2025-05-27 19:25:58,102 - INFO - joeynmt.training - Epoch   3, Step:    21200, Batch Loss:     1.126101, Batch Acc: 0.674477, Tokens per Sec:    24716, Lr: 0.000300
2025-05-27 19:26:01,319 - INFO - joeynmt.training - Epoch   3, Step:    21300, Batch Loss:     1.160099, Batch Acc: 0.672968, Tokens per Sec:    24748, Lr: 0.000300
2025-05-27 19:26:04,572 - INFO - joeynmt.training - Epoch   3, Step:    21400, Batch Loss:     1.190800, Batch Acc: 0.675664, Tokens per Sec:    25046, Lr: 0.000300
2025-05-27 19:26:07,826 - INFO - joeynmt.training - Epoch   3, Step:    21500, Batch Loss:     1.079594, Batch Acc: 0.677491, Tokens per Sec:    24813, Lr: 0.000300
2025-05-27 19:26:07,826 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:26:07,826 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:21, 41.79it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:13, 64.23it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 79.52it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 89.09it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 99.57it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 110.20it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:09, 86.91it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:10, 74.83it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:09, 83.75it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 103.97it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 112.78it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 85.15it/s] Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 80.99it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:08, 83.10it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 64.39it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 59.11it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 53.73it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:10, 59.00it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 60.02it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.33it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 59.75it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 59.89it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:08, 68.74it/s]Predicting...:  41%|████      | 379/923 [00:04<00:06, 88.25it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 96.84it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 90.59it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 85.10it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 100.94it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 106.44it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 108.16it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 100.29it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 79.80it/s] Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 87.14it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 62.05it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 49.37it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 56.30it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 43.96it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 42.16it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 50.28it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 53.78it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 49.34it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 45.05it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 35.82it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 34.64it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 39.04it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 36.02it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 40.58it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 34.05it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 43.06it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 41.50it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 50.01it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 62.02it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 44.66it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 52.59it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 61.54it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 74.07it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 82.71it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 84.38it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 67.54it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 66.45it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 84.87it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 95.97it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 67.07it/s]
2025-05-27 19:26:21,596 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.13, ppl:   3.09, acc:   0.68, generation: 13.7616[sec], evaluation: 0.0000[sec]
2025-05-27 19:26:21,596 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:26:22,047 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/19000.ckpt
2025-05-27 19:26:22,065 - INFO - joeynmt.training - Example #0
2025-05-27 19:26:22,066 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:26:22,066 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:26:22,066 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato queste due due cose che ho mostr<unk> @ ato questi due due due due anni , per ri<unk> @ dur<unk> @ re le g<unk> @ am<unk> @ be per la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ol<unk> @ i di tre mili<unk> @ one di anni , i tre mili<unk> @ one di di di anni , il 4<unk> @ 0 , 4<unk> @ 0 milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % di st<unk> @ at<unk> @ ura .
2025-05-27 19:26:22,066 - INFO - joeynmt.training - Example #1
2025-05-27 19:26:22,067 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:26:22,067 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:26:22,067 - INFO - joeynmt.training - 	Hypothesis: Ma non è un punto di vi<unk> @ sta , non è la ris<unk> @ or<unk> @ sa di questa con<unk> @ fer<unk> @ enza , non è il fatto che non è il fatto che non è il de<unk> @ fin<unk> @ ito , non è il de<unk> @ ter<unk> @ m<unk> @ ine .
2025-05-27 19:26:22,067 - INFO - joeynmt.training - Example #2
2025-05-27 19:26:22,068 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:26:22,068 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:26:22,068 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la s<unk> @ om<unk> @ ma è la c<unk> @ aus<unk> @ a della nostra c<unk> @ las<unk> @ se , il nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:26:22,069 - INFO - joeynmt.training - Example #3
2025-05-27 19:26:22,069 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:26:22,069 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:26:22,069 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , la cosa che si è s<unk> @ ent<unk> @ ito in v<unk> @ it<unk> @ to .
2025-05-27 19:26:22,069 - INFO - joeynmt.training - Example #4
2025-05-27 19:26:22,070 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:26:22,070 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:26:22,070 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa mi mostr<unk> @ a che vi mostr<unk> @ o è una v<unk> @ ec<unk> @ chi<unk> @ a che è una v<unk> @ ec<unk> @ chi<unk> @ ata di quello che sta succ<unk> @ e<unk> @ dendo in 2<unk> @ 5 anni .
2025-05-27 19:26:25,327 - INFO - joeynmt.training - Epoch   3, Step:    21600, Batch Loss:     1.107890, Batch Acc: 0.675775, Tokens per Sec:    21181, Lr: 0.000300
2025-05-27 19:26:28,543 - INFO - joeynmt.training - Epoch   3, Step:    21700, Batch Loss:     1.154062, Batch Acc: 0.673568, Tokens per Sec:    24219, Lr: 0.000300
2025-05-27 19:26:31,755 - INFO - joeynmt.training - Epoch   3, Step:    21800, Batch Loss:     1.072983, Batch Acc: 0.671800, Tokens per Sec:    24170, Lr: 0.000300
2025-05-27 19:26:35,005 - INFO - joeynmt.training - Epoch   3, Step:    21900, Batch Loss:     1.209550, Batch Acc: 0.675206, Tokens per Sec:    24967, Lr: 0.000300
2025-05-27 19:26:38,253 - INFO - joeynmt.training - Epoch   3, Step:    22000, Batch Loss:     1.233796, Batch Acc: 0.674246, Tokens per Sec:    24808, Lr: 0.000300
2025-05-27 19:26:38,254 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:26:38,254 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 71.41it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 95.26it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 112.29it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 111.66it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 124.48it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 129.93it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 105.41it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:13, 59.52it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 66.75it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 93.77it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 101.19it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 92.69it/s] Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 82.72it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 89.07it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 65.41it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 65.00it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 58.31it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:10, 58.43it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:09, 65.46it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 68.48it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 62.20it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 60.68it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 74.05it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 91.63it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 101.14it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 87.08it/s] Predicting...:  46%|████▌     | 424/923 [00:05<00:08, 59.00it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:06, 74.42it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:05, 80.71it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:05, 88.00it/s]Predicting...:  52%|█████▏    | 480/923 [00:05<00:04, 88.63it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 79.70it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 73.84it/s]Predicting...:  59%|█████▊    | 540/923 [00:06<00:05, 74.01it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 59.95it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 54.56it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 61.19it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 42.10it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 41.75it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 48.74it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 51.12it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 48.24it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 45.48it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 38.31it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 38.21it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:05, 42.61it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 38.38it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 41.78it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 33.17it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:05, 40.79it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 40.14it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 48.62it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 60.61it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 46.82it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 57.70it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 64.60it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 76.94it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 87.10it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 88.59it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:01, 72.22it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 71.25it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 86.81it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 95.53it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 67.78it/s]
2025-05-27 19:26:51,879 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.13, ppl:   3.08, acc:   0.68, generation: 13.6173[sec], evaluation: 0.0000[sec]
2025-05-27 19:26:51,880 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:26:52,329 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/19500.ckpt
2025-05-27 19:26:52,353 - INFO - joeynmt.training - Example #0
2025-05-27 19:26:52,354 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:26:52,354 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:26:52,354 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el anno sc<unk> @ or<unk> @ so che ho mostr<unk> @ ato questi due due anni , per costru<unk> @ ire questi due mili<unk> @ ar<unk> @ di di di persone che aveva di<unk> @ mostr<unk> @ ato che il g<unk> @ hi<unk> @ ac<unk> @ cio , per i tre milioni di anni , per le m<unk> @ oti<unk> @ v<unk> @ are , per le 1<unk> @ 4<unk> @ 0 milioni di persone che av<unk> @ evano tre milioni di m<unk> @ oti<unk> @ vi .
2025-05-27 19:26:52,354 - INFO - joeynmt.training - Example #1
2025-05-27 19:26:52,355 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:26:52,355 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:26:52,355 - INFO - joeynmt.training - 	Hypothesis: Ma non è n<unk> @ ec<unk> @ ess<unk> @ ario la ris<unk> @ post<unk> @ a , la di<unk> @ men<unk> @ sione di questa di<unk> @ men<unk> @ sione , non è il d<unk> @ ott<unk> @ ore , non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:26:52,355 - INFO - joeynmt.training - Example #2
2025-05-27 19:26:52,356 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:26:52,356 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:26:52,356 - INFO - joeynmt.training - 	Hypothesis: N<unk> @ el sen<unk> @ so è la ci<unk> @ ma è la c<unk> @ aus<unk> @ a del nostro sistema di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema glob<unk> @ ale glob<unk> @ ale glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:26:52,357 - INFO - joeynmt.training - Example #3
2025-05-27 19:26:52,357 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:26:52,357 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:26:52,357 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a e la c<unk> @ aus<unk> @ a e il p<unk> @ ezz<unk> @ o di s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:26:52,357 - INFO - joeynmt.training - Example #4
2025-05-27 19:26:52,358 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:26:52,358 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:26:52,358 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ o vi vi mostr<unk> @ o che vi mostr<unk> @ o è una c<unk> @ e<unk> @ qu<unk> @ i<unk> @ li<unk> @ bri<unk> @ o in cui abbiamo sc<unk> @ or<unk> @ so in cui abbiamo 2<unk> @ 5 anni .
2025-05-27 19:26:55,698 - INFO - joeynmt.training - Epoch   3, Step:    22100, Batch Loss:     0.982399, Batch Acc: 0.675638, Tokens per Sec:    20272, Lr: 0.000300
2025-05-27 19:26:59,089 - INFO - joeynmt.training - Epoch   3, Step:    22200, Batch Loss:     1.147901, Batch Acc: 0.674515, Tokens per Sec:    23016, Lr: 0.000300
2025-05-27 19:27:02,437 - INFO - joeynmt.training - Epoch   3, Step:    22300, Batch Loss:     1.179490, Batch Acc: 0.676085, Tokens per Sec:    23770, Lr: 0.000300
2025-05-27 19:27:05,832 - INFO - joeynmt.training - Epoch   3, Step:    22400, Batch Loss:     1.123448, Batch Acc: 0.674667, Tokens per Sec:    23744, Lr: 0.000300
2025-05-27 19:27:09,202 - INFO - joeynmt.training - Epoch   3, Step:    22500, Batch Loss:     1.073788, Batch Acc: 0.674979, Tokens per Sec:    23555, Lr: 0.000300
2025-05-27 19:27:09,202 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:27:09,202 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:25, 36.06it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:15, 56.01it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:17, 51.20it/s]Predicting...:   6%|▌         | 56/923 [00:01<00:14, 60.66it/s]Predicting...:   8%|▊         | 72/923 [00:01<00:11, 74.05it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 85.61it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 84.70it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:10, 74.40it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 42.13it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 46.79it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 54.13it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 76.90it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:08, 83.56it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 73.51it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 68.78it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 74.11it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:11, 56.08it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 53.48it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 48.34it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 46.19it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.11it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:09, 61.56it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 63.79it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 69.16it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 74.21it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 85.11it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 101.28it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 99.13it/s] Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 88.73it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 83.18it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 82.70it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 75.53it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 71.65it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 61.51it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.57it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 79.28it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 69.77it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:06, 60.75it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 51.18it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 48.62it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 57.30it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 41.18it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.34it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.63it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:08, 38.05it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 39.72it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 37.88it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 36.34it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:07, 34.14it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 32.97it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 38.68it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:06, 36.48it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 37.93it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:14, 16.17it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:09, 22.90it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:08, 24.81it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:06, 31.40it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 38.98it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:05, 33.46it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 36.15it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 46.10it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 51.76it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:01, 61.74it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 69.37it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 71.62it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 53.26it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 65.12it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 57.66it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 68.67it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 69.81it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 75.25it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 88.67it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 55.22it/s]
2025-05-27 19:27:25,930 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.12, ppl:   3.07, acc:   0.68, generation: 16.7147[sec], evaluation: 0.0000[sec]
2025-05-27 19:27:25,931 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:27:26,469 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/20000.ckpt
2025-05-27 19:27:26,493 - INFO - joeynmt.training - Example #0
2025-05-27 19:27:26,495 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:27:26,495 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:27:26,495 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato queste due milioni di persone , ho mostr<unk> @ ato queste due m<unk> @ ie f<unk> @ re<unk> @ ve per f<unk> @ ar sc<unk> @ o<unk> @ pr<unk> @ ire i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ atori per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ v<unk> @ are tre milioni di m<unk> @ oti<unk> @ v<unk> @ are 4<unk> @ 0 milioni di persone .
2025-05-27 19:27:26,495 - INFO - joeynmt.training - Example #1
2025-05-27 19:27:26,496 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:27:26,496 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:27:26,496 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il ris<unk> @ ult<unk> @ ato di questo tipo di ris<unk> @ ult<unk> @ ato , che non è il ris<unk> @ ult<unk> @ ato di queste probl<unk> @ emi , non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:27:26,496 - INFO - joeynmt.training - Example #2
2025-05-27 19:27:26,497 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:27:26,497 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:27:26,497 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ con<unk> @ si<unk> @ der<unk> @ azione è la c<unk> @ aus<unk> @ a della nostra c<unk> @ at<unk> @ ura glob<unk> @ ale .
2025-05-27 19:27:26,497 - INFO - joeynmt.training - Example #3
2025-05-27 19:27:26,498 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:27:26,498 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:27:26,498 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , si tr<unk> @ at<unk> @ ta di s<unk> @ é .
2025-05-27 19:27:26,498 - INFO - joeynmt.training - Example #4
2025-05-27 19:27:26,499 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:27:26,499 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:27:26,499 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma è che vi mostr<unk> @ o che vi mostr<unk> @ o è una delle ar<unk> @ ee che è una delle sc<unk> @ or<unk> @ sa di quello che succ<unk> @ ede in cui abbiamo sc<unk> @ or<unk> @ so 2<unk> @ 5 anni .
2025-05-27 19:27:29,951 - INFO - joeynmt.training - Epoch   3, Step:    22600, Batch Loss:     1.211226, Batch Acc: 0.673539, Tokens per Sec:    20063, Lr: 0.000300
2025-05-27 19:27:33,381 - INFO - joeynmt.training - Epoch   3, Step:    22700, Batch Loss:     1.139867, Batch Acc: 0.676098, Tokens per Sec:    23820, Lr: 0.000300
2025-05-27 19:27:36,855 - INFO - joeynmt.training - Epoch   3, Step:    22800, Batch Loss:     1.132043, Batch Acc: 0.678326, Tokens per Sec:    22311, Lr: 0.000300
2025-05-27 19:27:40,265 - INFO - joeynmt.training - Epoch   3, Step:    22900, Batch Loss:     1.041087, Batch Acc: 0.674013, Tokens per Sec:    23065, Lr: 0.000300
2025-05-27 19:27:43,671 - INFO - joeynmt.training - Epoch   3, Step:    23000, Batch Loss:     1.164066, Batch Acc: 0.677214, Tokens per Sec:    22909, Lr: 0.000300
2025-05-27 19:27:43,671 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:27:43,671 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:17, 53.07it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:13, 68.10it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:13, 63.58it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:11, 74.74it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 87.55it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:08, 100.85it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 84.15it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 101.04it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 46.03it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 50.08it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 58.13it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 80.02it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.76it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 72.58it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 62.40it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:11, 61.17it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:13, 48.69it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 49.51it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 47.20it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 46.11it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:13, 46.65it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 51.72it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:12, 46.04it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.86it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 66.45it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 70.58it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 76.52it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:07, 70.41it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 77.19it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 91.58it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:06, 76.68it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 67.41it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 68.85it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 80.50it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 76.65it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 85.54it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:05, 66.40it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 50.19it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:06, 56.94it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:07, 43.10it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 44.25it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 51.84it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:05, 52.48it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:05, 51.67it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 42.24it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 36.38it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 35.04it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 38.81it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 33.11it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 37.53it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 30.14it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 38.59it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.20it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 45.07it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 55.04it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 43.31it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 44.67it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 58.00it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 61.26it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 63.16it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 69.11it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.96it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 54.18it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 64.95it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 61.59it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 73.56it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 62.86it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 90.15it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.08it/s]
2025-05-27 19:27:59,303 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.12, ppl:   3.05, acc:   0.68, generation: 15.6226[sec], evaluation: 0.0000[sec]
2025-05-27 19:27:59,303 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:27:59,797 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/20500.ckpt
2025-05-27 19:27:59,820 - INFO - joeynmt.training - Example #0
2025-05-27 19:27:59,822 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:27:59,822 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:27:59,822 - INFO - joeynmt.training - 	Hypothesis: Ho mostr<unk> @ ato questa sc<unk> @ or<unk> @ sa , ho mostr<unk> @ ato questa fot<unk> @ o , per us<unk> @ are la p<unk> @ op<unk> @ ol<unk> @ ie per i tre milioni di persone che hanno sc<unk> @ oper<unk> @ to che i g<unk> @ over<unk> @ ni per i tre milioni di persone che av<unk> @ evano sc<unk> @ ar<unk> @ ic<unk> @ ato per tre milioni di persone che av<unk> @ evano sc<unk> @ oper<unk> @ to .
2025-05-27 19:27:59,822 - INFO - joeynmt.training - Example #1
2025-05-27 19:27:59,823 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:27:59,823 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:27:59,823 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato il fatto che non è la ris<unk> @ ult<unk> @ ata di questa in<unk> @ f<unk> @ re<unk> @ zione di questa di<unk> @ st<unk> @ anza , non è il d<unk> @ or<unk> @ ig<unk> @ in<unk> @ ale .
2025-05-27 19:27:59,823 - INFO - joeynmt.training - Example #2
2025-05-27 19:27:59,824 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:27:59,824 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:27:59,824 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la s<unk> @ edi<unk> @ a è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ale che il nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:27:59,824 - INFO - joeynmt.training - Example #3
2025-05-27 19:27:59,825 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:27:59,825 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:27:59,825 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in realtà , in m<unk> @ ezz<unk> @ o di s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:27:59,825 - INFO - joeynmt.training - Example #4
2025-05-27 19:27:59,826 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:27:59,826 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:27:59,826 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma fot<unk> @ o che vi mostr<unk> @ o una delle cose che è una delle sc<unk> @ or<unk> @ se , in realtà è succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:28:03,179 - INFO - joeynmt.training - Epoch   3, Step:    23100, Batch Loss:     1.077878, Batch Acc: 0.679209, Tokens per Sec:    20475, Lr: 0.000300
2025-05-27 19:28:06,608 - INFO - joeynmt.training - Epoch   3, Step:    23200, Batch Loss:     1.078556, Batch Acc: 0.678151, Tokens per Sec:    23185, Lr: 0.000300
2025-05-27 19:28:09,995 - INFO - joeynmt.training - Epoch   3, Step:    23300, Batch Loss:     1.088844, Batch Acc: 0.675817, Tokens per Sec:    23390, Lr: 0.000300
2025-05-27 19:28:13,423 - INFO - joeynmt.training - Epoch   3, Step:    23400, Batch Loss:     1.061806, Batch Acc: 0.678408, Tokens per Sec:    23050, Lr: 0.000300
2025-05-27 19:28:16,831 - INFO - joeynmt.training - Epoch   3, Step:    23500, Batch Loss:     1.066957, Batch Acc: 0.678564, Tokens per Sec:    23082, Lr: 0.000300
2025-05-27 19:28:16,832 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:28:16,832 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 63.15it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 76.44it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 88.26it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 91.65it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 97.66it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 110.76it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 104.76it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:10, 74.97it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 61.40it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 66.63it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 86.33it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 90.92it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 74.58it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 63.32it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 68.36it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 54.14it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 50.70it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 47.17it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 44.87it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 50.08it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 51.59it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 57.01it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 52.61it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 52.23it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 62.82it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 75.95it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 84.07it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 87.99it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 85.36it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 96.07it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 91.91it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 82.24it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 72.46it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 76.86it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.63it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 67.40it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 76.98it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 59.61it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 45.12it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 38.70it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 36.19it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 45.92it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 35.06it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 33.50it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 35.32it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 44.98it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 47.89it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 44.47it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 41.96it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 33.80it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 33.31it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 37.08it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 33.07it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.24it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.89it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 38.30it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.79it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 38.67it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 48.62it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.25it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.53it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 52.68it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 57.57it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 68.97it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 77.14it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 81.60it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 66.20it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 63.86it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 78.14it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 80.49it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 95.31it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.30it/s]
2025-05-27 19:28:32,409 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.11, ppl:   3.05, acc:   0.68, generation: 15.5649[sec], evaluation: 0.0000[sec]
2025-05-27 19:28:32,410 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:28:32,940 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/21000.ckpt
2025-05-27 19:28:32,965 - INFO - joeynmt.training - Example #0
2025-05-27 19:28:32,966 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:28:32,966 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:28:32,966 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa cosa che ho mostr<unk> @ ato per la f<unk> @ ar sc<unk> @ ar<unk> @ ic<unk> @ are per la f<unk> @ est<unk> @ r<unk> @ azione , che i su<unk> @ oi tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di persone che hanno fatto per i 4<unk> @ 0 milioni di persone che av<unk> @ evano av<unk> @ uto i 4<unk> @ 0 milioni di persone che av<unk> @ evano av<unk> @ uto il 4<unk> @ 0 % .
2025-05-27 19:28:32,966 - INFO - joeynmt.training - Example #1
2025-05-27 19:28:32,967 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:28:32,967 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:28:32,967 - INFO - joeynmt.training - 	Hypothesis: Ma non è n<unk> @ ec<unk> @ ess<unk> @ ario per la ris<unk> @ ol<unk> @ u<unk> @ zione di questa con<unk> @ n<unk> @ es<unk> @ sione , non è il fatto di sol<unk> @ ito .
2025-05-27 19:28:32,967 - INFO - joeynmt.training - Example #2
2025-05-27 19:28:32,968 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:28:32,968 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:28:32,968 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , è la s<unk> @ in<unk> @ cre<unk> @ di<unk> @ bile è la c<unk> @ li<unk> @ sta del nostro sistema glob<unk> @ ale .
2025-05-27 19:28:32,968 - INFO - joeynmt.training - Example #3
2025-05-27 19:28:32,969 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:28:32,969 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:28:32,969 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ om<unk> @ p<unk> @ a e la sc<unk> @ el<unk> @ ta .
2025-05-27 19:28:32,969 - INFO - joeynmt.training - Example #4
2025-05-27 19:28:32,970 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:28:32,970 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:28:32,970 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una delle cose che è una cell<unk> @ u<unk> @ la , che è una delle ulti<unk> @ me due anni .
2025-05-27 19:28:36,400 - INFO - joeynmt.training - Epoch   3, Step:    23600, Batch Loss:     1.203959, Batch Acc: 0.677745, Tokens per Sec:    19813, Lr: 0.000300
2025-05-27 19:28:36,575 - INFO - joeynmt.training - Epoch   3: total training loss 9021.71
2025-05-27 19:28:36,576 - INFO - joeynmt.training - EPOCH 4
2025-05-27 19:28:39,845 - INFO - joeynmt.training - Epoch   4, Step:    23700, Batch Loss:     1.035920, Batch Acc: 0.686407, Tokens per Sec:    23756, Lr: 0.000300
2025-05-27 19:28:43,194 - INFO - joeynmt.training - Epoch   4, Step:    23800, Batch Loss:     1.004512, Batch Acc: 0.688198, Tokens per Sec:    23411, Lr: 0.000300
2025-05-27 19:28:46,529 - INFO - joeynmt.training - Epoch   4, Step:    23900, Batch Loss:     1.083313, Batch Acc: 0.687419, Tokens per Sec:    23591, Lr: 0.000300
2025-05-27 19:28:49,912 - INFO - joeynmt.training - Epoch   4, Step:    24000, Batch Loss:     1.136104, Batch Acc: 0.687703, Tokens per Sec:    23338, Lr: 0.000300
2025-05-27 19:28:49,913 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:28:49,913 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 64.20it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.58it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 96.16it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 96.82it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 106.58it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 113.72it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 115.32it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 124.62it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 52.48it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 56.65it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 64.31it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 80.35it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.92it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.41it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 68.53it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 71.64it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 53.65it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 52.16it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 51.10it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.76it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 56.46it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.59it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 66.00it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 61.38it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 56.43it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 66.55it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 82.20it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 84.96it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 85.99it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 85.22it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 95.56it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 93.09it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 94.88it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 74.42it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 82.62it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 64.66it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 74.30it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 79.97it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 67.87it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 54.32it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 45.31it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 41.98it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.64it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:14, 23.57it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:12, 25.51it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:11, 27.48it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:08, 36.32it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 39.15it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 38.33it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 36.25it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 32.17it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 32.86it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 34.78it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 34.62it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.64it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 28.71it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 36.44it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.05it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 44.56it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 53.90it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 41.45it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 41.92it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 53.69it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 59.28it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 68.49it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 74.86it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.61it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 50.65it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 62.96it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 66.62it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 81.77it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 84.36it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 93.38it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 105.23it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.20it/s] 
2025-05-27 19:29:05,520 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.11, ppl:   3.03, acc:   0.68, generation: 15.5927[sec], evaluation: 0.0000[sec]
2025-05-27 19:29:05,520 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:29:06,097 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/21500.ckpt
2025-05-27 19:29:06,124 - INFO - joeynmt.training - Example #0
2025-05-27 19:29:06,126 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:29:06,126 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:29:06,126 - INFO - joeynmt.training - 	Hypothesis: E in cui ho mostr<unk> @ ato questa sc<unk> @ or<unk> @ sa , ho mostr<unk> @ ato questa fot<unk> @ o per ri<unk> @ dur<unk> @ re l&apos; eff<unk> @ etto di g<unk> @ hi<unk> @ ac<unk> @ cio per i tre mili<unk> @ ar<unk> @ di di di anni , per la c<unk> @ op<unk> @ ol<unk> @ azione per i tre mili<unk> @ ar<unk> @ di di di di anni .
2025-05-27 19:29:06,126 - INFO - joeynmt.training - Example #1
2025-05-27 19:29:06,127 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:29:06,127 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:29:06,127 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il ris<unk> @ ult<unk> @ ato di questo tipo di ris<unk> @ ult<unk> @ ato che la T<unk> @ erra non è il ris<unk> @ ult<unk> @ ato di questa con<unk> @ fer<unk> @ enza , non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:29:06,127 - INFO - joeynmt.training - Example #2
2025-05-27 19:29:06,128 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:29:06,128 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:29:06,128 - INFO - joeynmt.training - 	Hypothesis: In realtà , in cui la s<unk> @ itu<unk> @ azione è la c<unk> @ li<unk> @ sta , la c<unk> @ li<unk> @ m<unk> @ as<unk> @ ca del nostro sistema glob<unk> @ ale .
2025-05-27 19:29:06,128 - INFO - joeynmt.training - Example #3
2025-05-27 19:29:06,129 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:29:06,129 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:29:06,129 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una cosa che si trov<unk> @ a in par<unk> @ ola e la s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:29:06,129 - INFO - joeynmt.training - Example #4
2025-05-27 19:29:06,130 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:29:06,130 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:29:06,130 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa succ<unk> @ essi<unk> @ va che vi mostr<unk> @ er<unk> @ ò è una cell<unk> @ u<unk> @ la , è una delle ulti<unk> @ me anni .
2025-05-27 19:29:09,535 - INFO - joeynmt.training - Epoch   4, Step:    24100, Batch Loss:     1.082881, Batch Acc: 0.687395, Tokens per Sec:    18863, Lr: 0.000300
2025-05-27 19:29:12,906 - INFO - joeynmt.training - Epoch   4, Step:    24200, Batch Loss:     1.060001, Batch Acc: 0.685246, Tokens per Sec:    22934, Lr: 0.000300
2025-05-27 19:29:16,296 - INFO - joeynmt.training - Epoch   4, Step:    24300, Batch Loss:     1.085350, Batch Acc: 0.684724, Tokens per Sec:    23997, Lr: 0.000300
2025-05-27 19:29:19,672 - INFO - joeynmt.training - Epoch   4, Step:    24400, Batch Loss:     1.207040, Batch Acc: 0.685230, Tokens per Sec:    23492, Lr: 0.000300
2025-05-27 19:29:23,061 - INFO - joeynmt.training - Epoch   4, Step:    24500, Batch Loss:     1.087266, Batch Acc: 0.689559, Tokens per Sec:    23415, Lr: 0.000300
2025-05-27 19:29:23,061 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:29:23,061 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:16, 55.07it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 73.49it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:15, 56.41it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:13, 65.62it/s]Predicting...:   8%|▊         | 72/923 [00:01<00:10, 81.06it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:08, 94.79it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 92.21it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:10, 78.15it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 41.95it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 46.23it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 55.11it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 79.89it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 83.19it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 72.51it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 59.55it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 62.05it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:13, 49.53it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 46.87it/s]Predicting...:  30%|███       | 277/923 [00:04<00:15, 40.46it/s]Predicting...:  31%|███▏      | 289/923 [00:05<00:15, 40.03it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:13, 46.69it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 51.66it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:11, 53.33it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 51.10it/s]Predicting...:  38%|███▊      | 347/923 [00:06<00:12, 47.24it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:09, 56.50it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 71.68it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:07, 73.80it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 76.21it/s]Predicting...:  46%|████▌     | 424/923 [00:07<00:09, 52.11it/s]Predicting...:  48%|████▊     | 441/923 [00:07<00:07, 63.85it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:06, 67.47it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 65.23it/s]Predicting...:  52%|█████▏    | 480/923 [00:08<00:07, 60.90it/s]Predicting...:  54%|█████▎    | 494/923 [00:08<00:06, 64.90it/s]Predicting...:  54%|█████▍    | 503/923 [00:08<00:08, 52.37it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:06, 61.40it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 71.53it/s]Predicting...:  59%|█████▊    | 540/923 [00:09<00:06, 59.96it/s]Predicting...:  59%|█████▉    | 548/923 [00:09<00:07, 47.64it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:09, 37.60it/s]Predicting...:  62%|██████▏   | 568/923 [00:10<00:09, 35.67it/s]Predicting...:  63%|██████▎   | 580/923 [00:10<00:07, 43.33it/s]Predicting...:  64%|██████▎   | 587/923 [00:10<00:10, 31.89it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:10, 31.81it/s]Predicting...:  66%|██████▌   | 605/923 [00:11<00:10, 30.85it/s]Predicting...:  67%|██████▋   | 618/923 [00:11<00:08, 38.03it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:07, 40.11it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 36.25it/s]Predicting...:  70%|███████   | 647/923 [00:12<00:08, 33.16it/s]Predicting...:  71%|███████   | 653/923 [00:13<00:14, 19.26it/s]Predicting...:  72%|███████▏  | 661/923 [00:13<00:12, 20.66it/s]Predicting...:  73%|███████▎  | 671/923 [00:13<00:10, 25.11it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:10, 23.51it/s]Predicting...:  74%|███████▍  | 687/923 [00:14<00:09, 25.75it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:10, 22.54it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:07, 29.97it/s]Predicting...:  78%|███████▊  | 717/923 [00:15<00:06, 29.55it/s]Predicting...:  79%|███████▉  | 729/923 [00:15<00:06, 32.18it/s]Predicting...:  80%|████████  | 742/923 [00:15<00:04, 41.60it/s]Predicting...:  81%|████████  | 749/923 [00:16<00:05, 30.78it/s]Predicting...:  82%|████████▏ | 759/923 [00:16<00:05, 32.66it/s]Predicting...:  84%|████████▍ | 774/923 [00:16<00:03, 43.73it/s]Predicting...:  85%|████████▌ | 786/923 [00:16<00:02, 47.91it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 56.98it/s]Predicting...:  88%|████████▊ | 815/923 [00:17<00:01, 68.03it/s]Predicting...:  90%|████████▉ | 827/923 [00:17<00:01, 68.38it/s]Predicting...:  90%|█████████ | 835/923 [00:17<00:01, 46.09it/s]Predicting...:  92%|█████████▏| 850/923 [00:17<00:01, 57.62it/s]Predicting...:  93%|█████████▎| 862/923 [00:18<00:01, 58.23it/s]Predicting...:  95%|█████████▌| 878/923 [00:18<00:00, 70.25it/s]Predicting...:  97%|█████████▋| 892/923 [00:18<00:00, 73.32it/s]Predicting...:  98%|█████████▊| 908/923 [00:18<00:00, 78.55it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 91.81it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 49.64it/s]
2025-05-27 19:29:41,673 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.10, ppl:   3.02, acc:   0.68, generation: 18.5957[sec], evaluation: 0.0000[sec]
2025-05-27 19:29:41,674 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:29:42,237 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/22000.ckpt
2025-05-27 19:29:42,257 - INFO - joeynmt.training - Example #0
2025-05-27 19:29:42,259 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:29:42,259 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:29:42,259 - INFO - joeynmt.training - 	Hypothesis: E la l<unk> @ et<unk> @ ter<unk> @ almente ho mostr<unk> @ ato questa cosa che l&apos; anno sc<unk> @ or<unk> @ sa che la g<unk> @ ar<unk> @ t<unk> @ ica per i di<unk> @ segn<unk> @ ali che i g<unk> @ over<unk> @ ni per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di anni , che aveva 4<unk> @ 0 milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi .
2025-05-27 19:29:42,259 - INFO - joeynmt.training - Example #1
2025-05-27 19:29:42,260 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:29:42,260 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:29:42,260 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è un po &apos; di questo , non è un po &apos; di in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ ità di questo in<unk> @ cre<unk> @ di<unk> @ bile in<unk> @ segn<unk> @ ale , non è il d<unk> @ ott<unk> @ ico .
2025-05-27 19:29:42,260 - INFO - joeynmt.training - Example #2
2025-05-27 19:29:42,261 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:29:42,261 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:29:42,261 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la c<unk> @ li<unk> @ sta di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ando il nostro sistema di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale è il nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:29:42,261 - INFO - joeynmt.training - Example #3
2025-05-27 19:29:42,262 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:29:42,262 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:29:42,262 - INFO - joeynmt.training - 	Hypothesis: D<unk> @ ov<unk> @ ete s<unk> @ ent<unk> @ ito , e il più b<unk> @ el .
2025-05-27 19:29:42,262 - INFO - joeynmt.training - Example #4
2025-05-27 19:29:42,263 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:29:42,263 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:29:42,263 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ a la prima cosa che è succ<unk> @ ede in cui è una cosa che è succ<unk> @ ede in cui abbiamo sc<unk> @ oper<unk> @ to in cui abbiamo sc<unk> @ or<unk> @ so il 2<unk> @ 5 anni .
2025-05-27 19:29:45,633 - INFO - joeynmt.training - Epoch   4, Step:    24600, Batch Loss:     1.010595, Batch Acc: 0.685902, Tokens per Sec:    20138, Lr: 0.000300
2025-05-27 19:29:49,011 - INFO - joeynmt.training - Epoch   4, Step:    24700, Batch Loss:     1.053700, Batch Acc: 0.686683, Tokens per Sec:    22860, Lr: 0.000300
2025-05-27 19:29:52,376 - INFO - joeynmt.training - Epoch   4, Step:    24800, Batch Loss:     0.994363, Batch Acc: 0.687284, Tokens per Sec:    22887, Lr: 0.000300
2025-05-27 19:29:55,751 - INFO - joeynmt.training - Epoch   4, Step:    24900, Batch Loss:     1.139652, Batch Acc: 0.683940, Tokens per Sec:    23203, Lr: 0.000300
2025-05-27 19:29:59,118 - INFO - joeynmt.training - Epoch   4, Step:    25000, Batch Loss:     1.071697, Batch Acc: 0.688119, Tokens per Sec:    23252, Lr: 0.000300
2025-05-27 19:29:59,119 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:29:59,119 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 57.06it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 75.09it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 76.18it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:11, 77.63it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.06it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 111.57it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 107.38it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 116.00it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.40it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 53.76it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.29it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 80.25it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 88.28it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 76.93it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 59.71it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 68.44it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 53.49it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 52.91it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 50.78it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.54it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 54.22it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.43it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 62.64it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 64.52it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 72.52it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 82.72it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 95.61it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:07, 64.27it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 75.83it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 77.30it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 78.74it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 75.10it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 80.65it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 58.84it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 69.10it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 79.38it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:06, 53.82it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 44.88it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 42.40it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 48.62it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 36.83it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.84it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 35.19it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 42.52it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.21it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 39.82it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.38it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:09, 29.31it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 29.02it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 32.97it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.34it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 31.20it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 25.49it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 33.71it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 32.78it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 40.33it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 51.26it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 42.03it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 41.50it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 53.36it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 59.38it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 69.85it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 79.93it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 79.76it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 68.58it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 69.09it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 79.46it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 81.93it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 92.56it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 102.19it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.53it/s] 
2025-05-27 19:30:14,904 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.10, ppl:   3.01, acc:   0.68, generation: 15.7710[sec], evaluation: 0.0000[sec]
2025-05-27 19:30:14,904 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:30:15,412 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/22500.ckpt
2025-05-27 19:30:15,433 - INFO - joeynmt.training - Example #0
2025-05-27 19:30:15,434 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:30:15,434 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:30:15,434 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due due due anni , per ri<unk> @ dur<unk> @ re la p<unk> @ op<unk> @ i , che la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ol<unk> @ i , che hanno ri<unk> @ m<unk> @ b<unk> @ ato per tre mili<unk> @ ar<unk> @ di di di anni , e per la 4<unk> @ 0 anni , è stato il 4<unk> @ 0 e m<unk> @ oti<unk> @ vi .
2025-05-27 19:30:15,434 - INFO - joeynmt.training - Example #1
2025-05-27 19:30:15,435 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:30:15,435 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:30:15,435 - INFO - joeynmt.training - 	Hypothesis: Ma non è il t<unk> @ as<unk> @ so di questo , la cosa che non è il ris<unk> @ ult<unk> @ ato di questo in<unk> @ f<unk> @ lu<unk> @ en<unk> @ o , non è il d<unk> @ ott<unk> @ ore di questo , non è il d<unk> @ ott<unk> @ ico .
2025-05-27 19:30:15,435 - INFO - joeynmt.training - Example #2
2025-05-27 19:30:15,436 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:30:15,436 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:30:15,436 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ an<unk> @ ità è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore della nostra c<unk> @ li<unk> @ ma è il cu<unk> @ ore di un sistema glob<unk> @ ale .
2025-05-27 19:30:15,436 - INFO - joeynmt.training - Example #3
2025-05-27 19:30:15,437 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:30:15,437 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:30:15,437 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ c<unk> @ e<unk> @ zion<unk> @ a , e la cosa che si s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:30:15,437 - INFO - joeynmt.training - Example #4
2025-05-27 19:30:15,438 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:30:15,438 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:30:15,438 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma è una cosa che è succ<unk> @ esso , è una cosa che è succ<unk> @ esso in sc<unk> @ or<unk> @ so che è succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:30:18,798 - INFO - joeynmt.training - Epoch   4, Step:    25100, Batch Loss:     1.094341, Batch Acc: 0.683679, Tokens per Sec:    20586, Lr: 0.000300
2025-05-27 19:30:22,150 - INFO - joeynmt.training - Epoch   4, Step:    25200, Batch Loss:     1.038399, Batch Acc: 0.688114, Tokens per Sec:    24190, Lr: 0.000300
2025-05-27 19:30:25,459 - INFO - joeynmt.training - Epoch   4, Step:    25300, Batch Loss:     1.039276, Batch Acc: 0.687454, Tokens per Sec:    23131, Lr: 0.000300
2025-05-27 19:30:28,786 - INFO - joeynmt.training - Epoch   4, Step:    25400, Batch Loss:     1.012030, Batch Acc: 0.689163, Tokens per Sec:    23966, Lr: 0.000300
2025-05-27 19:30:32,129 - INFO - joeynmt.training - Epoch   4, Step:    25500, Batch Loss:     1.083997, Batch Acc: 0.687525, Tokens per Sec:    23947, Lr: 0.000300
2025-05-27 19:30:32,129 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:30:32,129 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 67.79it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 80.66it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:15, 58.28it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:11, 74.45it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 88.84it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:08, 102.65it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 98.19it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 109.55it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 46.01it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 52.46it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 61.86it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 90.81it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 97.30it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.63it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 73.98it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:09, 69.30it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:09, 66.32it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 63.26it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:10, 60.47it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 68.30it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 70.57it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 73.80it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 69.99it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 68.23it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 81.85it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 99.43it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 105.74it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 108.86it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 105.11it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 119.31it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 109.37it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 104.54it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.31it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 78.32it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:05, 70.36it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 79.66it/s]Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 81.27it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 53.31it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 47.14it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 54.11it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 46.06it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 43.61it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 42.19it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 51.68it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.08it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 45.08it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 45.38it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:08, 32.24it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 32.81it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.16it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 37.73it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 41.70it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 32.21it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 42.45it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 41.46it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 51.24it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 64.79it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 47.54it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:03, 49.04it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 55.77it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 77.85it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 82.66it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:00, 74.36it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 73.12it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 92.64it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 102.19it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 66.76it/s] 
2025-05-27 19:30:45,964 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.10, ppl:   2.99, acc:   0.68, generation: 13.8268[sec], evaluation: 0.0000[sec]
2025-05-27 19:30:45,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:30:46,464 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/23000.ckpt
2025-05-27 19:30:46,488 - INFO - joeynmt.training - Example #0
2025-05-27 19:30:46,489 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:30:46,490 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:30:46,490 - INFO - joeynmt.training - 	Hypothesis: E la rete di queste due volte , ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o , per ri<unk> @ dur<unk> @ re la g<unk> @ oc<unk> @ cia , che i g<unk> @ over<unk> @ ni per tre anni , per la met<unk> @ à di tre anni , per la 4<unk> @ 8 milioni di anni , per la 4<unk> @ 8 milioni di persone che av<unk> @ evano fatto per la 4<unk> @ 0 % .
2025-05-27 19:30:46,490 - INFO - joeynmt.training - Example #1
2025-05-27 19:30:46,491 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:30:46,491 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:30:46,491 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è un problema di in<unk> @ ten<unk> @ zione di questa in<unk> @ f<unk> @ lu<unk> @ enza , non è il d<unk> @ ott<unk> @ ore , non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:30:46,491 - INFO - joeynmt.training - Example #2
2025-05-27 19:30:46,492 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:30:46,492 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:30:46,492 - INFO - joeynmt.training - 	Hypothesis: In realtà , la c<unk> @ li<unk> @ sta è la c<unk> @ las<unk> @ se è la g<unk> @ hi<unk> @ es<unk> @ sione del sistema glob<unk> @ ale .
2025-05-27 19:30:46,492 - INFO - joeynmt.training - Example #3
2025-05-27 19:30:46,493 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:30:46,493 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:30:46,493 - INFO - joeynmt.training - 	Hypothesis: E &apos; più al<unk> @ ta , e il p<unk> @ ezz<unk> @ o , e il p<unk> @ ezz<unk> @ o .
2025-05-27 19:30:46,493 - INFO - joeynmt.training - Example #4
2025-05-27 19:30:46,494 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:30:46,494 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:30:46,494 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo p<unk> @ oco che vi mostr<unk> @ o è una delle cose che ho mostr<unk> @ ato a quello che sta succ<unk> @ e<unk> @ dendo in 2<unk> @ 5 anni .
2025-05-27 19:30:49,805 - INFO - joeynmt.training - Epoch   4, Step:    25600, Batch Loss:     1.165602, Batch Acc: 0.689896, Tokens per Sec:    20977, Lr: 0.000300
2025-05-27 19:30:53,177 - INFO - joeynmt.training - Epoch   4, Step:    25700, Batch Loss:     1.099198, Batch Acc: 0.691517, Tokens per Sec:    24065, Lr: 0.000300
2025-05-27 19:30:56,550 - INFO - joeynmt.training - Epoch   4, Step:    25800, Batch Loss:     1.106754, Batch Acc: 0.687349, Tokens per Sec:    23440, Lr: 0.000300
2025-05-27 19:30:59,932 - INFO - joeynmt.training - Epoch   4, Step:    25900, Batch Loss:     1.033412, Batch Acc: 0.690626, Tokens per Sec:    23497, Lr: 0.000300
2025-05-27 19:31:03,332 - INFO - joeynmt.training - Epoch   4, Step:    26000, Batch Loss:     1.048194, Batch Acc: 0.688440, Tokens per Sec:    23838, Lr: 0.000300
2025-05-27 19:31:03,332 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:31:03,332 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 66.87it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 78.06it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 89.68it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 96.33it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 100.48it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 108.45it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 109.71it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 122.93it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 49.88it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 55.86it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 65.05it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 92.24it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 99.04it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 72.84it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 61.59it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 67.60it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 54.11it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:13, 50.19it/s]Predicting...:  30%|███       | 277/923 [00:04<00:14, 44.71it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 43.27it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 49.97it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.55it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 57.46it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 59.23it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 67.22it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 76.62it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 81.46it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 85.13it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 89.28it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 100.55it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 100.74it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 94.74it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 80.57it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 82.51it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.44it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.67it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 76.63it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 59.65it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 47.02it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 42.69it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 39.48it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.70it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 37.11it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.36it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 35.54it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 44.22it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 45.23it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.51it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 36.92it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 30.07it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 28.83it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 33.10it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.13it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.81it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 31.66it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 42.15it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 39.25it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 48.34it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:02, 61.54it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 47.12it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 51.06it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 59.20it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 68.57it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 80.59it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 82.44it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 71.97it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 78.26it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 96.01it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 119.65it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 61.74it/s] 
2025-05-27 19:31:18,290 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.09, ppl:   2.98, acc:   0.69, generation: 14.9494[sec], evaluation: 0.0000[sec]
2025-05-27 19:31:18,290 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:31:18,753 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/23500.ckpt
2025-05-27 19:31:18,776 - INFO - joeynmt.training - Example #0
2025-05-27 19:31:18,777 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:31:18,777 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:31:18,777 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questa fot<unk> @ o , per ri<unk> @ guar<unk> @ do a questo , per esempio , per la sc<unk> @ oper<unk> @ ta di g<unk> @ hi<unk> @ ac<unk> @ cio per i tre milioni di anni , per la m<unk> @ oti<unk> @ v<unk> @ azione , per la sc<unk> @ oper<unk> @ ta del 4<unk> @ 8 milioni di anni , il 4<unk> @ 8 , che è stato il 4<unk> @ 8 milioni di anni .
2025-05-27 19:31:18,777 - INFO - joeynmt.training - Example #1
2025-05-27 19:31:18,778 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:31:18,778 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:31:18,778 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po &apos; di non è la cosa più in<unk> @ cre<unk> @ di<unk> @ bile , la cosa che è il fatto è il t<unk> @ ot<unk> @ ore , non è il d<unk> @ ott<unk> @ ore , non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:31:18,778 - INFO - joeynmt.training - Example #2
2025-05-27 19:31:18,779 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:31:18,779 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:31:18,779 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la s<unk> @ qu<unk> @ ad<unk> @ ra è la c<unk> @ li<unk> @ sta è la c<unk> @ li<unk> @ sta del nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:31:18,779 - INFO - joeynmt.training - Example #3
2025-05-27 19:31:18,779 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , si tr<unk> @ at<unk> @ ta di una cosa .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - Example #4
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:31:18,780 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa succ<unk> @ ede , vi mostr<unk> @ er<unk> @ ò una delle cose che è una delle due anni .
2025-05-27 19:31:22,184 - INFO - joeynmt.training - Epoch   4, Step:    26100, Batch Loss:     1.118849, Batch Acc: 0.689869, Tokens per Sec:    21254, Lr: 0.000300
2025-05-27 19:31:25,588 - INFO - joeynmt.training - Epoch   4, Step:    26200, Batch Loss:     0.974267, Batch Acc: 0.687538, Tokens per Sec:    23729, Lr: 0.000300
2025-05-27 19:31:28,977 - INFO - joeynmt.training - Epoch   4, Step:    26300, Batch Loss:     1.017440, Batch Acc: 0.687288, Tokens per Sec:    23286, Lr: 0.000300
2025-05-27 19:31:32,336 - INFO - joeynmt.training - Epoch   4, Step:    26400, Batch Loss:     1.052030, Batch Acc: 0.689610, Tokens per Sec:    23532, Lr: 0.000300
2025-05-27 19:31:35,710 - INFO - joeynmt.training - Epoch   4, Step:    26500, Batch Loss:     1.143665, Batch Acc: 0.690406, Tokens per Sec:    24135, Lr: 0.000300
2025-05-27 19:31:35,710 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:31:35,710 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 67.00it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.30it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 96.03it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 106.23it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 114.86it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 126.31it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:10, 80.10it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 95.49it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:17, 45.62it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 51.12it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 50.48it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 74.54it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.40it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 85.93it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 70.13it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 77.34it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.40it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 52.80it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 52.92it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 58.91it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 64.92it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 66.41it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 68.61it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 76.91it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 93.16it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 101.79it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 96.25it/s] Predicting...:  46%|████▌     | 424/923 [00:06<00:08, 60.49it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:07, 64.46it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 69.65it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 77.83it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 70.85it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 77.28it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 60.52it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.94it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 83.13it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 54.39it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 48.19it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 44.49it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 52.67it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.98it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 37.98it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.44it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.98it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 47.65it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.73it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.98it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 38.01it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 34.11it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 36.98it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.39it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.08it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 31.51it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 41.29it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.83it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 44.15it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 55.65it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 41.35it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.83it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 50.29it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 55.53it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 65.27it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 79.06it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 79.88it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 64.92it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 64.54it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 77.38it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 78.80it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 88.57it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 97.88it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.72it/s]
2025-05-27 19:31:50,924 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.09, ppl:   2.96, acc:   0.69, generation: 15.2010[sec], evaluation: 0.0000[sec]
2025-05-27 19:31:50,925 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:31:51,504 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/24000.ckpt
2025-05-27 19:31:51,529 - INFO - joeynmt.training - Example #0
2025-05-27 19:31:51,531 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:31:51,531 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:31:51,531 - INFO - joeynmt.training - 	Hypothesis: In<unk> @ fine , ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o , per c<unk> @ ento per c<unk> @ ento che i si<unk> @ ano st<unk> @ at<unk> @ or<unk> @ ali che i si<unk> @ ano di<unk> @ st<unk> @ in<unk> @ gu<unk> @ e per c<unk> @ ento di tre milioni di anni , per la m<unk> @ oti<unk> @ v<unk> @ azione .
2025-05-27 19:31:51,531 - INFO - joeynmt.training - Example #1
2025-05-27 19:31:51,532 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:31:51,532 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:31:51,532 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un po &apos; di qu<unk> @ ell&apos; in<unk> @ tr<unk> @ op<unk> @ po , la ver<unk> @ ità di questa con<unk> @ n<unk> @ es<unk> @ ità , non è il D<unk> @ ic<unk> @ i<unk> @ di<unk> @ o del gen<unk> @ ere , non è il D<unk> @ ic<unk> @ io .
2025-05-27 19:31:51,532 - INFO - joeynmt.training - Example #2
2025-05-27 19:31:51,533 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:31:51,533 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:31:51,533 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la s<unk> @ perim<unk> @ ent<unk> @ azione è la c<unk> @ li<unk> @ sta del nostro sistema glob<unk> @ ale del nostro sistema glob<unk> @ ale glob<unk> @ ale del nostro sistema glob<unk> @ ale .
2025-05-27 19:31:51,533 - INFO - joeynmt.training - Example #3
2025-05-27 19:31:51,534 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:31:51,534 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:31:51,534 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ ebbe la s<unk> @ edi<unk> @ a e la s<unk> @ om<unk> @ ma .
2025-05-27 19:31:51,534 - INFO - joeynmt.training - Example #4
2025-05-27 19:31:51,535 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:31:51,535 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:31:51,535 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o la mia cosa che vi mostr<unk> @ o è una delle cose che è succ<unk> @ esso in cui l&apos; ulti<unk> @ mo , che è succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:31:54,921 - INFO - joeynmt.training - Epoch   4, Step:    26600, Batch Loss:     1.065560, Batch Acc: 0.691241, Tokens per Sec:    20322, Lr: 0.000300
2025-05-27 19:31:58,244 - INFO - joeynmt.training - Epoch   4, Step:    26700, Batch Loss:     1.175195, Batch Acc: 0.689104, Tokens per Sec:    23697, Lr: 0.000300
2025-05-27 19:32:01,576 - INFO - joeynmt.training - Epoch   4, Step:    26800, Batch Loss:     0.997862, Batch Acc: 0.687696, Tokens per Sec:    24275, Lr: 0.000300
2025-05-27 19:32:04,932 - INFO - joeynmt.training - Epoch   4, Step:    26900, Batch Loss:     1.075265, Batch Acc: 0.688119, Tokens per Sec:    23660, Lr: 0.000300
2025-05-27 19:32:08,235 - INFO - joeynmt.training - Epoch   4, Step:    27000, Batch Loss:     1.029179, Batch Acc: 0.690199, Tokens per Sec:    24099, Lr: 0.000300
2025-05-27 19:32:08,235 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:32:08,235 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 60.60it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 73.86it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 87.32it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 99.56it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 109.47it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 122.43it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 110.31it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 123.70it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 55.71it/s] Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 61.18it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.05it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 87.07it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.12it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 59.26it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 65.55it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 52.52it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 50.57it/s]Predicting...:  30%|███       | 277/923 [00:03<00:13, 49.62it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 46.27it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.09it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 53.92it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 58.65it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.44it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 64.49it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 76.98it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 81.79it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 79.08it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:09, 53.93it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:07, 64.75it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 71.65it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:06, 73.30it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 68.57it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:06, 69.55it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 59.00it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.15it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 79.67it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 69.99it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:06, 54.14it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 44.30it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 41.00it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 49.05it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 37.49it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 37.21it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 38.55it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 48.15it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 45.62it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 42.25it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.79it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 32.47it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 31.92it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.18it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.50it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.97it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:09, 24.79it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 32.41it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 34.20it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 40.92it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 50.67it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 39.97it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 41.32it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 52.92it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 59.99it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 66.58it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 73.61it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 78.16it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 63.66it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 60.17it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 71.17it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 73.95it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 84.21it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.36it/s]
2025-05-27 19:32:24,063 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.09, ppl:   2.96, acc:   0.69, generation: 15.8153[sec], evaluation: 0.0000[sec]
2025-05-27 19:32:24,064 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:32:24,577 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/24500.ckpt
2025-05-27 19:32:24,601 - INFO - joeynmt.training - Example #0
2025-05-27 19:32:24,602 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:32:24,602 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:32:24,602 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa sc<unk> @ or<unk> @ sa che ho mostr<unk> @ ato per ri<unk> @ dur<unk> @ re la b<unk> @ or<unk> @ sa che i c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , per i tre anni , per la b<unk> @ att<unk> @ ag<unk> @ lia , per i tre anni , per la maggi<unk> @ or parte del 4<unk> @ 0 % di questi tre anni , per la maggi<unk> @ or parte del 4<unk> @ 0 % .
2025-05-27 19:32:24,602 - INFO - joeynmt.training - Example #1
2025-05-27 19:32:24,603 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:32:24,603 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:32:24,604 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato un problema .
2025-05-27 19:32:24,604 - INFO - joeynmt.training - Example #2
2025-05-27 19:32:24,604 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ itu<unk> @ azione è la c<unk> @ aus<unk> @ a è la c<unk> @ aus<unk> @ a del nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - Example #3
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:32:24,605 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in v<unk> @ ento e la b<unk> @ ell<unk> @ issi<unk> @ ma .
2025-05-27 19:32:24,606 - INFO - joeynmt.training - Example #4
2025-05-27 19:32:24,606 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:32:24,606 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:32:24,606 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una c<unk> @ el<unk> @ et<unk> @ ta che è una c<unk> @ r<unk> @ ot<unk> @ ta in sc<unk> @ or<unk> @ so .
2025-05-27 19:32:28,004 - INFO - joeynmt.training - Epoch   4, Step:    27100, Batch Loss:     0.985654, Batch Acc: 0.687564, Tokens per Sec:    20220, Lr: 0.000300
2025-05-27 19:32:31,294 - INFO - joeynmt.training - Epoch   4, Step:    27200, Batch Loss:     1.050802, Batch Acc: 0.693522, Tokens per Sec:    24360, Lr: 0.000300
2025-05-27 19:32:34,612 - INFO - joeynmt.training - Epoch   4, Step:    27300, Batch Loss:     1.008321, Batch Acc: 0.689137, Tokens per Sec:    24354, Lr: 0.000300
2025-05-27 19:32:37,924 - INFO - joeynmt.training - Epoch   4, Step:    27400, Batch Loss:     1.027371, Batch Acc: 0.690849, Tokens per Sec:    23757, Lr: 0.000300
2025-05-27 19:32:41,286 - INFO - joeynmt.training - Epoch   4, Step:    27500, Batch Loss:     1.095005, Batch Acc: 0.689751, Tokens per Sec:    23183, Lr: 0.000300
2025-05-27 19:32:41,286 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:32:41,286 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 70.19it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 84.28it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 88.96it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 93.76it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 101.01it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 103.98it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 72.55it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:11, 67.72it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:19, 40.69it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 47.52it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.04it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.89it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.41it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 71.36it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 79.44it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 61.95it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 62.05it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 57.29it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 59.77it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 64.54it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 74.11it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 74.53it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:06, 83.02it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 100.77it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:04, 108.37it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 110.92it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 119.36it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:03, 131.63it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:03, 120.37it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 107.60it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 102.67it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 97.90it/s] Predicting...:  58%|█████▊    | 531/923 [00:06<00:03, 104.23it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:05, 72.90it/s] Predicting...:  62%|██████▏   | 568/923 [00:07<00:05, 59.24it/s]Predicting...:  64%|██████▎   | 587/923 [00:07<00:06, 52.57it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:06, 50.43it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 50.35it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 59.37it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:04, 60.11it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 53.72it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 53.09it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 39.64it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 37.05it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 40.14it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 39.71it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 41.42it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 36.80it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 48.33it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:04, 41.64it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 52.79it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 65.43it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 50.14it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 59.93it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:02, 67.48it/s]Predicting...:  87%|████████▋ | 800/923 [00:11<00:01, 76.12it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 77.86it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 80.13it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:00, 83.42it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 78.01it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 95.90it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 118.44it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 70.71it/s] 
2025-05-27 19:32:54,349 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.08, ppl:   2.95, acc:   0.69, generation: 13.0539[sec], evaluation: 0.0000[sec]
2025-05-27 19:32:54,349 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:32:54,832 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/25000.ckpt
2025-05-27 19:32:54,856 - INFO - joeynmt.training - Example #0
2025-05-27 19:32:54,857 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:32:54,857 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:32:54,857 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due milioni di persone che hanno mostr<unk> @ ato per la f<unk> @ av<unk> @ e per la c<unk> @ aus<unk> @ a di tre mili<unk> @ ar<unk> @ elli che hanno in<unk> @ segn<unk> @ ato per i tre mili<unk> @ ar<unk> @ elli che hanno fatto per il 4<unk> @ 8 mili<unk> @ ar<unk> @ di di di di di di di di anni .
2025-05-27 19:32:54,857 - INFO - joeynmt.training - Example #1
2025-05-27 19:32:54,858 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:32:54,858 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:32:54,858 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato il punto di vi<unk> @ sta , non è stato stato stato il ter<unk> @ m<unk> @ ine di questo problema , non è il che è il ter<unk> @ m<unk> @ ine .
2025-05-27 19:32:54,858 - INFO - joeynmt.training - Example #2
2025-05-27 19:32:54,859 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:32:54,859 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:32:54,859 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la cosa è il nostro sistema di em<unk> @ er<unk> @ g<unk> @ ri<unk> @ g<unk> @ ere il nostro sistema glob<unk> @ ale .
2025-05-27 19:32:54,859 - INFO - joeynmt.training - Example #3
2025-05-27 19:32:54,860 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:32:54,860 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:32:54,860 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ c<unk> @ ri<unk> @ ve , e si tr<unk> @ at<unk> @ ta in s<unk> @ om<unk> @ ma .
2025-05-27 19:32:54,860 - INFO - joeynmt.training - Example #4
2025-05-27 19:32:54,861 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:32:54,861 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:32:54,861 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo f<unk> @ ar vedere la cosa che vi mostr<unk> @ a è una cell<unk> @ u<unk> @ la , è che è succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:32:58,207 - INFO - joeynmt.training - Epoch   4, Step:    27600, Batch Loss:     1.062792, Batch Acc: 0.688821, Tokens per Sec:    20510, Lr: 0.000300
2025-05-27 19:33:01,602 - INFO - joeynmt.training - Epoch   4, Step:    27700, Batch Loss:     1.075925, Batch Acc: 0.686993, Tokens per Sec:    23732, Lr: 0.000300
2025-05-27 19:33:04,946 - INFO - joeynmt.training - Epoch   4, Step:    27800, Batch Loss:     1.228719, Batch Acc: 0.688935, Tokens per Sec:    23380, Lr: 0.000300
2025-05-27 19:33:08,331 - INFO - joeynmt.training - Epoch   4, Step:    27900, Batch Loss:     1.025400, Batch Acc: 0.687964, Tokens per Sec:    24017, Lr: 0.000300
2025-05-27 19:33:11,694 - INFO - joeynmt.training - Epoch   4, Step:    28000, Batch Loss:     1.047979, Batch Acc: 0.691640, Tokens per Sec:    23753, Lr: 0.000300
2025-05-27 19:33:11,694 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:33:11,694 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:17, 52.80it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.09it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 103.88it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 114.15it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 112.57it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 130.46it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:08, 95.32it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:09, 79.44it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:08, 87.07it/s]Predicting...:  20%|██        | 185/923 [00:01<00:06, 113.43it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:06, 108.73it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:06, 105.52it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:06, 100.02it/s]Predicting...:  29%|██▉       | 267/923 [00:02<00:08, 73.35it/s] Predicting...:  30%|███       | 277/923 [00:03<00:09, 70.39it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:09, 63.41it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 70.68it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 74.01it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 77.72it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 77.77it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 103.30it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 106.33it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:06, 72.70it/s] Predicting...:  49%|████▉     | 455/923 [00:05<00:05, 88.54it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:05, 82.01it/s]Predicting...:  52%|█████▏    | 480/923 [00:05<00:05, 76.22it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 85.81it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 77.88it/s]Predicting...:  59%|█████▊    | 540/923 [00:06<00:05, 72.17it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:06, 54.94it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 49.93it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 57.55it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:07, 43.82it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 44.96it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 53.77it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 54.36it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 52.01it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 49.67it/s]Predicting...:  71%|███████   | 653/923 [00:08<00:05, 45.95it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 41.05it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:05, 46.50it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 39.00it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:05, 40.92it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 34.26it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:05, 42.60it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:05, 40.01it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 48.95it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:02, 62.25it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 49.48it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 62.49it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:01, 69.27it/s]Predicting...:  87%|████████▋ | 800/923 [00:11<00:01, 73.34it/s]Predicting...:  90%|████████▉ | 827/923 [00:11<00:01, 92.59it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:00, 79.40it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 72.08it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 86.77it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 112.68it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 71.73it/s] 
2025-05-27 19:33:24,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.08, ppl:   2.93, acc:   0.69, generation: 12.8677[sec], evaluation: 0.0000[sec]
2025-05-27 19:33:24,571 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:33:25,043 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/25500.ckpt
2025-05-27 19:33:25,067 - INFO - joeynmt.training - Example #0
2025-05-27 19:33:25,069 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:33:25,069 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:33:25,069 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , per il che il 4<unk> @ 0 % delle em<unk> @ is<unk> @ c<unk> @ k<unk> @ ing , per i tre anni , per le persone che hanno sc<unk> @ oper<unk> @ to per il 4<unk> @ 0 % delle persone che hanno fatto per il 4<unk> @ 0 % delle persone che hanno fatto per il 4<unk> @ 0 % delle persone .
2025-05-27 19:33:25,069 - INFO - joeynmt.training - Example #1
2025-05-27 19:33:25,070 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:33:25,070 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:33:25,070 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il fatto è il ter<unk> @ m<unk> @ ine di questo problema , il che non è il ris<unk> @ ult<unk> @ ato di questo probl<unk> @ emi , non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:33:25,070 - INFO - joeynmt.training - Example #2
2025-05-27 19:33:25,071 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:33:25,071 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:33:25,071 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , il nostro sistema è la c<unk> @ li<unk> @ m<unk> @ as<unk> @ c<unk> @ uno dei nostri c<unk> @ li<unk> @ m<unk> @ as<unk> @ c<unk> @ uno dei nostri sist<unk> @ emi glob<unk> @ ali .
2025-05-27 19:33:25,071 - INFO - joeynmt.training - Example #3
2025-05-27 19:33:25,072 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:33:25,072 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:33:25,072 - INFO - joeynmt.training - 	Hypothesis: E &apos; la cosa cosa cosa che si tr<unk> @ at<unk> @ ta di s<unk> @ om<unk> @ p<unk> @ e e e in l<unk> @ et<unk> @ ter<unk> @ almente .
2025-05-27 19:33:25,072 - INFO - joeynmt.training - Example #4
2025-05-27 19:33:25,073 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:33:25,073 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:33:25,073 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo tel<unk> @ e<unk> @ fon<unk> @ do , è una cell<unk> @ u<unk> @ la è una cell<unk> @ u<unk> @ la , che è succ<unk> @ esso in 2<unk> @ 5 anni .
2025-05-27 19:33:28,444 - INFO - joeynmt.training - Epoch   4, Step:    28100, Batch Loss:     1.050522, Batch Acc: 0.688771, Tokens per Sec:    20423, Lr: 0.000300
2025-05-27 19:33:31,810 - INFO - joeynmt.training - Epoch   4, Step:    28200, Batch Loss:     1.110902, Batch Acc: 0.683956, Tokens per Sec:    24119, Lr: 0.000300
2025-05-27 19:33:35,178 - INFO - joeynmt.training - Epoch   4, Step:    28300, Batch Loss:     1.047236, Batch Acc: 0.690302, Tokens per Sec:    23060, Lr: 0.000300
2025-05-27 19:33:38,528 - INFO - joeynmt.training - Epoch   4, Step:    28400, Batch Loss:     1.023646, Batch Acc: 0.687503, Tokens per Sec:    23809, Lr: 0.000300
2025-05-27 19:33:41,904 - INFO - joeynmt.training - Epoch   4, Step:    28500, Batch Loss:     1.117275, Batch Acc: 0.690655, Tokens per Sec:    23239, Lr: 0.000300
2025-05-27 19:33:41,904 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:33:41,904 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 66.02it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 77.60it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 86.19it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 91.54it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 78.98it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 92.05it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:12, 66.53it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:10, 79.77it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:19, 40.97it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 47.43it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.55it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 74.80it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 80.94it/s]Predicting...:  23%|██▎       | 211/923 [00:03<00:08, 81.16it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:08, 82.75it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 70.89it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 76.51it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 57.78it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 50.11it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 49.26it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:15, 41.12it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:13, 46.56it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 52.23it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 56.33it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 62.88it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.49it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 65.76it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 84.72it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:08, 64.83it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 75.53it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 77.29it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 87.04it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 87.17it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 85.62it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 77.87it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 82.22it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.82it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 71.54it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 81.67it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 51.82it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 45.96it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:08, 40.60it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 46.90it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 34.09it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:10, 32.57it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 33.58it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 43.68it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.84it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 39.48it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 35.28it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:10, 26.18it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 28.85it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.85it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:07, 32.39it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:06, 37.42it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.85it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 39.23it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:05, 39.39it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 47.63it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 59.82it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 50.82it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 51.28it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 58.98it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 82.24it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 83.82it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:00, 73.34it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 73.89it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 96.12it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 105.25it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.28it/s] 
2025-05-27 19:33:57,483 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.93, acc:   0.69, generation: 15.5703[sec], evaluation: 0.0000[sec]
2025-05-27 19:33:57,483 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:33:57,984 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/26000.ckpt
2025-05-27 19:33:58,003 - INFO - joeynmt.training - Example #0
2025-05-27 19:33:58,004 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:33:58,004 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:33:58,004 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due due milioni di persone che hanno mostr<unk> @ ato per ri<unk> @ port<unk> @ are le em<unk> @ o<unk> @ zioni che le em<unk> @ ic<unk> @ i<unk> @ p<unk> @ e che hanno ri<unk> @ m<unk> @ esso di tre milioni di persone che hanno ri<unk> @ m<unk> @ esso , per il 4<unk> @ 8 milioni di persone che av<unk> @ evano sc<unk> @ ar<unk> @ ic<unk> @ amente , è stato sc<unk> @ rit<unk> @ to .
2025-05-27 19:33:58,004 - INFO - joeynmt.training - Example #1
2025-05-27 19:33:58,005 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:33:58,005 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:33:58,005 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato il fatto è stato in<unk> @ tor<unk> @ no a questo problema , la ris<unk> @ ol<unk> @ u<unk> @ zione di questo problema , non è il d<unk> @ ott<unk> @ ore , non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:33:58,005 - INFO - joeynmt.training - Example #2
2025-05-27 19:33:58,006 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:33:58,006 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:33:58,006 - INFO - joeynmt.training - 	Hypothesis: In realtà , è la s<unk> @ fi<unk> @ da è la c<unk> @ aus<unk> @ a di un sistema di in<unk> @ ten<unk> @ zione di un sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:33:58,006 - INFO - joeynmt.training - Example #3
2025-05-27 19:33:58,007 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:33:58,007 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:33:58,007 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta tor<unk> @ n<unk> @ ando a W<unk> @ in<unk> @ ter e s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:33:58,007 - INFO - joeynmt.training - Example #4
2025-05-27 19:33:58,008 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:33:58,008 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:33:58,008 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ u una cosa che vi mostr<unk> @ a è una c<unk> @ aus<unk> @ a di quello che succ<unk> @ ede in cui è succ<unk> @ esso in cui è succ<unk> @ esso .
2025-05-27 19:34:01,319 - INFO - joeynmt.training - Epoch   4, Step:    28600, Batch Loss:     0.971825, Batch Acc: 0.692850, Tokens per Sec:    20610, Lr: 0.000300
2025-05-27 19:34:04,607 - INFO - joeynmt.training - Epoch   4, Step:    28700, Batch Loss:     1.151960, Batch Acc: 0.688212, Tokens per Sec:    23967, Lr: 0.000300
2025-05-27 19:34:07,922 - INFO - joeynmt.training - Epoch   4, Step:    28800, Batch Loss:     1.003408, Batch Acc: 0.689759, Tokens per Sec:    24176, Lr: 0.000300
2025-05-27 19:34:11,213 - INFO - joeynmt.training - Epoch   4, Step:    28900, Batch Loss:     1.121118, Batch Acc: 0.690049, Tokens per Sec:    24414, Lr: 0.000300
2025-05-27 19:34:14,443 - INFO - joeynmt.training - Epoch   4, Step:    29000, Batch Loss:     1.092637, Batch Acc: 0.688628, Tokens per Sec:    24774, Lr: 0.000300
2025-05-27 19:34:14,443 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:34:14,443 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 73.53it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 81.46it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 91.61it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 93.23it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:11, 74.51it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 90.29it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 98.11it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:13, 61.13it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 55.16it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 63.16it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 72.77it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 78.51it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:11, 62.41it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 64.80it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:12, 57.30it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 64.01it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:13, 50.57it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 49.92it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 49.93it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.33it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 56.88it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 60.71it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 61.66it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 65.18it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 71.78it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 86.98it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 90.80it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 92.41it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 85.68it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 95.31it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 91.33it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 83.98it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 74.15it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 74.76it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 64.08it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 71.09it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 82.20it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 61.90it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 50.86it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 46.18it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.72it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 46.93it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 35.55it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.23it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.36it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 41.08it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.98it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 40.72it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.33it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.51it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 31.17it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.96it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.46it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.68it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.69it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 35.23it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:07, 26.47it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 34.56it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:04, 42.79it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:05, 34.13it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 36.43it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 46.78it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 50.42it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 74.46it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.01it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 55.17it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 67.13it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 71.03it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 86.25it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 89.58it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 102.80it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.34it/s] 
2025-05-27 19:34:30,279 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.08, ppl:   2.93, acc:   0.69, generation: 15.8222[sec], evaluation: 0.0000[sec]
2025-05-27 19:34:30,614 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/26500.ckpt
2025-05-27 19:34:30,634 - INFO - joeynmt.training - Example #0
2025-05-27 19:34:30,636 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:34:30,636 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:34:30,636 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questi due due due due due anni , ho mostr<unk> @ ato questa fot<unk> @ o , per cui la f<unk> @ am<unk> @ ig<unk> @ lia , per le em<unk> @ o<unk> @ zioni che hanno di<unk> @ mostr<unk> @ ato che le em<unk> @ issi<unk> @ oni che hanno fatto per tre mili<unk> @ ar<unk> @ di di di anni , aveva tre milimilimilimilimili<unk> @ ar<unk> @ di di di persone che av<unk> @ evano sc<unk> @ oper<unk> @ to è stato sc<unk> @ oper<unk> @ to .
2025-05-27 19:34:30,636 - INFO - joeynmt.training - Example #1
2025-05-27 19:34:30,637 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:34:30,637 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:34:30,637 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato in<unk> @ ten<unk> @ zione di questo problema , la ris<unk> @ post<unk> @ a , non è il problema di questo problema di in<unk> @ f<unk> @ en<unk> @ om<unk> @ en<unk> @ o non è il d<unk> @ ic<unk> @ olo .
2025-05-27 19:34:30,637 - INFO - joeynmt.training - Example #2
2025-05-27 19:34:30,638 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:34:30,638 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:34:30,638 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , la sci<unk> @ enza è la c<unk> @ aus<unk> @ a di E<unk> @ is<unk> @ k<unk> @ p<unk> @ ev<unk> @ ole , il nostro sistema glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:34:30,638 - INFO - joeynmt.training - Example #3
2025-05-27 19:34:30,639 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:34:30,639 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:34:30,639 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , e la p<unk> @ elle , e si è s<unk> @ otto in un m<unk> @ ess<unk> @ aggio .
2025-05-27 19:34:30,639 - INFO - joeynmt.training - Example #4
2025-05-27 19:34:30,639 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:34:30,640 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:34:30,640 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ u la mia f<unk> @ am<unk> @ ig<unk> @ lia è una c<unk> @ ent<unk> @ ita di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:34:34,028 - INFO - joeynmt.training - Epoch   4, Step:    29100, Batch Loss:     1.034914, Batch Acc: 0.690883, Tokens per Sec:    21420, Lr: 0.000300
2025-05-27 19:34:37,415 - INFO - joeynmt.training - Epoch   4, Step:    29200, Batch Loss:     1.115932, Batch Acc: 0.691926, Tokens per Sec:    23374, Lr: 0.000300
2025-05-27 19:34:40,811 - INFO - joeynmt.training - Epoch   4, Step:    29300, Batch Loss:     1.124428, Batch Acc: 0.689345, Tokens per Sec:    23015, Lr: 0.000300
2025-05-27 19:34:44,158 - INFO - joeynmt.training - Epoch   4, Step:    29400, Batch Loss:     1.040303, Batch Acc: 0.694116, Tokens per Sec:    23496, Lr: 0.000300
2025-05-27 19:34:47,516 - INFO - joeynmt.training - Epoch   4, Step:    29500, Batch Loss:     1.138913, Batch Acc: 0.692031, Tokens per Sec:    23791, Lr: 0.000300
2025-05-27 19:34:47,516 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:34:47,517 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 64.33it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 80.04it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 86.47it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 93.77it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:11, 73.67it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 87.14it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:12, 65.03it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:10, 79.35it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:19, 41.38it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 46.87it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.97it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 78.23it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 79.46it/s]Predicting...:  23%|██▎       | 211/923 [00:03<00:08, 81.09it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 75.87it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 76.30it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 76.01it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 54.51it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 50.36it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 48.58it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:19, 33.03it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:16, 38.42it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:14, 43.09it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:12, 47.02it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 54.18it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 52.79it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:08, 62.79it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 73.30it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 81.29it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 86.96it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 86.12it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 95.60it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 90.12it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:05, 89.82it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 77.19it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 83.04it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 65.19it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 72.72it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:04, 79.53it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:05, 64.48it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 47.39it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 38.58it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 35.88it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:08, 42.17it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 32.84it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:10, 31.28it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:10, 30.20it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:08, 37.46it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 40.41it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 39.31it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 35.92it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:09, 29.43it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:08, 29.34it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:07, 32.94it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:07, 30.85it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 33.03it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:07, 31.14it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:05, 38.46it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:05, 35.83it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 44.64it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 54.36it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 40.13it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:03, 41.71it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 43.12it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 48.90it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 59.04it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 70.57it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 71.77it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 53.89it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 66.78it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:00, 69.22it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 83.82it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 73.72it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 85.32it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 96.69it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 55.58it/s]
2025-05-27 19:35:04,138 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.92, acc:   0.69, generation: 16.6086[sec], evaluation: 0.0000[sec]
2025-05-27 19:35:04,139 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:35:04,795 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/27000.ckpt
2025-05-27 19:35:04,820 - INFO - joeynmt.training - Example #0
2025-05-27 19:35:04,821 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:35:04,821 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:35:04,821 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so che ho mostr<unk> @ ato questi due f<unk> @ en<unk> @ om<unk> @ enti per la f<unk> @ am<unk> @ be per la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano tre mili<unk> @ ar<unk> @ di di di anni , il 4<unk> @ 8 per c<unk> @ ento , il 4<unk> @ 0 % della st<unk> @ a<unk> @ z<unk> @ o .
2025-05-27 19:35:04,821 - INFO - joeynmt.training - Example #1
2025-05-27 19:35:04,822 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:35:04,822 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:35:04,822 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il fatto che la ver<unk> @ ità di essere in<unk> @ t<unk> @ eg<unk> @ u<unk> @ ito , non è il D<unk> @ ic<unk> @ olo di questo problema , non è il D<unk> @ ic<unk> @ lo .
2025-05-27 19:35:04,822 - INFO - joeynmt.training - Example #2
2025-05-27 19:35:04,823 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:35:04,823 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:35:04,823 - INFO - joeynmt.training - 	Hypothesis: In realtà , la s<unk> @ edi<unk> @ a è la c<unk> @ aus<unk> @ a di in<unk> @ ten<unk> @ zione di un sistema glob<unk> @ ale glob<unk> @ ale glob<unk> @ ale .
2025-05-27 19:35:04,823 - INFO - joeynmt.training - Example #3
2025-05-27 19:35:04,824 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:35:04,824 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:35:04,824 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e la p<unk> @ op<unk> @ ol<unk> @ azione in m<unk> @ ezz<unk> @ o .
2025-05-27 19:35:04,824 - INFO - joeynmt.training - Example #4
2025-05-27 19:35:04,825 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:35:04,825 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:35:04,825 - INFO - joeynmt.training - 	Hypothesis: La prima prima cosa che vi mostr<unk> @ o la prima prima prima cosa che vi è succ<unk> @ esso a cui ho pres<unk> @ o una c<unk> @ op<unk> @ pi<unk> @ a che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:35:08,205 - INFO - joeynmt.training - Epoch   4, Step:    29600, Batch Loss:     0.916321, Batch Acc: 0.695426, Tokens per Sec:    19240, Lr: 0.000300
2025-05-27 19:35:11,579 - INFO - joeynmt.training - Epoch   4, Step:    29700, Batch Loss:     1.014105, Batch Acc: 0.691278, Tokens per Sec:    23360, Lr: 0.000300
2025-05-27 19:35:14,940 - INFO - joeynmt.training - Epoch   4, Step:    29800, Batch Loss:     1.057276, Batch Acc: 0.693243, Tokens per Sec:    23504, Lr: 0.000300
2025-05-27 19:35:18,301 - INFO - joeynmt.training - Epoch   4, Step:    29900, Batch Loss:     1.080278, Batch Acc: 0.690309, Tokens per Sec:    22933, Lr: 0.000300
2025-05-27 19:35:21,656 - INFO - joeynmt.training - Epoch   4, Step:    30000, Batch Loss:     0.997013, Batch Acc: 0.692016, Tokens per Sec:    22787, Lr: 0.000300
2025-05-27 19:35:21,656 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:35:21,656 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 59.30it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 75.36it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 77.92it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 81.99it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 86.08it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 102.96it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 102.84it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 116.13it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 47.39it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 50.90it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.00it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.41it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 94.07it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.88it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 76.34it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 79.96it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.25it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 51.98it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.49it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 54.31it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.57it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 58.63it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 63.88it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.77it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 64.50it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.03it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 81.13it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 87.69it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 83.16it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 89.88it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 85.10it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 90.76it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.65it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 78.98it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 55.00it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 61.17it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 69.62it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 58.21it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 46.98it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 43.02it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 42.40it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 48.61it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 35.69it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.49it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.32it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 44.36it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.68it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 42.85it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 41.26it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:09, 29.00it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 28.23it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 32.73it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.22it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 31.80it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 27.71it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 33.73it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 32.06it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 38.66it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 47.55it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.58it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 38.44it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 48.07it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 51.23it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 64.17it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 73.35it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.95it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 53.83it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 54.89it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 65.24it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 69.70it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 80.55it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 88.68it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 57.46it/s]
2025-05-27 19:35:37,733 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.91, acc:   0.69, generation: 16.0642[sec], evaluation: 0.0000[sec]
2025-05-27 19:35:37,734 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:35:38,324 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/27500.ckpt
2025-05-27 19:35:38,349 - INFO - joeynmt.training - Example #0
2025-05-27 19:35:38,350 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:35:38,350 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:35:38,350 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questa due o , ho mostr<unk> @ ato questa due o , per us<unk> @ are la p<unk> @ op<unk> @ ol<unk> @ ia per la f<unk> @ am<unk> @ ig<unk> @ ica che le g<unk> @ am<unk> @ be per tre mili<unk> @ ar<unk> @ di di anni , per la 4<unk> @ 8 % dei dati che av<unk> @ evano 1<unk> @ 5 % dei 4<unk> @ 8 % dei 4<unk> @ 8 per<unk> @ c<unk> @ ento .
2025-05-27 19:35:38,350 - INFO - joeynmt.training - Example #1
2025-05-27 19:35:38,351 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:35:38,351 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:35:38,351 - INFO - joeynmt.training - 	Hypothesis: Ma non è una cosa che la cosa che è che la T<unk> @ erra , la cosa che non si chiam<unk> @ a questa cosa spe<unk> @ ci<unk> @ ale , ma non è il d<unk> @ ott<unk> @ ore di questo problema .
2025-05-27 19:35:38,351 - INFO - joeynmt.training - Example #2
2025-05-27 19:35:38,352 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:35:38,352 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:35:38,352 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , è la cosa che è la c<unk> @ li<unk> @ sta del sistema di f<unk> @ ar c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a della nostra c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 19:35:38,352 - INFO - joeynmt.training - Example #3
2025-05-27 19:35:38,353 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:35:38,353 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:35:38,353 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , e si trov<unk> @ a a a a s<unk> @ om<unk> @ br<unk> @ a .
2025-05-27 19:35:38,353 - INFO - joeynmt.training - Example #4
2025-05-27 19:35:38,354 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:35:38,354 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:35:38,354 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa vi mostr<unk> @ o la cosa che vi mostr<unk> @ a è una c<unk> @ aus<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:35:41,756 - INFO - joeynmt.training - Epoch   4, Step:    30100, Batch Loss:     1.070397, Batch Acc: 0.690314, Tokens per Sec:    20351, Lr: 0.000300
2025-05-27 19:35:45,123 - INFO - joeynmt.training - Epoch   4, Step:    30200, Batch Loss:     1.029934, Batch Acc: 0.692770, Tokens per Sec:    23123, Lr: 0.000300
2025-05-27 19:35:48,431 - INFO - joeynmt.training - Epoch   4, Step:    30300, Batch Loss:     1.068291, Batch Acc: 0.692823, Tokens per Sec:    22747, Lr: 0.000300
2025-05-27 19:35:51,831 - INFO - joeynmt.training - Epoch   4, Step:    30400, Batch Loss:     1.085493, Batch Acc: 0.693905, Tokens per Sec:    23483, Lr: 0.000300
2025-05-27 19:35:55,200 - INFO - joeynmt.training - Epoch   4, Step:    30500, Batch Loss:     1.003633, Batch Acc: 0.692400, Tokens per Sec:    22890, Lr: 0.000300
2025-05-27 19:35:55,201 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:35:55,201 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 72.95it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 81.83it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.49it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 99.04it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 79.63it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 96.58it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 70.66it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:11, 68.78it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:19, 39.65it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 46.33it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.21it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 82.11it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 91.90it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:08, 86.22it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 76.76it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 82.93it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 64.78it/s]Predicting...:  30%|███       | 277/923 [00:04<00:10, 61.27it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:10, 59.69it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 64.54it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 68.45it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 75.89it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 65.51it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 74.16it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 80.93it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 86.29it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 91.29it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 98.76it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 111.14it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 112.23it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 99.77it/s] Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 83.37it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 91.39it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:05, 68.20it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 53.89it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 58.92it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:06, 48.32it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 47.90it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 55.12it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 54.93it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 48.07it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 45.86it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 37.20it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 35.72it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 39.33it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:10, 24.41it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:08, 29.43it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 28.67it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 37.96it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 38.43it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 46.04it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 56.92it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 40.72it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 43.59it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 58.01it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 64.93it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 77.83it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 90.58it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 92.91it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:00, 81.16it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 78.85it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 91.28it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 90.50it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 101.06it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 110.72it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 65.27it/s] 
2025-05-27 19:36:09,352 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.07, ppl:   2.90, acc:   0.69, generation: 14.1425[sec], evaluation: 0.0000[sec]
2025-05-27 19:36:09,353 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:36:09,977 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/28000.ckpt
2025-05-27 19:36:09,994 - INFO - joeynmt.training - Example #0
2025-05-27 19:36:09,995 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:36:09,995 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:36:09,995 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due due due f<unk> @ ami<unk> @ gl<unk> @ ie per la p<unk> @ op<unk> @ ol<unk> @ ia , per la c<unk> @ aus<unk> @ a di tre mili<unk> @ ar<unk> @ t<unk> @ ici , per i 4<unk> @ 8 milioni di anni , per la 4<unk> @ 8 milioni di anni , per la 4<unk> @ 8 , per c<unk> @ ento di 4<unk> @ 8 % della 4<unk> @ 0 % di 4<unk> @ 8 % di questi due per<unk> @ c<unk> @ ento .
2025-05-27 19:36:09,995 - INFO - joeynmt.training - Example #1
2025-05-27 19:36:09,996 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:36:09,996 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:36:09,996 - INFO - joeynmt.training - 	Hypothesis: Ma non è molto diff<unk> @ ic<unk> @ ile , non è la cap<unk> @ ac<unk> @ ità di questa s<unk> @ itu<unk> @ azione , non è il problema di E<unk> @ is<unk> @ is<unk> @ es non è il d<unk> @ ot<unk> @ o .
2025-05-27 19:36:09,996 - INFO - joeynmt.training - Example #2
2025-05-27 19:36:09,997 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:36:09,997 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:36:09,997 - INFO - joeynmt.training - 	Hypothesis: In un sen<unk> @ so di s<unk> @ om<unk> @ ma è la c<unk> @ li<unk> @ sta è la c<unk> @ li<unk> @ mit<unk> @ ata del nostro cu<unk> @ ore c<unk> @ li<unk> @ m<unk> @ as<unk> @ so .
2025-05-27 19:36:09,997 - INFO - joeynmt.training - Example #3
2025-05-27 19:36:09,998 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:36:09,998 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:36:09,998 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ per<unk> @ a e si trov<unk> @ a in v<unk> @ ento e si è s<unk> @ om<unk> @ p<unk> @ a .
2025-05-27 19:36:09,998 - INFO - joeynmt.training - Example #4
2025-05-27 19:36:09,999 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:36:09,999 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:36:09,999 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ ura che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:36:13,332 - INFO - joeynmt.training - Epoch   4, Step:    30600, Batch Loss:     1.087756, Batch Acc: 0.693993, Tokens per Sec:    20279, Lr: 0.000300
2025-05-27 19:36:16,688 - INFO - joeynmt.training - Epoch   4, Step:    30700, Batch Loss:     1.046287, Batch Acc: 0.695015, Tokens per Sec:    23687, Lr: 0.000300
2025-05-27 19:36:20,058 - INFO - joeynmt.training - Epoch   4, Step:    30800, Batch Loss:     1.170797, Batch Acc: 0.694960, Tokens per Sec:    23688, Lr: 0.000300
2025-05-27 19:36:23,475 - INFO - joeynmt.training - Epoch   4, Step:    30900, Batch Loss:     1.016402, Batch Acc: 0.695780, Tokens per Sec:    23958, Lr: 0.000300
2025-05-27 19:36:26,864 - INFO - joeynmt.training - Epoch   4, Step:    31000, Batch Loss:     1.067988, Batch Acc: 0.692140, Tokens per Sec:    24148, Lr: 0.000300
2025-05-27 19:36:26,864 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:36:26,864 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 64.19it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 78.80it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 89.89it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 97.45it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 86.48it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 103.21it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 72.32it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 89.49it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:16, 47.71it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 52.64it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.17it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 88.24it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 94.21it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 77.39it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 62.20it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 69.52it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:10, 61.53it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 59.14it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 58.35it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 57.20it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 61.06it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 68.06it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 78.85it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 75.95it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:06, 83.48it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 100.09it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:04, 108.40it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 113.54it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 117.45it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:03, 130.11it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:03, 120.95it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:03, 122.93it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:03, 108.49it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 90.03it/s] Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 97.72it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:05, 67.21it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 58.23it/s]Predicting...:  64%|██████▎   | 587/923 [00:07<00:06, 55.91it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:06, 53.07it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 51.46it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 60.53it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:04, 60.10it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:04, 60.27it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 55.12it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 44.45it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 40.62it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:05, 45.46it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 39.40it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:05, 41.21it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 36.90it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 46.44it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:04, 43.50it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 50.74it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:02, 62.60it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 50.28it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 62.70it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:01, 70.89it/s]Predicting...:  87%|████████▋ | 800/923 [00:11<00:01, 83.50it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 95.73it/s]Predicting...:  90%|████████▉ | 827/923 [00:11<00:00, 100.56it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:00, 75.70it/s] Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 75.65it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 97.09it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 120.82it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 71.87it/s] 
2025-05-27 19:36:39,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.06, ppl:   2.88, acc:   0.69, generation: 12.8438[sec], evaluation: 0.0000[sec]
2025-05-27 19:36:39,717 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:36:40,185 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/29000.ckpt
2025-05-27 19:36:40,203 - INFO - joeynmt.training - Example #0
2025-05-27 19:36:40,205 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:36:40,205 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:36:40,205 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per con<unk> @ to che i p<unk> @ es<unk> @ c<unk> @ enti per i con<unk> @ to che i g<unk> @ over<unk> @ ni per i m<unk> @ oti<unk> @ vi per i due milioni di anni , per i m<unk> @ oti<unk> @ vi per i due milioni di anni , i m<unk> @ oti<unk> @ vi per c<unk> @ ento di qu<unk> @ ei 4<unk> @ 8 % di qu<unk> @ ei 4<unk> @ 8 % di qu<unk> @ ei 4<unk> @ 8 % .
2025-05-27 19:36:40,205 - INFO - joeynmt.training - Example #1
2025-05-27 19:36:40,206 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:36:40,206 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:36:40,206 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un po &apos; di più diff<unk> @ ic<unk> @ ile per la ris<unk> @ ol<unk> @ vere probl<unk> @ emi spe<unk> @ ci<unk> @ ali , non è il d<unk> @ ot<unk> @ ti<unk> @ m<unk> @ enti di E<unk> @ is<unk> @ es .
2025-05-27 19:36:40,206 - INFO - joeynmt.training - Example #2
2025-05-27 19:36:40,207 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:36:40,207 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:36:40,207 - INFO - joeynmt.training - 	Hypothesis: In realtà , in un sen<unk> @ so di ci<unk> @ ma la s<unk> @ itu<unk> @ azione è la c<unk> @ li<unk> @ sta del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ mo .
2025-05-27 19:36:40,207 - INFO - joeynmt.training - Example #3
2025-05-27 19:36:40,208 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:36:40,208 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:36:40,208 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , si è s<unk> @ ent<unk> @ ito a s<unk> @ om<unk> @ p<unk> @ e .
2025-05-27 19:36:40,208 - INFO - joeynmt.training - Example #4
2025-05-27 19:36:40,209 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:36:40,209 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:36:40,209 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che mostr<unk> @ o è una c<unk> @ las<unk> @ se è una c<unk> @ en<unk> @ da di cosa succ<unk> @ e<unk> @ da , è succ<unk> @ esso in cui succ<unk> @ ede .
2025-05-27 19:36:43,493 - INFO - joeynmt.training - Epoch   4, Step:    31100, Batch Loss:     1.062386, Batch Acc: 0.693478, Tokens per Sec:    20751, Lr: 0.000300
2025-05-27 19:36:46,887 - INFO - joeynmt.training - Epoch   4, Step:    31200, Batch Loss:     1.095642, Batch Acc: 0.695083, Tokens per Sec:    22872, Lr: 0.000300
2025-05-27 19:36:50,250 - INFO - joeynmt.training - Epoch   4, Step:    31300, Batch Loss:     0.993557, Batch Acc: 0.689852, Tokens per Sec:    23492, Lr: 0.000300
2025-05-27 19:36:53,593 - INFO - joeynmt.training - Epoch   4, Step:    31400, Batch Loss:     1.105234, Batch Acc: 0.696545, Tokens per Sec:    23142, Lr: 0.000300
2025-05-27 19:36:56,498 - INFO - joeynmt.training - Epoch   4: total training loss 8445.86
2025-05-27 19:36:56,498 - INFO - joeynmt.training - EPOCH 5
2025-05-27 19:36:56,940 - INFO - joeynmt.training - Epoch   5, Step:    31500, Batch Loss:     1.056693, Batch Acc: 0.701887, Tokens per Sec:    22512, Lr: 0.000300
2025-05-27 19:36:56,940 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:36:56,940 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 79.50it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 101.07it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 111.12it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 119.16it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 123.63it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 116.65it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 97.87it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 53.97it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 60.30it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:10, 70.52it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 98.41it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 106.29it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 92.96it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 88.02it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 63.30it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 56.57it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:16, 39.51it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:14, 42.58it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:12, 47.97it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 55.22it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 59.33it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 66.56it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 78.02it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 85.96it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 88.17it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 84.46it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 96.38it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 98.44it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 101.02it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.53it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 71.87it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:09, 44.94it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:07, 54.00it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:06, 65.12it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:08, 45.98it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:08, 43.65it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 43.72it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 42.06it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 51.36it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 40.29it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 39.87it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 39.79it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 50.93it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.63it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 43.65it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 42.06it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 35.72it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 33.83it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 39.43it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:06, 36.61it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:05, 40.68it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 36.79it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:04, 46.51it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 45.09it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:03, 53.60it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:02, 65.06it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 50.40it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 63.60it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:01, 71.73it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 82.35it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 94.32it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 89.55it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:00, 74.11it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 71.92it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 96.79it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 106.78it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 64.75it/s] 
2025-05-27 19:37:11,204 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.06, ppl:   2.87, acc:   0.70, generation: 14.2553[sec], evaluation: 0.0000[sec]
2025-05-27 19:37:11,205 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:37:11,689 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/28500.ckpt
2025-05-27 19:37:11,707 - INFO - joeynmt.training - Example #0
2025-05-27 19:37:11,708 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:37:11,708 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:37:11,708 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questa due milioni di le<unk> @ a<unk> @ der per fare la f<unk> @ ec<unk> @ or<unk> @ ia per c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano , per tre milioni di anni , che ha av<unk> @ uto 4<unk> @ 8 % della maggi<unk> @ or<unk> @ anza di 4<unk> @ 8 % .
2025-05-27 19:37:11,708 - INFO - joeynmt.training - Example #1
2025-05-27 19:37:11,709 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:37:11,709 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:37:11,709 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ ra della nostra in<unk> @ f<unk> @ es<unk> @ sione , perché non è il d<unk> @ ott<unk> @ ore del problema .
2025-05-27 19:37:11,709 - INFO - joeynmt.training - Example #2
2025-05-27 19:37:11,710 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:37:11,710 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:37:11,710 - INFO - joeynmt.training - 	Hypothesis: In realtà , in realtà , è la cosa più in<unk> @ ten<unk> @ ne è la c<unk> @ li<unk> @ sta di c<unk> @ li<unk> @ enti c<unk> @ li<unk> @ enti glob<unk> @ ali .
2025-05-27 19:37:11,710 - INFO - joeynmt.training - Example #3
2025-05-27 19:37:11,711 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:37:11,711 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:37:11,711 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una cosa che si è ri<unk> @ ma<unk> @ sto e sc<unk> @ ar<unk> @ ic<unk> @ ato .
2025-05-27 19:37:11,711 - INFO - joeynmt.training - Example #4
2025-05-27 19:37:11,712 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:37:11,712 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:37:11,712 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ o è che vi mostr<unk> @ o è una c<unk> @ ur<unk> @ ata di quello che sta succ<unk> @ e<unk> @ dendo negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:37:15,043 - INFO - joeynmt.training - Epoch   5, Step:    31600, Batch Loss:     1.017351, Batch Acc: 0.703405, Tokens per Sec:    20769, Lr: 0.000300
2025-05-27 19:37:18,439 - INFO - joeynmt.training - Epoch   5, Step:    31700, Batch Loss:     1.040787, Batch Acc: 0.702403, Tokens per Sec:    23756, Lr: 0.000300
2025-05-27 19:37:21,846 - INFO - joeynmt.training - Epoch   5, Step:    31800, Batch Loss:     0.955986, Batch Acc: 0.706280, Tokens per Sec:    23735, Lr: 0.000300
2025-05-27 19:37:25,235 - INFO - joeynmt.training - Epoch   5, Step:    31900, Batch Loss:     1.005589, Batch Acc: 0.703023, Tokens per Sec:    23294, Lr: 0.000300
2025-05-27 19:37:28,629 - INFO - joeynmt.training - Epoch   5, Step:    32000, Batch Loss:     1.002492, Batch Acc: 0.698212, Tokens per Sec:    23509, Lr: 0.000300
2025-05-27 19:37:28,629 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:37:28,629 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:18, 48.13it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:13, 68.71it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 74.73it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 84.76it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:11, 76.58it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 86.82it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:12, 64.92it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 80.74it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:19, 40.55it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:17, 45.66it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 54.73it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 76.17it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 82.97it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 63.66it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 60.14it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 70.22it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:11, 56.96it/s]Predicting...:  30%|███       | 277/923 [00:04<00:11, 56.55it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 51.25it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.16it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:10, 59.02it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 62.57it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 57.31it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 49.24it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 61.45it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 78.88it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:05, 90.72it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 96.96it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 90.78it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 102.71it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 95.06it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 93.54it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 85.45it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:04, 92.63it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 73.37it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 83.36it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:06, 58.51it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 47.38it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 54.29it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:07, 43.04it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 43.55it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 51.93it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 53.59it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:05, 48.06it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 44.48it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:06, 38.68it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 36.15it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 39.33it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:06, 35.38it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 38.17it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 32.52it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 42.63it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 38.97it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 46.27it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 56.48it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 46.55it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 48.54it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 62.98it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 67.89it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 73.04it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 83.28it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 86.18it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 71.82it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 65.38it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 79.08it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 87.72it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 97.64it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 62.24it/s]
2025-05-27 19:37:43,468 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.87, acc:   0.70, generation: 14.8301[sec], evaluation: 0.0000[sec]
2025-05-27 19:37:43,468 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:37:43,948 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/29500.ckpt
2025-05-27 19:37:43,973 - INFO - joeynmt.training - Example #0
2025-05-27 19:37:43,974 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:37:43,974 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:37:43,974 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno ho mostr<unk> @ ato questa due milioni di m<unk> @ ezz<unk> @ o che ho mostr<unk> @ ato questa fot<unk> @ o , per cui la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano tre milioni di m<unk> @ oti<unk> @ vi per cui il 4<unk> @ 8 c<unk> @ ento di tre milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , il 4<unk> @ 8 % .
2025-05-27 19:37:43,974 - INFO - joeynmt.training - Example #1
2025-05-27 19:37:43,975 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:37:43,975 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:37:43,975 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po &apos; di più diff<unk> @ ic<unk> @ ile che la T<unk> @ erra è la ris<unk> @ ol<unk> @ u<unk> @ zione di questa part<unk> @ icol<unk> @ are , perché non è il D<unk> @ ic<unk> @ e<unk> @ k .
2025-05-27 19:37:43,975 - INFO - joeynmt.training - Example #2
2025-05-27 19:37:43,976 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:37:43,976 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:37:43,976 - INFO - joeynmt.training - 	Hypothesis: In realtà , è la c<unk> @ ura di str<unk> @ utt<unk> @ ura è la c<unk> @ li<unk> @ sta di c<unk> @ li<unk> @ et<unk> @ ter<unk> @ a , il nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:37:43,976 - INFO - joeynmt.training - Example #3
2025-05-27 19:37:43,977 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:37:43,977 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:37:43,977 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ ebbe in una v<unk> @ ento e la b<unk> @ ell<unk> @ issi<unk> @ ma .
2025-05-27 19:37:43,977 - INFO - joeynmt.training - Example #4
2025-05-27 19:37:43,978 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:37:43,978 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:37:43,978 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i , è una c<unk> @ el<unk> @ eb<unk> @ r<unk> @ ale che vi mostr<unk> @ o è succ<unk> @ esso in qu<unk> @ ell&apos; ulti<unk> @ ma 2<unk> @ 5 anni .
2025-05-27 19:37:47,323 - INFO - joeynmt.training - Epoch   5, Step:    32100, Batch Loss:     0.996844, Batch Acc: 0.705724, Tokens per Sec:    20851, Lr: 0.000300
2025-05-27 19:37:50,696 - INFO - joeynmt.training - Epoch   5, Step:    32200, Batch Loss:     0.975519, Batch Acc: 0.701359, Tokens per Sec:    22516, Lr: 0.000300
2025-05-27 19:37:54,027 - INFO - joeynmt.training - Epoch   5, Step:    32300, Batch Loss:     1.004193, Batch Acc: 0.701453, Tokens per Sec:    23109, Lr: 0.000300
2025-05-27 19:37:57,419 - INFO - joeynmt.training - Epoch   5, Step:    32400, Batch Loss:     1.059476, Batch Acc: 0.701335, Tokens per Sec:    23780, Lr: 0.000300
2025-05-27 19:38:00,813 - INFO - joeynmt.training - Epoch   5, Step:    32500, Batch Loss:     0.940009, Batch Acc: 0.701797, Tokens per Sec:    23550, Lr: 0.000300
2025-05-27 19:38:00,814 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:38:00,814 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 60.01it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 75.80it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 79.67it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 83.80it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 92.53it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 100.84it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 103.85it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 83.34it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:22, 35.39it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:19, 40.37it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 49.23it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 69.78it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 77.35it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 69.72it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 62.91it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 68.96it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:12, 53.32it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:14, 45.24it/s]Predicting...:  30%|███       | 277/923 [00:04<00:15, 42.80it/s]Predicting...:  31%|███▏      | 289/923 [00:05<00:16, 39.05it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:13, 47.49it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 53.83it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 62.59it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 60.04it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 57.29it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:08, 63.95it/s]Predicting...:  41%|████      | 379/923 [00:06<00:06, 80.91it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 85.78it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 94.26it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 92.82it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 107.56it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 106.94it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 110.93it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:04, 101.03it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:04, 84.48it/s] Predicting...:  59%|█████▊    | 540/923 [00:07<00:04, 78.80it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:06, 55.60it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 50.51it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 57.60it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:07, 41.89it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 41.19it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 49.96it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:05, 49.16it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 46.00it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 41.28it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 34.50it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 30.05it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.59it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 32.20it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.73it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 28.08it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 37.85it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.24it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 45.44it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 58.19it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 48.76it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 57.79it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 60.01it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 71.10it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 84.89it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 86.47it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 61.13it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 61.85it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 83.00it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 107.00it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.48it/s] 
2025-05-27 19:38:16,085 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.86, acc:   0.70, generation: 15.2622[sec], evaluation: 0.0000[sec]
2025-05-27 19:38:16,085 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:38:16,578 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/30000.ckpt
2025-05-27 19:38:16,601 - INFO - joeynmt.training - Example #0
2025-05-27 19:38:16,602 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:38:16,602 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:38:16,602 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questa f<unk> @ ec<unk> @ ie per f<unk> @ ar s<unk> @ ì che la c<unk> @ aus<unk> @ a di str<unk> @ utt<unk> @ ura , per le persone che hanno sc<unk> @ oper<unk> @ to che i dati per circa 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per tre milioni di di m<unk> @ oti<unk> @ vi per 4<unk> @ 8 milioni di di m<unk> @ oti<unk> @ vi .
2025-05-27 19:38:16,602 - INFO - joeynmt.training - Example #1
2025-05-27 19:38:16,603 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:38:16,603 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:38:16,603 - INFO - joeynmt.training - 	Hypothesis: Ma non è così che la cosa non è così che la ris<unk> @ post<unk> @ a è la di<unk> @ st<unk> @ azione di questo problema spe<unk> @ ci<unk> @ ale , non è il d<unk> @ ato di questo problema .
2025-05-27 19:38:16,603 - INFO - joeynmt.training - Example #2
2025-05-27 19:38:16,604 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:38:16,604 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:38:16,604 - INFO - joeynmt.training - 	Hypothesis: In realtà , in un cer<unk> @ to sen<unk> @ so è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema glob<unk> @ ale .
2025-05-27 19:38:16,605 - INFO - joeynmt.training - Example #3
2025-05-27 19:38:16,605 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:38:16,605 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:38:16,605 - INFO - joeynmt.training - 	Hypothesis: P<unk> @ ri<unk> @ ma di tutto il mondo , si è s<unk> @ om<unk> @ p<unk> @ ate e si trov<unk> @ a in s<unk> @ om<unk> @ m<unk> @ are .
2025-05-27 19:38:16,605 - INFO - joeynmt.training - Example #4
2025-05-27 19:38:16,606 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:38:16,606 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:38:16,606 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ aus<unk> @ a di cosa è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:38:19,931 - INFO - joeynmt.training - Epoch   5, Step:    32600, Batch Loss:     1.127135, Batch Acc: 0.704013, Tokens per Sec:    19940, Lr: 0.000300
2025-05-27 19:38:23,334 - INFO - joeynmt.training - Epoch   5, Step:    32700, Batch Loss:     1.070366, Batch Acc: 0.700162, Tokens per Sec:    23463, Lr: 0.000300
2025-05-27 19:38:26,712 - INFO - joeynmt.training - Epoch   5, Step:    32800, Batch Loss:     0.951402, Batch Acc: 0.699440, Tokens per Sec:    23061, Lr: 0.000300
2025-05-27 19:38:30,090 - INFO - joeynmt.training - Epoch   5, Step:    32900, Batch Loss:     0.981302, Batch Acc: 0.697892, Tokens per Sec:    22963, Lr: 0.000300
2025-05-27 19:38:33,480 - INFO - joeynmt.training - Epoch   5, Step:    33000, Batch Loss:     0.952078, Batch Acc: 0.701798, Tokens per Sec:    22992, Lr: 0.000300
2025-05-27 19:38:33,481 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:38:33,481 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 68.62it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 82.12it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 84.65it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 85.62it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 81.43it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 98.10it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 99.07it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 81.23it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 42.99it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 47.04it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.13it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.07it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 90.38it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 76.20it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 79.21it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 84.17it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 65.35it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 64.83it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:10, 58.30it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 65.07it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 69.80it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 77.54it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 81.93it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 88.96it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:04, 113.56it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 114.21it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 112.37it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:03, 123.78it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:03, 119.49it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:03, 114.49it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 103.81it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 96.78it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 91.88it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:05, 68.74it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:05, 59.88it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 64.73it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:06, 52.51it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 51.43it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 59.19it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 57.44it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 53.06it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 46.45it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 35.38it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 34.62it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 39.73it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 35.79it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 40.06it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 34.34it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:05, 42.92it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:04, 41.69it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 48.92it/s]Predicting...:  81%|████████  | 749/923 [00:11<00:03, 55.31it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 52.48it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 63.07it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:02, 66.35it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 88.15it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 88.23it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:01, 68.69it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 70.13it/s]Predicting...:  95%|█████████▌| 878/923 [00:12<00:00, 83.16it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 92.57it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 103.72it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 70.36it/s] 
2025-05-27 19:38:46,608 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.86, acc:   0.70, generation: 13.1196[sec], evaluation: 0.0000[sec]
2025-05-27 19:38:47,085 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/30500.ckpt
2025-05-27 19:38:47,107 - INFO - joeynmt.training - Example #0
2025-05-27 19:38:47,109 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:38:47,109 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:38:47,109 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per il vol<unk> @ o di un p<unk> @ ezz<unk> @ o di g<unk> @ hi<unk> @ ac<unk> @ cio che l&apos; E<unk> @ is<unk> @ c<unk> @ ca che ha av<unk> @ uto 4<unk> @ 8 milioni di rag<unk> @ i<unk> @ oni che ha av<unk> @ uto 4<unk> @ 8 anni , il 4<unk> @ 0 , 4<unk> @ 8 anni .
2025-05-27 19:38:47,109 - INFO - joeynmt.training - Example #1
2025-05-27 19:38:47,110 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:38:47,110 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:38:47,110 - INFO - joeynmt.training - 	Hypothesis: Ma non è così che la gente non è il fatto di questo problema di in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ ità di questo problema spe<unk> @ ci<unk> @ ale , non è il de<unk> @ ter<unk> @ min<unk> @ ato .
2025-05-27 19:38:47,110 - INFO - joeynmt.training - Example #2
2025-05-27 19:38:47,111 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:38:47,111 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:38:47,111 - INFO - joeynmt.training - 	Hypothesis: In sci<unk> @ enza , la s<unk> @ fi<unk> @ da è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio il nostro sistema glob<unk> @ ale .
2025-05-27 19:38:47,111 - INFO - joeynmt.training - Example #3
2025-05-27 19:38:47,112 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:38:47,112 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:38:47,112 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a e la sc<unk> @ al<unk> @ a e la sc<unk> @ u<unk> @ ola .
2025-05-27 19:38:47,112 - INFO - joeynmt.training - Example #4
2025-05-27 19:38:47,113 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:38:47,113 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:38:47,113 - INFO - joeynmt.training - 	Hypothesis: Il pros<unk> @ si<unk> @ mo f<unk> @ ar mostr<unk> @ o è una sc<unk> @ or<unk> @ sa che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:38:50,454 - INFO - joeynmt.training - Epoch   5, Step:    33100, Batch Loss:     1.026917, Batch Acc: 0.700696, Tokens per Sec:    20808, Lr: 0.000300
2025-05-27 19:38:53,861 - INFO - joeynmt.training - Epoch   5, Step:    33200, Batch Loss:     1.036924, Batch Acc: 0.700421, Tokens per Sec:    22996, Lr: 0.000300
2025-05-27 19:38:57,215 - INFO - joeynmt.training - Epoch   5, Step:    33300, Batch Loss:     1.082449, Batch Acc: 0.701215, Tokens per Sec:    23501, Lr: 0.000300
2025-05-27 19:39:00,601 - INFO - joeynmt.training - Epoch   5, Step:    33400, Batch Loss:     1.175248, Batch Acc: 0.704891, Tokens per Sec:    23705, Lr: 0.000300
2025-05-27 19:39:04,002 - INFO - joeynmt.training - Epoch   5, Step:    33500, Batch Loss:     0.990603, Batch Acc: 0.700022, Tokens per Sec:    22998, Lr: 0.000300
2025-05-27 19:39:04,002 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:39:04,002 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 59.10it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 75.97it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 84.45it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 95.41it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 102.27it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 116.75it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 115.54it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 118.99it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:24, 32.78it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:20, 38.19it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:18, 40.52it/s]Predicting...:  20%|██        | 185/923 [00:02<00:11, 61.85it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:10, 71.43it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 64.18it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 61.01it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 65.29it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:12, 52.12it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 47.50it/s]Predicting...:  30%|███       | 277/923 [00:04<00:14, 45.80it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 44.02it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:12, 49.59it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 53.34it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 59.07it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 54.02it/s]Predicting...:  38%|███▊      | 347/923 [00:06<00:11, 48.60it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:09, 56.83it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 72.80it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:08, 59.11it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:07, 66.61it/s]Predicting...:  46%|████▌     | 424/923 [00:07<00:07, 68.71it/s]Predicting...:  48%|████▊     | 441/923 [00:07<00:05, 81.92it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:05, 81.02it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:05, 86.76it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 71.64it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 78.39it/s]Predicting...:  54%|█████▍    | 503/923 [00:08<00:07, 54.62it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:06, 61.63it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 71.17it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 55.17it/s]Predicting...:  59%|█████▉    | 548/923 [00:09<00:09, 40.97it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:10, 35.39it/s]Predicting...:  62%|██████▏   | 568/923 [00:10<00:12, 29.15it/s]Predicting...:  63%|██████▎   | 580/923 [00:10<00:09, 36.89it/s]Predicting...:  64%|██████▎   | 587/923 [00:10<00:10, 32.64it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:10, 32.61it/s]Predicting...:  66%|██████▌   | 605/923 [00:11<00:09, 32.86it/s]Predicting...:  67%|██████▋   | 618/923 [00:11<00:07, 40.29it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:06, 43.06it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 37.39it/s]Predicting...:  70%|███████   | 647/923 [00:12<00:08, 34.30it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:09, 27.78it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:09, 26.72it/s]Predicting...:  73%|███████▎  | 671/923 [00:13<00:08, 30.90it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:09, 27.15it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:07, 30.77it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:09, 24.95it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:06, 31.62it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:06, 31.70it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:05, 38.38it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 48.82it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:04, 36.11it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 37.86it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 44.93it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 49.30it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 56.48it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 67.06it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 66.81it/s]Predicting...:  90%|█████████ | 835/923 [00:16<00:02, 41.28it/s]Predicting...:  92%|█████████▏| 850/923 [00:17<00:01, 52.60it/s]Predicting...:  93%|█████████▎| 862/923 [00:17<00:01, 54.67it/s]Predicting...:  95%|█████████▌| 878/923 [00:17<00:00, 67.84it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 72.19it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 85.60it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 96.83it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 51.89it/s]
2025-05-27 19:39:21,805 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.05, ppl:   2.85, acc:   0.70, generation: 17.7895[sec], evaluation: 0.0000[sec]
2025-05-27 19:39:21,806 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:39:22,370 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/31000.ckpt
2025-05-27 19:39:22,396 - INFO - joeynmt.training - Example #0
2025-05-27 19:39:22,397 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:39:22,397 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:39:22,397 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questa fot<unk> @ o per ri<unk> @ dur<unk> @ re la p<unk> @ op<unk> @ ol<unk> @ ia per la f<unk> @ am<unk> @ ig<unk> @ lia , che ha di<unk> @ mostr<unk> @ ato che i c<unk> @ av<unk> @ est<unk> @ i , per il 4<unk> @ 8 % del 4<unk> @ 8 % del 4<unk> @ 8 % di 4<unk> @ 8 % .
2025-05-27 19:39:22,397 - INFO - joeynmt.training - Example #1
2025-05-27 19:39:22,398 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:39:22,398 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:39:22,399 - INFO - joeynmt.training - 	Hypothesis: Ma non è più diff<unk> @ ic<unk> @ ile , la ris<unk> @ post<unk> @ a è la ris<unk> @ post<unk> @ a è il problema di D<unk> @ ic<unk> @ e non mostr<unk> @ a la di<unk> @ mostr<unk> @ a .
2025-05-27 19:39:22,399 - INFO - joeynmt.training - Example #2
2025-05-27 19:39:22,399 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:39:22,400 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:39:22,400 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ edi<unk> @ a è la c<unk> @ aus<unk> @ a di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a la nostra c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 19:39:22,400 - INFO - joeynmt.training - Example #3
2025-05-27 19:39:22,400 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:39:22,400 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:39:22,401 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ c<unk> @ ri<unk> @ va in par<unk> @ ole e la s<unk> @ qu<unk> @ ad<unk> @ ra .
2025-05-27 19:39:22,401 - INFO - joeynmt.training - Example #4
2025-05-27 19:39:22,401 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:39:22,401 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:39:22,402 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che mostr<unk> @ o che vi mostr<unk> @ o è una c<unk> @ en<unk> @ a , è una c<unk> @ en<unk> @ a , che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:39:25,837 - INFO - joeynmt.training - Epoch   5, Step:    33600, Batch Loss:     1.004092, Batch Acc: 0.702557, Tokens per Sec:    19923, Lr: 0.000300
2025-05-27 19:39:29,258 - INFO - joeynmt.training - Epoch   5, Step:    33700, Batch Loss:     1.002109, Batch Acc: 0.700994, Tokens per Sec:    24055, Lr: 0.000300
2025-05-27 19:39:32,672 - INFO - joeynmt.training - Epoch   5, Step:    33800, Batch Loss:     1.017096, Batch Acc: 0.700564, Tokens per Sec:    23806, Lr: 0.000300
2025-05-27 19:39:36,061 - INFO - joeynmt.training - Epoch   5, Step:    33900, Batch Loss:     1.035754, Batch Acc: 0.705753, Tokens per Sec:    23434, Lr: 0.000300
2025-05-27 19:39:39,467 - INFO - joeynmt.training - Epoch   5, Step:    34000, Batch Loss:     1.039697, Batch Acc: 0.704307, Tokens per Sec:    23909, Lr: 0.000300
2025-05-27 19:39:39,468 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:39:39,468 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 64.00it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 79.28it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 90.17it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 97.20it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 105.60it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 115.63it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 107.30it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 97.50it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:25, 31.52it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:21, 36.55it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:19, 39.28it/s]Predicting...:  20%|██        | 185/923 [00:03<00:12, 58.48it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:10, 67.50it/s]Predicting...:  23%|██▎       | 211/923 [00:03<00:10, 68.22it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 68.14it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 58.44it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 64.89it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:13, 50.35it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 47.84it/s]Predicting...:  30%|███       | 277/923 [00:04<00:14, 46.13it/s]Predicting...:  31%|███▏      | 289/923 [00:05<00:14, 45.15it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:12, 50.45it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 54.98it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 62.11it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 60.67it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:08, 67.20it/s]Predicting...:  41%|████      | 379/923 [00:06<00:06, 82.21it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 82.37it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 84.87it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 88.33it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 95.10it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 89.58it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:05, 85.93it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 72.34it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 75.13it/s]Predicting...:  54%|█████▍    | 503/923 [00:08<00:09, 43.77it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:07, 50.89it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:06, 60.50it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:07, 51.88it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 44.99it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:08, 41.36it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 36.43it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 43.40it/s]Predicting...:  64%|██████▎   | 587/923 [00:10<00:10, 31.51it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:09, 32.89it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 34.05it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 40.67it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:07, 40.85it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 36.49it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 35.03it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:09, 28.26it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:09, 28.02it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:07, 32.16it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 27.03it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:07, 29.50it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:09, 25.12it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 32.23it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:06, 32.08it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:05, 36.03it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 44.46it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:05, 33.62it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 34.58it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 43.68it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 47.23it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 55.82it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 66.48it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 66.83it/s]Predicting...:  90%|█████████ | 835/923 [00:16<00:01, 45.47it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 55.94it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 56.53it/s]Predicting...:  95%|█████████▌| 878/923 [00:17<00:00, 67.80it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 75.13it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 88.58it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 99.89it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 52.90it/s]
2025-05-27 19:39:56,932 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.84, acc:   0.70, generation: 17.4489[sec], evaluation: 0.0000[sec]
2025-05-27 19:39:56,932 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:39:57,486 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/31500.ckpt
2025-05-27 19:39:57,511 - INFO - joeynmt.training - Example #0
2025-05-27 19:39:57,513 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:39:57,513 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:39:57,513 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o ho mostr<unk> @ ato questa fot<unk> @ o , ho mostr<unk> @ ato questa fot<unk> @ o per per<unk> @ dere , per per<unk> @ dere , per i di<unk> @ sp<unk> @ ost<unk> @ are i v<unk> @ oc<unk> @ ali , per i due anni , per i di<unk> @ st<unk> @ i , per i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 , per c<unk> @ ento di qu<unk> @ elli che ha av<unk> @ uto il 4<unk> @ 0 % .
2025-05-27 19:39:57,513 - INFO - joeynmt.training - Example #1
2025-05-27 19:39:57,514 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:39:57,514 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:39:57,514 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è un punto di vi<unk> @ sta , non è abb<unk> @ ast<unk> @ anza , questo problema spe<unk> @ ci<unk> @ ale , questo problema spe<unk> @ ci<unk> @ ale , non è il d<unk> @ ott<unk> @ ore di E<unk> @ is<unk> @ t .
2025-05-27 19:39:57,514 - INFO - joeynmt.training - Example #2
2025-05-27 19:39:57,515 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:39:57,515 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:39:57,515 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il s<unk> @ esso è la cosa in<unk> @ ten<unk> @ zione è la c<unk> @ aus<unk> @ a di c<unk> @ li<unk> @ m<unk> @ as<unk> @ si<unk> @ mo .
2025-05-27 19:39:57,515 - INFO - joeynmt.training - Example #3
2025-05-27 19:39:57,516 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:39:57,516 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:39:57,516 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta che si è s<unk> @ ì , e la p<unk> @ eg<unk> @ gi<unk> @ o in m<unk> @ ezz<unk> @ o .
2025-05-27 19:39:57,516 - INFO - joeynmt.training - Example #4
2025-05-27 19:39:57,517 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:39:57,517 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:39:57,517 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una c<unk> @ aus<unk> @ a di una c<unk> @ las<unk> @ se è un c<unk> @ entr<unk> @ o di quello che succ<unk> @ e<unk> @ de<unk> @ va negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:40:00,945 - INFO - joeynmt.training - Epoch   5, Step:    34100, Batch Loss:     0.976248, Batch Acc: 0.699790, Tokens per Sec:    19825, Lr: 0.000300
2025-05-27 19:40:04,197 - INFO - joeynmt.training - Epoch   5, Step:    34200, Batch Loss:     1.045823, Batch Acc: 0.701585, Tokens per Sec:    24129, Lr: 0.000300
2025-05-27 19:40:07,466 - INFO - joeynmt.training - Epoch   5, Step:    34300, Batch Loss:     1.153490, Batch Acc: 0.703165, Tokens per Sec:    24509, Lr: 0.000300
2025-05-27 19:40:10,713 - INFO - joeynmt.training - Epoch   5, Step:    34400, Batch Loss:     0.976346, Batch Acc: 0.704039, Tokens per Sec:    24858, Lr: 0.000300
2025-05-27 19:40:13,941 - INFO - joeynmt.training - Epoch   5, Step:    34500, Batch Loss:     1.065631, Batch Acc: 0.704820, Tokens per Sec:    24695, Lr: 0.000300
2025-05-27 19:40:13,941 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:40:13,941 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:23, 38.79it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:15, 59.51it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 77.20it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 83.48it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 82.10it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:08, 94.96it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 100.97it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 114.40it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:16, 46.61it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:17, 44.14it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 53.65it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 76.55it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.46it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 70.73it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 59.62it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 66.90it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 54.04it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 51.95it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 52.79it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.34it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 56.08it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 62.34it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 63.02it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 56.96it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 53.20it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 63.21it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 78.83it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 84.49it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 89.10it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 83.49it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 93.49it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 92.69it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 86.65it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.34it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 81.53it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 59.85it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 65.51it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 72.81it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 55.72it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 45.03it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 42.19it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 39.93it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:06, 49.14it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 37.45it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.84it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.03it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 45.04it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 45.58it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 40.03it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.02it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:09, 28.79it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 28.61it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 31.90it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 27.92it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 29.30it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.07it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 36.69it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:05, 35.23it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 42.00it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:04, 38.91it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:05, 33.36it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 34.96it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 43.41it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 46.77it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 57.49it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 68.05it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 73.09it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 52.06it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 51.19it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 62.98it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 69.84it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 79.94it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 55.83it/s]
2025-05-27 19:40:30,487 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.83, acc:   0.70, generation: 16.5323[sec], evaluation: 0.0000[sec]
2025-05-27 19:40:30,488 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:40:31,068 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/32000.ckpt
2025-05-27 19:40:31,092 - INFO - joeynmt.training - Example #0
2025-05-27 19:40:31,094 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:40:31,094 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:40:31,094 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per fare la f<unk> @ am<unk> @ ig<unk> @ lia per la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , per gli str<unk> @ um<unk> @ enti che hanno fatto per i c<unk> @ aus<unk> @ a di tre milioni di anni , e i m<unk> @ oti<unk> @ vi per la qu<unk> @ ant<unk> @ ità di tre milioni di di di di di persone , ha fatto che ha av<unk> @ uto un 4<unk> @ 0 % .
2025-05-27 19:40:31,094 - INFO - joeynmt.training - Example #1
2025-05-27 19:40:31,095 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:40:31,095 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:40:31,095 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il punto di vi<unk> @ sta non è la di<unk> @ st<unk> @ anza di questa spe<unk> @ ci<unk> @ fic<unk> @ enza , e questo problema spe<unk> @ ci<unk> @ ale , non è il D<unk> @ ic<unk> @ io di D<unk> @ ic<unk> @ io , non è il D<unk> @ ic<unk> @ io .
2025-05-27 19:40:31,095 - INFO - joeynmt.training - Example #2
2025-05-27 19:40:31,096 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:40:31,096 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:40:31,096 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la nostra c<unk> @ li<unk> @ m<unk> @ as<unk> @ c<unk> @ uno di questi c<unk> @ li<unk> @ m<unk> @ as<unk> @ si di c<unk> @ li<unk> @ m<unk> @ as<unk> @ se , il nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ so di c<unk> @ li<unk> @ m<unk> @ as<unk> @ si<unk> @ mo .
2025-05-27 19:40:31,096 - INFO - joeynmt.training - Example #3
2025-05-27 19:40:31,097 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:40:31,097 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:40:31,097 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e sc<unk> @ eg<unk> @ li<unk> @ ere e la p<unk> @ at<unk> @ ric<unk> @ e .
2025-05-27 19:40:31,097 - INFO - joeynmt.training - Example #4
2025-05-27 19:40:31,098 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:40:31,098 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:40:31,098 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una c<unk> @ el<unk> @ eb<unk> @ r<unk> @ ale che vi mostr<unk> @ er<unk> @ ò cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:40:34,509 - INFO - joeynmt.training - Epoch   5, Step:    34600, Batch Loss:     0.992161, Batch Acc: 0.698099, Tokens per Sec:    19965, Lr: 0.000300
2025-05-27 19:40:37,885 - INFO - joeynmt.training - Epoch   5, Step:    34700, Batch Loss:     0.984120, Batch Acc: 0.700674, Tokens per Sec:    23924, Lr: 0.000300
2025-05-27 19:40:41,283 - INFO - joeynmt.training - Epoch   5, Step:    34800, Batch Loss:     1.022342, Batch Acc: 0.703398, Tokens per Sec:    24128, Lr: 0.000300
2025-05-27 19:40:44,678 - INFO - joeynmt.training - Epoch   5, Step:    34900, Batch Loss:     1.049352, Batch Acc: 0.701398, Tokens per Sec:    23602, Lr: 0.000300
2025-05-27 19:40:48,032 - INFO - joeynmt.training - Epoch   5, Step:    35000, Batch Loss:     1.030052, Batch Acc: 0.702226, Tokens per Sec:    23755, Lr: 0.000300
2025-05-27 19:40:48,032 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:40:48,032 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 71.31it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 84.52it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 84.78it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 91.23it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.79it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:10, 81.59it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 94.28it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:15, 49.52it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 53.87it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.85it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 87.09it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 92.54it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.79it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 83.40it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:07, 86.54it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 57.60it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 53.10it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 51.27it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 57.80it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.76it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.52it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 64.32it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 70.85it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 77.84it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 84.18it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 87.82it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 85.74it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 93.76it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 89.88it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 92.31it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 81.35it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 89.37it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 79.58it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 85.86it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 54.80it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 47.67it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 44.22it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 49.61it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 36.71it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 36.26it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.02it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.74it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.68it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 43.93it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 40.88it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 33.93it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 32.42it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.32it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 33.28it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.33it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 30.98it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 37.49it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.15it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 42.51it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 50.88it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 39.08it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.94it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 50.26it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 57.42it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 67.98it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 74.75it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 75.99it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 59.51it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.20it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 76.43it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 64.98it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 77.26it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.58it/s]
2025-05-27 19:41:03,282 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.83, acc:   0.70, generation: 15.2374[sec], evaluation: 0.0000[sec]
2025-05-27 19:41:03,283 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:41:03,898 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/33000.ckpt
2025-05-27 19:41:03,924 - INFO - joeynmt.training - Example #0
2025-05-27 19:41:03,925 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:41:03,925 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:41:03,925 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so che ho mostr<unk> @ ato questi due f<unk> @ ec<unk> @ i f<unk> @ ol<unk> @ i per con<unk> @ to che i p<unk> @ oco per cui i f<unk> @ ar c<unk> @ att<unk> @ are la c<unk> @ att<unk> @ u<unk> @ ale , per i 4<unk> @ 8 milioni di anni , per la qu<unk> @ ale , per il 4<unk> @ 0 per c<unk> @ ento di tre milioni di anni , e il 4<unk> @ 0 per c<unk> @ ento di tre milioni di persone .
2025-05-27 19:41:03,925 - INFO - joeynmt.training - Example #1
2025-05-27 19:41:03,926 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:41:03,926 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:41:03,926 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il fatto che la ris<unk> @ post<unk> @ a è la di<unk> @ st<unk> @ ha<unk> @ i questa part<unk> @ icol<unk> @ are , non è il D<unk> @ ic<unk> @ e non si ri<unk> @ es<unk> @ ce .
2025-05-27 19:41:03,926 - INFO - joeynmt.training - Example #2
2025-05-27 19:41:03,927 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:41:03,927 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:41:03,927 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ li<unk> @ sta è la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 19:41:03,927 - INFO - joeynmt.training - Example #3
2025-05-27 19:41:03,928 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:41:03,928 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:41:03,928 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o di par<unk> @ ole .
2025-05-27 19:41:03,928 - INFO - joeynmt.training - Example #4
2025-05-27 19:41:03,929 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:41:03,929 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:41:03,929 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una ser<unk> @ ie di ri<unk> @ pres<unk> @ a che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:41:07,304 - INFO - joeynmt.training - Epoch   5, Step:    35100, Batch Loss:     1.048132, Batch Acc: 0.702882, Tokens per Sec:    19943, Lr: 0.000300
2025-05-27 19:41:10,665 - INFO - joeynmt.training - Epoch   5, Step:    35200, Batch Loss:     1.031295, Batch Acc: 0.702867, Tokens per Sec:    23683, Lr: 0.000300
2025-05-27 19:41:14,037 - INFO - joeynmt.training - Epoch   5, Step:    35300, Batch Loss:     1.104566, Batch Acc: 0.701653, Tokens per Sec:    23292, Lr: 0.000300
2025-05-27 19:41:17,409 - INFO - joeynmt.training - Epoch   5, Step:    35400, Batch Loss:     0.918054, Batch Acc: 0.705179, Tokens per Sec:    23315, Lr: 0.000300
2025-05-27 19:41:20,777 - INFO - joeynmt.training - Epoch   5, Step:    35500, Batch Loss:     0.931359, Batch Acc: 0.699580, Tokens per Sec:    23343, Lr: 0.000300
2025-05-27 19:41:20,777 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:41:20,777 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 63.18it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 82.35it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 88.97it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 91.99it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 91.18it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 98.62it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 68.89it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 84.87it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 41.93it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 46.10it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 55.76it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 78.39it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 84.51it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 71.57it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 70.89it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 74.49it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 55.00it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 54.12it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 50.12it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 45.59it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 48.62it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 51.27it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 54.53it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 61.70it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 51.35it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:12, 46.65it/s]Predicting...:  41%|████      | 379/923 [00:06<00:09, 60.16it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:07, 68.26it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:07, 72.78it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 77.98it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 88.95it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 84.01it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:05, 85.10it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 73.91it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 78.82it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:09, 44.99it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:07, 55.53it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 67.85it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 47.50it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:09, 39.39it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 36.88it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 43.46it/s]Predicting...:  64%|██████▎   | 587/923 [00:10<00:10, 30.64it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:10, 32.19it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:12, 25.02it/s]Predicting...:  67%|██████▋   | 618/923 [00:11<00:09, 32.52it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:08, 36.25it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:08, 34.46it/s]Predicting...:  70%|███████   | 647/923 [00:12<00:08, 32.10it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:10, 26.65it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:10, 26.05it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:08, 30.21it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:08, 27.41it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:07, 30.35it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:09, 24.73it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:06, 32.74it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:08, 24.54it/s]Predicting...:  79%|███████▉  | 729/923 [00:15<00:07, 27.06it/s]Predicting...:  80%|████████  | 742/923 [00:15<00:05, 35.95it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:05, 30.03it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 33.36it/s]Predicting...:  84%|████████▍ | 774/923 [00:16<00:03, 42.28it/s]Predicting...:  85%|████████▌ | 786/923 [00:16<00:02, 48.55it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 57.50it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 66.30it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 65.36it/s]Predicting...:  90%|█████████ | 835/923 [00:17<00:01, 44.54it/s]Predicting...:  92%|█████████▏| 850/923 [00:17<00:01, 55.65it/s]Predicting...:  93%|█████████▎| 862/923 [00:17<00:01, 55.42it/s]Predicting...:  95%|█████████▌| 878/923 [00:17<00:00, 68.78it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 74.92it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 85.98it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 98.29it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 51.22it/s]
2025-05-27 19:41:38,810 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.84, acc:   0.70, generation: 18.0192[sec], evaluation: 0.0000[sec]
2025-05-27 19:41:39,221 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/32500.ckpt
2025-05-27 19:41:39,246 - INFO - joeynmt.training - Example #0
2025-05-27 19:41:39,248 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:41:39,248 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:41:39,248 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per ri<unk> @ port<unk> @ are i p<unk> @ ezz<unk> @ i di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io che i v<unk> @ u<unk> @ ot<unk> @ ano per i 4<unk> @ 8 <unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per tre milioni di di di persone che ha av<unk> @ uto 4<unk> @ 8 % .
2025-05-27 19:41:39,248 - INFO - joeynmt.training - Example #1
2025-05-27 19:41:39,249 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:41:39,249 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:41:39,249 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ ten<unk> @ den<unk> @ za , la ver<unk> @ ità di questa part<unk> @ icol<unk> @ are , non è il d<unk> @ ot<unk> @ ti<unk> @ mo di E<unk> @ is<unk> @ p<unk> @ it<unk> @ t<unk> @ ura .
2025-05-27 19:41:39,249 - INFO - joeynmt.training - Example #2
2025-05-27 19:41:39,250 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:41:39,250 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:41:39,250 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la p<unk> @ eg<unk> @ gi<unk> @ ore è la b<unk> @ att<unk> @ ag<unk> @ ante della nostra c<unk> @ li<unk> @ sta .
2025-05-27 19:41:39,250 - INFO - joeynmt.training - Example #3
2025-05-27 19:41:39,251 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:41:39,251 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:41:39,251 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ à in ver<unk> @ no e la p<unk> @ eg<unk> @ gi<unk> @ ore .
2025-05-27 19:41:39,251 - INFO - joeynmt.training - Example #4
2025-05-27 19:41:39,252 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:41:39,252 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:41:39,252 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una ver<unk> @ a che vi mostr<unk> @ er<unk> @ ò la sua car<unk> @ ta è una ser<unk> @ ie di con<unk> @ si<unk> @ der<unk> @ azione che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:41:42,661 - INFO - joeynmt.training - Epoch   5, Step:    35600, Batch Loss:     1.065678, Batch Acc: 0.698835, Tokens per Sec:    20439, Lr: 0.000300
2025-05-27 19:41:46,061 - INFO - joeynmt.training - Epoch   5, Step:    35700, Batch Loss:     1.053087, Batch Acc: 0.701896, Tokens per Sec:    23145, Lr: 0.000300
2025-05-27 19:41:49,447 - INFO - joeynmt.training - Epoch   5, Step:    35800, Batch Loss:     0.986227, Batch Acc: 0.699020, Tokens per Sec:    23254, Lr: 0.000300
2025-05-27 19:41:52,822 - INFO - joeynmt.training - Epoch   5, Step:    35900, Batch Loss:     1.049119, Batch Acc: 0.701975, Tokens per Sec:    23355, Lr: 0.000300
2025-05-27 19:41:56,197 - INFO - joeynmt.training - Epoch   5, Step:    36000, Batch Loss:     0.999187, Batch Acc: 0.701679, Tokens per Sec:    23230, Lr: 0.000300
2025-05-27 19:41:56,197 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:41:56,197 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:20, 45.08it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:13, 64.30it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 77.43it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 84.40it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 93.33it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:08, 104.11it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 100.93it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 82.10it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 45.10it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 50.35it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 57.16it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.07it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.74it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 74.70it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 65.08it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 70.34it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 57.42it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.66it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 53.28it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 51.26it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 56.33it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.43it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 62.32it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 58.36it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.82it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 63.56it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 75.59it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 78.06it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 74.96it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 74.29it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 84.96it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 77.05it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 77.81it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 70.04it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 74.25it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 56.16it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 62.14it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 70.74it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 56.74it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 46.42it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 42.00it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.28it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 47.11it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 39.72it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 39.99it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.32it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 45.01it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 47.28it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 45.01it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 39.48it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 30.96it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 30.83it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.23it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 27.99it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 30.29it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 29.35it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 37.63it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:05, 36.09it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 44.07it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 51.53it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 40.29it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 41.91it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 47.72it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 52.97it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 62.46it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 72.51it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 71.82it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 51.02it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 62.06it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 61.06it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 70.77it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 74.57it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 88.26it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 57.62it/s]
2025-05-27 19:42:12,230 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.84, acc:   0.70, generation: 16.0191[sec], evaluation: 0.0000[sec]
2025-05-27 19:42:12,628 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/33500.ckpt
2025-05-27 19:42:12,654 - INFO - joeynmt.training - Example #0
2025-05-27 19:42:12,655 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:42:12,655 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:42:12,656 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due f<unk> @ ogli<unk> @ hi per f<unk> @ ar s<unk> @ ì che la p<unk> @ op<unk> @ ol<unk> @ ia che i g<unk> @ ar<unk> @ t<unk> @ ici , per i 4<unk> @ 8 <unk> @ 8 milioni di anni , per i 4<unk> @ 8 <unk> @ 8 milioni di anni , per i 4<unk> @ 8 milioni di anni , è stato m<unk> @ and<unk> @ ato a tre milioni di anni , per il 4<unk> @ 8 % .
2025-05-27 19:42:12,656 - INFO - joeynmt.training - Example #1
2025-05-27 19:42:12,656 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:42:12,657 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:42:12,657 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza il ris<unk> @ ult<unk> @ ato della di<unk> @ st<unk> @ anza di questa spe<unk> @ ci<unk> @ fica , perché non è il D<unk> @ ic<unk> @ e<unk> @ o del problema .
2025-05-27 19:42:12,657 - INFO - joeynmt.training - Example #2
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Hypothesis: In un sen<unk> @ so di sen<unk> @ so è la c<unk> @ li<unk> @ sta è la c<unk> @ li<unk> @ sta del nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - Example #3
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:42:12,658 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in v<unk> @ inc<unk> @ ere e la v<unk> @ oc<unk> @ e .
2025-05-27 19:42:12,659 - INFO - joeynmt.training - Example #4
2025-05-27 19:42:12,659 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:42:12,659 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:42:12,659 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ate che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a che vi mostr<unk> @ er<unk> @ ò quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:42:16,083 - INFO - joeynmt.training - Epoch   5, Step:    36100, Batch Loss:     0.988846, Batch Acc: 0.704979, Tokens per Sec:    20666, Lr: 0.000300
2025-05-27 19:42:19,464 - INFO - joeynmt.training - Epoch   5, Step:    36200, Batch Loss:     1.083730, Batch Acc: 0.705511, Tokens per Sec:    23005, Lr: 0.000300
2025-05-27 19:42:22,839 - INFO - joeynmt.training - Epoch   5, Step:    36300, Batch Loss:     0.781799, Batch Acc: 0.706125, Tokens per Sec:    24006, Lr: 0.000300
2025-05-27 19:42:26,215 - INFO - joeynmt.training - Epoch   5, Step:    36400, Batch Loss:     1.112786, Batch Acc: 0.702919, Tokens per Sec:    23279, Lr: 0.000300
2025-05-27 19:42:29,582 - INFO - joeynmt.training - Epoch   5, Step:    36500, Batch Loss:     1.028872, Batch Acc: 0.701857, Tokens per Sec:    22635, Lr: 0.000300
2025-05-27 19:42:29,583 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:42:29,583 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 82.71it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 82.44it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 94.19it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 91.87it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 78.19it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:09, 89.63it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:12, 66.10it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:12, 63.96it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:21, 36.86it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:18, 42.94it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 52.77it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 77.12it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.45it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:08, 83.52it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 77.27it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:07, 86.05it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:11, 55.25it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 53.66it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 49.26it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.60it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.49it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 61.18it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 58.44it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.97it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 63.29it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 77.76it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 84.07it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 74.66it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 75.11it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 87.31it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 84.56it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 91.48it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:04, 90.25it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:05, 74.53it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 79.23it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 87.79it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:05, 64.34it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:10, 32.93it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:08, 38.70it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 32.84it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 32.61it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 39.89it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 42.22it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.49it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:06, 39.72it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 32.02it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 31.41it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 34.96it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 29.29it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 33.14it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 27.63it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:05, 36.25it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 33.70it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 42.40it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 51.80it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 41.41it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:03, 41.78it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 53.44it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 59.91it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 64.48it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 76.09it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 81.67it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 63.82it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 63.07it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 76.20it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 80.98it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 107.47it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 57.35it/s] 
2025-05-27 19:42:45,690 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.04, ppl:   2.83, acc:   0.70, generation: 16.0938[sec], evaluation: 0.0000[sec]
2025-05-27 19:42:45,690 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:42:46,362 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/34000.ckpt
2025-05-27 19:42:46,387 - INFO - joeynmt.training - Example #0
2025-05-27 19:42:46,389 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:42:46,389 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:42:46,389 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i di f<unk> @ ar ri<unk> @ m<unk> @ b<unk> @ ol<unk> @ i che i c<unk> @ att<unk> @ es<unk> @ ci che i si<unk> @ ano le persone che hanno sc<unk> @ oper<unk> @ to per i 4<unk> @ 0 anni , per la 4<unk> @ 0 , per c<unk> @ ento di tre milioni di anni , per sc<unk> @ ar<unk> @ ic<unk> @ are , per 4<unk> @ 0 % .
2025-05-27 19:42:46,389 - INFO - joeynmt.training - Example #1
2025-05-27 19:42:46,390 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:42:46,390 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:42:46,390 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza , la giu<unk> @ st<unk> @ izi<unk> @ a , non è il d<unk> @ ato di questa part<unk> @ icol<unk> @ are , non è il d<unk> @ ato di D<unk> @ ic<unk> @ io .
2025-05-27 19:42:46,390 - INFO - joeynmt.training - Example #2
2025-05-27 19:42:46,391 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:42:46,391 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:42:46,391 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la c<unk> @ li<unk> @ sta è il c<unk> @ li<unk> @ vello di ci<unk> @ b<unk> @ o del nostro s<unk> @ ito .
2025-05-27 19:42:46,391 - INFO - joeynmt.training - Example #3
2025-05-27 19:42:46,392 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:42:46,392 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:42:46,392 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o .
2025-05-27 19:42:46,392 - INFO - joeynmt.training - Example #4
2025-05-27 19:42:46,393 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:42:46,393 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:42:46,393 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o la cosa che vi mostr<unk> @ o è una c<unk> @ el<unk> @ a che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:42:49,757 - INFO - joeynmt.training - Epoch   5, Step:    36600, Batch Loss:     1.007432, Batch Acc: 0.698927, Tokens per Sec:    19018, Lr: 0.000300
2025-05-27 19:42:53,097 - INFO - joeynmt.training - Epoch   5, Step:    36700, Batch Loss:     1.259095, Batch Acc: 0.697684, Tokens per Sec:    24399, Lr: 0.000300
2025-05-27 19:42:56,383 - INFO - joeynmt.training - Epoch   5, Step:    36800, Batch Loss:     1.031609, Batch Acc: 0.703178, Tokens per Sec:    24150, Lr: 0.000300
2025-05-27 19:42:59,703 - INFO - joeynmt.training - Epoch   5, Step:    36900, Batch Loss:     0.987558, Batch Acc: 0.704923, Tokens per Sec:    23708, Lr: 0.000300
2025-05-27 19:43:03,025 - INFO - joeynmt.training - Epoch   5, Step:    37000, Batch Loss:     1.015571, Batch Acc: 0.704313, Tokens per Sec:    24008, Lr: 0.000300
2025-05-27 19:43:03,026 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:43:03,026 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 58.04it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 80.27it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 93.02it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 103.73it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 115.37it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 125.14it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 116.05it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 91.91it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:23, 33.59it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:19, 40.54it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 50.05it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 74.17it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 83.19it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 74.24it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 59.36it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 67.22it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 51.83it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 47.50it/s]Predicting...:  30%|███       | 277/923 [00:04<00:14, 45.55it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 44.04it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 51.86it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 54.89it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 60.61it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 60.68it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 71.92it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 88.56it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 97.08it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 102.98it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 99.03it/s] Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 109.56it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 104.80it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 103.65it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 86.14it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 94.23it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:07, 57.13it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 65.44it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 58.35it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 49.87it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 45.66it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 42.25it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.92it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 37.38it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.70it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.44it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.88it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 46.96it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 44.34it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 42.43it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 34.53it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 33.26it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 37.38it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.41it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 36.60it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 30.35it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 38.76it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 34.53it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 41.97it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 52.14it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 41.05it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 41.13it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 52.91it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 61.01it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 67.34it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 79.10it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 84.35it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 69.43it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 69.66it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 81.35it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 81.03it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 92.22it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.04it/s]
2025-05-27 19:43:18,413 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.03, ppl:   2.81, acc:   0.70, generation: 15.3744[sec], evaluation: 0.0000[sec]
2025-05-27 19:43:18,414 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:43:18,920 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/36000.ckpt
2025-05-27 19:43:18,946 - INFO - joeynmt.training - Example #0
2025-05-27 19:43:18,947 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:43:18,947 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:43:18,947 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ ti per fare questo f<unk> @ en<unk> @ om<unk> @ en<unk> @ o che la g<unk> @ hi<unk> @ ac<unk> @ cio per il li<unk> @ vello di ci<unk> @ b<unk> @ o di tre milioni di anni , per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 ore .
2025-05-27 19:43:18,947 - INFO - joeynmt.training - Example #1
2025-05-27 19:43:18,948 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:43:18,948 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:43:18,948 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza il ris<unk> @ ult<unk> @ ato di questa part<unk> @ icol<unk> @ are la di<unk> @ st<unk> @ anza di questa part<unk> @ icol<unk> @ are , non è il D<unk> @ ic<unk> @ io .
2025-05-27 19:43:18,948 - INFO - joeynmt.training - Example #2
2025-05-27 19:43:18,949 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:43:18,949 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:43:18,949 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la lin<unk> @ gu<unk> @ a è la c<unk> @ li<unk> @ sta del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 19:43:18,949 - INFO - joeynmt.training - Example #3
2025-05-27 19:43:18,950 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:43:18,950 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:43:18,950 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ei sc<unk> @ o<unk> @ pr<unk> @ ire il p<unk> @ eg<unk> @ gi<unk> @ o .
2025-05-27 19:43:18,950 - INFO - joeynmt.training - Example #4
2025-05-27 19:43:18,951 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:43:18,951 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:43:18,951 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ a una ser<unk> @ ie di queste sc<unk> @ or<unk> @ sa che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:43:22,313 - INFO - joeynmt.training - Epoch   5, Step:    37100, Batch Loss:     1.083645, Batch Acc: 0.703863, Tokens per Sec:    20257, Lr: 0.000300
2025-05-27 19:43:25,681 - INFO - joeynmt.training - Epoch   5, Step:    37200, Batch Loss:     0.944459, Batch Acc: 0.702090, Tokens per Sec:    22808, Lr: 0.000300
2025-05-27 19:43:29,078 - INFO - joeynmt.training - Epoch   5, Step:    37300, Batch Loss:     1.001483, Batch Acc: 0.703914, Tokens per Sec:    23641, Lr: 0.000300
2025-05-27 19:43:32,454 - INFO - joeynmt.training - Epoch   5, Step:    37400, Batch Loss:     1.101585, Batch Acc: 0.707795, Tokens per Sec:    23141, Lr: 0.000300
2025-05-27 19:43:35,844 - INFO - joeynmt.training - Epoch   5, Step:    37500, Batch Loss:     1.048201, Batch Acc: 0.708003, Tokens per Sec:    22921, Lr: 0.000300
2025-05-27 19:43:35,844 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:43:35,844 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 64.89it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 85.16it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 83.58it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 91.27it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 109.23it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 136.27it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:08, 90.92it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 66.24it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:10, 74.04it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 96.40it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 101.96it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 80.92it/s] Predicting...:  25%|██▌       | 235/923 [00:02<00:11, 60.81it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 63.26it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 51.82it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:14, 46.47it/s]Predicting...:  30%|███       | 277/923 [00:04<00:15, 42.92it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:15, 40.41it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:13, 47.03it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 51.12it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 58.75it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 66.61it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 76.11it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 90.29it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 90.48it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 92.60it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 99.40it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 111.34it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 103.83it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 105.90it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 95.94it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 94.66it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 74.31it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 75.85it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:05, 64.95it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 58.80it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 65.77it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:06, 48.51it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 47.08it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 55.14it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 51.70it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 51.14it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:05, 46.19it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 38.19it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 35.88it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 40.95it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:08, 28.30it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:07, 31.73it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 33.58it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:04, 43.98it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 42.41it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 51.15it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 64.64it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 50.17it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 62.27it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:01, 70.72it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 82.74it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 95.67it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:00, 99.06it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:00, 75.18it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 75.85it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 92.54it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 115.59it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 67.44it/s] 
2025-05-27 19:43:49,539 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.03, ppl:   2.80, acc:   0.70, generation: 13.6860[sec], evaluation: 0.0000[sec]
2025-05-27 19:43:49,540 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:43:50,010 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/35500.ckpt
2025-05-27 19:43:50,028 - INFO - joeynmt.training - Example #0
2025-05-27 19:43:50,029 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:43:50,029 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:43:50,029 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato queste due f<unk> @ ami<unk> @ gl<unk> @ ie per ri<unk> @ dur<unk> @ re le p<unk> @ op<unk> @ ol<unk> @ azioni che hanno fatto per un c<unk> @ ac<unk> @ co di tre milioni di anni , che hanno fatto per la sc<unk> @ u<unk> @ ola che ha av<unk> @ uto il 4<unk> @ 8 anni , per il 4<unk> @ 8 anni , per il 4<unk> @ 8 anni , per il 4<unk> @ 8 anni .
2025-05-27 19:43:50,029 - INFO - joeynmt.training - Example #1
2025-05-27 19:43:50,030 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:43:50,030 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:43:50,030 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza il t<unk> @ as<unk> @ so di questo problema , non è il problema di essere un problema di probl<unk> @ emi spe<unk> @ ci<unk> @ ale , non è il d<unk> @ ic<unk> @ lo .
2025-05-27 19:43:50,030 - INFO - joeynmt.training - Example #2
2025-05-27 19:43:50,031 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:43:50,031 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:43:50,031 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di s<unk> @ otto str<unk> @ at<unk> @ ta è la c<unk> @ li<unk> @ et<unk> @ ta di un sistema glob<unk> @ ale c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ita di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 19:43:50,031 - INFO - joeynmt.training - Example #3
2025-05-27 19:43:50,032 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:43:50,032 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:43:50,032 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ à in v<unk> @ ento e si tr<unk> @ at<unk> @ ta di una cosa .
2025-05-27 19:43:50,032 - INFO - joeynmt.training - Example #4
2025-05-27 19:43:50,033 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:43:50,033 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:43:50,033 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a che è succ<unk> @ esso in qu<unk> @ ell&apos; ulti<unk> @ mo 2<unk> @ 5 anni .
2025-05-27 19:43:53,385 - INFO - joeynmt.training - Epoch   5, Step:    37600, Batch Loss:     0.966200, Batch Acc: 0.702517, Tokens per Sec:    20150, Lr: 0.000300
2025-05-27 19:43:56,764 - INFO - joeynmt.training - Epoch   5, Step:    37700, Batch Loss:     1.012017, Batch Acc: 0.706502, Tokens per Sec:    23394, Lr: 0.000300
2025-05-27 19:44:00,197 - INFO - joeynmt.training - Epoch   5, Step:    37800, Batch Loss:     0.911164, Batch Acc: 0.701971, Tokens per Sec:    22714, Lr: 0.000300
2025-05-27 19:44:03,741 - INFO - joeynmt.training - Epoch   5, Step:    37900, Batch Loss:     1.109449, Batch Acc: 0.703921, Tokens per Sec:    22311, Lr: 0.000300
2025-05-27 19:44:07,134 - INFO - joeynmt.training - Epoch   5, Step:    38000, Batch Loss:     0.994119, Batch Acc: 0.703855, Tokens per Sec:    23365, Lr: 0.000300
2025-05-27 19:44:07,134 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:44:07,135 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 67.44it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 74.61it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 84.37it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 88.13it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 94.07it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 104.71it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 104.47it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 84.03it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 43.39it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 49.55it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 49.22it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 73.08it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 81.66it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 71.62it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 59.84it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 65.82it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:14, 46.04it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:15, 42.83it/s]Predicting...:  30%|███       | 277/923 [00:04<00:14, 43.64it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 45.80it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.39it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:10, 58.15it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 61.22it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 58.72it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 53.12it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 61.62it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 77.74it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 84.18it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 86.02it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 89.05it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 96.14it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 70.83it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 72.94it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 67.51it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 74.46it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 60.61it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 67.44it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 76.27it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 57.87it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 45.78it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 40.43it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:08, 39.61it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 46.72it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 34.69it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.56it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:08, 36.64it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 45.51it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.98it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 40.55it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 36.34it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:09, 29.70it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 30.15it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:07, 32.89it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:10, 22.34it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:09, 25.45it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:09, 23.36it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 30.92it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 31.29it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:05, 38.05it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 47.85it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 37.56it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 37.94it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 49.45it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 55.35it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:01, 65.26it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 70.75it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 74.26it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 51.39it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 60.87it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 55.66it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 68.92it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 75.26it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 82.56it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 54.89it/s]
2025-05-27 19:44:23,966 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 16.8172[sec], evaluation: 0.0000[sec]
2025-05-27 19:44:23,970 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:44:24,537 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/34500.ckpt
2025-05-27 19:44:24,565 - INFO - joeynmt.training - Example #0
2025-05-27 19:44:24,568 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:44:24,568 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:44:24,568 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ta per entr<unk> @ amb<unk> @ i per fare due di<unk> @ ta per cui la p<unk> @ op<unk> @ ol<unk> @ i per la c<unk> @ att<unk> @ en<unk> @ zione di tre milioni di anni , che ha fatto per la loro c<unk> @ aus<unk> @ a di tre milioni di anni , per il 4<unk> @ 8 % del 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 per c<unk> @ ento di 4<unk> @ 8 % .
2025-05-27 19:44:24,568 - INFO - joeynmt.training - Example #1
2025-05-27 19:44:24,569 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:44:24,569 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:44:24,569 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abb<unk> @ ast<unk> @ anza for<unk> @ te , la ver<unk> @ ità di questa con<unk> @ v<unk> @ in<unk> @ zione di questo problema , non è la d<unk> @ oc<unk> @ cia del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 19:44:24,569 - INFO - joeynmt.training - Example #2
2025-05-27 19:44:24,570 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:44:24,570 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:44:24,570 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ gu<unk> @ a è la c<unk> @ li<unk> @ mat<unk> @ ica è la c<unk> @ li<unk> @ mat<unk> @ ica del nostro c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:44:24,570 - INFO - joeynmt.training - Example #3
2025-05-27 19:44:24,571 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:44:24,571 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:44:24,571 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e in b<unk> @ att<unk> @ ag<unk> @ lia .
2025-05-27 19:44:24,571 - INFO - joeynmt.training - Example #4
2025-05-27 19:44:24,572 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:44:24,572 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:44:24,572 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i , vi mostr<unk> @ er<unk> @ ò è una delle con<unk> @ v<unk> @ in<unk> @ ta di una ser<unk> @ ie di c<unk> @ las<unk> @ se .
2025-05-27 19:44:27,974 - INFO - joeynmt.training - Epoch   5, Step:    38100, Batch Loss:     1.006528, Batch Acc: 0.703630, Tokens per Sec:    20032, Lr: 0.000300
2025-05-27 19:44:31,356 - INFO - joeynmt.training - Epoch   5, Step:    38200, Batch Loss:     1.104752, Batch Acc: 0.703352, Tokens per Sec:    23398, Lr: 0.000300
2025-05-27 19:44:34,710 - INFO - joeynmt.training - Epoch   5, Step:    38300, Batch Loss:     0.935929, Batch Acc: 0.704651, Tokens per Sec:    23473, Lr: 0.000300
2025-05-27 19:44:38,065 - INFO - joeynmt.training - Epoch   5, Step:    38400, Batch Loss:     0.931884, Batch Acc: 0.704325, Tokens per Sec:    23781, Lr: 0.000300
2025-05-27 19:44:41,379 - INFO - joeynmt.training - Epoch   5, Step:    38500, Batch Loss:     0.869940, Batch Acc: 0.707657, Tokens per Sec:    23604, Lr: 0.000300
2025-05-27 19:44:41,379 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:44:41,380 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 68.74it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 80.11it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 89.75it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 101.16it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 104.96it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 117.69it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 108.86it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 86.09it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:17, 44.12it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 48.49it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 58.16it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 83.56it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 92.15it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 80.31it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 63.75it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 70.16it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:13, 48.95it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:13, 47.21it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 47.24it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 49.50it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.40it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.86it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 67.00it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 68.35it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 73.23it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 86.64it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 87.47it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 87.75it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 91.58it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 96.69it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 91.76it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 87.13it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 73.39it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:07, 60.52it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:08, 47.04it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:07, 54.85it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 67.94it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 63.75it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:06, 54.65it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:06, 54.08it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:06, 52.23it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 62.10it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:07, 41.75it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 42.13it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 51.79it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 54.16it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 49.33it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:05, 47.24it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:06, 38.67it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 36.15it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:05, 42.20it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:06, 35.94it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 38.06it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 26.63it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:06, 35.75it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 34.64it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 42.06it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 53.75it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 42.48it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 46.07it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 56.75it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 61.12it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 72.79it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 81.16it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 88.15it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 66.79it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 49.63it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 63.43it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 69.90it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 84.17it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 61.51it/s]
2025-05-27 19:44:56,394 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.79, acc:   0.70, generation: 15.0056[sec], evaluation: 0.0000[sec]
2025-05-27 19:44:56,693 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/35000.ckpt
2025-05-27 19:44:56,716 - INFO - joeynmt.training - Example #0
2025-05-27 19:44:56,717 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:44:56,717 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:44:56,717 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due f<unk> @ ung<unk> @ hi per l&apos; anno , per cui l&apos; eff<unk> @ etto di c<unk> @ aus<unk> @ a che i g<unk> @ ar<unk> @ t<unk> @ ic<unk> @ chi<unk> @ a , per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 milioni di anni , per c<unk> @ ento di due mili<unk> @ ar<unk> @ di di anni .
2025-05-27 19:44:56,717 - INFO - joeynmt.training - Example #1
2025-05-27 19:44:56,718 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:44:56,718 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:44:56,718 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ mente la di<unk> @ men<unk> @ sione di questo problema , non è il d<unk> @ ott<unk> @ ore di questo problema .
2025-05-27 19:44:56,718 - INFO - joeynmt.training - Example #2
2025-05-27 19:44:56,719 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:44:56,719 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:44:56,719 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di sen<unk> @ so è la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a è la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a del nostro sistema glob<unk> @ ale .
2025-05-27 19:44:56,719 - INFO - joeynmt.training - Example #3
2025-05-27 19:44:56,720 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:44:56,720 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:44:56,720 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e la v<unk> @ ento .
2025-05-27 19:44:56,720 - INFO - joeynmt.training - Example #4
2025-05-27 19:44:56,721 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:44:56,721 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:44:56,721 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ u la pros<unk> @ si<unk> @ ma f<unk> @ u una ri<unk> @ ma<unk> @ zione che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:45:00,005 - INFO - joeynmt.training - Epoch   5, Step:    38600, Batch Loss:     1.148260, Batch Acc: 0.707450, Tokens per Sec:    21386, Lr: 0.000300
2025-05-27 19:45:03,355 - INFO - joeynmt.training - Epoch   5, Step:    38700, Batch Loss:     1.015639, Batch Acc: 0.704338, Tokens per Sec:    23687, Lr: 0.000300
2025-05-27 19:45:06,701 - INFO - joeynmt.training - Epoch   5, Step:    38800, Batch Loss:     1.010447, Batch Acc: 0.703564, Tokens per Sec:    23924, Lr: 0.000300
2025-05-27 19:45:10,039 - INFO - joeynmt.training - Epoch   5, Step:    38900, Batch Loss:     1.034839, Batch Acc: 0.706106, Tokens per Sec:    23627, Lr: 0.000300
2025-05-27 19:45:13,372 - INFO - joeynmt.training - Epoch   5, Step:    39000, Batch Loss:     1.021238, Batch Acc: 0.711367, Tokens per Sec:    23788, Lr: 0.000300
2025-05-27 19:45:13,372 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:45:13,372 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 63.79it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 72.94it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 78.31it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 88.71it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 90.38it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 101.93it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 105.98it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 84.89it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.84it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 54.50it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 64.78it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 89.41it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 99.15it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 83.36it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 73.84it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 76.10it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 57.87it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 51.30it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 52.17it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.62it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 56.08it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.39it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 61.50it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:10, 55.86it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:13, 43.46it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 52.98it/s]Predicting...:  41%|████      | 379/923 [00:05<00:08, 66.36it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:07, 73.89it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 78.74it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 81.73it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 91.07it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 92.56it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 98.04it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.77it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 95.85it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:04, 82.79it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 92.80it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:05, 63.75it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:06, 56.40it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 63.16it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:06, 50.53it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 48.44it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 56.69it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 56.36it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 52.26it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:05, 48.92it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 40.76it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:06, 38.25it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:05, 42.89it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 37.86it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 41.13it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 34.94it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:04, 45.84it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 45.50it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 51.48it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 63.95it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 49.13it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 57.73it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 64.36it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 74.28it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 82.82it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 87.15it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 70.54it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 67.45it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 81.37it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 91.51it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 125.00it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 66.37it/s] 
2025-05-27 19:45:27,289 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 13.9078[sec], evaluation: 0.0000[sec]
2025-05-27 19:45:27,289 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:45:27,732 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/36500.ckpt
2025-05-27 19:45:27,751 - INFO - joeynmt.training - Example #0
2025-05-27 19:45:27,752 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:45:27,752 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:45:27,752 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ ami<unk> @ gl<unk> @ ie per sc<unk> @ or<unk> @ r<unk> @ ere che i g<unk> @ over<unk> @ ni di g<unk> @ hi<unk> @ ac<unk> @ cio che gli in<unk> @ segn<unk> @ ano per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 per c<unk> @ ento di qu<unk> @ at<unk> @ tro m<unk> @ oti<unk> @ vi per il 4<unk> @ 0 % .
2025-05-27 19:45:27,752 - INFO - joeynmt.training - Example #1
2025-05-27 19:45:27,753 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:45:27,753 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:45:27,753 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ t<unk> @ eg<unk> @ r<unk> @ are la cap<unk> @ ac<unk> @ ità di ris<unk> @ ol<unk> @ vere questo problema , non è che la de<unk> @ fin<unk> @ ita del D<unk> @ ic<unk> @ one .
2025-05-27 19:45:27,753 - INFO - joeynmt.training - Example #2
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di s<unk> @ é , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ mo .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - Example #3
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:45:27,754 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e si sp<unk> @ ost<unk> @ ano in un peri<unk> @ o<unk> @ do .
2025-05-27 19:45:27,755 - INFO - joeynmt.training - Example #4
2025-05-27 19:45:27,755 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:45:27,755 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:45:27,755 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ av<unk> @ ore , che vi mostr<unk> @ er<unk> @ ò è una st<unk> @ anza di con<unk> @ v<unk> @ in<unk> @ zione che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:45:31,068 - INFO - joeynmt.training - Epoch   5, Step:    39100, Batch Loss:     0.973794, Batch Acc: 0.703697, Tokens per Sec:    21059, Lr: 0.000300
2025-05-27 19:45:34,411 - INFO - joeynmt.training - Epoch   5, Step:    39200, Batch Loss:     1.020282, Batch Acc: 0.704406, Tokens per Sec:    24182, Lr: 0.000300
2025-05-27 19:45:37,765 - INFO - joeynmt.training - Epoch   5, Step:    39300, Batch Loss:     0.906127, Batch Acc: 0.707566, Tokens per Sec:    24230, Lr: 0.000300
2025-05-27 19:45:40,288 - INFO - joeynmt.training - Epoch   5: total training loss 8075.49
2025-05-27 19:45:40,288 - INFO - joeynmt.training - EPOCH 6
2025-05-27 19:45:41,103 - INFO - joeynmt.training - Epoch   6, Step:    39400, Batch Loss:     0.915078, Batch Acc: 0.714096, Tokens per Sec:    25031, Lr: 0.000300
2025-05-27 19:45:44,441 - INFO - joeynmt.training - Epoch   6, Step:    39500, Batch Loss:     1.075939, Batch Acc: 0.713132, Tokens per Sec:    23049, Lr: 0.000300
2025-05-27 19:45:44,441 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:45:44,441 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 72.59it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.77it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 93.96it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 101.40it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 101.66it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 110.03it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 90.05it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 46.03it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 49.17it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 58.55it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 80.83it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 90.48it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.86it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 70.85it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 73.24it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 59.36it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 53.71it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 53.40it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.57it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 54.09it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.55it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.88it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 67.34it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 56.98it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 65.77it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 83.47it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 89.52it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 85.79it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 84.35it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 94.43it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 88.90it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 90.34it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 75.40it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 82.97it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 57.06it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 62.86it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 73.68it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 58.55it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 50.37it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 46.44it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 39.90it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 48.73it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 34.08it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 35.08it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.03it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 41.93it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 42.37it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 38.89it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 36.89it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:09, 28.14it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 26.90it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 31.31it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 28.45it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 32.02it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 28.69it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 38.38it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.83it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 44.42it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 55.87it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 41.40it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 41.73it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 48.51it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 55.06it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 67.56it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 82.40it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 85.53it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:00, 75.16it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 74.50it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 87.74it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 96.31it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 129.80it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.01it/s] 
2025-05-27 19:45:59,831 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 15.3809[sec], evaluation: 0.0000[sec]
2025-05-27 19:45:59,831 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:46:00,291 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/37000.ckpt
2025-05-27 19:46:00,315 - INFO - joeynmt.training - Example #0
2025-05-27 19:46:00,316 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:46:00,316 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ eg<unk> @ li ulti<unk> @ mi sono mostr<unk> @ ato per ri<unk> @ vel<unk> @ are i due o i p<unk> @ ezz<unk> @ i di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ali che gli u<unk> @ is<unk> @ c<unk> @ atori di g<unk> @ hi<unk> @ ac<unk> @ cio per i qual<unk> @ i aveva tre milioni di persone che aveva fatto per il 4<unk> @ 8 milioni di persone che aveva av<unk> @ uto il 4<unk> @ 0 % .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - Example #1
2025-05-27 19:46:00,317 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza della giu<unk> @ st<unk> @ izi<unk> @ a , perché non è il D<unk> @ ic<unk> @ olo del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 19:46:00,317 - INFO - joeynmt.training - Example #2
2025-05-27 19:46:00,318 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:46:00,318 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:46:00,318 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di sin<unk> @ g<unk> @ olo , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:46:00,318 - INFO - joeynmt.training - Example #3
2025-05-27 19:46:00,319 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:46:00,319 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:46:00,319 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ anno in v<unk> @ it<unk> @ tor<unk> @ no al v<unk> @ ento .
2025-05-27 19:46:00,319 - INFO - joeynmt.training - Example #4
2025-05-27 19:46:00,320 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:46:00,320 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:46:00,320 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ ra<unk> @ ff<unk> @ a , una c<unk> @ en<unk> @ a che è succ<unk> @ esso in qu<unk> @ ale succ<unk> @ essi<unk> @ vo .
2025-05-27 19:46:03,553 - INFO - joeynmt.training - Epoch   6, Step:    39600, Batch Loss:     0.956309, Batch Acc: 0.715008, Tokens per Sec:    21420, Lr: 0.000300
2025-05-27 19:46:06,806 - INFO - joeynmt.training - Epoch   6, Step:    39700, Batch Loss:     1.081409, Batch Acc: 0.714331, Tokens per Sec:    24310, Lr: 0.000300
2025-05-27 19:46:10,056 - INFO - joeynmt.training - Epoch   6, Step:    39800, Batch Loss:     0.977097, Batch Acc: 0.710388, Tokens per Sec:    24306, Lr: 0.000300
2025-05-27 19:46:13,304 - INFO - joeynmt.training - Epoch   6, Step:    39900, Batch Loss:     0.945780, Batch Acc: 0.716647, Tokens per Sec:    25225, Lr: 0.000300
2025-05-27 19:46:16,384 - INFO - joeynmt.training - Epoch   6, Step:    40000, Batch Loss:     0.970733, Batch Acc: 0.716024, Tokens per Sec:    25176, Lr: 0.000300
2025-05-27 19:46:16,384 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:46:16,385 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 66.07it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 91.95it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 109.57it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 89.52it/s] Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 109.01it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 93.03it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 52.22it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 57.55it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 67.25it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 72.62it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 82.48it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 76.34it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 71.77it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 81.47it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 63.87it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 62.86it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:10, 57.90it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 64.64it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 67.23it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 69.94it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 68.12it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 74.92it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 88.86it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 97.47it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 102.33it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 96.15it/s] Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 107.77it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 107.14it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 106.78it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 98.05it/s] Predicting...:  56%|█████▌    | 517/923 [00:06<00:06, 63.43it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:05, 71.45it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 53.88it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 48.66it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 45.48it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 44.28it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 43.97it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 45.04it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 52.71it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 51.26it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 48.26it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 43.28it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 35.30it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 34.21it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 39.04it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:10, 23.19it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:08, 27.54it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 25.84it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:06, 35.19it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.18it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 44.35it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 55.16it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 46.28it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 45.68it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 58.94it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 67.83it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 70.96it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 82.15it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 84.62it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 56.72it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 57.75it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 70.43it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 78.42it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 92.60it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 62.79it/s]
2025-05-27 19:46:31,099 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.77, acc:   0.71, generation: 14.7009[sec], evaluation: 0.0000[sec]
2025-05-27 19:46:31,100 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:46:31,591 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/37500.ckpt
2025-05-27 19:46:31,615 - INFO - joeynmt.training - Example #0
2025-05-27 19:46:31,616 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:46:31,616 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:46:31,616 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno questi due di<unk> @ f<unk> @ en<unk> @ om<unk> @ en<unk> @ i che la p<unk> @ op<unk> @ ol<unk> @ azione per la sc<unk> @ ar<unk> @ t<unk> @ ica che la chiam<unk> @ ata E<unk> @ is<unk> @ c<unk> @ app<unk> @ e che ha av<unk> @ uto i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 , il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 19:46:31,616 - INFO - joeynmt.training - Example #1
2025-05-27 19:46:31,617 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:46:31,617 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:46:31,617 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza in<unk> @ t<unk> @ eg<unk> @ r<unk> @ ità di questi probl<unk> @ emi spe<unk> @ ci<unk> @ ali spe<unk> @ ci<unk> @ almente il problema di E<unk> @ is<unk> @ es .
2025-05-27 19:46:31,617 - INFO - joeynmt.training - Example #2
2025-05-27 19:46:31,618 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:46:31,618 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:46:31,618 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di s<unk> @ é , la c<unk> @ las<unk> @ se è la c<unk> @ las<unk> @ se è la c<unk> @ aus<unk> @ a del nostro sistema glob<unk> @ ale .
2025-05-27 19:46:31,618 - INFO - joeynmt.training - Example #3
2025-05-27 19:46:31,619 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:46:31,619 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:46:31,619 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e sp<unk> @ esso .
2025-05-27 19:46:31,619 - INFO - joeynmt.training - Example #4
2025-05-27 19:46:31,620 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:46:31,620 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:46:31,620 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ ero che vi mostr<unk> @ o è una ser<unk> @ ie di di<unk> @ f<unk> @ lu<unk> @ enza che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:46:34,796 - INFO - joeynmt.training - Epoch   6, Step:    40100, Batch Loss:     0.975426, Batch Acc: 0.708260, Tokens per Sec:    20766, Lr: 0.000300
2025-05-27 19:46:37,982 - INFO - joeynmt.training - Epoch   6, Step:    40200, Batch Loss:     0.932832, Batch Acc: 0.714145, Tokens per Sec:    25258, Lr: 0.000300
2025-05-27 19:46:41,161 - INFO - joeynmt.training - Epoch   6, Step:    40300, Batch Loss:     0.993497, Batch Acc: 0.711992, Tokens per Sec:    24225, Lr: 0.000300
2025-05-27 19:46:44,357 - INFO - joeynmt.training - Epoch   6, Step:    40400, Batch Loss:     0.946739, Batch Acc: 0.712467, Tokens per Sec:    25156, Lr: 0.000300
2025-05-27 19:46:47,541 - INFO - joeynmt.training - Epoch   6, Step:    40500, Batch Loss:     0.920450, Batch Acc: 0.710537, Tokens per Sec:    24728, Lr: 0.000300
2025-05-27 19:46:47,542 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:46:47,542 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 67.96it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 84.06it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 91.22it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 100.23it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 109.30it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 122.31it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 108.62it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 51.54it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 54.80it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 63.60it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 88.78it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 97.27it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 79.14it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 64.36it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 69.20it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 55.44it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 53.99it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 53.90it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:16, 38.59it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:14, 43.97it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:12, 50.18it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 54.38it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 61.28it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.19it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 66.89it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 82.69it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 87.88it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 89.49it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 96.27it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 105.41it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 95.07it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 98.02it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 84.90it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 87.85it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.86it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 80.34it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 52.29it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 47.19it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 39.35it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.04it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.81it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 38.15it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.82it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 45.79it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 44.33it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.88it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.67it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.78it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 31.22it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.54it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 32.55it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.55it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 26.90it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 34.03it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 30.22it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 36.07it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 46.14it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 40.84it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.34it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 43.29it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 48.21it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 56.93it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 68.89it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 73.19it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 60.46it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 58.06it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 80.32it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 103.86it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.82it/s] 
2025-05-27 19:47:03,242 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.71, generation: 15.6912[sec], evaluation: 0.0000[sec]
2025-05-27 19:47:03,670 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/38500.ckpt
2025-05-27 19:47:03,692 - INFO - joeynmt.training - Example #0
2025-05-27 19:47:03,693 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:47:03,694 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:47:03,694 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questa due f<unk> @ anno per fare la f<unk> @ am<unk> @ ig<unk> @ lia per la f<unk> @ am<unk> @ ig<unk> @ lia per i g<unk> @ ri<unk> @ g<unk> @ etti , che aveva tre milioni di anni , per i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io , per i 4<unk> @ 8 anni , per 4<unk> @ 8 , per c<unk> @ ento , per 4<unk> @ 8 anni .
2025-05-27 19:47:03,694 - INFO - joeynmt.training - Example #1
2025-05-27 19:47:03,694 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:47:03,694 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:47:03,695 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la di<unk> @ st<unk> @ ha<unk> @ i questo problema spe<unk> @ ci<unk> @ ale , non è il d<unk> @ ato di questo problema .
2025-05-27 19:47:03,695 - INFO - joeynmt.training - Example #2
2025-05-27 19:47:03,696 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:47:03,696 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:47:03,696 - INFO - joeynmt.training - 	Hypothesis: In sen<unk> @ so , la cosa più in<unk> @ ten<unk> @ zione è la c<unk> @ li<unk> @ sta del sistema di c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma è il cu<unk> @ ore del nostro sistema di c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma .
2025-05-27 19:47:03,696 - INFO - joeynmt.training - Example #3
2025-05-27 19:47:03,696 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un inter<unk> @ no e si trov<unk> @ a in est<unk> @ ate .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - Example #4
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:47:03,697 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ anno la mia prima f<unk> @ est<unk> @ a , è una c<unk> @ ura che vi mostr<unk> @ o è una ser<unk> @ ie di ri<unk> @ g<unk> @ am<unk> @ be , che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:47:06,905 - INFO - joeynmt.training - Epoch   6, Step:    40600, Batch Loss:     0.923593, Batch Acc: 0.714932, Tokens per Sec:    22023, Lr: 0.000300
2025-05-27 19:47:10,198 - INFO - joeynmt.training - Epoch   6, Step:    40700, Batch Loss:     0.939308, Batch Acc: 0.711349, Tokens per Sec:    24566, Lr: 0.000300
2025-05-27 19:47:13,516 - INFO - joeynmt.training - Epoch   6, Step:    40800, Batch Loss:     0.911384, Batch Acc: 0.708633, Tokens per Sec:    23838, Lr: 0.000300
2025-05-27 19:47:16,851 - INFO - joeynmt.training - Epoch   6, Step:    40900, Batch Loss:     0.913877, Batch Acc: 0.713175, Tokens per Sec:    24466, Lr: 0.000300
2025-05-27 19:47:20,154 - INFO - joeynmt.training - Epoch   6, Step:    41000, Batch Loss:     0.982886, Batch Acc: 0.711012, Tokens per Sec:    23576, Lr: 0.000300
2025-05-27 19:47:20,154 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:47:20,154 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 68.97it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 85.02it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 89.25it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 92.37it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 104.91it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 114.16it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 113.55it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 88.18it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:19, 40.05it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:17, 45.23it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 54.04it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 76.36it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 80.02it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 67.82it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:12, 53.84it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:11, 56.26it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:13, 47.83it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 47.19it/s]Predicting...:  30%|███       | 277/923 [00:04<00:14, 46.00it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 45.09it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 51.48it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 53.73it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 58.64it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 56.18it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 49.40it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 59.20it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 76.27it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 82.91it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 87.65it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 93.49it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 102.03it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 96.89it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 100.85it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:04, 90.46it/s] Predicting...:  54%|█████▎    | 494/923 [00:07<00:04, 97.04it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:07, 57.81it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 67.54it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 50.41it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 48.30it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 45.42it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:06, 49.78it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 36.11it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 35.25it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 35.17it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 43.62it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.43it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.75it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:06, 39.66it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 30.74it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 29.83it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 33.82it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 28.76it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 31.91it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:09, 24.60it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 31.39it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 32.18it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 39.18it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 49.07it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 38.86it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:03, 41.16it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 55.07it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 57.83it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 62.56it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 69.76it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 69.97it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 45.43it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 55.37it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 56.75it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 69.16it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 74.41it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 89.77it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.21it/s]
2025-05-27 19:47:36,589 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.78, acc:   0.70, generation: 16.4217[sec], evaluation: 0.0000[sec]
2025-05-27 19:47:36,936 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/38000.ckpt
2025-05-27 19:47:36,962 - INFO - joeynmt.training - Example #0
2025-05-27 19:47:36,964 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:47:36,964 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:47:36,964 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ att<unk> @ or<unk> @ ie per s<unk> @ ent<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio per la qu<unk> @ ale di m<unk> @ oti<unk> @ vo per cui aveva tre milioni di anni , per la rag<unk> @ ione per cui aveva 1<unk> @ 3 milioni di anni , per cui aveva 4<unk> @ 0 , aveva tre milioni di anni , per c<unk> @ ento per c<unk> @ ento , per c<unk> @ ento .
2025-05-27 19:47:36,964 - INFO - joeynmt.training - Example #1
2025-05-27 19:47:36,965 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:47:36,965 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:47:36,965 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la ver<unk> @ ità non è abb<unk> @ ast<unk> @ anza , perché non è il d<unk> @ ato di questo problema , non è il d<unk> @ ic<unk> @ lo .
2025-05-27 19:47:36,965 - INFO - joeynmt.training - Example #2
2025-05-27 19:47:36,966 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:47:36,966 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:47:36,966 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ ea è la c<unk> @ atti<unk> @ va em<unk> @ er<unk> @ gen<unk> @ za , il nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 19:47:36,967 - INFO - joeynmt.training - Example #3
2025-05-27 19:47:36,967 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:47:36,967 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:47:36,967 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e p<unk> @ es<unk> @ o in est<unk> @ ate .
2025-05-27 19:47:36,967 - INFO - joeynmt.training - Example #4
2025-05-27 19:47:36,968 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:47:36,968 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:47:36,968 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ er<unk> @ ò è una lin<unk> @ ea di ri<unk> @ vi<unk> @ sta che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:47:40,314 - INFO - joeynmt.training - Epoch   6, Step:    41100, Batch Loss:     0.973762, Batch Acc: 0.708386, Tokens per Sec:    21105, Lr: 0.000300
2025-05-27 19:47:43,620 - INFO - joeynmt.training - Epoch   6, Step:    41200, Batch Loss:     1.102358, Batch Acc: 0.715113, Tokens per Sec:    23920, Lr: 0.000300
2025-05-27 19:47:46,923 - INFO - joeynmt.training - Epoch   6, Step:    41300, Batch Loss:     0.992423, Batch Acc: 0.713868, Tokens per Sec:    23942, Lr: 0.000300
2025-05-27 19:47:50,224 - INFO - joeynmt.training - Epoch   6, Step:    41400, Batch Loss:     1.018340, Batch Acc: 0.710152, Tokens per Sec:    23339, Lr: 0.000300
2025-05-27 19:47:53,556 - INFO - joeynmt.training - Epoch   6, Step:    41500, Batch Loss:     0.889909, Batch Acc: 0.708863, Tokens per Sec:    24323, Lr: 0.000300
2025-05-27 19:47:53,556 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:47:53,556 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 72.38it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 78.29it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 88.69it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 97.05it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 104.44it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 118.22it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 115.04it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:10, 79.27it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 63.38it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:10, 70.92it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 93.13it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 99.86it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 85.81it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 76.71it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:08, 76.96it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:10, 61.48it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 58.26it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 53.25it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:12, 49.53it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.78it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.57it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.80it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 60.61it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:08, 67.82it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.82it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 82.19it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 81.99it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:06, 78.86it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 86.23it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 85.27it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 81.76it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 75.68it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 79.08it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 64.27it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 68.96it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 78.98it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 59.48it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 48.50it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 45.45it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 42.60it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 51.50it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.20it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 36.85it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 38.25it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.63it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 44.68it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:07, 38.66it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 35.20it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:09, 29.52it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:09, 28.49it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 32.47it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.69it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 33.17it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 28.11it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 35.96it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 32.89it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 40.23it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 50.08it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.20it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.42it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 50.17it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 54.32it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:02, 57.98it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 69.79it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 75.79it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 63.34it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.81it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 76.36it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 79.32it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 90.79it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.36it/s]
2025-05-27 19:48:08,860 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.77, acc:   0.71, generation: 15.2914[sec], evaluation: 0.0000[sec]
2025-05-27 19:48:09,334 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/41000.ckpt
2025-05-27 19:48:09,357 - INFO - joeynmt.training - Example #0
2025-05-27 19:48:09,358 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:48:09,359 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:48:09,359 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose , per cui è stato in<unk> @ segn<unk> @ ato per ri<unk> @ dur<unk> @ re il fatto che il g<unk> @ hi<unk> @ ac<unk> @ cio , che il p<unk> @ es<unk> @ c<unk> @ ano per i 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per 4<unk> @ 8 % , per c<unk> @ ento , 4<unk> @ 0 % , per c<unk> @ ento , il 4<unk> @ 0 % di c<unk> @ ento .
2025-05-27 19:48:09,359 - INFO - joeynmt.training - Example #1
2025-05-27 19:48:09,360 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:48:09,360 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:48:09,360 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza di in<unk> @ f<unk> @ lu<unk> @ enza , il problema di E<unk> @ is<unk> @ c<unk> @ ito non è il D<unk> @ ic<unk> @ e<unk> @ qu<unk> @ i<unk> @ v<unk> @ ale non è il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:48:09,360 - INFO - joeynmt.training - Example #2
2025-05-27 19:48:09,361 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:48:09,361 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:48:09,361 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ ea in<unk> @ ten<unk> @ zione di ci<unk> @ b<unk> @ o , il cu<unk> @ ore glob<unk> @ ale è il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:48:09,361 - INFO - joeynmt.training - Example #3
2025-05-27 19:48:09,361 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un po &apos; di p<unk> @ oco di v<unk> @ in<unk> @ ver<unk> @ no .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - Example #4
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:48:09,362 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una ser<unk> @ ie di sc<unk> @ or<unk> @ so che è succ<unk> @ esso in un cer<unk> @ to di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:48:12,718 - INFO - joeynmt.training - Epoch   6, Step:    41600, Batch Loss:     0.920644, Batch Acc: 0.712992, Tokens per Sec:    21069, Lr: 0.000300
2025-05-27 19:48:16,051 - INFO - joeynmt.training - Epoch   6, Step:    41700, Batch Loss:     0.904138, Batch Acc: 0.709555, Tokens per Sec:    23500, Lr: 0.000300
2025-05-27 19:48:19,380 - INFO - joeynmt.training - Epoch   6, Step:    41800, Batch Loss:     0.982042, Batch Acc: 0.709775, Tokens per Sec:    24247, Lr: 0.000300
2025-05-27 19:48:22,712 - INFO - joeynmt.training - Epoch   6, Step:    41900, Batch Loss:     0.961464, Batch Acc: 0.711346, Tokens per Sec:    23931, Lr: 0.000300
2025-05-27 19:48:26,040 - INFO - joeynmt.training - Epoch   6, Step:    42000, Batch Loss:     1.056597, Batch Acc: 0.715668, Tokens per Sec:    23975, Lr: 0.000300
2025-05-27 19:48:26,041 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:48:26,041 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 76.09it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 94.76it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 103.32it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 95.80it/s] Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.77it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 113.38it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 123.87it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:13, 56.98it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 61.30it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 57.14it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 79.12it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 88.09it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 83.93it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 63.15it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 68.24it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 53.80it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 53.31it/s]Predicting...:  30%|███       | 277/923 [00:03<00:13, 49.52it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.24it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 59.85it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 66.44it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 75.23it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 72.40it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 83.34it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 95.52it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 99.88it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 101.35it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 101.15it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 109.00it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 108.03it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 111.63it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:03, 112.64it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 84.76it/s] Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 90.39it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 58.71it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 48.72it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 53.87it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 38.66it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:08, 38.98it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 44.19it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 44.12it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 40.92it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:07, 38.19it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 34.04it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 32.74it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 35.42it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 32.56it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 36.02it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 33.15it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 40.84it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 38.53it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 45.65it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 53.47it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 42.19it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 42.59it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 53.79it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 60.49it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 71.45it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 82.54it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 80.11it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 64.19it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.00it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 75.68it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 80.54it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 94.83it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 63.79it/s]
2025-05-27 19:48:40,525 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.77, acc:   0.71, generation: 14.4710[sec], evaluation: 0.0000[sec]
2025-05-27 19:48:40,526 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:48:41,035 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/40500.ckpt
2025-05-27 19:48:41,060 - INFO - joeynmt.training - Example #0
2025-05-27 19:48:41,062 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:48:41,062 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:48:41,062 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due sono entr<unk> @ amb<unk> @ i per ri<unk> @ fer<unk> @ im<unk> @ enti che gli ar<unk> @ t<unk> @ t<unk> @ ici che gli ar<unk> @ t<unk> @ t<unk> @ ici che gli an<unk> @ ti<unk> @ chi di qu<unk> @ elli che hanno sc<unk> @ oper<unk> @ to per il 4<unk> @ 8 ore del 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 19:48:41,062 - INFO - joeynmt.training - Example #1
2025-05-27 19:48:41,063 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:48:41,063 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:48:41,063 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ cre<unk> @ di<unk> @ bile la di<unk> @ st<unk> @ azione di questo spe<unk> @ ci<unk> @ f<unk> @ ico non è il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 19:48:41,063 - INFO - joeynmt.training - Example #2
2025-05-27 19:48:41,064 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:48:41,064 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:48:41,064 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa in<unk> @ ten<unk> @ zione è la str<unk> @ utt<unk> @ ura del sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a del nostro sistema glob<unk> @ ale .
2025-05-27 19:48:41,064 - INFO - joeynmt.training - Example #3
2025-05-27 19:48:41,065 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:48:41,065 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:48:41,065 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e p<unk> @ oco , e sp<unk> @ esso , il v<unk> @ ento .
2025-05-27 19:48:41,065 - INFO - joeynmt.training - Example #4
2025-05-27 19:48:41,065 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:48:41,066 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:48:41,066 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una c<unk> @ en<unk> @ a che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:48:44,433 - INFO - joeynmt.training - Epoch   6, Step:    42100, Batch Loss:     0.988765, Batch Acc: 0.711307, Tokens per Sec:    20686, Lr: 0.000300
2025-05-27 19:48:47,774 - INFO - joeynmt.training - Epoch   6, Step:    42200, Batch Loss:     1.002575, Batch Acc: 0.711778, Tokens per Sec:    24188, Lr: 0.000300
2025-05-27 19:48:51,113 - INFO - joeynmt.training - Epoch   6, Step:    42300, Batch Loss:     0.840640, Batch Acc: 0.711487, Tokens per Sec:    24413, Lr: 0.000300
2025-05-27 19:48:54,424 - INFO - joeynmt.training - Epoch   6, Step:    42400, Batch Loss:     1.033729, Batch Acc: 0.711376, Tokens per Sec:    23645, Lr: 0.000300
2025-05-27 19:48:57,742 - INFO - joeynmt.training - Epoch   6, Step:    42500, Batch Loss:     0.964622, Batch Acc: 0.710679, Tokens per Sec:    23429, Lr: 0.000300
2025-05-27 19:48:57,743 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:48:57,743 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 81.90it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 100.29it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 104.89it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 110.94it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 113.66it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 128.45it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 130.69it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:13, 59.27it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 65.50it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:10, 72.03it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 111.05it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 96.46it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 86.11it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:08, 76.13it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 70.00it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 61.51it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 63.87it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:09, 66.33it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 75.96it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 70.76it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 80.53it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 95.94it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 101.62it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:05, 94.32it/s] Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 106.17it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 108.58it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 113.04it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 101.89it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:06, 66.95it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:05, 65.56it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 53.47it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 50.29it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 56.41it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 40.92it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 40.13it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 46.77it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:06, 46.83it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 43.62it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 39.92it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:08, 32.48it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:08, 31.40it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.05it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 34.60it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 36.56it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:07, 29.88it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 38.95it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 37.48it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 42.05it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 50.27it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 40.81it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 42.55it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 52.99it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 59.46it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 69.14it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 81.29it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 79.41it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 61.06it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 63.20it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 76.40it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 83.95it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 98.52it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 65.63it/s]
2025-05-27 19:49:11,815 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 14.0638[sec], evaluation: 0.0000[sec]
2025-05-27 19:49:11,815 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:49:12,281 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/39000.ckpt
2025-05-27 19:49:12,297 - INFO - joeynmt.training - Example #0
2025-05-27 19:49:12,299 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:49:12,299 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:49:12,299 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i , per cerc<unk> @ are di con<unk> @ to che le cose f<unk> @ ami<unk> @ gl<unk> @ ie c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are i 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per il 4<unk> @ 0 % .
2025-05-27 19:49:12,299 - INFO - joeynmt.training - Example #1
2025-05-27 19:49:12,300 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:49:12,300 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:49:12,300 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza di tutto il ris<unk> @ ult<unk> @ ato di questo problema , perché non è la de<unk> @ fin<unk> @ i<unk> @ zione dell&apos; E<unk> @ is<unk> @ es .
2025-05-27 19:49:12,300 - INFO - joeynmt.training - Example #2
2025-05-27 19:49:12,301 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:49:12,301 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:49:12,301 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più grande in<unk> @ ten<unk> @ zione è la c<unk> @ li<unk> @ sta del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a del nostro sistema glob<unk> @ ale .
2025-05-27 19:49:12,301 - INFO - joeynmt.training - Example #3
2025-05-27 19:49:12,302 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:49:12,302 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:49:12,302 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un v<unk> @ ento e la v<unk> @ ento .
2025-05-27 19:49:12,302 - INFO - joeynmt.training - Example #4
2025-05-27 19:49:12,303 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:49:12,303 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:49:12,303 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa vi mostr<unk> @ er<unk> @ ò è una c<unk> @ aus<unk> @ a di cosa è succ<unk> @ esso in qu<unk> @ ale è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:49:15,670 - INFO - joeynmt.training - Epoch   6, Step:    42600, Batch Loss:     1.018079, Batch Acc: 0.712480, Tokens per Sec:    20769, Lr: 0.000300
2025-05-27 19:49:19,036 - INFO - joeynmt.training - Epoch   6, Step:    42700, Batch Loss:     0.987539, Batch Acc: 0.712018, Tokens per Sec:    24069, Lr: 0.000300
2025-05-27 19:49:22,381 - INFO - joeynmt.training - Epoch   6, Step:    42800, Batch Loss:     0.902094, Batch Acc: 0.712251, Tokens per Sec:    23621, Lr: 0.000300
2025-05-27 19:49:25,708 - INFO - joeynmt.training - Epoch   6, Step:    42900, Batch Loss:     1.018026, Batch Acc: 0.712610, Tokens per Sec:    23474, Lr: 0.000300
2025-05-27 19:49:29,064 - INFO - joeynmt.training - Epoch   6, Step:    43000, Batch Loss:     0.835032, Batch Acc: 0.713454, Tokens per Sec:    23794, Lr: 0.000300
2025-05-27 19:49:29,064 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:49:29,065 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:16, 54.15it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 72.22it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:11, 75.48it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 86.66it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 97.68it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 111.66it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 110.02it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 120.99it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 43.05it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 48.40it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 48.97it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 69.81it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 80.65it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:08, 78.94it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 69.96it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 75.25it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 56.11it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 52.73it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 52.39it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 48.67it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.09it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 60.53it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 66.99it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 70.27it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 76.02it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 91.76it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 95.17it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 98.31it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 100.69it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 111.86it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 101.88it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 96.81it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 92.21it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 92.90it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 67.92it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 72.77it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 58.17it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:06, 53.94it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 58.16it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 45.35it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 46.46it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 43.99it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 53.08it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 50.16it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 47.81it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 45.26it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 37.02it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 37.40it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:05, 42.06it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 35.69it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 40.35it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 31.86it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 41.86it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 39.95it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 44.91it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 55.04it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 46.04it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 48.08it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 58.31it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 65.55it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 74.65it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 81.77it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 80.33it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 66.66it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 67.04it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 75.58it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 84.25it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 115.20it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 64.78it/s] 
2025-05-27 19:49:43,321 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 14.2478[sec], evaluation: 0.0000[sec]
2025-05-27 19:49:43,321 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:49:43,790 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/39500.ckpt
2025-05-27 19:49:43,813 - INFO - joeynmt.training - Example #0
2025-05-27 19:49:43,814 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:49:43,814 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:49:43,814 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due due cas<unk> @ e , per arriv<unk> @ are a fare due cas<unk> @ e di pr<unk> @ on<unk> @ ti che i g<unk> @ am<unk> @ be le cose che hanno fatto per il 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , per i 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , per c<unk> @ ento , per il 4<unk> @ 8 % di qu<unk> @ 4<unk> @ 8 % di qu<unk> @ 4<unk> @ 8 % .
2025-05-27 19:49:43,814 - INFO - joeynmt.training - Example #1
2025-05-27 19:49:43,815 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:49:43,815 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:49:43,815 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza , perché non è abb<unk> @ ast<unk> @ anza in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ ità di probl<unk> @ emi , perché non è il d<unk> @ ott<unk> @ ore di E<unk> @ is<unk> @ s<unk> @ ore .
2025-05-27 19:49:43,815 - INFO - joeynmt.training - Example #2
2025-05-27 19:49:43,816 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:49:43,816 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:49:43,816 - INFO - joeynmt.training - 	Hypothesis: In un sen<unk> @ so , è la cosa in<unk> @ ten<unk> @ da è la di<unk> @ st<unk> @ anza di un sistema di ris<unk> @ chio di c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 19:49:43,816 - INFO - joeynmt.training - Example #3
2025-05-27 19:49:43,817 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:49:43,817 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:49:43,817 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e la v<unk> @ in<unk> @ am<unk> @ a .
2025-05-27 19:49:43,817 - INFO - joeynmt.training - Example #4
2025-05-27 19:49:43,818 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:49:43,818 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:49:43,818 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ am<unk> @ ma , è una sc<unk> @ rit<unk> @ ta che vi mostr<unk> @ er<unk> @ ò cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:49:47,083 - INFO - joeynmt.training - Epoch   6, Step:    43100, Batch Loss:     0.994172, Batch Acc: 0.714079, Tokens per Sec:    20393, Lr: 0.000300
2025-05-27 19:49:50,415 - INFO - joeynmt.training - Epoch   6, Step:    43200, Batch Loss:     0.866510, Batch Acc: 0.715704, Tokens per Sec:    23260, Lr: 0.000300
2025-05-27 19:49:53,739 - INFO - joeynmt.training - Epoch   6, Step:    43300, Batch Loss:     0.922122, Batch Acc: 0.712647, Tokens per Sec:    23251, Lr: 0.000300
2025-05-27 19:49:57,071 - INFO - joeynmt.training - Epoch   6, Step:    43400, Batch Loss:     0.981141, Batch Acc: 0.714273, Tokens per Sec:    24058, Lr: 0.000300
2025-05-27 19:50:00,434 - INFO - joeynmt.training - Epoch   6, Step:    43500, Batch Loss:     1.012473, Batch Acc: 0.712238, Tokens per Sec:    23826, Lr: 0.000300
2025-05-27 19:50:00,434 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:50:00,434 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 62.35it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 82.01it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.46it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 101.57it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.38it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:07, 107.47it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 106.78it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 85.16it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.83it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 54.91it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 52.73it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 78.62it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 86.36it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 77.20it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 79.81it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 81.60it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 57.21it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 56.56it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.48it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 54.85it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.06it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 62.00it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 67.89it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 55.56it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 63.77it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 82.12it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 91.17it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 88.14it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 83.75it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 78.95it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 79.41it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 83.82it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 77.40it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 80.80it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 61.41it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.74it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 78.12it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 57.48it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 49.98it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 47.92it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 44.10it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 52.00it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 37.15it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.93it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.27it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 45.88it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.37it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.99it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 36.99it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.88it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 32.72it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.43it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 30.75it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 33.01it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 31.33it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 39.88it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.40it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 45.71it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 54.64it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:03, 45.06it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 45.82it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 53.37it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 55.75it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 66.75it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 77.19it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 80.86it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 66.03it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 61.12it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 73.80it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 80.12it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 109.01it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 61.00it/s] 
2025-05-27 19:50:15,580 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 15.1324[sec], evaluation: 0.0000[sec]
2025-05-27 19:50:15,580 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:50:16,190 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/41500.ckpt
2025-05-27 19:50:16,213 - INFO - joeynmt.training - Example #0
2025-05-27 19:50:16,214 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:50:16,214 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:50:16,214 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due due cas<unk> @ i , per f<unk> @ ar s<unk> @ ì che le c<unk> @ ure po<unk> @ ver<unk> @ i , che i c<unk> @ aus<unk> @ ano i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 % del 4<unk> @ 8 % delle 4<unk> @ 8 % .
2025-05-27 19:50:16,214 - INFO - joeynmt.training - Example #1
2025-05-27 19:50:16,215 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:50:16,215 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:50:16,216 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza , non è abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questi probl<unk> @ emi spe<unk> @ ci<unk> @ ali , perché non mostr<unk> @ a il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 19:50:16,216 - INFO - joeynmt.training - Example #2
2025-05-27 19:50:16,216 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ ea in<unk> @ ten<unk> @ zione è la ci<unk> @ ma alla nostra c<unk> @ li<unk> @ sta del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - Example #3
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e sp<unk> @ esso .
2025-05-27 19:50:16,217 - INFO - joeynmt.training - Example #4
2025-05-27 19:50:16,218 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:50:16,218 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:50:16,218 - INFO - joeynmt.training - 	Hypothesis: La prima cosa che vi mostr<unk> @ o è che vi mostr<unk> @ er<unk> @ ò è una ser<unk> @ ie di due anni .
2025-05-27 19:50:19,573 - INFO - joeynmt.training - Epoch   6, Step:    43600, Batch Loss:     1.034857, Batch Acc: 0.710115, Tokens per Sec:    19767, Lr: 0.000300
2025-05-27 19:50:22,884 - INFO - joeynmt.training - Epoch   6, Step:    43700, Batch Loss:     1.062245, Batch Acc: 0.716441, Tokens per Sec:    23086, Lr: 0.000300
2025-05-27 19:50:26,212 - INFO - joeynmt.training - Epoch   6, Step:    43800, Batch Loss:     0.877512, Batch Acc: 0.710551, Tokens per Sec:    23752, Lr: 0.000300
2025-05-27 19:50:29,567 - INFO - joeynmt.training - Epoch   6, Step:    43900, Batch Loss:     0.945952, Batch Acc: 0.709442, Tokens per Sec:    24175, Lr: 0.000300
2025-05-27 19:50:32,908 - INFO - joeynmt.training - Epoch   6, Step:    44000, Batch Loss:     1.130818, Batch Acc: 0.707058, Tokens per Sec:    23228, Lr: 0.000300
2025-05-27 19:50:32,908 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:50:32,908 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:16, 56.19it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.00it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.76it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 101.06it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 115.55it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 134.34it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 107.75it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:12, 60.82it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 66.76it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:09, 76.52it/s]Predicting...:  20%|██        | 185/923 [00:02<00:06, 105.79it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 116.67it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 94.61it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 89.83it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:09, 69.12it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 65.58it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 61.46it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 68.15it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 73.50it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 76.01it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 71.91it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 61.81it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 71.94it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 92.35it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 98.91it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:05, 87.29it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 90.39it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 101.39it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 98.70it/s] Predicting...:  51%|█████     | 469/923 [00:05<00:04, 105.84it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 91.23it/s] Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 82.86it/s]Predicting...:  59%|█████▊    | 540/923 [00:06<00:05, 75.67it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 43.76it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:08, 42.20it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:08, 41.31it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 37.00it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 39.31it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 39.87it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 49.65it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 52.36it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 47.72it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:07, 39.15it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 34.04it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 34.87it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 41.06it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 36.31it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 36.70it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 29.39it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 39.70it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 37.92it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 47.15it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 58.35it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 46.16it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 57.75it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 62.63it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 74.17it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 84.03it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 86.58it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 66.81it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 68.97it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 88.10it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 96.48it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 66.15it/s]
2025-05-27 19:50:46,871 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.75, acc:   0.71, generation: 13.9539[sec], evaluation: 0.0000[sec]
2025-05-27 19:50:47,181 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/40000.ckpt
2025-05-27 19:50:47,204 - INFO - joeynmt.training - Example #0
2025-05-27 19:50:47,205 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:50:47,205 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:50:47,205 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per ri<unk> @ vel<unk> @ are il 4<unk> @ 0 % di c<unk> @ att<unk> @ ic<unk> @ amente che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono i b<unk> @ att<unk> @ ag<unk> @ gi , che ha fatto per il 4<unk> @ 0 % .
2025-05-27 19:50:47,205 - INFO - joeynmt.training - Example #1
2025-05-27 19:50:47,206 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:50:47,206 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:50:47,206 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza di questa part<unk> @ icol<unk> @ are , perché non è il D<unk> @ ic<unk> @ e<unk> @ da non c&apos; è il D<unk> @ ic<unk> @ e<unk> @ E<unk> @ is<unk> @ is<unk> @ ce .
2025-05-27 19:50:47,206 - INFO - joeynmt.training - Example #2
2025-05-27 19:50:47,207 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:50:47,207 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:50:47,207 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il c<unk> @ li<unk> @ mat<unk> @ ico è il g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore glob<unk> @ ale del nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:50:47,207 - INFO - joeynmt.training - Example #3
2025-05-27 19:50:47,208 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:50:47,208 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:50:47,208 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una cosa , e sp<unk> @ esso .
2025-05-27 19:50:47,208 - INFO - joeynmt.training - Example #4
2025-05-27 19:50:47,209 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:50:47,209 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:50:47,209 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una ri<unk> @ chi<unk> @ est<unk> @ a che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:50:50,467 - INFO - joeynmt.training - Epoch   6, Step:    44100, Batch Loss:     1.047242, Batch Acc: 0.712157, Tokens per Sec:    22400, Lr: 0.000300
2025-05-27 19:50:53,728 - INFO - joeynmt.training - Epoch   6, Step:    44200, Batch Loss:     0.971652, Batch Acc: 0.708965, Tokens per Sec:    24304, Lr: 0.000300
2025-05-27 19:50:56,995 - INFO - joeynmt.training - Epoch   6, Step:    44300, Batch Loss:     1.073068, Batch Acc: 0.713844, Tokens per Sec:    23762, Lr: 0.000300
2025-05-27 19:51:00,277 - INFO - joeynmt.training - Epoch   6, Step:    44400, Batch Loss:     0.944246, Batch Acc: 0.714165, Tokens per Sec:    24156, Lr: 0.000300
2025-05-27 19:51:03,561 - INFO - joeynmt.training - Epoch   6, Step:    44500, Batch Loss:     1.057765, Batch Acc: 0.712576, Tokens per Sec:    22853, Lr: 0.000300
2025-05-27 19:51:03,561 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:51:03,561 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 69.24it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 84.27it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.86it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 96.20it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 98.41it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 110.56it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 122.67it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:13, 58.98it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 64.90it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:10, 74.73it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 101.73it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 109.95it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 91.03it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 85.35it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 60.80it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 55.22it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 53.15it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 58.95it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 62.73it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 64.02it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 63.40it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 71.08it/s]Predicting...:  41%|████      | 379/923 [00:04<00:06, 84.26it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 93.39it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 92.53it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 93.82it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 103.52it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 99.08it/s] Predicting...:  51%|█████     | 469/923 [00:05<00:04, 96.74it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 80.43it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 84.87it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 64.73it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 73.68it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 84.77it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 53.51it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 52.42it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:08, 44.31it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 52.57it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.54it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 39.03it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:08, 39.15it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 49.27it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 45.90it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 43.63it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 42.23it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 34.55it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 33.57it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.92it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 32.23it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 36.28it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 29.45it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 38.17it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 35.55it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 42.27it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 52.32it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 50.50it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 45.63it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 55.77it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 59.86it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 70.26it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 82.10it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 86.01it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 68.76it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 68.84it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 79.09it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 80.21it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 94.13it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 95.40it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 64.19it/s]
2025-05-27 19:51:17,953 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.74, acc:   0.71, generation: 14.3789[sec], evaluation: 0.0000[sec]
2025-05-27 19:51:17,953 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:51:18,472 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/42000.ckpt
2025-05-27 19:51:18,497 - INFO - joeynmt.training - Example #0
2025-05-27 19:51:18,499 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:51:18,499 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:51:18,499 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ eg<unk> @ li anni , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per in<unk> @ segn<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i con<unk> @ to che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati , per i cas<unk> @ i di tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di anni , che av<unk> @ evano fatto , il 4<unk> @ 8 % .
2025-05-27 19:51:18,499 - INFO - joeynmt.training - Example #1
2025-05-27 19:51:18,500 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:51:18,500 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:51:18,500 - INFO - joeynmt.training - 	Hypothesis: Ma non è molto più for<unk> @ te , non è molto la di<unk> @ st<unk> @ ica di questo problema , che non è la di<unk> @ mostr<unk> @ a di questo problema , non ci mostr<unk> @ a il problema .
2025-05-27 19:51:18,500 - INFO - joeynmt.training - Example #2
2025-05-27 19:51:18,501 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:51:18,501 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:51:18,501 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ i<unk> @ ché la g<unk> @ hi<unk> @ es<unk> @ c<unk> @ ente è la c<unk> @ li<unk> @ ente del nostro c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:51:18,501 - INFO - joeynmt.training - Example #3
2025-05-27 19:51:18,502 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:51:18,502 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:51:18,502 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta divent<unk> @ ando un p<unk> @ om<unk> @ o e si sp<unk> @ ost<unk> @ a .
2025-05-27 19:51:18,502 - INFO - joeynmt.training - Example #4
2025-05-27 19:51:18,503 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:51:18,503 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:51:18,503 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i di cosa sta per mostr<unk> @ are è una ser<unk> @ ie di cosa che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:51:21,824 - INFO - joeynmt.training - Epoch   6, Step:    44600, Batch Loss:     1.004138, Batch Acc: 0.711657, Tokens per Sec:    19404, Lr: 0.000300
2025-05-27 19:51:25,159 - INFO - joeynmt.training - Epoch   6, Step:    44700, Batch Loss:     1.027022, Batch Acc: 0.713241, Tokens per Sec:    23874, Lr: 0.000300
2025-05-27 19:51:28,483 - INFO - joeynmt.training - Epoch   6, Step:    44800, Batch Loss:     0.891977, Batch Acc: 0.712686, Tokens per Sec:    24444, Lr: 0.000300
2025-05-27 19:51:31,782 - INFO - joeynmt.training - Epoch   6, Step:    44900, Batch Loss:     0.940800, Batch Acc: 0.715694, Tokens per Sec:    23596, Lr: 0.000300
2025-05-27 19:51:35,098 - INFO - joeynmt.training - Epoch   6, Step:    45000, Batch Loss:     1.107118, Batch Acc: 0.710944, Tokens per Sec:    23768, Lr: 0.000300
2025-05-27 19:51:35,098 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:51:35,098 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 59.74it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 74.91it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 84.05it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 86.77it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 86.63it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 98.40it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 106.52it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 88.06it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 52.73it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 56.94it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 66.18it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 94.21it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 102.63it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 88.46it/s] Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 78.27it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 82.13it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.13it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 51.13it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 55.97it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 61.05it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.82it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 62.57it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 60.02it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 65.49it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.02it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 80.88it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 83.24it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 84.90it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 96.91it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 93.03it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 88.04it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 82.70it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 89.36it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 70.97it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 79.18it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 59.59it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 57.61it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 50.39it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 57.18it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 40.50it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 38.27it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 38.79it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.39it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 47.54it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 44.69it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 43.32it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 32.65it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 31.47it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 34.40it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 30.84it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.40it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 33.94it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:04, 43.93it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 42.85it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:03, 49.83it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 57.53it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 43.63it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 43.98it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 51.90it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 58.50it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 67.01it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 77.20it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 76.77it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 63.34it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.24it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 76.05it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 82.38it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 95.19it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 63.08it/s]
2025-05-27 19:51:49,744 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.74, acc:   0.71, generation: 14.6321[sec], evaluation: 0.0000[sec]
2025-05-27 19:51:49,744 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:51:50,282 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/44000.ckpt
2025-05-27 19:51:50,307 - INFO - joeynmt.training - Example #0
2025-05-27 19:51:50,308 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:51:50,308 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:51:50,308 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due cas<unk> @ i , per c<unk> @ ento di cui i g<unk> @ hi<unk> @ ac<unk> @ cio , per il g<unk> @ hi<unk> @ ac<unk> @ cio , per i g<unk> @ hi<unk> @ ac<unk> @ cio , per i prim<unk> @ i anni , il 4<unk> @ 8 milioni di di anni , il 4<unk> @ 8 , il 4<unk> @ 8 milioni di anni , il 4<unk> @ 8 , il 4<unk> @ 8 anni , il 4<unk> @ 8 , il 4<unk> @ 8 , il 4<unk> @ 8 % del 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , il 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti .
2025-05-27 19:51:50,308 - INFO - joeynmt.training - Example #1
2025-05-27 19:51:50,309 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:51:50,309 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:51:50,310 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la ter<unk> @ m<unk> @ em<unk> @ or<unk> @ ia di questi probl<unk> @ emi spe<unk> @ ci<unk> @ ali , perché non è il d<unk> @ ott<unk> @ ore .
2025-05-27 19:51:50,310 - INFO - joeynmt.training - Example #2
2025-05-27 19:51:50,310 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il s<unk> @ ac<unk> @ co di str<unk> @ um<unk> @ ento è il g<unk> @ hi<unk> @ ac<unk> @ cio c<unk> @ li<unk> @ ato della nostra c<unk> @ li<unk> @ sta del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - Example #3
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un s<unk> @ ac<unk> @ co di v<unk> @ ento e sc<unk> @ u<unk> @ ola .
2025-05-27 19:51:50,311 - INFO - joeynmt.training - Example #4
2025-05-27 19:51:50,312 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:51:50,312 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:51:50,312 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ol<unk> @ ia che vi mostr<unk> @ er<unk> @ ò una ser<unk> @ ie di lin<unk> @ ea che mostr<unk> @ a cosa che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:51:53,663 - INFO - joeynmt.training - Epoch   6, Step:    45100, Batch Loss:     0.930807, Batch Acc: 0.714058, Tokens per Sec:    20509, Lr: 0.000300
2025-05-27 19:51:56,963 - INFO - joeynmt.training - Epoch   6, Step:    45200, Batch Loss:     1.095223, Batch Acc: 0.712028, Tokens per Sec:    24454, Lr: 0.000300
2025-05-27 19:52:00,299 - INFO - joeynmt.training - Epoch   6, Step:    45300, Batch Loss:     1.203117, Batch Acc: 0.715022, Tokens per Sec:    24330, Lr: 0.000300
2025-05-27 19:52:03,629 - INFO - joeynmt.training - Epoch   6, Step:    45400, Batch Loss:     1.020797, Batch Acc: 0.709885, Tokens per Sec:    24092, Lr: 0.000300
2025-05-27 19:52:06,939 - INFO - joeynmt.training - Epoch   6, Step:    45500, Batch Loss:     0.922666, Batch Acc: 0.711967, Tokens per Sec:    23961, Lr: 0.000300
2025-05-27 19:52:06,939 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:52:06,939 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 63.88it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 78.60it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 91.86it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 104.12it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 88.16it/s] Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 106.07it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 90.31it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 49.26it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 54.07it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.35it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 77.73it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 86.47it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 83.66it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 60.25it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 70.45it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 59.72it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 58.06it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 57.46it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 63.55it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 67.86it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 74.16it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 76.62it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:06, 84.02it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 101.94it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:04, 109.27it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 115.69it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 109.48it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:03, 122.84it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 116.34it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 109.76it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 102.79it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:06, 63.78it/s] Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 69.84it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 57.66it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 53.16it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:06, 53.32it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:06, 50.95it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 49.73it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 59.19it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:04, 59.21it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 55.00it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:05, 48.84it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 40.59it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 38.47it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:05, 43.26it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 37.16it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 42.22it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 34.79it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 45.45it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 41.55it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 50.90it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 62.54it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 47.33it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 59.97it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 64.77it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 70.11it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 81.76it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 85.04it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:01, 68.79it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 64.94it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 77.62it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 105.88it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 68.04it/s] 
2025-05-27 19:52:20,514 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.73, acc:   0.71, generation: 13.5670[sec], evaluation: 0.0000[sec]
2025-05-27 19:52:20,515 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:52:20,989 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/42500.ckpt
2025-05-27 19:52:21,012 - INFO - joeynmt.training - Example #0
2025-05-27 19:52:21,013 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:52:21,013 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:52:21,013 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i , per pot<unk> @ er di<unk> @ mostr<unk> @ are che la c<unk> @ ura ci ha mostr<unk> @ ato che la c<unk> @ ura ci ha con<unk> @ si<unk> @ der<unk> @ ato che il g<unk> @ hi<unk> @ ac<unk> @ cio di tre milioni di anni , che aveva sc<unk> @ oper<unk> @ to , che aveva 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , e &apos; 4<unk> @ 8 St<unk> @ ati Un<unk> @ ati , è stato m<unk> @ and<unk> @ ato a qu<unk> @ asi .
2025-05-27 19:52:21,013 - INFO - joeynmt.training - Example #1
2025-05-27 19:52:21,014 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:52:21,014 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:52:21,014 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ ica di questa part<unk> @ icol<unk> @ are questa part<unk> @ icol<unk> @ are questo problema , non è il D<unk> @ ic<unk> @ em<unk> @ io .
2025-05-27 19:52:21,014 - INFO - joeynmt.training - Example #2
2025-05-27 19:52:21,015 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:52:21,015 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:52:21,015 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ li<unk> @ sta del sistema c<unk> @ li<unk> @ ente è la c<unk> @ li<unk> @ sta del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 19:52:21,015 - INFO - joeynmt.training - Example #3
2025-05-27 19:52:21,016 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:52:21,016 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:52:21,016 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e si trov<unk> @ a in est<unk> @ ate .
2025-05-27 19:52:21,016 - INFO - joeynmt.training - Example #4
2025-05-27 19:52:21,017 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:52:21,017 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:52:21,017 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ ero , che vi mostr<unk> @ er<unk> @ ò è una sc<unk> @ or<unk> @ sa che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:52:24,274 - INFO - joeynmt.training - Epoch   6, Step:    45600, Batch Loss:     1.036303, Batch Acc: 0.713704, Tokens per Sec:    20844, Lr: 0.000300
2025-05-27 19:52:27,541 - INFO - joeynmt.training - Epoch   6, Step:    45700, Batch Loss:     0.984434, Batch Acc: 0.709844, Tokens per Sec:    23581, Lr: 0.000300
2025-05-27 19:52:30,775 - INFO - joeynmt.training - Epoch   6, Step:    45800, Batch Loss:     1.062224, Batch Acc: 0.714300, Tokens per Sec:    24646, Lr: 0.000300
2025-05-27 19:52:34,011 - INFO - joeynmt.training - Epoch   6, Step:    45900, Batch Loss:     0.970977, Batch Acc: 0.713643, Tokens per Sec:    25071, Lr: 0.000300
2025-05-27 19:52:37,236 - INFO - joeynmt.training - Epoch   6, Step:    46000, Batch Loss:     1.009284, Batch Acc: 0.714878, Tokens per Sec:    23946, Lr: 0.000300
2025-05-27 19:52:37,236 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:52:37,236 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 78.53it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 88.43it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 99.79it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 102.35it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 114.26it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 123.58it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 121.38it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 132.84it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 59.33it/s] Predicting...:  17%|█▋        | 160/923 [00:01<00:11, 66.71it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 88.73it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 97.21it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 88.03it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:08, 78.29it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 61.60it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 57.77it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 55.65it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:10, 60.06it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 63.31it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 66.32it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 64.33it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 73.21it/s]Predicting...:  41%|████      | 379/923 [00:04<00:06, 86.48it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 92.58it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 91.65it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 93.42it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 102.70it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 99.44it/s] Predicting...:  51%|█████     | 469/923 [00:05<00:04, 96.53it/s]Predicting...:  52%|█████▏    | 480/923 [00:05<00:05, 85.18it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 88.94it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 75.41it/s]Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 88.16it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:05, 66.93it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 55.96it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 60.39it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 42.03it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 41.00it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 48.09it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:06, 47.82it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 44.74it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 40.79it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 33.88it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:08, 32.69it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 35.75it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 31.45it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 34.47it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:14, 16.06it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:09, 22.64it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:08, 25.17it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:05, 32.39it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:04, 41.56it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 37.28it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.20it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 49.52it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 53.70it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 62.15it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 73.22it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 73.83it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 54.99it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 64.59it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.02it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 73.69it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 72.70it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 87.89it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 61.29it/s]
2025-05-27 19:52:52,309 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.74, acc:   0.71, generation: 15.0593[sec], evaluation: 0.0000[sec]
2025-05-27 19:52:52,668 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/43000.ckpt
2025-05-27 19:52:52,694 - INFO - joeynmt.training - Example #0
2025-05-27 19:52:52,695 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:52:52,695 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:52:52,695 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due cas<unk> @ i sono arriv<unk> @ ati per ri<unk> @ dur<unk> @ re le col<unk> @ ie di p<unk> @ op<unk> @ ol<unk> @ i , che i c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are i due milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento di tre milioni di m<unk> @ oti<unk> @ vi .
2025-05-27 19:52:52,695 - INFO - joeynmt.training - Example #1
2025-05-27 19:52:52,696 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:52:52,696 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:52:52,696 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:52:52,696 - INFO - joeynmt.training - Example #2
2025-05-27 19:52:52,697 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:52:52,697 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:52:52,697 - INFO - joeynmt.training - 	Hypothesis: In questo sen<unk> @ so , il s<unk> @ ett<unk> @ ore c<unk> @ li<unk> @ mat<unk> @ ico è il c<unk> @ li<unk> @ m<unk> @ as<unk> @ si<unk> @ mo glob<unk> @ ale .
2025-05-27 19:52:52,698 - INFO - joeynmt.training - Example #3
2025-05-27 19:52:52,698 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:52:52,698 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:52:52,698 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e si sp<unk> @ esso .
2025-05-27 19:52:52,698 - INFO - joeynmt.training - Example #4
2025-05-27 19:52:52,699 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:52:52,699 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:52:52,699 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma fin<unk> @ ito che vi mostr<unk> @ er<unk> @ ò una lin<unk> @ ea di ri<unk> @ vol<unk> @ g<unk> @ ere una ri<unk> @ vi<unk> @ sta , che è succ<unk> @ e<unk> @ dendo negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:52:56,033 - INFO - joeynmt.training - Epoch   6, Step:    46100, Batch Loss:     0.956820, Batch Acc: 0.712317, Tokens per Sec:    20930, Lr: 0.000300
2025-05-27 19:52:59,360 - INFO - joeynmt.training - Epoch   6, Step:    46200, Batch Loss:     0.876255, Batch Acc: 0.711524, Tokens per Sec:    23960, Lr: 0.000300
2025-05-27 19:53:02,678 - INFO - joeynmt.training - Epoch   6, Step:    46300, Batch Loss:     0.980503, Batch Acc: 0.713840, Tokens per Sec:    23753, Lr: 0.000300
2025-05-27 19:53:06,013 - INFO - joeynmt.training - Epoch   6, Step:    46400, Batch Loss:     0.801335, Batch Acc: 0.713013, Tokens per Sec:    24066, Lr: 0.000300
2025-05-27 19:53:09,342 - INFO - joeynmt.training - Epoch   6, Step:    46500, Batch Loss:     0.989470, Batch Acc: 0.712453, Tokens per Sec:    23309, Lr: 0.000300
2025-05-27 19:53:09,343 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:53:09,343 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 76.84it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 95.32it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 106.37it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 106.61it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 112.20it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 123.45it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 117.54it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 89.73it/s] Predicting...:  15%|█▍        | 134/923 [00:02<00:24, 32.73it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:20, 38.52it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 48.89it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 74.81it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.38it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:08, 82.29it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:07, 85.07it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 61.58it/s]Predicting...:  30%|███       | 277/923 [00:04<00:10, 58.97it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 53.52it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 59.18it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 62.20it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 67.11it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 66.29it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 73.06it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 84.59it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 90.56it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 91.18it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 86.82it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 94.08it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 92.49it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 92.75it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.89it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 95.60it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 80.15it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 86.12it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:05, 63.80it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 56.64it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:06, 50.79it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 57.21it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 40.91it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 39.38it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 39.01it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 47.05it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.23it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 42.98it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.55it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 32.68it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 33.54it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 38.59it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.68it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.08it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 26.85it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 35.98it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 38.28it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 45.65it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 55.09it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 43.89it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 43.37it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 54.21it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 60.21it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 72.44it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 79.90it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 82.23it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 62.21it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 62.25it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 83.85it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 92.94it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 62.37it/s]
2025-05-27 19:53:24,154 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.01, ppl:   2.73, acc:   0.71, generation: 14.7984[sec], evaluation: 0.0000[sec]
2025-05-27 19:53:24,155 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:53:24,699 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/43500.ckpt
2025-05-27 19:53:24,719 - INFO - joeynmt.training - Example #0
2025-05-27 19:53:24,721 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:53:24,721 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:53:24,721 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so anno questi due f<unk> @ ig<unk> @ ure che sono stati mostr<unk> @ ati per con<unk> @ si<unk> @ der<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono che gli ar<unk> @ t<unk> @ icol<unk> @ i , per il 4<unk> @ 8 anni , per il 4<unk> @ 8 anni , per c<unk> @ ento di sc<unk> @ or<unk> @ r<unk> @ ere , 4<unk> @ 8 % .
2025-05-27 19:53:24,721 - INFO - joeynmt.training - Example #1
2025-05-27 19:53:24,722 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:53:24,722 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:53:24,722 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ ità di questo part<unk> @ icol<unk> @ are di questo part<unk> @ icol<unk> @ are , perché non è il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ ente .
2025-05-27 19:53:24,722 - INFO - joeynmt.training - Example #2
2025-05-27 19:53:24,723 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:53:24,723 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:53:24,723 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il g<unk> @ hi<unk> @ ac<unk> @ cio è il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 19:53:24,723 - INFO - joeynmt.training - Example #3
2025-05-27 19:53:24,724 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:53:24,724 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:53:24,724 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta in v<unk> @ ento e la v<unk> @ ento .
2025-05-27 19:53:24,724 - INFO - joeynmt.training - Example #4
2025-05-27 19:53:24,725 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:53:24,725 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:53:24,725 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ u , la pros<unk> @ si<unk> @ ma f<unk> @ u una ser<unk> @ ie di c<unk> @ en<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:53:28,073 - INFO - joeynmt.training - Epoch   6, Step:    46600, Batch Loss:     0.920914, Batch Acc: 0.711636, Tokens per Sec:    20669, Lr: 0.000300
2025-05-27 19:53:31,406 - INFO - joeynmt.training - Epoch   6, Step:    46700, Batch Loss:     0.988418, Batch Acc: 0.711800, Tokens per Sec:    24140, Lr: 0.000300
2025-05-27 19:53:34,729 - INFO - joeynmt.training - Epoch   6, Step:    46800, Batch Loss:     1.014533, Batch Acc: 0.710192, Tokens per Sec:    23938, Lr: 0.000300
2025-05-27 19:53:38,011 - INFO - joeynmt.training - Epoch   6, Step:    46900, Batch Loss:     1.078282, Batch Acc: 0.712970, Tokens per Sec:    23490, Lr: 0.000300
2025-05-27 19:53:41,349 - INFO - joeynmt.training - Epoch   6, Step:    47000, Batch Loss:     1.001593, Batch Acc: 0.709393, Tokens per Sec:    23741, Lr: 0.000300
2025-05-27 19:53:41,349 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:53:41,349 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 69.73it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 93.51it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 100.93it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 97.68it/s] Predicting...:   8%|▊         | 72/923 [00:00<00:09, 86.58it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 100.92it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 101.71it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 117.47it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 52.77it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:14, 55.43it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 65.54it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 92.20it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 96.08it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 87.00it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 79.88it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:07, 84.57it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:09, 66.03it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 61.57it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 60.73it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 67.44it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 72.67it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 76.57it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 72.02it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 79.90it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 97.31it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 99.27it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 104.55it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 109.48it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 113.62it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 109.53it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 102.03it/s]Predicting...:  52%|█████▏    | 480/923 [00:05<00:04, 92.45it/s] Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 92.74it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 71.71it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:05, 75.26it/s]Predicting...:  59%|█████▊    | 540/923 [00:06<00:05, 65.86it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:06, 56.21it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 51.75it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 46.54it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 54.72it/s]Predicting...:  64%|██████▎   | 587/923 [00:07<00:08, 39.39it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 39.76it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 41.67it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 50.52it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 52.84it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:06, 46.71it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 45.83it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 38.82it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 38.42it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:05, 43.35it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 33.35it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 37.18it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 35.14it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 44.14it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 41.18it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 48.27it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 57.29it/s]Predicting...:  81%|████████  | 749/923 [00:11<00:03, 49.17it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 46.15it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 54.29it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 58.05it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 68.15it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 76.72it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 76.33it/s]Predicting...:  90%|█████████ | 835/923 [00:12<00:01, 58.44it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 69.90it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 69.39it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 81.50it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 86.13it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 96.02it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 67.45it/s]
2025-05-27 19:53:55,047 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.72, acc:   0.71, generation: 13.6850[sec], evaluation: 0.0000[sec]
2025-05-27 19:53:55,048 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:53:55,570 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/44500.ckpt
2025-05-27 19:53:55,594 - INFO - joeynmt.training - Example #0
2025-05-27 19:53:55,595 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:53:55,596 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:53:55,596 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ ie per c<unk> @ att<unk> @ ur<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ato che gli ar<unk> @ t<unk> @ ici per i tre milioni di anni , per il ci<unk> @ b<unk> @ o di c<unk> @ att<unk> @ ur<unk> @ b<unk> @ i , per circa 4<unk> @ 8 milioni di anni .
2025-05-27 19:53:55,596 - INFO - joeynmt.training - Example #1
2025-05-27 19:53:55,597 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:53:55,597 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:53:55,597 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la di<unk> @ st<unk> @ ha<unk> @ i questa spe<unk> @ ci<unk> @ fic<unk> @ azione di questo problema , non è il d<unk> @ ic<unk> @ lo .
2025-05-27 19:53:55,597 - INFO - joeynmt.training - Example #2
2025-05-27 19:53:55,598 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:53:55,598 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:53:55,598 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio è il cu<unk> @ ore della nostra c<unk> @ li<unk> @ sta del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma .
2025-05-27 19:53:55,598 - INFO - joeynmt.training - Example #3
2025-05-27 19:53:55,599 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:53:55,599 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:53:55,599 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta s<unk> @ com<unk> @ met<unk> @ te di ri<unk> @ m<unk> @ ine e sp<unk> @ edi<unk> @ re .
2025-05-27 19:53:55,599 - INFO - joeynmt.training - Example #4
2025-05-27 19:53:55,599 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:53:55,600 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:53:55,600 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o vi mostr<unk> @ o , è una c<unk> @ ura di queste par<unk> @ ti , è una c<unk> @ en<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:53:58,960 - INFO - joeynmt.training - Epoch   6, Step:    47100, Batch Loss:     1.031964, Batch Acc: 0.712316, Tokens per Sec:    20378, Lr: 0.000300
2025-05-27 19:54:02,258 - INFO - joeynmt.training - Epoch   6, Step:    47200, Batch Loss:     0.944164, Batch Acc: 0.710039, Tokens per Sec:    23761, Lr: 0.000300
2025-05-27 19:54:04,651 - INFO - joeynmt.training - Epoch   6: total training loss 7812.54
2025-05-27 19:54:04,651 - INFO - joeynmt.training - EPOCH 7
2025-05-27 19:54:05,591 - INFO - joeynmt.training - Epoch   7, Step:    47300, Batch Loss:     1.017185, Batch Acc: 0.719619, Tokens per Sec:    24036, Lr: 0.000300
2025-05-27 19:54:08,923 - INFO - joeynmt.training - Epoch   7, Step:    47400, Batch Loss:     0.846242, Batch Acc: 0.724797, Tokens per Sec:    24151, Lr: 0.000300
2025-05-27 19:54:12,229 - INFO - joeynmt.training - Epoch   7, Step:    47500, Batch Loss:     0.843096, Batch Acc: 0.723164, Tokens per Sec:    22843, Lr: 0.000300
2025-05-27 19:54:12,229 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:54:12,229 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 59.42it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 75.37it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 80.86it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 85.93it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.79it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 111.15it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 109.45it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 118.27it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 51.19it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 55.08it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 63.81it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 86.91it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 93.77it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 77.50it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 78.95it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 83.66it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.03it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 54.37it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.06it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.51it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.27it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.56it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 59.96it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 57.36it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 67.57it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.25it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 85.21it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 79.71it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:06, 79.01it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 85.40it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 85.48it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 85.21it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.34it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 82.29it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 61.22it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 65.49it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 76.51it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 62.77it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 47.87it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 41.52it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 38.22it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.55it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 37.59it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 36.19it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.17it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 47.39it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.48it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 46.05it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 42.66it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 35.18it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 34.10it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.75it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.93it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.00it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 30.17it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 39.44it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 39.42it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 47.49it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 58.40it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 45.52it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 44.02it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 51.21it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 52.38it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 64.98it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 74.31it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 74.55it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 60.47it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 61.86it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 75.59it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 80.57it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 93.58it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 95.15it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 61.09it/s]
2025-05-27 19:54:27,353 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.73, acc:   0.71, generation: 15.1103[sec], evaluation: 0.0000[sec]
2025-05-27 19:54:27,694 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/45000.ckpt
2025-05-27 19:54:27,718 - INFO - joeynmt.training - Example #0
2025-05-27 19:54:27,719 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:54:27,719 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:54:27,719 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ ie per far<unk> @ lo per con<unk> @ si<unk> @ der<unk> @ are che la c<unk> @ aus<unk> @ a di con<unk> @ si<unk> @ der<unk> @ are la c<unk> @ aus<unk> @ a di tre milioni di anni , per la c<unk> @ aus<unk> @ a di tre milioni di anni , il 4<unk> @ 8 stati , 4<unk> @ 8 stati , per c<unk> @ ento di tre milioni di m<unk> @ oti<unk> @ vi .
2025-05-27 19:54:27,720 - INFO - joeynmt.training - Example #1
2025-05-27 19:54:27,720 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:54:27,720 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:54:27,720 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la ter<unk> @ n<unk> @ ità di questo probl<unk> @ em<unk> @ at<unk> @ ico , non è il D<unk> @ ic<unk> @ lo .
2025-05-27 19:54:27,721 - INFO - joeynmt.training - Example #2
2025-05-27 19:54:27,721 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:54:27,721 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la ci<unk> @ ma è la ci<unk> @ ma è la ci<unk> @ ma è la c<unk> @ aus<unk> @ a del cu<unk> @ ore .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - Example #3
2025-05-27 19:54:27,722 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e p<unk> @ eg<unk> @ gi<unk> @ o .
2025-05-27 19:54:27,722 - INFO - joeynmt.training - Example #4
2025-05-27 19:54:27,723 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:54:27,723 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:54:27,723 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ oc<unk> @ sione che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a di cosa che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:54:31,079 - INFO - joeynmt.training - Epoch   7, Step:    47600, Batch Loss:     0.937515, Batch Acc: 0.721090, Tokens per Sec:    21168, Lr: 0.000300
2025-05-27 19:54:34,408 - INFO - joeynmt.training - Epoch   7, Step:    47700, Batch Loss:     0.923773, Batch Acc: 0.719630, Tokens per Sec:    24055, Lr: 0.000300
2025-05-27 19:54:37,746 - INFO - joeynmt.training - Epoch   7, Step:    47800, Batch Loss:     1.038290, Batch Acc: 0.720740, Tokens per Sec:    24274, Lr: 0.000300
2025-05-27 19:54:41,086 - INFO - joeynmt.training - Epoch   7, Step:    47900, Batch Loss:     0.897056, Batch Acc: 0.720792, Tokens per Sec:    24153, Lr: 0.000300
2025-05-27 19:54:44,415 - INFO - joeynmt.training - Epoch   7, Step:    48000, Batch Loss:     0.904347, Batch Acc: 0.722577, Tokens per Sec:    23891, Lr: 0.000300
2025-05-27 19:54:44,416 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:54:44,416 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 62.38it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 80.95it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 94.47it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 94.11it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.21it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 111.27it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:10, 75.48it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 92.95it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:21, 35.94it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:18, 41.70it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 49.95it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 73.71it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 79.72it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 76.68it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 66.03it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 70.73it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 55.40it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 46.90it/s]Predicting...:  30%|███       | 277/923 [00:04<00:14, 46.05it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 45.86it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 50.58it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 53.57it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 57.67it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 55.09it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 52.93it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 62.59it/s]Predicting...:  41%|████      | 379/923 [00:06<00:06, 79.26it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 81.93it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 75.89it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 78.47it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 86.95it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 93.90it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 98.83it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 81.93it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:06, 66.21it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 55.07it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 62.98it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 73.64it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 59.87it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 46.25it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 38.48it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 38.23it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 46.37it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 37.01it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.88it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 35.10it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 44.88it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 43.03it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 40.86it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 37.40it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 31.61it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 31.96it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:07, 34.30it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 29.27it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 33.41it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:08, 26.66it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 35.36it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:05, 35.72it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 43.12it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 52.97it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 42.58it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 39.28it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 48.31it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 52.96it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 63.95it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 71.14it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 74.99it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 61.47it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 60.59it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 73.19it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 78.46it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 91.94it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 93.96it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.50it/s]
2025-05-27 19:55:00,767 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 16.3379[sec], evaluation: 0.0000[sec]
2025-05-27 19:55:00,768 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:55:01,424 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/46000.ckpt
2025-05-27 19:55:01,448 - INFO - joeynmt.training - Example #0
2025-05-27 19:55:01,450 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:55:01,450 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:55:01,450 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno questi due f<unk> @ ami<unk> @ gl<unk> @ ie per ri<unk> @ l<unk> @ ev<unk> @ are per ri<unk> @ dur<unk> @ re la g<unk> @ hi<unk> @ ac<unk> @ cio per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ vi per tre anni .
2025-05-27 19:55:01,450 - INFO - joeynmt.training - Example #1
2025-05-27 19:55:01,451 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:55:01,451 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:55:01,451 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza , la di<unk> @ st<unk> @ anza di questo problema , perché non è la di<unk> @ st<unk> @ anza di questo problema , perché non è il d<unk> @ ic<unk> @ lo .
2025-05-27 19:55:01,451 - INFO - joeynmt.training - Example #2
2025-05-27 19:55:01,452 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:55:01,452 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:55:01,452 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ aus<unk> @ a di str<unk> @ utt<unk> @ ura è la c<unk> @ aus<unk> @ a della nostra c<unk> @ li<unk> @ mat<unk> @ ica del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ so glob<unk> @ ale .
2025-05-27 19:55:01,452 - INFO - joeynmt.training - Example #3
2025-05-27 19:55:01,453 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:55:01,453 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:55:01,453 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e sc<unk> @ ar<unk> @ ic<unk> @ amente nella v<unk> @ est<unk> @ ate .
2025-05-27 19:55:01,453 - INFO - joeynmt.training - Example #4
2025-05-27 19:55:01,454 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:55:01,454 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:55:01,454 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i che vi mostr<unk> @ a una ser<unk> @ ie di fr<unk> @ on<unk> @ te a quello che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:55:04,772 - INFO - joeynmt.training - Epoch   7, Step:    48100, Batch Loss:     0.928656, Batch Acc: 0.722501, Tokens per Sec:    18991, Lr: 0.000300
2025-05-27 19:55:08,092 - INFO - joeynmt.training - Epoch   7, Step:    48200, Batch Loss:     0.984023, Batch Acc: 0.722955, Tokens per Sec:    24350, Lr: 0.000300
2025-05-27 19:55:11,408 - INFO - joeynmt.training - Epoch   7, Step:    48300, Batch Loss:     0.960830, Batch Acc: 0.720857, Tokens per Sec:    23349, Lr: 0.000300
2025-05-27 19:55:14,725 - INFO - joeynmt.training - Epoch   7, Step:    48400, Batch Loss:     1.092453, Batch Acc: 0.720792, Tokens per Sec:    23730, Lr: 0.000300
2025-05-27 19:55:18,041 - INFO - joeynmt.training - Epoch   7, Step:    48500, Batch Loss:     0.913644, Batch Acc: 0.722453, Tokens per Sec:    24203, Lr: 0.000300
2025-05-27 19:55:18,042 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:55:18,042 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 66.91it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.50it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 97.78it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 109.86it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 118.03it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 90.03it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 81.56it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 44.08it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 49.58it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 59.21it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 84.65it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.75it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.54it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 74.77it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 82.04it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:08, 75.17it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 69.74it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:10, 60.67it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 65.60it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 69.26it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 73.19it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 64.62it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 73.48it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 82.19it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 88.49it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 93.59it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 92.63it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 103.75it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 97.05it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 95.09it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 81.53it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 88.83it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:06, 63.99it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:05, 74.36it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 58.57it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 51.75it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 44.55it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 52.90it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 40.14it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 40.96it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 40.78it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 50.74it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 50.95it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 48.40it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 44.07it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 35.89it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 35.47it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 38.55it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 31.95it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 35.32it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 31.87it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 39.28it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 39.34it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 42.84it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 51.88it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 42.60it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 41.31it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 50.43it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 52.78it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:02, 60.38it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 70.07it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 68.96it/s]Predicting...:  90%|█████████ | 835/923 [00:13<00:01, 51.29it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 63.30it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 62.89it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 79.31it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 83.46it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 98.98it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 99.04it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 62.84it/s]
2025-05-27 19:55:32,744 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.72, acc:   0.71, generation: 14.6897[sec], evaluation: 0.0000[sec]
2025-05-27 19:55:33,106 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/45500.ckpt
2025-05-27 19:55:33,129 - INFO - joeynmt.training - Example #0
2025-05-27 19:55:33,131 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:55:33,131 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:55:33,131 - INFO - joeynmt.training - 	Hypothesis: In<unk> @ fine , ho mostr<unk> @ ato queste due cose sono st<unk> @ ate mostr<unk> @ ando per ri<unk> @ fer<unk> @ ire per ri<unk> @ dur<unk> @ re il g<unk> @ hi<unk> @ ac<unk> @ cio per i 4<unk> @ 8 anni , che l&apos; ar<unk> @ t<unk> @ ic<unk> @ olo per i 4<unk> @ 8 anni , per il 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , 4<unk> @ 8 anni , il 4<unk> @ 8 , 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per il 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per il 4<unk> @ 0 % .
2025-05-27 19:55:33,131 - INFO - joeynmt.training - Example #1
2025-05-27 19:55:33,132 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:55:33,132 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:55:33,132 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ r<unk> @ ità di questo problema spe<unk> @ ci<unk> @ ale , questo problema , perché non è il D<unk> @ ic<unk> @ e<unk> @ o , perché non è il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 19:55:33,132 - INFO - joeynmt.training - Example #2
2025-05-27 19:55:33,133 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:55:33,133 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:55:33,133 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ aus<unk> @ a di un cer<unk> @ to sen<unk> @ so , il cu<unk> @ ore del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 19:55:33,133 - INFO - joeynmt.training - Example #3
2025-05-27 19:55:33,134 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:55:33,134 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:55:33,134 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e il p<unk> @ ul<unk> @ in<unk> @ ter .
2025-05-27 19:55:33,134 - INFO - joeynmt.training - Example #4
2025-05-27 19:55:33,135 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:55:33,135 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:55:33,135 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ er<unk> @ ò una c<unk> @ en<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:55:36,459 - INFO - joeynmt.training - Epoch   7, Step:    48600, Batch Loss:     0.896581, Batch Acc: 0.721263, Tokens per Sec:    21320, Lr: 0.000300
2025-05-27 19:55:39,766 - INFO - joeynmt.training - Epoch   7, Step:    48700, Batch Loss:     1.062214, Batch Acc: 0.718866, Tokens per Sec:    23942, Lr: 0.000300
2025-05-27 19:55:43,082 - INFO - joeynmt.training - Epoch   7, Step:    48800, Batch Loss:     0.988642, Batch Acc: 0.718605, Tokens per Sec:    24502, Lr: 0.000300
2025-05-27 19:55:46,423 - INFO - joeynmt.training - Epoch   7, Step:    48900, Batch Loss:     1.082211, Batch Acc: 0.716929, Tokens per Sec:    23930, Lr: 0.000300
2025-05-27 19:55:49,738 - INFO - joeynmt.training - Epoch   7, Step:    49000, Batch Loss:     0.996822, Batch Acc: 0.719882, Tokens per Sec:    23647, Lr: 0.000300
2025-05-27 19:55:49,738 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:55:49,738 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:17, 50.83it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 69.75it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 84.07it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 95.32it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 97.47it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 111.08it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 109.42it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 118.62it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:23, 33.37it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:19, 39.19it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:16, 45.92it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 69.72it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 79.29it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 75.79it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 65.07it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 70.47it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 55.58it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 49.05it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 48.59it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 46.20it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.83it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:11, 55.36it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 60.16it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 59.15it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 65.43it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.98it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 86.66it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 88.98it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 73.12it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 84.71it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 82.56it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 88.47it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 77.36it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:04, 89.19it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 77.64it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 86.62it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 51.11it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 46.50it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 44.06it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:06, 51.90it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 38.29it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 36.15it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 33.96it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 42.62it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.53it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 39.88it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.98it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 33.09it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 30.66it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 32.96it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 29.69it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 29.81it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:09, 24.45it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 32.70it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 32.25it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 37.54it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 48.41it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 38.97it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 39.51it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 49.30it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 56.68it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 70.49it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 82.82it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 81.91it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 54.18it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 48.31it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 61.13it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 69.86it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 95.34it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.48it/s]
2025-05-27 19:56:06,095 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 16.3424[sec], evaluation: 0.0000[sec]
2025-05-27 19:56:06,095 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:56:06,603 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/46500.ckpt
2025-05-27 19:56:06,628 - INFO - joeynmt.training - Example #0
2025-05-27 19:56:06,630 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:56:06,630 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:56:06,630 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due p<unk> @ ezz<unk> @ e per ri<unk> @ dur<unk> @ re le ci<unk> @ b<unk> @ re per il g<unk> @ hi<unk> @ ac<unk> @ cio , che il g<unk> @ hi<unk> @ ac<unk> @ cio per i tre mili<unk> @ ar<unk> @ di di di di m<unk> @ oti<unk> @ v<unk> @ are il 4<unk> @ 0 % del 4<unk> @ 8 anni , per il 4<unk> @ 8 , per c<unk> @ ento di circa il 4<unk> @ 8 % .
2025-05-27 19:56:06,630 - INFO - joeynmt.training - Example #1
2025-05-27 19:56:06,631 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:56:06,631 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:56:06,631 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza in<unk> @ t<unk> @ eg<unk> @ r<unk> @ ità di questo problema spe<unk> @ ci<unk> @ ale .
2025-05-27 19:56:06,631 - INFO - joeynmt.training - Example #2
2025-05-27 19:56:06,632 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:56:06,632 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:56:06,632 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a è la c<unk> @ aus<unk> @ a di E<unk> @ is<unk> @ k<unk> @ p<unk> @ ing , il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 19:56:06,632 - INFO - joeynmt.training - Example #3
2025-05-27 19:56:06,633 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:56:06,633 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:56:06,633 - INFO - joeynmt.training - 	Hypothesis: Si può essere in est<unk> @ ate e la v<unk> @ in<unk> @ ver<unk> @ no .
2025-05-27 19:56:06,633 - INFO - joeynmt.training - Example #4
2025-05-27 19:56:06,634 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:56:06,634 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:56:06,634 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ ura che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ aus<unk> @ a di quello che succ<unk> @ e<unk> @ de<unk> @ va negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:56:09,913 - INFO - joeynmt.training - Epoch   7, Step:    49100, Batch Loss:     0.906914, Batch Acc: 0.717846, Tokens per Sec:    20751, Lr: 0.000300
2025-05-27 19:56:13,141 - INFO - joeynmt.training - Epoch   7, Step:    49200, Batch Loss:     0.993157, Batch Acc: 0.717604, Tokens per Sec:    23964, Lr: 0.000300
2025-05-27 19:56:16,325 - INFO - joeynmt.training - Epoch   7, Step:    49300, Batch Loss:     0.904869, Batch Acc: 0.718545, Tokens per Sec:    25086, Lr: 0.000300
2025-05-27 19:56:19,543 - INFO - joeynmt.training - Epoch   7, Step:    49400, Batch Loss:     0.961923, Batch Acc: 0.718802, Tokens per Sec:    24208, Lr: 0.000300
2025-05-27 19:56:22,767 - INFO - joeynmt.training - Epoch   7, Step:    49500, Batch Loss:     0.952128, Batch Acc: 0.718578, Tokens per Sec:    24672, Lr: 0.000300
2025-05-27 19:56:22,767 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:56:22,768 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 75.25it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.49it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 84.49it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 92.33it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 97.53it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 110.56it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 118.82it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:13, 57.03it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 60.01it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 57.46it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 79.59it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.66it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.35it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 67.30it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 71.46it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 58.48it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 53.22it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 50.22it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 48.86it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.11it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.49it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 59.88it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 58.71it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 57.32it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 67.04it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 83.85it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 91.68it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 90.76it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 96.02it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 108.46it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 105.24it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 103.23it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 98.01it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 95.44it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 62.94it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 65.36it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 60.06it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 51.85it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 47.40it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 55.10it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 44.99it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 43.25it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 41.57it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 51.59it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 51.10it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 46.89it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 36.66it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 32.12it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 32.80it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.03it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 35.33it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:05, 39.41it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 33.76it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:04, 44.42it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 44.12it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 51.28it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:02, 62.68it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 47.95it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 56.34it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 62.30it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 73.68it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 82.49it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 85.55it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 66.38it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 64.81it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 79.29it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 87.05it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 101.08it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 104.46it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 64.11it/s] 
2025-05-27 19:56:37,174 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.70, acc:   0.71, generation: 14.3980[sec], evaluation: 0.0000[sec]
2025-05-27 19:56:37,175 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:56:37,604 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/47500.ckpt
2025-05-27 19:56:37,625 - INFO - joeynmt.training - Example #0
2025-05-27 19:56:37,626 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:56:37,626 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:56:37,626 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due p<unk> @ es<unk> @ ci per ri<unk> @ chi<unk> @ ede che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che aveva tre milioni di anni , per il 4<unk> @ 0 % del m<unk> @ oti<unk> @ vo per 4<unk> @ 8 anni , per il 4<unk> @ 8 , per c<unk> @ ento di sol<unk> @ ito , per il 4<unk> @ 8 anni .
2025-05-27 19:56:37,626 - INFO - joeynmt.training - Example #1
2025-05-27 19:56:37,627 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:56:37,627 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:56:37,627 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ ra di ter<unk> @ m<unk> @ ini di questo problema spe<unk> @ ci<unk> @ ci<unk> @ ale che non ci mostr<unk> @ a il problema di E<unk> @ is<unk> @ p<unk> @ ke .
2025-05-27 19:56:37,627 - INFO - joeynmt.training - Example #2
2025-05-27 19:56:37,628 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:56:37,628 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:56:37,628 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è il g<unk> @ hi<unk> @ ac<unk> @ cio è il g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ so glob<unk> @ ale .
2025-05-27 19:56:37,629 - INFO - joeynmt.training - Example #3
2025-05-27 19:56:37,629 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:56:37,629 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:56:37,629 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ etro e in<unk> @ ver<unk> @ no .
2025-05-27 19:56:37,629 - INFO - joeynmt.training - Example #4
2025-05-27 19:56:37,630 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:56:37,630 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:56:37,630 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ er<unk> @ ò , è una lin<unk> @ ea di queste cose è succ<unk> @ essi<unk> @ ve negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:56:40,878 - INFO - joeynmt.training - Epoch   7, Step:    49600, Batch Loss:     0.866403, Batch Acc: 0.719806, Tokens per Sec:    21784, Lr: 0.000300
2025-05-27 19:56:44,033 - INFO - joeynmt.training - Epoch   7, Step:    49700, Batch Loss:     1.054184, Batch Acc: 0.721658, Tokens per Sec:    25257, Lr: 0.000300
2025-05-27 19:56:47,231 - INFO - joeynmt.training - Epoch   7, Step:    49800, Batch Loss:     0.996471, Batch Acc: 0.721132, Tokens per Sec:    24720, Lr: 0.000300
2025-05-27 19:56:50,403 - INFO - joeynmt.training - Epoch   7, Step:    49900, Batch Loss:     0.925125, Batch Acc: 0.718474, Tokens per Sec:    24987, Lr: 0.000300
2025-05-27 19:56:53,609 - INFO - joeynmt.training - Epoch   7, Step:    50000, Batch Loss:     0.975262, Batch Acc: 0.717855, Tokens per Sec:    24793, Lr: 0.000300
2025-05-27 19:56:53,610 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:56:53,610 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 74.97it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 90.10it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 97.93it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 100.32it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 108.63it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 90.44it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 84.28it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 55.35it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 60.58it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 68.60it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 94.26it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:06, 104.16it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 90.90it/s] Predicting...:  25%|██▌       | 235/923 [00:02<00:07, 86.14it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 89.95it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 62.68it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 61.54it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 59.47it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 63.54it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 67.00it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 71.12it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 66.24it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 62.81it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 74.58it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 93.09it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 100.83it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 97.58it/s] Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 105.64it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 107.43it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 110.14it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 100.02it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 79.13it/s] Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 87.68it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:06, 62.01it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 53.02it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 59.48it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:06, 48.61it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 48.26it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 55.26it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 55.99it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 50.26it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 45.58it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 37.30it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 35.49it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 39.48it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 35.82it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 39.56it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 33.60it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 43.34it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:04, 44.21it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 52.29it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 58.47it/s]Predicting...:  81%|████████  | 749/923 [00:11<00:03, 47.71it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 47.51it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 57.25it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 63.01it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 71.42it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 81.64it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 82.29it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:00, 73.79it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 70.11it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 83.35it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 92.06it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 121.03it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 68.85it/s] 
2025-05-27 19:57:07,026 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 13.4074[sec], evaluation: 0.0000[sec]
2025-05-27 19:57:07,314 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/47000.ckpt
2025-05-27 19:57:07,330 - INFO - joeynmt.training - Example #0
2025-05-27 19:57:07,331 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:57:07,332 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:57:07,332 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato questi due pun<unk> @ ti per ri<unk> @ dur<unk> @ re la str<unk> @ utt<unk> @ ura che i g<unk> @ am<unk> @ be per la qu<unk> @ ale che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i tre milioni di anni , che aveva fatto per il 4<unk> @ 8 % di qu<unk> @ ei di<unk> @ st<unk> @ in<unk> @ gu<unk> @ ig<unk> @ ni , ha fatto il 4<unk> @ 8 % di tutti i stati in gra<unk> @ do di fare il 4<unk> @ 8 % .
2025-05-27 19:57:07,332 - INFO - joeynmt.training - Example #1
2025-05-27 19:57:07,332 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:57:07,332 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:57:07,333 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza l&apos; in<unk> @ st<unk> @ a<unk> @ da di questo problema , perché non è l&apos; in<unk> @ tr<unk> @ ap<unk> @ i<unk> @ anto di qu<unk> @ ei probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 19:57:07,333 - INFO - joeynmt.training - Example #2
2025-05-27 19:57:07,333 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:57:07,333 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:57:07,333 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore glob<unk> @ ale del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 19:57:07,334 - INFO - joeynmt.training - Example #3
2025-05-27 19:57:07,334 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:57:07,334 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:57:07,334 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta s<unk> @ com<unk> @ par<unk> @ si e in est<unk> @ ate nel sen<unk> @ so .
2025-05-27 19:57:07,334 - INFO - joeynmt.training - Example #4
2025-05-27 19:57:07,335 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:57:07,335 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:57:07,335 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una st<unk> @ anza che vi mostr<unk> @ er<unk> @ ò la sc<unk> @ or<unk> @ sa che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:57:10,566 - INFO - joeynmt.training - Epoch   7, Step:    50100, Batch Loss:     0.882641, Batch Acc: 0.721609, Tokens per Sec:    22305, Lr: 0.000300
2025-05-27 19:57:13,735 - INFO - joeynmt.training - Epoch   7, Step:    50200, Batch Loss:     0.871790, Batch Acc: 0.720433, Tokens per Sec:    24476, Lr: 0.000300
2025-05-27 19:57:16,925 - INFO - joeynmt.training - Epoch   7, Step:    50300, Batch Loss:     0.917008, Batch Acc: 0.718225, Tokens per Sec:    25166, Lr: 0.000300
2025-05-27 19:57:20,145 - INFO - joeynmt.training - Epoch   7, Step:    50400, Batch Loss:     0.944351, Batch Acc: 0.719042, Tokens per Sec:    24736, Lr: 0.000300
2025-05-27 19:57:23,346 - INFO - joeynmt.training - Epoch   7, Step:    50500, Batch Loss:     0.917323, Batch Acc: 0.716335, Tokens per Sec:    24512, Lr: 0.000300
2025-05-27 19:57:23,346 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:57:23,346 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 76.74it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 89.44it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 104.24it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 113.86it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 112.48it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 124.24it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 94.12it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 109.31it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:20, 37.66it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:17, 43.30it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 53.95it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 79.87it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 91.98it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 85.51it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 78.65it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 57.04it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 56.26it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.49it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 57.36it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 60.63it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 65.60it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 59.57it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 56.60it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 65.46it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.53it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 91.73it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 98.40it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 99.14it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 105.82it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 100.93it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 98.05it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 81.80it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 89.94it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 72.31it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 81.27it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 54.40it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 51.15it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 45.65it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 53.47it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 41.11it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 40.26it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 40.28it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 49.76it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.40it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 41.74it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:09, 29.77it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 25.45it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:10, 25.84it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 30.12it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:09, 26.44it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:08, 29.47it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 25.62it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 32.81it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 32.85it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 40.44it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 48.45it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 39.54it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 33.85it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 45.19it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 49.88it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 59.21it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 69.90it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 70.51it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 51.12it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 62.74it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 66.38it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 77.90it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 84.39it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 97.19it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.79it/s]
2025-05-27 19:57:39,061 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 15.7009[sec], evaluation: 0.0000[sec]
2025-05-27 19:57:39,550 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/48500.ckpt
2025-05-27 19:57:39,575 - INFO - joeynmt.training - Example #0
2025-05-27 19:57:39,576 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:57:39,577 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:57:39,577 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due cas<unk> @ i sono stati mostr<unk> @ ati per ri<unk> @ fer<unk> @ m<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ cio , per i g<unk> @ hi<unk> @ ac<unk> @ cio , per i 4<unk> @ 8 anni , per c<unk> @ ento di qu<unk> @ elli che hanno av<unk> @ uto 4<unk> @ 8 anni , aveva av<unk> @ uto 4<unk> @ 8 , per c<unk> @ ento di 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per c<unk> @ ento .
2025-05-27 19:57:39,577 - INFO - joeynmt.training - Example #1
2025-05-27 19:57:39,577 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:57:39,578 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:57:39,578 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ n<unk> @ ra di questo problema spe<unk> @ ci<unk> @ ale , perché non mostr<unk> @ a il problema di E<unk> @ is<unk> @ es .
2025-05-27 19:57:39,578 - INFO - joeynmt.training - Example #2
2025-05-27 19:57:39,578 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ itu<unk> @ azione è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ o glob<unk> @ ale .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - Example #3
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e p<unk> @ oco , e poi si trov<unk> @ a in est<unk> @ ate .
2025-05-27 19:57:39,579 - INFO - joeynmt.training - Example #4
2025-05-27 19:57:39,580 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:57:39,580 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:57:39,580 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ am<unk> @ a che vi mostr<unk> @ er<unk> @ ò una st<unk> @ anza di tra<unk> @ ff<unk> @ ic<unk> @ i<unk> @ ente , che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:57:42,940 - INFO - joeynmt.training - Epoch   7, Step:    50600, Batch Loss:     0.923917, Batch Acc: 0.716311, Tokens per Sec:    20316, Lr: 0.000300
2025-05-27 19:57:45,396 - INFO - joeynmt.training - Epoch   7, Step:    50700, Batch Loss:     1.021105, Batch Acc: 0.718706, Tokens per Sec:    33233, Lr: 0.000300
2025-05-27 19:57:47,299 - INFO - joeynmt.training - Epoch   7, Step:    50800, Batch Loss:     0.961667, Batch Acc: 0.716964, Tokens per Sec:    42201, Lr: 0.000300
2025-05-27 19:57:49,217 - INFO - joeynmt.training - Epoch   7, Step:    50900, Batch Loss:     1.029240, Batch Acc: 0.719173, Tokens per Sec:    41163, Lr: 0.000300
2025-05-27 19:57:51,129 - INFO - joeynmt.training - Epoch   7, Step:    51000, Batch Loss:     0.973920, Batch Acc: 0.722641, Tokens per Sec:    42673, Lr: 0.000300
2025-05-27 19:57:51,130 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:57:51,130 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 64.09it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 85.17it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.94it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 94.61it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 101.72it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 107.21it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:11, 69.77it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 63.52it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:10, 72.72it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 94.59it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 99.80it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 84.15it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 82.41it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 77.35it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:10, 63.41it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 55.69it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 54.17it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:12, 52.22it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 56.96it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.59it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 62.47it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 65.56it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 58.49it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 68.01it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 83.28it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 91.08it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 92.60it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 100.06it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 106.34it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 105.52it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 99.89it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 90.87it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 93.71it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:07, 54.00it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:06, 63.75it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 50.43it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 47.49it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 43.50it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.47it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 40.63it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 40.82it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 40.34it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 49.89it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 51.71it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 44.10it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 35.95it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.07it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 29.88it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 34.64it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.61it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.13it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 29.00it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 37.80it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.96it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 42.30it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 52.12it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 45.65it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 47.72it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 61.47it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 66.35it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 79.06it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 88.23it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 83.12it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 64.37it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 59.21it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 70.47it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 75.17it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 89.07it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 62.33it/s]
2025-05-27 19:58:05,950 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 14.8085[sec], evaluation: 0.0000[sec]
2025-05-27 19:58:06,286 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/48000.ckpt
2025-05-27 19:58:06,310 - INFO - joeynmt.training - Example #0
2025-05-27 19:58:06,312 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:58:06,312 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:58:06,312 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cas<unk> @ e , per far<unk> @ lo per c<unk> @ aus<unk> @ a di in<unk> @ f<unk> @ lu<unk> @ en<unk> @ z<unk> @ i , che la g<unk> @ hi<unk> @ ac<unk> @ cia , per il 4<unk> @ 0 % di qu<unk> @ elli di 4<unk> @ 8 % di 4<unk> @ 8 milioni di m<unk> @ oti<unk> @ vi per c<unk> @ ento , 4<unk> @ 0 % di m<unk> @ ezz<unk> @ o .
2025-05-27 19:58:06,312 - INFO - joeynmt.training - Example #1
2025-05-27 19:58:06,313 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:58:06,313 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:58:06,313 - INFO - joeynmt.training - 	Hypothesis: Ma non è così for<unk> @ t<unk> @ un<unk> @ at<unk> @ amente la di<unk> @ st<unk> @ ha<unk> @ i questa part<unk> @ icol<unk> @ are , che non è il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:58:06,313 - INFO - joeynmt.training - Example #2
2025-05-27 19:58:06,314 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:58:06,314 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:58:06,314 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa c<unk> @ aus<unk> @ a di sen<unk> @ so è la g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ata del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico glob<unk> @ ale .
2025-05-27 19:58:06,314 - INFO - joeynmt.training - Example #3
2025-05-27 19:58:06,315 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:58:06,315 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:58:06,315 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si è sp<unk> @ esso in est<unk> @ ate .
2025-05-27 19:58:06,315 - INFO - joeynmt.training - Example #4
2025-05-27 19:58:06,316 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:58:06,316 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:58:06,316 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ anno la mia pros<unk> @ si<unk> @ ma f<unk> @ u una st<unk> @ anza di in<unk> @ contr<unk> @ o , che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:58:07,855 - INFO - joeynmt.training - Epoch   7, Step:    51100, Batch Loss:     1.058849, Batch Acc: 0.718445, Tokens per Sec:    42247, Lr: 0.000300
2025-05-27 19:58:09,443 - INFO - joeynmt.training - Epoch   7, Step:    51200, Batch Loss:     0.938377, Batch Acc: 0.717991, Tokens per Sec:    50118, Lr: 0.000300
2025-05-27 19:58:11,009 - INFO - joeynmt.training - Epoch   7, Step:    51300, Batch Loss:     0.988798, Batch Acc: 0.718162, Tokens per Sec:    50263, Lr: 0.000300
2025-05-27 19:58:12,627 - INFO - joeynmt.training - Epoch   7, Step:    51400, Batch Loss:     1.033448, Batch Acc: 0.716381, Tokens per Sec:    47414, Lr: 0.000300
2025-05-27 19:58:14,171 - INFO - joeynmt.training - Epoch   7, Step:    51500, Batch Loss:     0.905081, Batch Acc: 0.717815, Tokens per Sec:    50584, Lr: 0.000300
2025-05-27 19:58:14,171 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:58:14,171 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:09, 92.80it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 110.67it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 120.41it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 138.25it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:08, 101.46it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:09, 83.79it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:10, 71.27it/s]Predicting...:  20%|██        | 185/923 [00:01<00:07, 94.89it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:07, 101.20it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:06, 101.38it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:07, 88.28it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 88.03it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:09, 67.76it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 63.20it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 62.00it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 69.31it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 69.86it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:08, 69.61it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 74.23it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 83.37it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:04, 109.25it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 105.28it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 107.56it/s]Predicting...:  48%|████▊     | 441/923 [00:04<00:04, 119.18it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:03, 117.57it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:03, 117.73it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 103.21it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 83.27it/s] Predicting...:  58%|█████▊    | 531/923 [00:05<00:04, 91.69it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:05, 67.75it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:06, 53.00it/s]Predicting...:  63%|██████▎   | 580/923 [00:06<00:05, 59.31it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:06, 48.34it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:06, 46.13it/s]Predicting...:  67%|██████▋   | 618/923 [00:07<00:05, 54.62it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 50.97it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 47.84it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:06, 43.91it/s]Predicting...:  71%|███████   | 653/923 [00:08<00:07, 37.27it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 36.46it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 40.45it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 36.64it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:05, 41.72it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 34.20it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 43.74it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:04, 42.03it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 49.59it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:02, 63.15it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 54.59it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 63.90it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:02, 66.48it/s]Predicting...:  87%|████████▋ | 800/923 [00:11<00:01, 78.63it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 87.31it/s]Predicting...:  90%|████████▉ | 827/923 [00:11<00:01, 90.25it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:00, 75.86it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 69.41it/s]Predicting...:  95%|█████████▌| 878/923 [00:12<00:00, 83.15it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 92.56it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 123.69it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 72.78it/s] 
2025-05-27 19:58:26,861 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.71, acc:   0.71, generation: 12.6821[sec], evaluation: 0.0000[sec]
2025-05-27 19:58:27,268 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/50500.ckpt
2025-05-27 19:58:27,286 - INFO - joeynmt.training - Example #0
2025-05-27 19:58:27,287 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:58:27,287 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:58:27,287 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due p<unk> @ ezz<unk> @ i di p<unk> @ om<unk> @ enti per di<unk> @ st<unk> @ in<unk> @ gu<unk> @ ere , che l&apos; or<unk> @ t<unk> @ is<unk> @ c<unk> @ ina , che ha fatto per il 4<unk> @ 0 % di questi tre milioni di rag<unk> @ i<unk> @ oni di rag<unk> @ i<unk> @ oni , per il 4<unk> @ 0 % .
2025-05-27 19:58:27,287 - INFO - joeynmt.training - Example #1
2025-05-27 19:58:27,288 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:58:27,288 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:58:27,288 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perché non è il d<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:58:27,288 - INFO - joeynmt.training - Example #2
2025-05-27 19:58:27,289 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:58:27,289 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:58:27,289 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , la cu<unk> @ c<unk> @ ina del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ e del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico .
2025-05-27 19:58:27,289 - INFO - joeynmt.training - Example #3
2025-05-27 19:58:27,290 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:58:27,290 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:58:27,290 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ta divent<unk> @ a un v<unk> @ ento e p<unk> @ oco , e p<unk> @ oco .
2025-05-27 19:58:27,290 - INFO - joeynmt.training - Example #4
2025-05-27 19:58:27,291 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:58:27,291 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:58:27,291 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ re<unk> @ qu<unk> @ ent<unk> @ ale è una c<unk> @ en<unk> @ a di queste cose è succ<unk> @ esso una c<unk> @ en<unk> @ a di ciò che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:58:28,823 - INFO - joeynmt.training - Epoch   7, Step:    51600, Batch Loss:     0.892131, Batch Acc: 0.719960, Tokens per Sec:    39443, Lr: 0.000300
2025-05-27 19:58:30,330 - INFO - joeynmt.training - Epoch   7, Step:    51700, Batch Loss:     0.937356, Batch Acc: 0.721311, Tokens per Sec:    50985, Lr: 0.000300
2025-05-27 19:58:31,819 - INFO - joeynmt.training - Epoch   7, Step:    51800, Batch Loss:     0.932051, Batch Acc: 0.716875, Tokens per Sec:    51303, Lr: 0.000300
2025-05-27 19:58:33,362 - INFO - joeynmt.training - Epoch   7, Step:    51900, Batch Loss:     0.944488, Batch Acc: 0.717506, Tokens per Sec:    51111, Lr: 0.000300
2025-05-27 19:58:34,939 - INFO - joeynmt.training - Epoch   7, Step:    52000, Batch Loss:     0.915180, Batch Acc: 0.719544, Tokens per Sec:    50272, Lr: 0.000300
2025-05-27 19:58:34,939 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:58:34,939 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:09, 93.02it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:06, 129.76it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 138.21it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 103.78it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:10, 75.34it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:11, 66.96it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:10, 74.33it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 97.31it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 101.50it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 92.08it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:06, 100.75it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:08, 73.12it/s] Predicting...:  30%|███       | 277/923 [00:03<00:09, 71.60it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:09, 67.73it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 74.35it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:07, 76.49it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 79.41it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 73.79it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 83.63it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 98.58it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 103.63it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 108.45it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 102.96it/s]Predicting...:  48%|████▊     | 441/923 [00:04<00:04, 112.10it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 106.92it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 107.47it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 92.74it/s] Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 70.85it/s]Predicting...:  59%|█████▊    | 540/923 [00:06<00:05, 69.31it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:06, 61.10it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:06, 54.92it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 49.14it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 57.38it/s]Predicting...:  64%|██████▎   | 587/923 [00:07<00:11, 30.13it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:10, 31.45it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:09, 34.76it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 45.16it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:06, 47.76it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 48.48it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 44.80it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 37.33it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:08, 32.25it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 37.49it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:08, 29.39it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 34.26it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:07, 28.56it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 38.53it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 40.32it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 49.00it/s]Predicting...:  81%|████████  | 749/923 [00:11<00:03, 52.06it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 48.52it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 59.49it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 63.56it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 75.75it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 86.18it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 88.29it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 72.62it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 72.13it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 90.73it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 101.20it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 67.85it/s] 
2025-05-27 19:58:48,551 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.69, acc:   0.71, generation: 13.6041[sec], evaluation: 0.0000[sec]
2025-05-27 19:58:48,552 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:58:49,005 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/49000.ckpt
2025-05-27 19:58:49,028 - INFO - joeynmt.training - Example #0
2025-05-27 19:58:49,030 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:58:49,030 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:58:49,030 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cas<unk> @ i di c<unk> @ op<unk> @ pi<unk> @ a per ven<unk> @ ire in gra<unk> @ do di f<unk> @ att<unk> @ ur<unk> @ ale , che l&apos; or<unk> @ ig<unk> @ is<unk> @ c<unk> @ ina per le tre milioni di anni , che av<unk> @ evo tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % del c<unk> @ ento .
2025-05-27 19:58:49,030 - INFO - joeynmt.training - Example #1
2025-05-27 19:58:49,031 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:58:49,031 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:58:49,031 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ za in<unk> @ tel<unk> @ li<unk> @ gente , perché non ci mostr<unk> @ a il problema di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 19:58:49,031 - INFO - joeynmt.training - Example #2
2025-05-27 19:58:49,032 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:58:49,032 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:58:49,032 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ li<unk> @ mat<unk> @ ica è la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio .
2025-05-27 19:58:49,032 - INFO - joeynmt.training - Example #3
2025-05-27 19:58:49,033 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:58:49,033 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:58:49,033 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e in<unk> @ ver<unk> @ no .
2025-05-27 19:58:49,033 - INFO - joeynmt.training - Example #4
2025-05-27 19:58:49,034 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:58:49,034 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:58:49,034 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ oll<unk> @ ia che vi mostr<unk> @ er<unk> @ ò , è una st<unk> @ anza di queste ulti<unk> @ me 2<unk> @ 5 anni .
2025-05-27 19:58:50,618 - INFO - joeynmt.training - Epoch   7, Step:    52100, Batch Loss:     1.048749, Batch Acc: 0.720453, Tokens per Sec:    37457, Lr: 0.000300
2025-05-27 19:58:52,152 - INFO - joeynmt.training - Epoch   7, Step:    52200, Batch Loss:     0.912745, Batch Acc: 0.719662, Tokens per Sec:    52475, Lr: 0.000300
2025-05-27 19:58:53,735 - INFO - joeynmt.training - Epoch   7, Step:    52300, Batch Loss:     0.974463, Batch Acc: 0.716770, Tokens per Sec:    48573, Lr: 0.000300
2025-05-27 19:58:55,255 - INFO - joeynmt.training - Epoch   7, Step:    52400, Batch Loss:     0.889552, Batch Acc: 0.721057, Tokens per Sec:    51280, Lr: 0.000300
2025-05-27 19:58:56,784 - INFO - joeynmt.training - Epoch   7, Step:    52500, Batch Loss:     1.093569, Batch Acc: 0.719462, Tokens per Sec:    51373, Lr: 0.000300
2025-05-27 19:58:56,784 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:58:56,784 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 87.01it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 102.84it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 115.98it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 121.76it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 122.29it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 134.90it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:08, 94.91it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:09, 80.24it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:08, 88.49it/s]Predicting...:  22%|██▏       | 201/923 [00:01<00:05, 120.88it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:06, 111.87it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 95.07it/s] Predicting...:  29%|██▉       | 267/923 [00:02<00:08, 75.48it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 71.33it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:09, 67.07it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 68.66it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 72.59it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 76.10it/s]Predicting...:  37%|███▋      | 337/923 [00:03<00:09, 65.11it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 62.68it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 74.70it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 96.02it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:05, 97.32it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 100.18it/s]Predicting...:  48%|████▊     | 441/923 [00:04<00:04, 113.96it/s]Predicting...:  49%|████▉     | 455/923 [00:04<00:04, 116.88it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:03, 119.10it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 100.93it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:05, 77.09it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:05, 74.81it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:06, 58.33it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:06, 56.68it/s]Predicting...:  63%|██████▎   | 580/923 [00:06<00:05, 61.24it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:06, 47.60it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:07, 45.17it/s]Predicting...:  67%|██████▋   | 618/923 [00:07<00:05, 54.05it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 50.91it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 48.68it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:06, 45.63it/s]Predicting...:  71%|███████   | 653/923 [00:08<00:06, 38.90it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 37.50it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 39.71it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 35.70it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:05, 40.33it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 33.73it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:04, 43.18it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:04, 42.79it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 52.79it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:02, 63.66it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 49.51it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 58.69it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:02, 65.34it/s]Predicting...:  87%|████████▋ | 800/923 [00:11<00:01, 75.31it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 87.48it/s]Predicting...:  90%|████████▉ | 827/923 [00:11<00:01, 91.24it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:01, 69.12it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 72.98it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 94.79it/s]Predicting...:  98%|█████████▊| 908/923 [00:12<00:00, 102.24it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 72.60it/s] 
2025-05-27 19:59:09,505 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.72, generation: 12.7137[sec], evaluation: 0.0000[sec]
2025-05-27 19:59:09,506 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 19:59:09,985 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/51000.ckpt
2025-05-27 19:59:10,003 - INFO - joeynmt.training - Example #0
2025-05-27 19:59:10,004 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:59:10,004 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:59:10,004 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due pol<unk> @ iti<unk> @ che , per l&apos; ho mostr<unk> @ ato che le g<unk> @ am<unk> @ be per la qu<unk> @ ale ri<unk> @ chi<unk> @ ede che l&apos; or<unk> @ ig<unk> @ ine di circa 4<unk> @ 8 milioni di anni , che av<unk> @ evo per il 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , per 4<unk> @ 8 c<unk> @ ento è stato in<unk> @ cre<unk> @ di<unk> @ bile per c<unk> @ ento .
2025-05-27 19:59:10,004 - INFO - joeynmt.training - Example #1
2025-05-27 19:59:10,005 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:59:10,005 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:59:10,005 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è così for<unk> @ te l&apos; in<unk> @ cre<unk> @ di<unk> @ bile problema che la di<unk> @ st<unk> @ in<unk> @ zione di questo part<unk> @ icol<unk> @ are , perché non è il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:59:10,005 - INFO - joeynmt.training - Example #2
2025-05-27 19:59:10,006 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:59:10,006 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:59:10,006 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a è la c<unk> @ ur<unk> @ i<unk> @ os<unk> @ ità del nostro c<unk> @ li<unk> @ ma del nostro c<unk> @ li<unk> @ ma .
2025-05-27 19:59:10,006 - INFO - joeynmt.training - Example #3
2025-05-27 19:59:10,007 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:59:10,007 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:59:10,007 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e la p<unk> @ op<unk> @ ol<unk> @ azione .
2025-05-27 19:59:10,007 - INFO - joeynmt.training - Example #4
2025-05-27 19:59:10,008 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:59:10,008 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:59:10,008 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ am<unk> @ ig<unk> @ lia che vi mostr<unk> @ o è una lin<unk> @ ea di in<unk> @ contr<unk> @ o l&apos; ulti<unk> @ ma 2<unk> @ 5 anni .
2025-05-27 19:59:11,595 - INFO - joeynmt.training - Epoch   7, Step:    52600, Batch Loss:     1.052136, Batch Acc: 0.721824, Tokens per Sec:    39003, Lr: 0.000300
2025-05-27 19:59:13,182 - INFO - joeynmt.training - Epoch   7, Step:    52700, Batch Loss:     0.969910, Batch Acc: 0.722401, Tokens per Sec:    50837, Lr: 0.000300
2025-05-27 19:59:14,753 - INFO - joeynmt.training - Epoch   7, Step:    52800, Batch Loss:     0.946687, Batch Acc: 0.714761, Tokens per Sec:    49395, Lr: 0.000300
2025-05-27 19:59:16,365 - INFO - joeynmt.training - Epoch   7, Step:    52900, Batch Loss:     0.947894, Batch Acc: 0.717765, Tokens per Sec:    50276, Lr: 0.000300
2025-05-27 19:59:17,949 - INFO - joeynmt.training - Epoch   7, Step:    53000, Batch Loss:     0.857063, Batch Acc: 0.721369, Tokens per Sec:    50260, Lr: 0.000300
2025-05-27 19:59:17,950 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:59:17,950 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:09, 100.40it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:07, 119.00it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:06, 127.40it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:05, 144.10it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:05, 151.87it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:07, 101.06it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:08, 87.96it/s] Predicting...:  17%|█▋        | 160/923 [00:01<00:07, 95.41it/s]Predicting...:  20%|██        | 185/923 [00:01<00:05, 123.18it/s]Predicting...:  22%|██▏       | 201/923 [00:01<00:05, 125.02it/s]Predicting...:  24%|██▍       | 224/923 [00:01<00:06, 116.46it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:06, 107.52it/s]Predicting...:  29%|██▉       | 267/923 [00:02<00:08, 79.75it/s] Predicting...:  30%|███       | 277/923 [00:02<00:08, 75.85it/s]Predicting...:  31%|███▏      | 289/923 [00:02<00:08, 71.33it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 77.19it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:07, 77.96it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 82.47it/s]Predicting...:  38%|███▊      | 347/923 [00:03<00:07, 81.61it/s]Predicting...:  39%|███▉      | 361/923 [00:03<00:06, 88.26it/s]Predicting...:  41%|████      | 379/923 [00:03<00:05, 100.89it/s]Predicting...:  43%|████▎     | 393/923 [00:03<00:04, 107.50it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 115.50it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 105.00it/s]Predicting...:  48%|████▊     | 441/923 [00:04<00:04, 110.75it/s]Predicting...:  49%|████▉     | 455/923 [00:04<00:04, 108.23it/s]Predicting...:  51%|█████     | 469/923 [00:04<00:04, 110.23it/s]Predicting...:  54%|█████▎    | 494/923 [00:04<00:04, 105.48it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 88.77it/s] Predicting...:  59%|█████▊    | 540/923 [00:05<00:04, 87.29it/s]Predicting...:  60%|██████    | 556/923 [00:05<00:05, 66.95it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:06, 58.92it/s]Predicting...:  63%|██████▎   | 580/923 [00:06<00:05, 66.17it/s]Predicting...:  65%|██████▍   | 596/923 [00:06<00:06, 50.67it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:06, 50.56it/s]Predicting...:  67%|██████▋   | 618/923 [00:07<00:05, 58.41it/s]Predicting...:  68%|██████▊   | 630/923 [00:07<00:04, 58.77it/s]Predicting...:  69%|██████▉   | 639/923 [00:07<00:05, 56.62it/s]Predicting...:  70%|███████   | 647/923 [00:07<00:05, 52.60it/s]Predicting...:  71%|███████   | 653/923 [00:07<00:06, 43.45it/s]Predicting...:  72%|███████▏  | 661/923 [00:08<00:06, 39.12it/s]Predicting...:  73%|███████▎  | 671/923 [00:08<00:05, 46.36it/s]Predicting...:  73%|███████▎  | 678/923 [00:08<00:06, 38.07it/s]Predicting...:  74%|███████▍  | 687/923 [00:08<00:05, 42.16it/s]Predicting...:  75%|███████▌  | 696/923 [00:09<00:06, 34.70it/s]Predicting...:  77%|███████▋  | 708/923 [00:09<00:04, 45.25it/s]Predicting...:  78%|███████▊  | 717/923 [00:09<00:04, 44.19it/s]Predicting...:  79%|███████▉  | 729/923 [00:09<00:03, 54.58it/s]Predicting...:  80%|████████  | 742/923 [00:09<00:02, 64.94it/s]Predicting...:  82%|████████▏ | 759/923 [00:10<00:03, 49.14it/s]Predicting...:  84%|████████▍ | 774/923 [00:10<00:02, 60.59it/s]Predicting...:  85%|████████▌ | 786/923 [00:10<00:02, 66.04it/s]Predicting...:  87%|████████▋ | 800/923 [00:10<00:01, 77.21it/s]Predicting...:  88%|████████▊ | 815/923 [00:10<00:01, 89.01it/s]Predicting...:  90%|████████▉ | 827/923 [00:10<00:01, 93.94it/s]Predicting...:  92%|█████████▏| 850/923 [00:11<00:00, 74.25it/s]Predicting...:  93%|█████████▎| 862/923 [00:11<00:00, 70.60it/s]Predicting...:  95%|█████████▌| 878/923 [00:11<00:00, 83.26it/s]Predicting...:  97%|█████████▋| 892/923 [00:11<00:00, 92.66it/s]Predicting...: 100%|██████████| 923/923 [00:11<00:00, 123.91it/s]Predicting...: 100%|██████████| 923/923 [00:11<00:00, 78.14it/s] 
2025-05-27 19:59:29,769 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.72, generation: 11.8121[sec], evaluation: 0.0000[sec]
2025-05-27 19:59:30,093 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/51500.ckpt
2025-05-27 19:59:30,115 - INFO - joeynmt.training - Example #0
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due cas<unk> @ e per ri<unk> @ dur<unk> @ re la g<unk> @ hi<unk> @ ac<unk> @ cio che il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio che ha av<unk> @ uto per il 4<unk> @ 0 anni , che ha av<unk> @ uto 4<unk> @ 0 % di questi stati , per 4<unk> @ 0 % , per c<unk> @ ento , per 4<unk> @ 0 % , per c<unk> @ ento .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - Example #1
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:59:30,117 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è molto for<unk> @ te , la di<unk> @ st<unk> @ in<unk> @ zione di questo spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 19:59:30,118 - INFO - joeynmt.training - Example #2
2025-05-27 19:59:30,118 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:59:30,118 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:59:30,118 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a è la g<unk> @ hi<unk> @ ar<unk> @ t<unk> @ ica del nostro c<unk> @ li<unk> @ ente glob<unk> @ ale .
2025-05-27 19:59:30,118 - INFO - joeynmt.training - Example #3
2025-05-27 19:59:30,119 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:59:30,119 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:59:30,119 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e p<unk> @ eg<unk> @ gi<unk> @ o .
2025-05-27 19:59:30,119 - INFO - joeynmt.training - Example #4
2025-05-27 19:59:30,120 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:59:30,120 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:59:30,120 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ ura di sc<unk> @ or<unk> @ so di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:59:31,728 - INFO - joeynmt.training - Epoch   7, Step:    53100, Batch Loss:     0.969383, Batch Acc: 0.715483, Tokens per Sec:    38701, Lr: 0.000300
2025-05-27 19:59:33,274 - INFO - joeynmt.training - Epoch   7, Step:    53200, Batch Loss:     0.974634, Batch Acc: 0.716615, Tokens per Sec:    50635, Lr: 0.000300
2025-05-27 19:59:34,869 - INFO - joeynmt.training - Epoch   7, Step:    53300, Batch Loss:     0.975251, Batch Acc: 0.719924, Tokens per Sec:    51403, Lr: 0.000300
2025-05-27 19:59:36,449 - INFO - joeynmt.training - Epoch   7, Step:    53400, Batch Loss:     1.083496, Batch Acc: 0.719999, Tokens per Sec:    49307, Lr: 0.000300
2025-05-27 19:59:37,977 - INFO - joeynmt.training - Epoch   7, Step:    53500, Batch Loss:     1.029567, Batch Acc: 0.720755, Tokens per Sec:    53138, Lr: 0.000300
2025-05-27 19:59:37,977 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 19:59:37,977 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:08, 106.41it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:06, 137.24it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:05, 147.38it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:05, 139.03it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:12, 62.60it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 52.52it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 60.18it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 67.12it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 73.93it/s]Predicting...:  23%|██▎       | 211/923 [00:02<00:09, 73.93it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 78.68it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 70.87it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 81.98it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 59.42it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 59.44it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 56.16it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 64.16it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 68.89it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 77.14it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 70.16it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 68.34it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 63.65it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 77.45it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 81.34it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 88.14it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 85.79it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 101.07it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 95.34it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 103.34it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:03, 110.43it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 97.11it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 93.44it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:05, 67.39it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 56.97it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 64.45it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:09, 33.66it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:09, 35.19it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 42.48it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 45.64it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 46.02it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 45.65it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 37.31it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 35.53it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 41.72it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 35.20it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 39.51it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:13, 16.99it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:09, 23.80it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:07, 26.81it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:05, 35.64it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 47.17it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.02it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 49.52it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:03, 44.78it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:02, 53.12it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 66.24it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.53it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 62.30it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.66it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 85.33it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 108.37it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 61.36it/s] 
2025-05-27 19:59:53,028 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.00, ppl:   2.73, acc:   0.71, generation: 15.0432[sec], evaluation: 0.0000[sec]
2025-05-27 19:59:53,038 - INFO - joeynmt.training - Example #0
2025-05-27 19:59:53,039 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 19:59:53,039 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 19:59:53,039 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato queste due f<unk> @ ec<unk> @ i per fare una b<unk> @ arri<unk> @ era che le g<unk> @ am<unk> @ be per i g<unk> @ hi<unk> @ ac<unk> @ cio , per il g<unk> @ hi<unk> @ ac<unk> @ cio , per il 4<unk> @ 0 % dei due anni , per il 4<unk> @ 0 per c<unk> @ ento di 4<unk> @ 0 % , per circa 4<unk> @ 0 % , per il 4<unk> @ 0 % .
2025-05-27 19:59:53,039 - INFO - joeynmt.training - Example #1
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza di questo problema spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ i<unk> @ di<unk> @ tà .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - Example #2
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ ca di sen<unk> @ so è la propr<unk> @ ia c<unk> @ ura ar<unk> @ t<unk> @ ica del nostro c<unk> @ li<unk> @ m<unk> @ as<unk> @ ma glob<unk> @ ale .
2025-05-27 19:59:53,040 - INFO - joeynmt.training - Example #3
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e sc<unk> @ or<unk> @ so .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - Example #4
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 19:59:53,041 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ er<unk> @ ò è una sc<unk> @ or<unk> @ sa che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 19:59:54,623 - INFO - joeynmt.training - Epoch   7, Step:    53600, Batch Loss:     1.051299, Batch Acc: 0.716289, Tokens per Sec:    48787, Lr: 0.000300
2025-05-27 19:59:56,155 - INFO - joeynmt.training - Epoch   7, Step:    53700, Batch Loss:     0.904229, Batch Acc: 0.716551, Tokens per Sec:    51460, Lr: 0.000300
2025-05-27 19:59:57,717 - INFO - joeynmt.training - Epoch   7, Step:    53800, Batch Loss:     0.939724, Batch Acc: 0.719157, Tokens per Sec:    49396, Lr: 0.000300
2025-05-27 19:59:59,252 - INFO - joeynmt.training - Epoch   7, Step:    53900, Batch Loss:     1.005880, Batch Acc: 0.717717, Tokens per Sec:    51363, Lr: 0.000300
2025-05-27 20:00:00,850 - INFO - joeynmt.training - Epoch   7, Step:    54000, Batch Loss:     1.073071, Batch Acc: 0.716572, Tokens per Sec:    50353, Lr: 0.000300
2025-05-27 20:00:00,850 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:00:00,850 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 80.26it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 105.93it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 121.78it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:06, 126.40it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:06, 131.35it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 133.82it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:09, 87.04it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:10, 73.33it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:09, 80.03it/s]Predicting...:  20%|██        | 185/923 [00:01<00:07, 102.15it/s]Predicting...:  22%|██▏       | 201/923 [00:01<00:06, 110.09it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 95.14it/s] Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 91.01it/s]Predicting...:  29%|██▉       | 267/923 [00:02<00:09, 70.81it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 68.65it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:09, 64.31it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:08, 69.30it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 72.15it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:07, 77.90it/s]Predicting...:  37%|███▋      | 337/923 [00:03<00:08, 71.28it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 67.55it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 78.15it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 95.10it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:05, 104.99it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:05, 101.11it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:05, 98.07it/s] Predicting...:  48%|████▊     | 441/923 [00:04<00:04, 106.81it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 109.56it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:03, 113.69it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:03, 109.36it/s]Predicting...:  56%|█████▌    | 517/923 [00:05<00:04, 82.95it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 81.53it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:06, 58.75it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:06, 52.59it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 58.20it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:07, 44.60it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:07, 44.18it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 51.15it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 53.00it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 50.64it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:06, 41.72it/s]Predicting...:  71%|███████   | 653/923 [00:08<00:07, 36.01it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 36.46it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 41.42it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 37.87it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:06, 39.22it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:07, 30.39it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:05, 40.07it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:05, 38.97it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:04, 47.83it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:03, 58.57it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 47.86it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 58.49it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:02, 64.70it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 85.78it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 84.10it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:00, 74.05it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 72.97it/s]Predicting...:  95%|█████████▌| 878/923 [00:12<00:00, 84.65it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 80.19it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 90.65it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 70.62it/s]
2025-05-27 20:00:13,928 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.68, acc:   0.72, generation: 13.0701[sec], evaluation: 0.0000[sec]
2025-05-27 20:00:13,928 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:00:14,413 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/50000.ckpt
2025-05-27 20:00:14,436 - INFO - joeynmt.training - Example #0
2025-05-27 20:00:14,438 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:00:14,438 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:00:14,438 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due col<unk> @ ie , per c<unk> @ aus<unk> @ a di c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , che i g<unk> @ hi<unk> @ ac<unk> @ cio , per i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 % dei m<unk> @ ezz<unk> @ i di 4<unk> @ 0 % , il 4<unk> @ 0 % , il 4<unk> @ 0 % , il 4<unk> @ 0 % .
2025-05-27 20:00:14,438 - INFO - joeynmt.training - Example #1
2025-05-27 20:00:14,439 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:00:14,439 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:00:14,439 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza che la cap<unk> @ ac<unk> @ ità di questo problema , perché non è il d<unk> @ ato di questo problema , perché non è il d<unk> @ ic<unk> @ lo , perché non mostr<unk> @ a il li<unk> @ vello del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:00:14,439 - INFO - joeynmt.training - Example #2
2025-05-27 20:00:14,440 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:00:14,440 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:00:14,440 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a è la g<unk> @ hi<unk> @ es<unk> @ ia del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:00:14,440 - INFO - joeynmt.training - Example #3
2025-05-27 20:00:14,441 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:00:14,441 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:00:14,441 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ à in v<unk> @ ento e si ri<unk> @ es<unk> @ ce a s<unk> @ om<unk> @ ma .
2025-05-27 20:00:14,441 - INFO - joeynmt.training - Example #4
2025-05-27 20:00:14,442 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:00:14,442 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:00:14,442 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una ser<unk> @ ie di di<unk> @ seg<unk> @ ni è una ri<unk> @ vi<unk> @ sta di quello che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:00:17,706 - INFO - joeynmt.training - Epoch   7, Step:    54100, Batch Loss:     1.103794, Batch Acc: 0.718718, Tokens per Sec:    20240, Lr: 0.000300
2025-05-27 20:00:21,028 - INFO - joeynmt.training - Epoch   7, Step:    54200, Batch Loss:     0.924506, Batch Acc: 0.718096, Tokens per Sec:    23304, Lr: 0.000300
2025-05-27 20:00:24,368 - INFO - joeynmt.training - Epoch   7, Step:    54300, Batch Loss:     1.001195, Batch Acc: 0.717553, Tokens per Sec:    23496, Lr: 0.000300
2025-05-27 20:00:27,723 - INFO - joeynmt.training - Epoch   7, Step:    54400, Batch Loss:     0.922021, Batch Acc: 0.718443, Tokens per Sec:    23457, Lr: 0.000300
2025-05-27 20:00:31,074 - INFO - joeynmt.training - Epoch   7, Step:    54500, Batch Loss:     1.125536, Batch Acc: 0.721234, Tokens per Sec:    23962, Lr: 0.000300
2025-05-27 20:00:31,074 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:00:31,074 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 72.57it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 87.88it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 93.74it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 94.74it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 109.69it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 120.69it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 121.23it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:12, 63.32it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 54.79it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.34it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 87.05it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 97.56it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 97.28it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 89.54it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 62.26it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 59.20it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 52.99it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 59.16it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.84it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 66.68it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 62.22it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 59.37it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 71.42it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 91.78it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 100.94it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 106.78it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 117.98it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:03, 129.10it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:03, 133.19it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:03, 117.96it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 85.34it/s] Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 91.21it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 58.57it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 54.68it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 60.69it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 42.64it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 41.31it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 49.20it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 52.82it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 49.84it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:05, 46.12it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 37.11it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 36.68it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 39.31it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 34.92it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 40.28it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:08, 27.64it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 36.45it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 37.59it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 44.33it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 56.21it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 45.39it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 55.60it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 61.22it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 73.36it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 82.67it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 86.18it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 62.73it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 65.63it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 85.22it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 83.50it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 66.26it/s]
2025-05-27 20:00:45,012 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.71, generation: 13.9296[sec], evaluation: 0.0000[sec]
2025-05-27 20:00:45,314 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/49500.ckpt
2025-05-27 20:00:45,330 - INFO - joeynmt.training - Example #0
2025-05-27 20:00:45,331 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:00:45,331 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:00:45,331 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due cas<unk> @ i che si sono ri<unk> @ ma<unk> @ sto per di<unk> @ mostr<unk> @ are che la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , per i g<unk> @ am<unk> @ enti di tre milioni di anni , per il 4<unk> @ 0 per c<unk> @ ento di 4<unk> @ 0 % del 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:00:45,332 - INFO - joeynmt.training - Example #1
2025-05-27 20:00:45,332 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:00:45,332 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:00:45,332 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la cosa che non è abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perché non è il de<unk> @ st<unk> @ ino di questo problema .
2025-05-27 20:00:45,332 - INFO - joeynmt.training - Example #2
2025-05-27 20:00:45,333 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:00:45,333 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:00:45,333 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:00:45,333 - INFO - joeynmt.training - Example #3
2025-05-27 20:00:45,334 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:00:45,334 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:00:45,334 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un sen<unk> @ so .
2025-05-27 20:00:45,334 - INFO - joeynmt.training - Example #4
2025-05-27 20:00:45,335 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:00:45,335 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:00:45,335 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ aus<unk> @ a di una c<unk> @ las<unk> @ se che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:00:48,600 - INFO - joeynmt.training - Epoch   7, Step:    54600, Batch Loss:     0.864507, Batch Acc: 0.724240, Tokens per Sec:    22037, Lr: 0.000300
2025-05-27 20:00:51,945 - INFO - joeynmt.training - Epoch   7, Step:    54700, Batch Loss:     0.942118, Batch Acc: 0.719107, Tokens per Sec:    23862, Lr: 0.000300
2025-05-27 20:00:55,273 - INFO - joeynmt.training - Epoch   7, Step:    54800, Batch Loss:     1.020761, Batch Acc: 0.718342, Tokens per Sec:    23794, Lr: 0.000300
2025-05-27 20:00:58,620 - INFO - joeynmt.training - Epoch   7, Step:    54900, Batch Loss:     1.024190, Batch Acc: 0.719716, Tokens per Sec:    23958, Lr: 0.000300
2025-05-27 20:01:01,940 - INFO - joeynmt.training - Epoch   7, Step:    55000, Batch Loss:     1.074166, Batch Acc: 0.722933, Tokens per Sec:    23434, Lr: 0.000300
2025-05-27 20:01:01,940 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:01:01,940 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 86.96it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 91.52it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 101.11it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 104.03it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 97.39it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:07, 108.60it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 72.65it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 87.62it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.25it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 54.61it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.88it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 91.11it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 98.13it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 83.18it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 76.26it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 83.82it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 59.17it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 57.21it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 57.51it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 61.33it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 62.50it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.81it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 69.94it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 60.33it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 71.09it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 87.27it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 87.94it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 93.31it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 87.91it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 95.83it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 96.67it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 99.35it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 84.33it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 90.84it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 69.42it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 73.90it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 56.38it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 50.52it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 55.85it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.42it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 38.41it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:08, 37.39it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 45.81it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 48.70it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 46.18it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:09, 28.76it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 25.84it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:09, 27.54it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 31.87it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 30.38it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 33.46it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 26.57it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 33.23it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.52it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 44.12it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 52.42it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 39.25it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.74it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 51.23it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 52.92it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 63.54it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 71.84it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 76.52it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 59.88it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 61.77it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 74.79it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 80.69it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 93.39it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.84it/s]
2025-05-27 20:01:17,124 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.68, acc:   0.71, generation: 15.1715[sec], evaluation: 0.0000[sec]
2025-05-27 20:01:17,462 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/52000.ckpt
2025-05-27 20:01:17,486 - INFO - joeynmt.training - Example #0
2025-05-27 20:01:17,488 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:01:17,488 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:01:17,488 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so di questi due p<unk> @ ezz<unk> @ i , per ot<unk> @ ten<unk> @ ere i con<unk> @ si<unk> @ der<unk> @ ato per i con<unk> @ to che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano per tre mili<unk> @ ar<unk> @ di di di bas<unk> @ e per tre mili<unk> @ ar<unk> @ di di di di tre milioni di anni , per 4<unk> @ 8 per c<unk> @ ento di tre milioni di anni .
2025-05-27 20:01:17,488 - INFO - joeynmt.training - Example #1
2025-05-27 20:01:17,489 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:01:17,489 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:01:17,489 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza di questo problema , perché non è la di<unk> @ st<unk> @ ha<unk> @ i un problema , non ci mostr<unk> @ a il fatto di E<unk> @ is<unk> @ es .
2025-05-27 20:01:17,489 - INFO - joeynmt.training - Example #2
2025-05-27 20:01:17,490 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:01:17,490 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:01:17,490 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , la c<unk> @ aus<unk> @ a del nostro c<unk> @ li<unk> @ m<unk> @ are il nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:01:17,490 - INFO - joeynmt.training - Example #3
2025-05-27 20:01:17,491 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:01:17,491 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:01:17,491 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ in<unk> @ ver<unk> @ no .
2025-05-27 20:01:17,491 - INFO - joeynmt.training - Example #4
2025-05-27 20:01:17,492 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:01:17,492 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:01:17,492 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ ura sc<unk> @ or<unk> @ sa che è acc<unk> @ a<unk> @ du<unk> @ to in 2<unk> @ 5 anni .
2025-05-27 20:01:20,877 - INFO - joeynmt.training - Epoch   7, Step:    55100, Batch Loss:     0.970567, Batch Acc: 0.720251, Tokens per Sec:    22090, Lr: 0.000300
2025-05-27 20:01:23,404 - INFO - joeynmt.training - Epoch   7: total training loss 7609.72
2025-05-27 20:01:23,405 - INFO - joeynmt.training - EPOCH 8
2025-05-27 20:01:24,244 - INFO - joeynmt.training - Epoch   8, Step:    55200, Batch Loss:     0.832647, Batch Acc: 0.726619, Tokens per Sec:    24229, Lr: 0.000300
2025-05-27 20:01:27,596 - INFO - joeynmt.training - Epoch   8, Step:    55300, Batch Loss:     0.835632, Batch Acc: 0.726820, Tokens per Sec:    24147, Lr: 0.000300
2025-05-27 20:01:30,922 - INFO - joeynmt.training - Epoch   8, Step:    55400, Batch Loss:     0.916764, Batch Acc: 0.730144, Tokens per Sec:    23275, Lr: 0.000300
2025-05-27 20:01:34,279 - INFO - joeynmt.training - Epoch   8, Step:    55500, Batch Loss:     1.006729, Batch Acc: 0.732935, Tokens per Sec:    24829, Lr: 0.000300
2025-05-27 20:01:34,279 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:01:34,280 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 73.43it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 86.71it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.32it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 83.72it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 96.69it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 100.33it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 110.23it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:17, 45.73it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 51.90it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 58.82it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 84.10it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.99it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 84.57it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 78.08it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 82.12it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 51.57it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 50.36it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.79it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.72it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 58.49it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 65.44it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 60.30it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 52.05it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 61.75it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 76.73it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 84.26it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 82.34it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:09, 54.39it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:07, 65.60it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 70.67it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 77.74it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 70.41it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 78.89it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.90it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.26it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 80.47it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 52.48it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 42.94it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 38.70it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 46.47it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 34.57it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 37.03it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.23it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 45.63it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 46.82it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 43.11it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:09, 28.25it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:10, 24.69it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:10, 25.80it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 29.73it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 26.07it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 28.96it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:15, 14.59it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:10, 20.42it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:08, 23.90it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:06, 31.39it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 39.02it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:05, 31.63it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 34.20it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 44.81it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 49.43it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 59.65it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 67.47it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 65.40it/s]Predicting...:  90%|█████████ | 835/923 [00:16<00:01, 46.18it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:00, 61.32it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 71.58it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 77.73it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 77.18it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 53.17it/s]
2025-05-27 20:01:51,652 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.67, acc:   0.72, generation: 17.3585[sec], evaluation: 0.0000[sec]
2025-05-27 20:01:51,653 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:01:52,188 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/53000.ckpt
2025-05-27 20:01:52,210 - INFO - joeynmt.training - Example #0
2025-05-27 20:01:52,212 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:01:52,212 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:01:52,212 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so di questi due cas<unk> @ i , ho mostr<unk> @ ato queste due cose , che non av<unk> @ evo l&apos; in<unk> @ du<unk> @ stri<unk> @ ale , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano che i g<unk> @ over<unk> @ ni , per i tre milioni di anni , che aveva il 4<unk> @ 0 per c<unk> @ ento del 4<unk> @ 0 per c<unk> @ ento , per c<unk> @ ento è stato sp<unk> @ esso .
2025-05-27 20:01:52,212 - INFO - joeynmt.training - Example #1
2025-05-27 20:01:52,213 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:01:52,213 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:01:52,213 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ azione di questo part<unk> @ icol<unk> @ are , perché non è il fatto che il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:01:52,213 - INFO - joeynmt.training - Example #2
2025-05-27 20:01:52,214 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:01:52,214 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:01:52,214 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ t<unk> @ amente , la cosa più po<unk> @ ver<unk> @ a , la c<unk> @ aus<unk> @ a del nostro c<unk> @ li<unk> @ mi<unk> @ zz<unk> @ ante , la c<unk> @ ura del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico .
2025-05-27 20:01:52,214 - INFO - joeynmt.training - Example #3
2025-05-27 20:01:52,215 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:01:52,215 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:01:52,215 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si in<unk> @ ver<unk> @ g<unk> @ og<unk> @ na .
2025-05-27 20:01:52,215 - INFO - joeynmt.training - Example #4
2025-05-27 20:01:52,216 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:01:52,216 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:01:52,216 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ant<unk> @ ast<unk> @ ica che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:01:55,555 - INFO - joeynmt.training - Epoch   8, Step:    55600, Batch Loss:     0.865546, Batch Acc: 0.728781, Tokens per Sec:    20332, Lr: 0.000300
2025-05-27 20:01:58,885 - INFO - joeynmt.training - Epoch   8, Step:    55700, Batch Loss:     0.901741, Batch Acc: 0.728456, Tokens per Sec:    24115, Lr: 0.000300
2025-05-27 20:02:02,207 - INFO - joeynmt.training - Epoch   8, Step:    55800, Batch Loss:     0.836093, Batch Acc: 0.724106, Tokens per Sec:    23753, Lr: 0.000300
2025-05-27 20:02:05,541 - INFO - joeynmt.training - Epoch   8, Step:    55900, Batch Loss:     0.906986, Batch Acc: 0.729602, Tokens per Sec:    24153, Lr: 0.000300
2025-05-27 20:02:08,855 - INFO - joeynmt.training - Epoch   8, Step:    56000, Batch Loss:     0.982921, Batch Acc: 0.723710, Tokens per Sec:    24034, Lr: 0.000300
2025-05-27 20:02:08,856 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:02:08,856 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 71.23it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 91.63it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 100.45it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 98.48it/s] Predicting...:   8%|▊         | 72/923 [00:00<00:08, 102.42it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 109.24it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 105.14it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 107.84it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 51.97it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 57.01it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 65.77it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 89.27it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 96.82it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 83.34it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 80.97it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 86.51it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 60.50it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 60.42it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 58.56it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 64.72it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 69.93it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 80.45it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 76.26it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 84.90it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 100.26it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:04, 106.54it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 113.83it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 95.11it/s] Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 105.67it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 102.01it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 106.08it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 101.62it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 81.76it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 78.97it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:05, 63.60it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 54.88it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 62.66it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:06, 51.94it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:06, 51.40it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 60.65it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 53.92it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 51.47it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 48.54it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:06, 40.39it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:06, 38.95it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:05, 43.27it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 38.23it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:05, 41.75it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:06, 33.69it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:05, 42.10it/s]Predicting...:  78%|███████▊  | 717/923 [00:10<00:05, 39.87it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:04, 46.18it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 55.07it/s]Predicting...:  81%|████████  | 749/923 [00:11<00:03, 44.24it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 46.06it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 57.40it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:02, 64.17it/s]Predicting...:  87%|████████▋ | 800/923 [00:11<00:01, 77.28it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 87.06it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 89.59it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:01, 71.66it/s]Predicting...:  93%|█████████▎| 862/923 [00:12<00:00, 68.31it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 92.90it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 102.17it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 70.32it/s] 
2025-05-27 20:02:21,991 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.69, acc:   0.71, generation: 13.1262[sec], evaluation: 0.0000[sec]
2025-05-27 20:02:21,997 - INFO - joeynmt.training - Example #0
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so per l&apos; anno sc<unk> @ or<unk> @ so per pot<unk> @ er fare queste due f<unk> @ att<unk> @ or<unk> @ ie per la f<unk> @ att<unk> @ or<unk> @ ia di ar<unk> @ t<unk> @ ic<unk> @ l<unk> @ et<unk> @ ta per i ris<unk> @ ol<unk> @ vere i 4<unk> @ 8 milioni di anni , per la fine del 4<unk> @ 0 per c<unk> @ ento .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - Example #1
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza l&apos; in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ ità di questo problema spe<unk> @ ci<unk> @ ale , perché non è il d<unk> @ ato del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:02:21,998 - INFO - joeynmt.training - Example #2
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa po<unk> @ ver<unk> @ a ar<unk> @ t<unk> @ t<unk> @ ic<unk> @ amente la c<unk> @ ura po<unk> @ ver<unk> @ a glob<unk> @ ale .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - Example #3
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si mu<unk> @ ov<unk> @ ono in est<unk> @ ate .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - Example #4
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:02:21,999 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i che vi mostr<unk> @ er<unk> @ ò è una ser<unk> @ ie di ri<unk> @ pres<unk> @ sione che è acc<unk> @ a<unk> @ du<unk> @ to in qu<unk> @ ale è acc<unk> @ a<unk> @ du<unk> @ to negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:02:25,396 - INFO - joeynmt.training - Epoch   8, Step:    56100, Batch Loss:     0.970964, Batch Acc: 0.729042, Tokens per Sec:    22976, Lr: 0.000300
2025-05-27 20:02:28,887 - INFO - joeynmt.training - Epoch   8, Step:    56200, Batch Loss:     0.977907, Batch Acc: 0.725521, Tokens per Sec:    22918, Lr: 0.000300
2025-05-27 20:02:32,220 - INFO - joeynmt.training - Epoch   8, Step:    56300, Batch Loss:     0.960168, Batch Acc: 0.726512, Tokens per Sec:    23570, Lr: 0.000300
2025-05-27 20:02:35,569 - INFO - joeynmt.training - Epoch   8, Step:    56400, Batch Loss:     0.876900, Batch Acc: 0.726602, Tokens per Sec:    23885, Lr: 0.000300
2025-05-27 20:02:38,927 - INFO - joeynmt.training - Epoch   8, Step:    56500, Batch Loss:     0.953993, Batch Acc: 0.728034, Tokens per Sec:    24046, Lr: 0.000300
2025-05-27 20:02:38,928 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:02:38,928 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 78.54it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 93.30it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 98.62it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 99.54it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 99.45it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 114.02it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 114.67it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 88.67it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:17, 46.16it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 51.25it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 61.15it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 84.90it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 93.73it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.76it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 76.54it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 81.93it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 56.67it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 55.99it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 53.25it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 57.84it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 60.73it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.75it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 60.03it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 67.13it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.94it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 87.09it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 91.16it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 95.89it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 100.89it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 94.27it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 94.38it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.77it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 87.75it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 63.72it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 73.83it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 51.83it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 43.90it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 42.00it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.89it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 35.99it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.01it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.93it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 42.98it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.23it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 40.62it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 34.62it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 32.94it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 31.00it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 34.34it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 30.37it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 33.61it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 28.98it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 37.01it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 34.41it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 42.36it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 48.59it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.01it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 39.58it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 48.27it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 52.74it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 60.56it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 71.60it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 71.86it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 49.10it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 62.73it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 59.75it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 71.97it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 74.99it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 85.31it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.24it/s]
2025-05-27 20:02:54,523 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.67, acc:   0.72, generation: 15.5807[sec], evaluation: 0.0000[sec]
2025-05-27 20:02:54,526 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:02:55,066 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/54500.ckpt
2025-05-27 20:02:55,093 - INFO - joeynmt.training - Example #0
2025-05-27 20:02:55,095 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:02:55,095 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:02:55,095 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so che le due volte ho mostr<unk> @ ato questi due col<unk> @ i f<unk> @ ami<unk> @ li<unk> @ ari per ri<unk> @ dur<unk> @ re il g<unk> @ hi<unk> @ ac<unk> @ cio che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per circa 4<unk> @ 8 milioni di anni , che aveva tre milioni di anni , che aveva tre milioni di anni , il 4<unk> @ 8 .
2025-05-27 20:02:55,095 - INFO - joeynmt.training - Example #1
2025-05-27 20:02:55,096 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:02:55,096 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:02:55,096 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la in<unk> @ f<unk> @ lu<unk> @ enza , la giu<unk> @ st<unk> @ izi<unk> @ a , perché non è il D<unk> @ ic<unk> @ ke , perché non è il g<unk> @ hi<unk> @ ac<unk> @ cio del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:02:55,096 - INFO - joeynmt.training - Example #2
2025-05-27 20:02:55,097 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:02:55,097 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:02:55,097 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ ura po<unk> @ ver<unk> @ a è il g<unk> @ hi<unk> @ ac<unk> @ cio c<unk> @ entr<unk> @ ale del nostro c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:02:55,097 - INFO - joeynmt.training - Example #3
2025-05-27 20:02:55,098 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:02:55,098 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:02:55,098 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e in<unk> @ ver<unk> @ no .
2025-05-27 20:02:55,098 - INFO - joeynmt.training - Example #4
2025-05-27 20:02:55,099 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:02:55,099 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:02:55,099 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ami<unk> @ li<unk> @ are è che , è succ<unk> @ esso in un cam<unk> @ po &apos; di sc<unk> @ or<unk> @ so che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:02:58,454 - INFO - joeynmt.training - Epoch   8, Step:    56600, Batch Loss:     0.845121, Batch Acc: 0.729236, Tokens per Sec:    20067, Lr: 0.000300
2025-05-27 20:03:01,778 - INFO - joeynmt.training - Epoch   8, Step:    56700, Batch Loss:     0.955137, Batch Acc: 0.726356, Tokens per Sec:    23004, Lr: 0.000300
2025-05-27 20:03:05,110 - INFO - joeynmt.training - Epoch   8, Step:    56800, Batch Loss:     1.059188, Batch Acc: 0.721777, Tokens per Sec:    24145, Lr: 0.000300
2025-05-27 20:03:08,425 - INFO - joeynmt.training - Epoch   8, Step:    56900, Batch Loss:     1.047122, Batch Acc: 0.722755, Tokens per Sec:    23470, Lr: 0.000300
2025-05-27 20:03:11,762 - INFO - joeynmt.training - Epoch   8, Step:    57000, Batch Loss:     0.918987, Batch Acc: 0.725991, Tokens per Sec:    23887, Lr: 0.000300
2025-05-27 20:03:11,762 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:03:11,762 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 75.63it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 90.37it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.12it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 90.88it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 103.38it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 116.45it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 102.65it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 116.22it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 52.45it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 56.04it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 63.62it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.79it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 95.14it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.64it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 62.58it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 67.30it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:13, 48.11it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:14, 46.81it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 46.63it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 44.96it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 50.30it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 52.96it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 59.18it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 63.30it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 57.36it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 68.02it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 84.02it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 89.58it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 93.27it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 81.81it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 72.68it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 72.70it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 76.78it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 68.14it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:06, 68.57it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 55.56it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 59.95it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 70.84it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:07, 54.23it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 43.58it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 39.40it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 38.41it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 47.02it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 37.19it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 37.52it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.63it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 47.27it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:05, 50.18it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 45.23it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 39.31it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 30.76it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 31.13it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.71it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.28it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:06, 34.02it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 28.46it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 37.02it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 38.03it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 44.04it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 50.52it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.81it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 39.33it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 47.60it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 52.17it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 62.67it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 70.47it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.00it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 53.34it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 67.38it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 44.50it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 57.83it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 64.39it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 78.78it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 57.34it/s]
2025-05-27 20:03:27,874 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.99, ppl:   2.68, acc:   0.72, generation: 16.0977[sec], evaluation: 0.0000[sec]
2025-05-27 20:03:27,880 - INFO - joeynmt.training - Example #0
2025-05-27 20:03:27,880 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:03:27,880 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:03:27,880 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so di questi due sono i tre milioni di persone che av<unk> @ evo due o , per con<unk> @ si<unk> @ der<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio che l&apos; ar<unk> @ t<unk> @ ic<unk> @ e<unk> @ o , che l&apos; ho av<unk> @ uto tre milioni di anni , che aveva tre milioni di anni , che aveva av<unk> @ uto tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 , il 4<unk> @ 0 per c<unk> @ ento è stato in<unk> @ tr<unk> @ att<unk> @ ato .
2025-05-27 20:03:27,880 - INFO - joeynmt.training - Example #1
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza la ver<unk> @ ità non è abb<unk> @ ast<unk> @ anza il ris<unk> @ ult<unk> @ ato di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:03:27,881 - INFO - joeynmt.training - Example #2
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:03:27,881 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ i<unk> @ ché la c<unk> @ li<unk> @ mat<unk> @ ica è il g<unk> @ hi<unk> @ ac<unk> @ cio del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - Example #3
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ oc<unk> @ e e sp<unk> @ azz<unk> @ at<unk> @ ura .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - Example #4
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:03:27,882 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ec<unk> @ i che vi mostr<unk> @ o è una sc<unk> @ at<unk> @ ola che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:03:31,233 - INFO - joeynmt.training - Epoch   8, Step:    57100, Batch Loss:     0.977826, Batch Acc: 0.720254, Tokens per Sec:    23864, Lr: 0.000300
2025-05-27 20:03:34,560 - INFO - joeynmt.training - Epoch   8, Step:    57200, Batch Loss:     0.982867, Batch Acc: 0.722773, Tokens per Sec:    23112, Lr: 0.000300
2025-05-27 20:03:37,789 - INFO - joeynmt.training - Epoch   8, Step:    57300, Batch Loss:     0.830619, Batch Acc: 0.727495, Tokens per Sec:    24419, Lr: 0.000300
2025-05-27 20:03:40,990 - INFO - joeynmt.training - Epoch   8, Step:    57400, Batch Loss:     0.967940, Batch Acc: 0.722503, Tokens per Sec:    24202, Lr: 0.000300
2025-05-27 20:03:44,237 - INFO - joeynmt.training - Epoch   8, Step:    57500, Batch Loss:     1.075971, Batch Acc: 0.726320, Tokens per Sec:    24901, Lr: 0.000300
2025-05-27 20:03:44,237 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:03:44,238 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 74.02it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 100.41it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 112.02it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 107.62it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 117.90it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 116.59it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 127.20it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 58.34it/s] Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.70it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 76.49it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 84.33it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 78.84it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:09, 71.96it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 81.01it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 53.79it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 53.92it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 51.14it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 56.61it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.81it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 67.61it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 61.01it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:10, 56.73it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 67.26it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 80.91it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 89.36it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 84.21it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 97.18it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 98.03it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 74.15it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 80.97it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.78it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 84.31it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 74.50it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 82.95it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 54.84it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 48.55it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 45.36it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 53.30it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:07, 42.98it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 40.64it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 41.97it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:05, 51.25it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.71it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 43.02it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.98it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.83it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 31.63it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 36.47it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 31.48it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.10it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 29.33it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 38.87it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 38.77it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 45.40it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 54.15it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 43.40it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 48.31it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 57.82it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 61.21it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 73.40it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 81.08it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 82.32it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 66.77it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 68.63it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 83.63it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 89.78it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 103.01it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 63.27it/s] 
2025-05-27 20:03:58,839 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 14.5883[sec], evaluation: 0.0000[sec]
2025-05-27 20:03:58,840 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:03:59,319 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/52500.ckpt
2025-05-27 20:03:59,337 - INFO - joeynmt.training - Example #0
2025-05-27 20:03:59,339 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:03:59,339 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:03:59,339 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ec<unk> @ i , per tras<unk> @ cor<unk> @ r<unk> @ ere il g<unk> @ hi<unk> @ ac<unk> @ cio che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano per tre milioni di volte , che aveva tre milioni di persone che hanno av<unk> @ uto il 4<unk> @ 0 % di persone che aveva av<unk> @ uto 4<unk> @ 0 % .
2025-05-27 20:03:59,339 - INFO - joeynmt.training - Example #1
2025-05-27 20:03:59,340 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:03:59,340 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:03:59,340 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza in<unk> @ tel<unk> @ li<unk> @ g<unk> @ enti di questo problema spe<unk> @ ci<unk> @ ale , perché non è il problema .
2025-05-27 20:03:59,340 - INFO - joeynmt.training - Example #2
2025-05-27 20:03:59,341 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:03:59,341 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:03:59,341 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ perim<unk> @ ent<unk> @ azione po<unk> @ ver<unk> @ a il nostro s<unk> @ ac<unk> @ co di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale .
2025-05-27 20:03:59,341 - INFO - joeynmt.training - Example #3
2025-05-27 20:03:59,342 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:03:59,342 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:03:59,342 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , si ri<unk> @ es<unk> @ ce nel v<unk> @ ento e sp<unk> @ ost<unk> @ arsi nel sen<unk> @ so di .
2025-05-27 20:03:59,342 - INFO - joeynmt.training - Example #4
2025-05-27 20:03:59,342 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:03:59,343 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:03:59,343 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma f<unk> @ ig<unk> @ lia che vi mostr<unk> @ er<unk> @ ò è una sc<unk> @ or<unk> @ sa che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:04:02,621 - INFO - joeynmt.training - Epoch   8, Step:    57600, Batch Loss:     0.861217, Batch Acc: 0.724293, Tokens per Sec:    21165, Lr: 0.000300
2025-05-27 20:04:05,891 - INFO - joeynmt.training - Epoch   8, Step:    57700, Batch Loss:     0.829147, Batch Acc: 0.725260, Tokens per Sec:    24595, Lr: 0.000300
2025-05-27 20:04:09,220 - INFO - joeynmt.training - Epoch   8, Step:    57800, Batch Loss:     0.926882, Batch Acc: 0.727870, Tokens per Sec:    24787, Lr: 0.000300
2025-05-27 20:04:12,550 - INFO - joeynmt.training - Epoch   8, Step:    57900, Batch Loss:     0.934220, Batch Acc: 0.725572, Tokens per Sec:    23953, Lr: 0.000300
2025-05-27 20:04:15,869 - INFO - joeynmt.training - Epoch   8, Step:    58000, Batch Loss:     0.987032, Batch Acc: 0.720879, Tokens per Sec:    23728, Lr: 0.000300
2025-05-27 20:04:15,869 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:04:15,869 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 71.58it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 86.64it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 97.13it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 102.51it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 112.63it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 121.90it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 111.58it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 121.17it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 46.64it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 50.40it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 57.94it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.73it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 92.52it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.97it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 80.19it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 84.13it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 58.02it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 54.65it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 57.58it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 62.69it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 63.36it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 73.09it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 68.09it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 74.56it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 84.44it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 87.87it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 93.11it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 90.96it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 98.03it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:05, 89.69it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 95.44it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 86.04it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 87.39it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 66.72it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 68.26it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 79.44it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 62.06it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 47.04it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:09, 38.87it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 36.35it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 44.35it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 35.84it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:09, 35.69it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.66it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 42.56it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 43.42it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:07, 39.04it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 34.60it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 26.83it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:09, 26.78it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 31.19it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:09, 27.05it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 30.40it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 28.00it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 36.37it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.86it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 42.38it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 52.78it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.15it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.27it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 53.32it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 54.85it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 65.13it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 73.32it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.28it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 48.25it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 60.83it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 62.92it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 78.87it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 82.77it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 87.38it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.87it/s]
2025-05-27 20:04:31,298 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 15.4162[sec], evaluation: 0.0000[sec]
2025-05-27 20:04:31,669 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/55000.ckpt
2025-05-27 20:04:31,695 - INFO - joeynmt.training - Example #0
2025-05-27 20:04:31,696 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:04:31,696 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:04:31,696 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questa due di<unk> @ mostr<unk> @ a che le due di<unk> @ ta di tre milioni di anni , che è stato il g<unk> @ hi<unk> @ ac<unk> @ cio , che il g<unk> @ hi<unk> @ ac<unk> @ cio , che ha fatto per tre milioni di anni , che ha fatto per tre milioni di anni , che aveva tre milioni di anni , che aveva tre milioni di anni , il 4<unk> @ 0 .
2025-05-27 20:04:31,696 - INFO - joeynmt.training - Example #1
2025-05-27 20:04:31,697 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:04:31,697 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:04:31,697 - INFO - joeynmt.training - 	Hypothesis: Ma questo non sembr<unk> @ a essere abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perché non è il D<unk> @ ic<unk> @ co di E<unk> @ is<unk> @ s<unk> @ sa .
2025-05-27 20:04:31,697 - INFO - joeynmt.training - Example #2
2025-05-27 20:04:31,698 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:04:31,698 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:04:31,698 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il suo f<unk> @ en<unk> @ om<unk> @ en<unk> @ o è il g<unk> @ hi<unk> @ ac<unk> @ cio più po<unk> @ ver<unk> @ a il nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:04:31,699 - INFO - joeynmt.training - Example #3
2025-05-27 20:04:31,699 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:04:31,699 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:04:31,699 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ento e sp<unk> @ eg<unk> @ n<unk> @ ata .
2025-05-27 20:04:31,699 - INFO - joeynmt.training - Example #4
2025-05-27 20:04:31,700 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:04:31,700 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:04:31,700 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o , è una sc<unk> @ at<unk> @ ola che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:04:35,041 - INFO - joeynmt.training - Epoch   8, Step:    58100, Batch Loss:     0.869903, Batch Acc: 0.721736, Tokens per Sec:    20906, Lr: 0.000300
2025-05-27 20:04:38,365 - INFO - joeynmt.training - Epoch   8, Step:    58200, Batch Loss:     0.945279, Batch Acc: 0.727009, Tokens per Sec:    24092, Lr: 0.000300
2025-05-27 20:04:41,680 - INFO - joeynmt.training - Epoch   8, Step:    58300, Batch Loss:     0.983631, Batch Acc: 0.724972, Tokens per Sec:    23371, Lr: 0.000300
2025-05-27 20:04:45,039 - INFO - joeynmt.training - Epoch   8, Step:    58400, Batch Loss:     0.950355, Batch Acc: 0.727241, Tokens per Sec:    24576, Lr: 0.000300
2025-05-27 20:04:48,393 - INFO - joeynmt.training - Epoch   8, Step:    58500, Batch Loss:     0.867925, Batch Acc: 0.727380, Tokens per Sec:    24187, Lr: 0.000300
2025-05-27 20:04:48,393 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:04:48,393 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 70.56it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 91.96it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 104.57it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 110.18it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 120.30it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 131.62it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 126.98it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:09, 86.73it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:09, 78.63it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:08, 86.90it/s]Predicting...:  20%|██        | 185/923 [00:01<00:06, 114.52it/s]Predicting...:  22%|██▏       | 201/923 [00:01<00:06, 117.56it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:06, 101.41it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 91.27it/s] Predicting...:  29%|██▉       | 267/923 [00:02<00:09, 69.75it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 67.98it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:09, 64.50it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 67.15it/s]Predicting...:  34%|███▍      | 314/923 [00:03<00:08, 71.54it/s]Predicting...:  35%|███▌      | 327/923 [00:03<00:08, 72.86it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:07, 78.15it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 85.58it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:04, 108.24it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 104.59it/s]Predicting...:  46%|████▌     | 424/923 [00:04<00:04, 102.41it/s]Predicting...:  48%|████▊     | 441/923 [00:04<00:04, 113.57it/s]Predicting...:  49%|████▉     | 455/923 [00:04<00:04, 105.64it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 112.59it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 99.05it/s] Predicting...:  56%|█████▌    | 517/923 [00:05<00:05, 80.78it/s]Predicting...:  58%|█████▊    | 531/923 [00:05<00:04, 88.78it/s]Predicting...:  59%|█████▉    | 548/923 [00:06<00:06, 61.47it/s]Predicting...:  62%|██████▏   | 568/923 [00:06<00:06, 54.83it/s]Predicting...:  63%|██████▎   | 580/923 [00:06<00:05, 60.00it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:06, 48.74it/s]Predicting...:  66%|██████▌   | 605/923 [00:07<00:06, 48.08it/s]Predicting...:  67%|██████▋   | 618/923 [00:07<00:05, 56.76it/s]Predicting...:  68%|██████▊   | 630/923 [00:07<00:04, 59.38it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 55.26it/s]Predicting...:  70%|███████   | 647/923 [00:08<00:05, 52.21it/s]Predicting...:  71%|███████   | 653/923 [00:08<00:05, 45.39it/s]Predicting...:  72%|███████▏  | 661/923 [00:08<00:05, 44.21it/s]Predicting...:  73%|███████▎  | 671/923 [00:08<00:05, 48.42it/s]Predicting...:  73%|███████▎  | 678/923 [00:09<00:06, 40.53it/s]Predicting...:  74%|███████▍  | 687/923 [00:09<00:05, 45.28it/s]Predicting...:  75%|███████▌  | 696/923 [00:09<00:05, 40.08it/s]Predicting...:  77%|███████▋  | 708/923 [00:09<00:04, 51.31it/s]Predicting...:  78%|███████▊  | 717/923 [00:09<00:04, 47.30it/s]Predicting...:  79%|███████▉  | 729/923 [00:10<00:03, 57.65it/s]Predicting...:  80%|████████  | 742/923 [00:10<00:02, 68.99it/s]Predicting...:  82%|████████▏ | 759/923 [00:10<00:03, 43.85it/s]Predicting...:  84%|████████▍ | 774/923 [00:10<00:02, 51.92it/s]Predicting...:  85%|████████▌ | 786/923 [00:11<00:02, 58.16it/s]Predicting...:  88%|████████▊ | 815/923 [00:11<00:01, 79.33it/s]Predicting...:  90%|████████▉ | 827/923 [00:11<00:01, 80.80it/s]Predicting...:  92%|█████████▏| 850/923 [00:11<00:00, 73.47it/s]Predicting...:  93%|█████████▎| 862/923 [00:11<00:00, 69.00it/s]Predicting...:  97%|█████████▋| 892/923 [00:12<00:00, 89.72it/s]Predicting...:  98%|█████████▊| 908/923 [00:12<00:00, 99.90it/s]Predicting...: 100%|██████████| 923/923 [00:12<00:00, 74.54it/s]
2025-05-27 20:05:00,785 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 12.3832[sec], evaluation: 0.0000[sec]
2025-05-27 20:05:00,786 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:05:01,280 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/54000.ckpt
2025-05-27 20:05:01,305 - INFO - joeynmt.training - Example #0
2025-05-27 20:05:01,306 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:05:01,306 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:05:01,306 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose che si sono ri<unk> @ ma<unk> @ sto per s<unk> @ par<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io di tre milioni di anni , che l&apos; hanno av<unk> @ uto tre milioni di anni , che aveva tre milioni di anni , che aveva tre milioni di anni , che aveva fatto per il 4<unk> @ 8 o del 4<unk> @ 8 pa<unk> @ esi , per il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:05:01,306 - INFO - joeynmt.training - Example #1
2025-05-27 20:05:01,307 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:05:01,307 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:05:01,307 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza la ris<unk> @ post<unk> @ a è abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are , perché non è il D<unk> @ ic<unk> @ ke .
2025-05-27 20:05:01,307 - INFO - joeynmt.training - Example #2
2025-05-27 20:05:01,308 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:05:01,308 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:05:01,308 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ ura di g<unk> @ hi<unk> @ ac<unk> @ cio è il sistema di c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 20:05:01,308 - INFO - joeynmt.training - Example #3
2025-05-27 20:05:01,309 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:05:01,309 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:05:01,309 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e in<unk> @ ver<unk> @ no .
2025-05-27 20:05:01,309 - INFO - joeynmt.training - Example #4
2025-05-27 20:05:01,310 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:05:01,310 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:05:01,310 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una sc<unk> @ oper<unk> @ ta di una ser<unk> @ ie di sc<unk> @ or<unk> @ so che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:05:04,604 - INFO - joeynmt.training - Epoch   8, Step:    58600, Batch Loss:     0.906940, Batch Acc: 0.727501, Tokens per Sec:    20869, Lr: 0.000300
2025-05-27 20:05:07,928 - INFO - joeynmt.training - Epoch   8, Step:    58700, Batch Loss:     0.896413, Batch Acc: 0.721611, Tokens per Sec:    23144, Lr: 0.000300
2025-05-27 20:05:11,253 - INFO - joeynmt.training - Epoch   8, Step:    58800, Batch Loss:     0.948070, Batch Acc: 0.723784, Tokens per Sec:    23812, Lr: 0.000300
2025-05-27 20:05:14,571 - INFO - joeynmt.training - Epoch   8, Step:    58900, Batch Loss:     0.882876, Batch Acc: 0.727058, Tokens per Sec:    23831, Lr: 0.000300
2025-05-27 20:05:17,921 - INFO - joeynmt.training - Epoch   8, Step:    59000, Batch Loss:     0.955374, Batch Acc: 0.719520, Tokens per Sec:    23653, Lr: 0.000300
2025-05-27 20:05:17,921 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:05:17,921 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 86.14it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 98.00it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 107.34it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 107.26it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 88.76it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:08, 104.06it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 104.45it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 118.56it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:14, 53.64it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 60.74it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 63.03it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 89.13it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 99.92it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.91it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:09, 71.21it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 78.75it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 53.78it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 51.42it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 49.89it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.28it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.23it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 66.39it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 60.38it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:10, 54.31it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 65.05it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 84.41it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 93.71it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 96.18it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 87.46it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 101.55it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 96.25it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 95.95it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 83.78it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 88.21it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 58.16it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 68.48it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 48.37it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 46.59it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 44.49it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.90it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 40.84it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 38.45it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 38.78it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 47.66it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 49.29it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 44.59it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:09, 28.68it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:14, 18.23it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:12, 20.23it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:10, 25.14it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:10, 24.08it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 28.26it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 25.32it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 35.07it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:05, 34.65it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 41.72it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 51.92it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 42.58it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 46.61it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 59.16it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 67.83it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 93.37it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 93.63it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:00, 75.79it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 73.57it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 87.72it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 95.69it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 128.30it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.18it/s] 
2025-05-27 20:05:33,268 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 15.3382[sec], evaluation: 0.0000[sec]
2025-05-27 20:05:33,597 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/55500.ckpt
2025-05-27 20:05:33,619 - INFO - joeynmt.training - Example #0
2025-05-27 20:05:33,620 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:05:33,620 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:05:33,620 - INFO - joeynmt.training - 	Hypothesis: L<unk> @ o sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due cose , per fare per c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i ter<unk> @ n<unk> @ ati<unk> @ vi , per i tre milioni di anni , il 4<unk> @ 8 milioni di anni , il 4<unk> @ 0 per c<unk> @ ento è stato m<unk> @ and<unk> @ ato a tre milioni di anni .
2025-05-27 20:05:33,620 - INFO - joeynmt.training - Example #1
2025-05-27 20:05:33,621 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:05:33,621 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:05:33,621 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ f<unk> @ ico , perché non è il D<unk> @ ic<unk> @ co di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:05:33,622 - INFO - joeynmt.training - Example #2
2025-05-27 20:05:33,622 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:05:33,622 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:05:33,623 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ata del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 20:05:33,623 - INFO - joeynmt.training - Example #3
2025-05-27 20:05:33,623 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:05:33,623 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:05:33,623 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e sp<unk> @ or<unk> @ g<unk> @ ere in est<unk> @ ate .
2025-05-27 20:05:33,624 - INFO - joeynmt.training - Example #4
2025-05-27 20:05:33,624 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:05:33,624 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:05:33,624 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una di<unk> @ men<unk> @ sione che vi mostr<unk> @ er<unk> @ ò una ser<unk> @ ie di di<unk> @ seg<unk> @ no , è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:05:36,905 - INFO - joeynmt.training - Epoch   8, Step:    59100, Batch Loss:     1.046824, Batch Acc: 0.723724, Tokens per Sec:    21393, Lr: 0.000300
2025-05-27 20:05:40,235 - INFO - joeynmt.training - Epoch   8, Step:    59200, Batch Loss:     0.952020, Batch Acc: 0.723345, Tokens per Sec:    23746, Lr: 0.000300
2025-05-27 20:05:43,571 - INFO - joeynmt.training - Epoch   8, Step:    59300, Batch Loss:     1.006374, Batch Acc: 0.723797, Tokens per Sec:    23362, Lr: 0.000300
2025-05-27 20:05:46,905 - INFO - joeynmt.training - Epoch   8, Step:    59400, Batch Loss:     0.960032, Batch Acc: 0.725800, Tokens per Sec:    23790, Lr: 0.000300
2025-05-27 20:05:50,234 - INFO - joeynmt.training - Epoch   8, Step:    59500, Batch Loss:     0.891898, Batch Acc: 0.720716, Tokens per Sec:    24143, Lr: 0.000300
2025-05-27 20:05:50,234 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:05:50,235 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 66.72it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 76.10it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 88.36it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 89.41it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 79.04it/s]Predicting...:  10%|▉         | 88/923 [00:01<00:08, 95.07it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 101.91it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 116.24it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.51it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 55.17it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 65.07it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 92.41it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 96.30it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 80.31it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:12, 55.73it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 62.77it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 54.71it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:13, 49.52it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 48.43it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 45.15it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 48.66it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 52.76it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 55.24it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 61.32it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 49.35it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 60.58it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.14it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 92.70it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 75.91it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 86.86it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 100.53it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 90.27it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 92.63it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.82it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 82.45it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 57.45it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 60.35it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 70.09it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 58.35it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 48.92it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 44.51it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 38.97it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 45.34it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 34.08it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:10, 31.38it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 33.35it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 43.03it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 41.37it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 39.65it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:09, 28.14it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:11, 23.32it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:11, 23.70it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:09, 27.67it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 25.35it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 28.49it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:09, 23.40it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 31.10it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 30.17it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 37.93it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 49.71it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 41.55it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:03, 41.46it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 51.65it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 54.84it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:01, 61.84it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 71.47it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 73.18it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 50.58it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 65.86it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:00, 67.95it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 82.89it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 87.94it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 102.15it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.00it/s] 
2025-05-27 20:06:06,731 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.65, acc:   0.72, generation: 16.4831[sec], evaluation: 0.0000[sec]
2025-05-27 20:06:07,091 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/56500.ckpt
2025-05-27 20:06:07,117 - INFO - joeynmt.training - Example #0
2025-05-27 20:06:07,118 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:06:07,118 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:06:07,118 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due cose che sono per per di<unk> @ mostr<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ cio per i ris<unk> @ ult<unk> @ ati , che i g<unk> @ hi<unk> @ ac<unk> @ cio che ha av<unk> @ uto per i ris<unk> @ ol<unk> @ vere , per i cas<unk> @ i di circa 4<unk> @ 8 milioni di anni , aveva fatto , il 4<unk> @ 8 , per c<unk> @ ento è stato s<unk> @ otto i 4<unk> @ 8 % , per c<unk> @ ento è stato in<unk> @ segn<unk> @ ato .
2025-05-27 20:06:07,119 - INFO - joeynmt.training - Example #1
2025-05-27 20:06:07,120 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:06:07,120 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:06:07,120 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ t<unk> @ eg<unk> @ gi<unk> @ o la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perché non ci mostr<unk> @ a il ci<unk> @ b<unk> @ o del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:06:07,120 - INFO - joeynmt.training - Example #2
2025-05-27 20:06:07,121 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:06:07,121 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:06:07,121 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cu<unk> @ ore po<unk> @ ver<unk> @ a è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 20:06:07,121 - INFO - joeynmt.training - Example #3
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ in<unk> @ no e sp<unk> @ or<unk> @ co .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - Example #4
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:06:07,122 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ ura di queste cose è una c<unk> @ ura di queste ulti<unk> @ me 2<unk> @ 5 anni .
2025-05-27 20:06:10,471 - INFO - joeynmt.training - Epoch   8, Step:    59600, Batch Loss:     0.956957, Batch Acc: 0.725553, Tokens per Sec:    21586, Lr: 0.000300
2025-05-27 20:06:13,797 - INFO - joeynmt.training - Epoch   8, Step:    59700, Batch Loss:     0.967702, Batch Acc: 0.725328, Tokens per Sec:    23907, Lr: 0.000300
2025-05-27 20:06:17,096 - INFO - joeynmt.training - Epoch   8, Step:    59800, Batch Loss:     0.937669, Batch Acc: 0.726265, Tokens per Sec:    23363, Lr: 0.000300
2025-05-27 20:06:20,424 - INFO - joeynmt.training - Epoch   8, Step:    59900, Batch Loss:     0.947396, Batch Acc: 0.729186, Tokens per Sec:    24275, Lr: 0.000300
2025-05-27 20:06:23,718 - INFO - joeynmt.training - Epoch   8, Step:    60000, Batch Loss:     0.915935, Batch Acc: 0.726619, Tokens per Sec:    23531, Lr: 0.000300
2025-05-27 20:06:23,719 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:06:23,719 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 69.57it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 80.71it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 89.82it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 90.04it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 99.38it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 110.41it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 103.80it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 116.15it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 49.09it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 52.35it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 59.14it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.94it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 88.23it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 76.80it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 76.34it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 74.44it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 59.43it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 51.72it/s]Predicting...:  30%|███       | 277/923 [00:03<00:13, 49.65it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:14, 45.01it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.19it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.78it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 61.41it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 56.51it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 51.38it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 60.17it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 76.13it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 79.54it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 84.59it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 83.54it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 88.69it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 91.68it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 89.26it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 75.44it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 78.14it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.67it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.22it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 76.17it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 59.80it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 51.36it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 48.11it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 45.30it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 55.10it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 41.51it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 40.55it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.28it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 43.99it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 45.02it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 42.27it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:10, 26.87it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:11, 24.13it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:10, 25.43it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 30.39it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:09, 26.89it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 30.25it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:09, 24.64it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 32.57it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 32.25it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 39.75it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 48.26it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 39.27it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 39.84it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 49.35it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 55.26it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 62.47it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 70.34it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 68.48it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 50.63it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 62.55it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 62.07it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 70.93it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 76.27it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 87.41it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 97.35it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 57.36it/s]
2025-05-27 20:06:39,825 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 16.0918[sec], evaluation: 0.0000[sec]
2025-05-27 20:06:40,210 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/58000.ckpt
2025-05-27 20:06:40,236 - INFO - joeynmt.training - Example #0
2025-05-27 20:06:40,237 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:06:40,238 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:06:40,238 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due f<unk> @ ut<unk> @ ure per di<unk> @ mostr<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io di milioni di m<unk> @ oti<unk> @ vi per tre milioni di m<unk> @ oti<unk> @ v<unk> @ azioni , per il 4<unk> @ 8 % dei 4<unk> @ 8 % .
2025-05-27 20:06:40,238 - INFO - joeynmt.training - Example #1
2025-05-27 20:06:40,239 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:06:40,239 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:06:40,239 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza di questo problema spe<unk> @ ci<unk> @ f<unk> @ ico , perché non è il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ -<unk> @ o<unk> @ -<unk> @ di<unk> @ mostr<unk> @ a il ci<unk> @ b<unk> @ o .
2025-05-27 20:06:40,239 - INFO - joeynmt.training - Example #2
2025-05-27 20:06:40,240 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:06:40,240 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:06:40,240 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:06:40,240 - INFO - joeynmt.training - Example #3
2025-05-27 20:06:40,241 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:06:40,241 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:06:40,241 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di s<unk> @ otto , e sp<unk> @ ost<unk> @ a in ter<unk> @ m<unk> @ ini di sp<unk> @ ost<unk> @ a .
2025-05-27 20:06:40,241 - INFO - joeynmt.training - Example #4
2025-05-27 20:06:40,242 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:06:40,242 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:06:40,242 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a che mostr<unk> @ a la cosa che è acc<unk> @ a<unk> @ du<unk> @ to negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:06:43,596 - INFO - joeynmt.training - Epoch   8, Step:    60100, Batch Loss:     0.907745, Batch Acc: 0.727528, Tokens per Sec:    21608, Lr: 0.000300
2025-05-27 20:06:46,934 - INFO - joeynmt.training - Epoch   8, Step:    60200, Batch Loss:     0.876212, Batch Acc: 0.725155, Tokens per Sec:    23550, Lr: 0.000300
2025-05-27 20:06:50,249 - INFO - joeynmt.training - Epoch   8, Step:    60300, Batch Loss:     1.051937, Batch Acc: 0.725409, Tokens per Sec:    23730, Lr: 0.000300
2025-05-27 20:06:53,562 - INFO - joeynmt.training - Epoch   8, Step:    60400, Batch Loss:     0.970691, Batch Acc: 0.727848, Tokens per Sec:    24092, Lr: 0.000300
2025-05-27 20:06:56,901 - INFO - joeynmt.training - Epoch   8, Step:    60500, Batch Loss:     1.004747, Batch Acc: 0.726003, Tokens per Sec:    24243, Lr: 0.000300
2025-05-27 20:06:56,902 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:06:56,902 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 68.89it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 99.40it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 106.77it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 111.72it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 116.39it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 114.05it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 122.35it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 49.95it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:14, 53.00it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 61.09it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 87.18it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 91.93it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 72.67it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:09, 73.58it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 78.92it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 64.00it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 62.01it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:12, 51.97it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.09it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.44it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 56.56it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 59.73it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 65.67it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 80.84it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 85.24it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 89.37it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 86.61it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 99.62it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 95.18it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 100.42it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 102.88it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 75.73it/s] Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 82.86it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 58.16it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 52.96it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 45.13it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 49.17it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.30it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 38.48it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.46it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 45.61it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 43.27it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:07, 39.74it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:10, 26.24it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:11, 23.05it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:12, 21.07it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:09, 27.06it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:09, 26.25it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 31.52it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 30.07it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 40.75it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 38.25it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 43.85it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 51.60it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.61it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 38.60it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 46.39it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 51.79it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 62.38it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 69.08it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 69.20it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 48.90it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 58.66it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 54.68it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 71.28it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 77.99it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 91.56it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.03it/s]
2025-05-27 20:07:12,547 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 15.6360[sec], evaluation: 0.0000[sec]
2025-05-27 20:07:12,863 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/57500.ckpt
2025-05-27 20:07:12,886 - INFO - joeynmt.training - Example #0
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due f<unk> @ re , per ri<unk> @ un<unk> @ ire per di<unk> @ mostr<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io di anni , per il g<unk> @ hi<unk> @ ac<unk> @ cio , per i tre milioni di di di di di m<unk> @ oti<unk> @ vi per tre milioni di anni , il 4<unk> @ 8 .
2025-05-27 20:07:12,888 - INFO - joeynmt.training - Example #1
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:07:12,888 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:07:12,889 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perché non è il D<unk> @ ic<unk> @ i<unk> @ di<unk> @ rit<unk> @ t<unk> @ ura perché non è il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ -<unk> @ e<unk> @ -<unk> @ e<unk> @ -<unk> @ e<unk> @ -<unk> @ di<unk> @ mostr<unk> @ a .
2025-05-27 20:07:12,889 - INFO - joeynmt.training - Example #2
2025-05-27 20:07:12,889 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:07:12,889 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:07:12,890 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa po<unk> @ ver<unk> @ a il con<unk> @ su<unk> @ mo di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ mit<unk> @ ato glob<unk> @ ale .
2025-05-27 20:07:12,890 - INFO - joeynmt.training - Example #3
2025-05-27 20:07:12,890 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:07:12,890 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:07:12,890 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di nel v<unk> @ ento e si ri<unk> @ un<unk> @ is<unk> @ ce nel sen<unk> @ so .
2025-05-27 20:07:12,891 - INFO - joeynmt.training - Example #4
2025-05-27 20:07:12,891 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:07:12,891 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:07:12,891 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ ata che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:07:16,171 - INFO - joeynmt.training - Epoch   8, Step:    60600, Batch Loss:     0.968528, Batch Acc: 0.722152, Tokens per Sec:    21307, Lr: 0.000300
2025-05-27 20:07:19,510 - INFO - joeynmt.training - Epoch   8, Step:    60700, Batch Loss:     0.889202, Batch Acc: 0.724981, Tokens per Sec:    24085, Lr: 0.000300
2025-05-27 20:07:22,840 - INFO - joeynmt.training - Epoch   8, Step:    60800, Batch Loss:     0.993212, Batch Acc: 0.726207, Tokens per Sec:    24072, Lr: 0.000300
2025-05-27 20:07:26,189 - INFO - joeynmt.training - Epoch   8, Step:    60900, Batch Loss:     0.883454, Batch Acc: 0.719330, Tokens per Sec:    23756, Lr: 0.000300
2025-05-27 20:07:29,501 - INFO - joeynmt.training - Epoch   8, Step:    61000, Batch Loss:     0.918673, Batch Acc: 0.724677, Tokens per Sec:    23559, Lr: 0.000300
2025-05-27 20:07:29,501 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:07:29,501 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 73.29it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 91.54it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 101.76it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 88.00it/s] Predicting...:   8%|▊         | 72/923 [00:00<00:09, 91.56it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 103.14it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 104.19it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 117.17it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 49.78it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 54.20it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 52.37it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 76.56it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 86.48it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 87.10it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 73.15it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 73.39it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 59.39it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 55.90it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 54.46it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.14it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.38it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 52.81it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 59.03it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 59.42it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 66.87it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.64it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 84.13it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 86.07it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 85.90it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 94.66it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 91.73it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 92.78it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.95it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 95.99it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 76.19it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 80.76it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 49.73it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 45.24it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 41.98it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 49.26it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 36.97it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 37.42it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.28it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 43.49it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:07, 41.56it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.26it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:10, 27.40it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 26.47it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 27.54it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 31.36it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:09, 27.19it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 30.76it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:09, 24.77it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 32.98it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.07it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 41.95it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 50.37it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 40.11it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 38.45it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 48.80it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 50.16it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 59.99it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 68.89it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 73.88it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 67.94it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 67.13it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 78.83it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 80.36it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 89.18it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 100.38it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.34it/s] 
2025-05-27 20:07:45,337 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.65, acc:   0.72, generation: 15.8215[sec], evaluation: 0.0000[sec]
2025-05-27 20:07:45,703 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/60000.ckpt
2025-05-27 20:07:45,729 - INFO - joeynmt.training - Example #0
2025-05-27 20:07:45,730 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:07:45,730 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:07:45,730 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due cas<unk> @ i sono stati in<unk> @ contr<unk> @ ati per port<unk> @ are il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio , per tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di anni , che aveva tre milioni di m<unk> @ oti<unk> @ vi per tre milioni di persone che hanno av<unk> @ uto 4<unk> @ 8 % , per c<unk> @ ento .
2025-05-27 20:07:45,730 - INFO - joeynmt.training - Example #1
2025-05-27 20:07:45,731 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:07:45,731 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:07:45,731 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza in<unk> @ tel<unk> @ li<unk> @ gente che non è abb<unk> @ ast<unk> @ anza per il problema .
2025-05-27 20:07:45,731 - INFO - joeynmt.training - Example #2
2025-05-27 20:07:45,732 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:07:45,732 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il nostro sistema c<unk> @ li<unk> @ m<unk> @ as<unk> @ so di c<unk> @ li<unk> @ m<unk> @ as<unk> @ so di c<unk> @ li<unk> @ m<unk> @ are .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - Example #3
2025-05-27 20:07:45,733 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ op<unk> @ olo e in<unk> @ ver<unk> @ no .
2025-05-27 20:07:45,733 - INFO - joeynmt.training - Example #4
2025-05-27 20:07:45,734 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:07:45,734 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:07:45,734 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una c<unk> @ ic<unk> @ l<unk> @ et<unk> @ ta che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:07:49,067 - INFO - joeynmt.training - Epoch   8, Step:    61100, Batch Loss:     1.028203, Batch Acc: 0.727743, Tokens per Sec:    20358, Lr: 0.000300
2025-05-27 20:07:52,442 - INFO - joeynmt.training - Epoch   8, Step:    61200, Batch Loss:     1.033765, Batch Acc: 0.718878, Tokens per Sec:    24171, Lr: 0.000300
2025-05-27 20:07:55,672 - INFO - joeynmt.training - Epoch   8, Step:    61300, Batch Loss:     0.970850, Batch Acc: 0.727347, Tokens per Sec:    24009, Lr: 0.000300
2025-05-27 20:07:58,869 - INFO - joeynmt.training - Epoch   8, Step:    61400, Batch Loss:     0.859320, Batch Acc: 0.726590, Tokens per Sec:    24562, Lr: 0.000300
2025-05-27 20:08:02,087 - INFO - joeynmt.training - Epoch   8, Step:    61500, Batch Loss:     1.006210, Batch Acc: 0.724052, Tokens per Sec:    25192, Lr: 0.000300
2025-05-27 20:08:02,087 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:08:02,087 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 82.90it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 89.97it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 106.94it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 108.14it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 108.22it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 117.86it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 124.44it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:05, 135.77it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 58.48it/s] Predicting...:  17%|█▋        | 160/923 [00:01<00:11, 66.92it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.80it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 94.38it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 86.03it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:09, 71.44it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:08, 77.25it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.39it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 49.88it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.12it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.05it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 57.03it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.04it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:10, 53.79it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 50.96it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 61.18it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 79.37it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 88.28it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 90.53it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:07, 62.87it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 75.84it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 75.85it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 84.60it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 78.97it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 79.52it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 64.61it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 69.17it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 78.05it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 63.72it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 47.07it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 45.04it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.78it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.39it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.75it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 37.97it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 38.38it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 48.34it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 48.52it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 44.76it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:09, 29.11it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 26.36it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 27.38it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 31.38it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 28.59it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 31.28it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 30.51it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 39.49it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 39.15it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 47.35it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 57.72it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 42.82it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 45.74it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 58.16it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 63.75it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 74.64it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 80.98it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 82.42it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 62.47it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 58.94it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 70.41it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 74.40it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 84.84it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 96.48it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.32it/s]
2025-05-27 20:08:17,403 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.3023[sec], evaluation: 0.0000[sec]
2025-05-27 20:08:17,404 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:08:17,946 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/60500.ckpt
2025-05-27 20:08:17,966 - INFO - joeynmt.training - Example #0
2025-05-27 20:08:17,967 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:08:17,967 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:08:17,967 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose per cui sono st<unk> @ ate per di<unk> @ mostr<unk> @ are che l&apos; or<unk> @ ig<unk> @ ine per qu<unk> @ elli che f<unk> @ anno le g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ate che gli or<unk> @ b<unk> @ i di tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % , il 4<unk> @ 0 % del 4<unk> @ 0 % , il 4<unk> @ 0 % , il 4<unk> @ 0 % .
2025-05-27 20:08:17,968 - INFO - joeynmt.training - Example #1
2025-05-27 20:08:17,968 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:08:17,969 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:08:17,969 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ in<unk> @ zione di questo part<unk> @ icol<unk> @ are probl<unk> @ emi , perché non è il D<unk> @ ic<unk> @ co .
2025-05-27 20:08:17,969 - INFO - joeynmt.training - Example #2
2025-05-27 20:08:17,970 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:08:17,970 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:08:17,970 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ li<unk> @ sta di in<unk> @ ten<unk> @ zione di ci<unk> @ o<unk> @ è che la c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:08:17,970 - INFO - joeynmt.training - Example #3
2025-05-27 20:08:17,970 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:08:17,971 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:08:17,971 - INFO - joeynmt.training - 	Hypothesis: Si cres<unk> @ ce in est<unk> @ ate e si s<unk> @ ente in est<unk> @ ate e si sp<unk> @ ost<unk> @ a .
2025-05-27 20:08:17,971 - INFO - joeynmt.training - Example #4
2025-05-27 20:08:17,971 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:08:17,971 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:08:17,972 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una st<unk> @ anza di sc<unk> @ al<unk> @ a che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:08:21,321 - INFO - joeynmt.training - Epoch   8, Step:    61600, Batch Loss:     0.964379, Batch Acc: 0.723971, Tokens per Sec:    19894, Lr: 0.000300
2025-05-27 20:08:24,643 - INFO - joeynmt.training - Epoch   8, Step:    61700, Batch Loss:     0.914526, Batch Acc: 0.721261, Tokens per Sec:    23220, Lr: 0.000300
2025-05-27 20:08:27,994 - INFO - joeynmt.training - Epoch   8, Step:    61800, Batch Loss:     0.958155, Batch Acc: 0.726194, Tokens per Sec:    24164, Lr: 0.000300
2025-05-27 20:08:31,353 - INFO - joeynmt.training - Epoch   8, Step:    61900, Batch Loss:     0.989612, Batch Acc: 0.721152, Tokens per Sec:    23262, Lr: 0.000300
2025-05-27 20:08:34,706 - INFO - joeynmt.training - Epoch   8, Step:    62000, Batch Loss:     1.064082, Batch Acc: 0.726258, Tokens per Sec:    23495, Lr: 0.000300
2025-05-27 20:08:34,707 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:08:34,707 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 77.82it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 85.47it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.85it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 100.38it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 90.32it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:08, 100.92it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 70.04it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 85.32it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:19, 41.51it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 46.70it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 55.20it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 78.84it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 83.79it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:10, 68.83it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 60.71it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 67.88it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 53.36it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 52.12it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 50.55it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.26it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 57.58it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 58.33it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 65.39it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 60.22it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 66.85it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.17it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 83.77it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 86.97it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:08, 55.86it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:07, 65.69it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 69.48it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 75.24it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 69.91it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 76.96it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 57.08it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 65.36it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 73.59it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 58.78it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 46.17it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 40.24it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 38.80it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 46.98it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 36.10it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 35.08it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 33.98it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 44.29it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.64it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.19it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 35.59it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:09, 28.72it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 27.86it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:08, 29.95it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 25.75it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 27.67it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:09, 23.08it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 31.58it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 32.60it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 39.14it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 48.51it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 37.84it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 38.49it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 47.01it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 49.98it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 57.16it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 66.84it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 73.77it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 69.75it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 59.24it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 71.23it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 73.02it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 83.42it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 93.24it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 55.24it/s]
2025-05-27 20:08:51,430 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 16.7091[sec], evaluation: 0.0000[sec]
2025-05-27 20:08:51,788 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/59000.ckpt
2025-05-27 20:08:51,809 - INFO - joeynmt.training - Example #0
2025-05-27 20:08:51,811 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:08:51,811 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:08:51,811 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due cas<unk> @ i sono i due cas<unk> @ i che gli ar<unk> @ t<unk> @ av<unk> @ ol<unk> @ i che i po<unk> @ ver<unk> @ i che gli ar<unk> @ t<unk> @ t<unk> @ av<unk> @ amo per tre milioni di anni , i con<unk> @ si<unk> @ der<unk> @ ati , per tre milioni di anni , il 4<unk> @ 0 % dei m<unk> @ oti<unk> @ vi per tre milioni di anni .
2025-05-27 20:08:51,811 - INFO - joeynmt.training - Example #1
2025-05-27 20:08:51,812 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:08:51,812 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:08:51,812 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te l&apos; in<unk> @ cre<unk> @ di<unk> @ bil<unk> @ ità di questo problema , perché non è la di<unk> @ mostr<unk> @ a il D<unk> @ ic<unk> @ co .
2025-05-27 20:08:51,812 - INFO - joeynmt.training - Example #2
2025-05-27 20:08:51,813 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:08:51,813 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:08:51,813 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa po<unk> @ ver<unk> @ tà , la c<unk> @ atti<unk> @ va è la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ ente glob<unk> @ ale .
2025-05-27 20:08:51,814 - INFO - joeynmt.training - Example #3
2025-05-27 20:08:51,814 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:08:51,814 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:08:51,814 - INFO - joeynmt.training - 	Hypothesis: Si cres<unk> @ ce in gi<unk> @ ro <unk> @ ù e la sc<unk> @ or<unk> @ r<unk> @ azione .
2025-05-27 20:08:51,814 - INFO - joeynmt.training - Example #4
2025-05-27 20:08:51,815 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:08:51,815 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:08:51,815 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o , che vi mostr<unk> @ er<unk> @ ò è una lin<unk> @ ea di ri<unk> @ pres<unk> @ a che , in realtà è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:08:55,182 - INFO - joeynmt.training - Epoch   8, Step:    62100, Batch Loss:     0.944730, Batch Acc: 0.728110, Tokens per Sec:    21396, Lr: 0.000300
2025-05-27 20:08:58,522 - INFO - joeynmt.training - Epoch   8, Step:    62200, Batch Loss:     0.932534, Batch Acc: 0.726813, Tokens per Sec:    24623, Lr: 0.000300
2025-05-27 20:09:01,877 - INFO - joeynmt.training - Epoch   8, Step:    62300, Batch Loss:     0.935615, Batch Acc: 0.724272, Tokens per Sec:    23385, Lr: 0.000300
2025-05-27 20:09:05,243 - INFO - joeynmt.training - Epoch   8, Step:    62400, Batch Loss:     0.869099, Batch Acc: 0.725053, Tokens per Sec:    23298, Lr: 0.000300
2025-05-27 20:09:08,583 - INFO - joeynmt.training - Epoch   8, Step:    62500, Batch Loss:     0.945453, Batch Acc: 0.724223, Tokens per Sec:    23678, Lr: 0.000300
2025-05-27 20:09:08,583 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:09:08,583 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:08, 109.97it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 108.32it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 113.35it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 113.68it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.92it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:07, 109.66it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 72.65it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 89.15it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 43.10it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 48.65it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 58.19it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 82.81it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 93.83it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 85.36it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 71.28it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 77.05it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 61.75it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 60.25it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 53.31it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 59.18it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 63.50it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 64.77it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 63.27it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 71.88it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 87.81it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 90.72it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 91.96it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 98.82it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 107.19it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 100.88it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 98.73it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 83.05it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 86.30it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 69.02it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 76.77it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 73.23it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 59.71it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 54.67it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 47.89it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 55.30it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 38.82it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 38.44it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:08, 36.74it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.17it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 44.97it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:07, 40.21it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:07, 36.40it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:09, 29.05it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:09, 28.47it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:08, 31.17it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 28.16it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 31.88it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 29.69it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 40.25it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.97it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:03, 49.67it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:02, 62.44it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 45.90it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 55.92it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 57.83it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 68.52it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 73.17it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 75.74it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 58.87it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 61.22it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 74.94it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 81.10it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 92.65it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 62.39it/s]
2025-05-27 20:09:23,389 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 14.7937[sec], evaluation: 0.0000[sec]
2025-05-27 20:09:23,390 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:09:23,916 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/59500.ckpt
2025-05-27 20:09:23,943 - INFO - joeynmt.training - Example #0
2025-05-27 20:09:23,944 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:09:23,944 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:09:23,944 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due di<unk> @ mostr<unk> @ ano che il g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i che gli ar<unk> @ t<unk> @ av<unk> @ i , per i qu<unk> @ elli che av<unk> @ evano fatto il 4<unk> @ 0 % dei qu<unk> @ at<unk> @ tro anni .
2025-05-27 20:09:23,944 - INFO - joeynmt.training - Example #1
2025-05-27 20:09:23,945 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:09:23,945 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:09:23,945 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza in<unk> @ f<unk> @ lu<unk> @ ente , perché non è abb<unk> @ ast<unk> @ anza per questo problema spe<unk> @ ci<unk> @ ale .
2025-05-27 20:09:23,945 - INFO - joeynmt.training - Example #2
2025-05-27 20:09:23,946 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:09:23,946 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:09:23,946 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ atti<unk> @ va è l&apos; ec<unk> @ c<unk> @ e<unk> @ zione ar<unk> @ t<unk> @ ico , il cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:09:23,946 - INFO - joeynmt.training - Example #3
2025-05-27 20:09:23,947 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:09:23,947 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:09:23,947 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e si ri<unk> @ es<unk> @ ce a fare in est<unk> @ ate .
2025-05-27 20:09:23,947 - INFO - joeynmt.training - Example #4
2025-05-27 20:09:23,948 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:09:23,948 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:09:23,948 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o è una ri<unk> @ vi<unk> @ sta di una ser<unk> @ ie di sc<unk> @ or<unk> @ so che cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:09:27,318 - INFO - joeynmt.training - Epoch   8, Step:    62600, Batch Loss:     0.974163, Batch Acc: 0.721454, Tokens per Sec:    20704, Lr: 0.000300
2025-05-27 20:09:30,645 - INFO - joeynmt.training - Epoch   8, Step:    62700, Batch Loss:     0.866050, Batch Acc: 0.727997, Tokens per Sec:    23485, Lr: 0.000300
2025-05-27 20:09:33,960 - INFO - joeynmt.training - Epoch   8, Step:    62800, Batch Loss:     0.927264, Batch Acc: 0.725510, Tokens per Sec:    23866, Lr: 0.000300
2025-05-27 20:09:37,284 - INFO - joeynmt.training - Epoch   8, Step:    62900, Batch Loss:     0.839326, Batch Acc: 0.724435, Tokens per Sec:    23672, Lr: 0.000300
2025-05-27 20:09:40,592 - INFO - joeynmt.training - Epoch   8, Step:    63000, Batch Loss:     0.869455, Batch Acc: 0.723693, Tokens per Sec:    23962, Lr: 0.000300
2025-05-27 20:09:40,593 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:09:40,593 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 70.85it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 81.10it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 87.38it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 90.57it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 101.97it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 110.88it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 72.96it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 84.86it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:25, 31.30it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:21, 36.37it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:16, 45.08it/s]Predicting...:  20%|██        | 185/923 [00:02<00:11, 66.40it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:09, 74.91it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 71.74it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 70.10it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 77.54it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 53.41it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 51.47it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.18it/s]Predicting...:  33%|███▎      | 302/923 [00:05<00:11, 52.32it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:10, 55.63it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 56.80it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 61.51it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 52.69it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 62.39it/s]Predicting...:  41%|████      | 379/923 [00:06<00:06, 78.79it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:05, 88.37it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 80.13it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 74.44it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 84.40it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:05, 84.46it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:05, 90.59it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 75.37it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 77.71it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 69.84it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 68.08it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 78.22it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:05, 72.48it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:06, 55.44it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 47.13it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 35.72it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:08, 42.55it/s]Predicting...:  64%|██████▎   | 587/923 [00:10<00:13, 24.82it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:12, 26.31it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:11, 27.53it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:08, 36.56it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:07, 36.85it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 36.56it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:09, 27.73it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:11, 23.82it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:11, 23.74it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:09, 27.53it/s]Predicting...:  73%|███████▎  | 678/923 [00:13<00:09, 25.09it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:08, 26.80it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:16, 13.96it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:10, 19.92it/s]Predicting...:  78%|███████▊  | 717/923 [00:15<00:11, 18.54it/s]Predicting...:  79%|███████▉  | 729/923 [00:15<00:07, 25.31it/s]Predicting...:  80%|████████  | 742/923 [00:15<00:05, 35.04it/s]Predicting...:  81%|████████  | 749/923 [00:16<00:05, 31.18it/s]Predicting...:  82%|████████▏ | 759/923 [00:16<00:05, 32.71it/s]Predicting...:  84%|████████▍ | 774/923 [00:16<00:03, 42.90it/s]Predicting...:  85%|████████▌ | 786/923 [00:16<00:03, 44.87it/s]Predicting...:  87%|████████▋ | 800/923 [00:17<00:02, 51.63it/s]Predicting...:  88%|████████▊ | 815/923 [00:17<00:01, 60.10it/s]Predicting...:  90%|████████▉ | 827/923 [00:17<00:01, 61.71it/s]Predicting...:  90%|█████████ | 835/923 [00:17<00:01, 46.48it/s]Predicting...:  92%|█████████▏| 850/923 [00:17<00:01, 55.68it/s]Predicting...:  93%|█████████▎| 862/923 [00:18<00:01, 55.59it/s]Predicting...:  95%|█████████▌| 878/923 [00:18<00:00, 69.80it/s]Predicting...:  97%|█████████▋| 892/923 [00:18<00:00, 71.47it/s]Predicting...:  98%|█████████▊| 908/923 [00:18<00:00, 80.61it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 93.36it/s]Predicting...: 100%|██████████| 923/923 [00:18<00:00, 49.45it/s]
2025-05-27 20:09:59,274 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 18.6668[sec], evaluation: 0.0000[sec]
2025-05-27 20:09:59,275 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:09:59,909 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/61000.ckpt
2025-05-27 20:09:59,933 - INFO - joeynmt.training - Example #0
2025-05-27 20:09:59,935 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:09:59,935 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:09:59,935 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due col<unk> @ ie che mostr<unk> @ a per con<unk> @ si<unk> @ der<unk> @ are i due milioni di g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati , che gli ar<unk> @ t<unk> @ av<unk> @ ol<unk> @ i , per tre milioni di anni , il 4<unk> @ 8 <unk> @ 8 anni .
2025-05-27 20:09:59,935 - INFO - joeynmt.training - Example #1
2025-05-27 20:09:59,936 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:09:59,936 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:09:59,936 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questa spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ co di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:09:59,936 - INFO - joeynmt.training - Example #2
2025-05-27 20:09:59,937 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:09:59,937 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:09:59,937 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cer<unk> @ ta di un cer<unk> @ to sen<unk> @ so è la c<unk> @ atti<unk> @ va è il cu<unk> @ ore c<unk> @ atti<unk> @ vo al cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:09:59,937 - INFO - joeynmt.training - Example #3
2025-05-27 20:09:59,938 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:09:59,938 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:09:59,938 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ em<unk> @ br<unk> @ a , e si ri<unk> @ vol<unk> @ g<unk> @ ano in est<unk> @ ate .
2025-05-27 20:09:59,938 - INFO - joeynmt.training - Example #4
2025-05-27 20:09:59,939 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:09:59,939 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:09:59,939 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ o è una c<unk> @ ura di di<unk> @ seg<unk> @ na che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:10:01,811 - INFO - joeynmt.training - Epoch   8: total training loss 7420.14
2025-05-27 20:10:01,811 - INFO - joeynmt.training - EPOCH 9
2025-05-27 20:10:03,255 - INFO - joeynmt.training - Epoch   9, Step:    63100, Batch Loss:     0.922769, Batch Acc: 0.729110, Tokens per Sec:    23835, Lr: 0.000300
2025-05-27 20:10:06,464 - INFO - joeynmt.training - Epoch   9, Step:    63200, Batch Loss:     0.801125, Batch Acc: 0.734902, Tokens per Sec:    24542, Lr: 0.000300
2025-05-27 20:10:09,789 - INFO - joeynmt.training - Epoch   9, Step:    63300, Batch Loss:     0.981043, Batch Acc: 0.733147, Tokens per Sec:    23574, Lr: 0.000300
2025-05-27 20:10:13,103 - INFO - joeynmt.training - Epoch   9, Step:    63400, Batch Loss:     0.901834, Batch Acc: 0.732712, Tokens per Sec:    23662, Lr: 0.000300
2025-05-27 20:10:16,401 - INFO - joeynmt.training - Epoch   9, Step:    63500, Batch Loss:     0.929982, Batch Acc: 0.735861, Tokens per Sec:    23490, Lr: 0.000300
2025-05-27 20:10:16,402 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:10:16,402 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 58.42it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 70.04it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 85.01it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 91.15it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 96.70it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 103.81it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 103.66it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 117.54it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 52.16it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 55.58it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.85it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 84.04it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 90.81it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 80.58it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 77.31it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 79.53it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:10, 64.94it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 58.93it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 60.50it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 58.65it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 60.39it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 65.04it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 66.19it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 67.64it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 72.85it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 86.63it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 89.60it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 84.79it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:06, 78.87it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 88.04it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 68.05it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 75.84it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 68.42it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:06, 69.93it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:07, 57.84it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 62.87it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 74.13it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:07, 54.51it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 50.28it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 49.24it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 46.87it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 52.47it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 38.65it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 37.69it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 39.38it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 45.06it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 45.75it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 41.30it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 37.93it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 32.78it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 32.23it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.56it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 32.86it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 37.17it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 26.79it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 35.90it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.46it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 44.71it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 51.25it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 38.16it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 39.03it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 49.37it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 53.88it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 65.63it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 74.68it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 74.42it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 60.42it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 59.71it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 68.98it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 75.47it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 87.44it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.69it/s]
2025-05-27 20:10:31,626 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 15.2099[sec], evaluation: 0.0000[sec]
2025-05-27 20:10:31,993 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/62000.ckpt
2025-05-27 20:10:32,017 - INFO - joeynmt.training - Example #0
2025-05-27 20:10:32,018 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:10:32,018 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:10:32,018 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ rit<unk> @ ti per far<unk> @ lo per fare due di<unk> @ os<unk> @ i , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che gli st<unk> @ avano per tre milioni di anni , che aveva tre milioni di anni , il 4<unk> @ 8 , il 4<unk> @ 8 stati di qu<unk> @ asi 4<unk> @ 8 stati , per c<unk> @ ento è stato in<unk> @ tor<unk> @ no , per tre milioni di anni , il 4<unk> @ 0 .
2025-05-27 20:10:32,018 - INFO - joeynmt.training - Example #1
2025-05-27 20:10:32,019 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:10:32,019 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:10:32,019 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ f<unk> @ lu<unk> @ enza la giu<unk> @ sta , perché non è la de<unk> @ ter<unk> @ min<unk> @ azione che non mostr<unk> @ a la de<unk> @ ter<unk> @ min<unk> @ azione .
2025-05-27 20:10:32,019 - INFO - joeynmt.training - Example #2
2025-05-27 20:10:32,020 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:10:32,020 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:10:32,020 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ itu<unk> @ azione ar<unk> @ t<unk> @ t<unk> @ ica è la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 20:10:32,020 - INFO - joeynmt.training - Example #3
2025-05-27 20:10:32,021 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:10:32,021 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:10:32,021 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:10:32,021 - INFO - joeynmt.training - Example #4
2025-05-27 20:10:32,022 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:10:32,022 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:10:32,022 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @ ò , è una st<unk> @ anza di cor<unk> @ r<unk> @ ente che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:10:35,379 - INFO - joeynmt.training - Epoch   9, Step:    63600, Batch Loss:     0.845048, Batch Acc: 0.732903, Tokens per Sec:    21493, Lr: 0.000300
2025-05-27 20:10:38,706 - INFO - joeynmt.training - Epoch   9, Step:    63700, Batch Loss:     1.009884, Batch Acc: 0.727767, Tokens per Sec:    23674, Lr: 0.000300
2025-05-27 20:10:42,054 - INFO - joeynmt.training - Epoch   9, Step:    63800, Batch Loss:     0.849872, Batch Acc: 0.735904, Tokens per Sec:    23844, Lr: 0.000300
2025-05-27 20:10:45,373 - INFO - joeynmt.training - Epoch   9, Step:    63900, Batch Loss:     0.973657, Batch Acc: 0.733241, Tokens per Sec:    24272, Lr: 0.000300
2025-05-27 20:10:48,696 - INFO - joeynmt.training - Epoch   9, Step:    64000, Batch Loss:     0.903640, Batch Acc: 0.736774, Tokens per Sec:    24570, Lr: 0.000300
2025-05-27 20:10:48,696 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:10:48,696 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:15, 60.26it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:12, 74.14it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 86.41it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 92.33it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 97.69it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 104.65it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 71.93it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 86.74it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 42.30it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 47.50it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 57.61it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 83.42it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.55it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 77.62it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 61.15it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 71.81it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 51.47it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 52.17it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 46.60it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:14, 43.79it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:12, 48.09it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:11, 51.16it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:12, 47.09it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:13, 42.30it/s]Predicting...:  39%|███▉      | 361/923 [00:06<00:11, 50.75it/s]Predicting...:  41%|████      | 379/923 [00:06<00:08, 67.95it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:07, 74.20it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 75.71it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 73.82it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 85.61it/s]Predicting...:  49%|████▉     | 455/923 [00:07<00:05, 84.59it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:05, 90.23it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 79.92it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 85.13it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:08, 49.01it/s]Predicting...:  56%|█████▌    | 517/923 [00:08<00:07, 53.36it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:06, 64.35it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:07, 53.97it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 45.52it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:08, 43.48it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:08, 40.37it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:06, 51.57it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 38.49it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:08, 37.15it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:08, 35.64it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:06, 44.40it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 45.55it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:06, 42.13it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 36.76it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 31.20it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 30.42it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:07, 33.65it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 30.40it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 31.89it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:08, 25.26it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 32.75it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 33.36it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 41.50it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 50.85it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 37.08it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 37.24it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 48.16it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 55.63it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:01, 66.99it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 79.10it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 81.74it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 66.71it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 67.63it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 86.87it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 92.34it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.36it/s]
2025-05-27 20:11:05,089 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 16.3790[sec], evaluation: 0.0000[sec]
2025-05-27 20:11:05,475 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/63500.ckpt
2025-05-27 20:11:05,500 - INFO - joeynmt.training - Example #0
2025-05-27 20:11:05,502 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:11:05,502 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:11:05,502 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ rit<unk> @ ti per ri<unk> @ dur<unk> @ re questi due di<unk> @ ti per con<unk> @ to che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ a<unk> @ io di anni , il 4<unk> @ 8 , il 4<unk> @ 8 ore di 4<unk> @ 8 ore , il 4<unk> @ 8 ore di 4<unk> @ 8 ore , il 4<unk> @ 0 % di 4<unk> @ 8 ore .
2025-05-27 20:11:05,502 - INFO - joeynmt.training - Example #1
2025-05-27 20:11:05,503 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:11:05,503 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:11:05,503 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ lo .
2025-05-27 20:11:05,503 - INFO - joeynmt.training - Example #2
2025-05-27 20:11:05,504 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:11:05,504 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:11:05,504 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la s<unk> @ itu<unk> @ azione po<unk> @ ver<unk> @ ica è la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 20:11:05,504 - INFO - joeynmt.training - Example #3
2025-05-27 20:11:05,505 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:11:05,505 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:11:05,505 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ à in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:11:05,505 - INFO - joeynmt.training - Example #4
2025-05-27 20:11:05,506 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:11:05,506 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:11:05,506 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o è una sc<unk> @ at<unk> @ ola , è una sc<unk> @ at<unk> @ ola di ri<unk> @ dur<unk> @ re la di<unk> @ men<unk> @ sione negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:11:08,860 - INFO - joeynmt.training - Epoch   9, Step:    64100, Batch Loss:     0.859963, Batch Acc: 0.729641, Tokens per Sec:    20848, Lr: 0.000300
2025-05-27 20:11:12,178 - INFO - joeynmt.training - Epoch   9, Step:    64200, Batch Loss:     0.847830, Batch Acc: 0.729255, Tokens per Sec:    23826, Lr: 0.000300
2025-05-27 20:11:15,512 - INFO - joeynmt.training - Epoch   9, Step:    64300, Batch Loss:     0.927588, Batch Acc: 0.734656, Tokens per Sec:    23468, Lr: 0.000300
2025-05-27 20:11:18,841 - INFO - joeynmt.training - Epoch   9, Step:    64400, Batch Loss:     0.952501, Batch Acc: 0.734671, Tokens per Sec:    23820, Lr: 0.000300
2025-05-27 20:11:22,167 - INFO - joeynmt.training - Epoch   9, Step:    64500, Batch Loss:     0.983788, Batch Acc: 0.732569, Tokens per Sec:    23998, Lr: 0.000300
2025-05-27 20:11:22,167 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:11:22,167 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 64.70it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 78.20it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 81.97it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 90.69it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 92.71it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 103.73it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 97.78it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 110.79it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 51.69it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 57.46it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 57.08it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 83.21it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 91.94it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 77.67it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 77.38it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 80.36it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 57.34it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 53.83it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.90it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 51.96it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 55.73it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 57.80it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:10, 54.00it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 50.40it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 57.67it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 72.07it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 79.44it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 85.79it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 86.37it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 100.48it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 98.28it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 98.96it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 84.54it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 85.11it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.39it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 64.38it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 72.42it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 67.80it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 54.22it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 48.34it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.24it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.02it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 36.30it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.34it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.27it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 44.50it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.60it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 47.02it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 44.13it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.41it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 30.11it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 33.52it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 30.10it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 33.18it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 26.02it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 33.57it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.59it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 43.29it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 51.77it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.52it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 39.90it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 51.85it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 55.66it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 67.91it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 80.30it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 80.10it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 63.41it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 59.18it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 69.98it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 74.10it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 85.60it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.59it/s]
2025-05-27 20:11:37,672 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.4910[sec], evaluation: 0.0000[sec]
2025-05-27 20:11:38,066 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/58500.ckpt
2025-05-27 20:11:38,090 - INFO - joeynmt.training - Example #0
2025-05-27 20:11:38,091 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:11:38,092 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:11:38,092 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , ho mostr<unk> @ ato queste due col<unk> @ azioni per in<unk> @ tr<unk> @ o<unk> @ d<unk> @ otto le g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati per i po<unk> @ ver<unk> @ i che st<unk> @ avano fac<unk> @ endo questi due milioni di anni , ha av<unk> @ uto 4<unk> @ 8 milioni di anni , ha av<unk> @ uto 4<unk> @ 8 ore , il 4<unk> @ 0 % di qu<unk> @ at<unk> @ tro St<unk> @ ati Un<unk> @ iti , è stato sp<unk> @ esso .
2025-05-27 20:11:38,092 - INFO - joeynmt.training - Example #1
2025-05-27 20:11:38,093 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:11:38,093 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:11:38,093 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ tor<unk> @ no a questa part<unk> @ icol<unk> @ are probl<unk> @ emi a questo problema spe<unk> @ ci<unk> @ f<unk> @ ico , perché non è il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 20:11:38,093 - INFO - joeynmt.training - Example #2
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a è la c<unk> @ atti<unk> @ va è la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 20:11:38,094 - INFO - joeynmt.training - Example #3
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:11:38,094 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:11:38,095 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ar<unk> @ anno in in<unk> @ ver<unk> @ no e sc<unk> @ ar<unk> @ s<unk> @ are in est<unk> @ ate .
2025-05-27 20:11:38,095 - INFO - joeynmt.training - Example #4
2025-05-27 20:11:38,095 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:11:38,095 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:11:38,095 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a di di<unk> @ seg<unk> @ na che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:11:41,466 - INFO - joeynmt.training - Epoch   9, Step:    64600, Batch Loss:     0.912761, Batch Acc: 0.722823, Tokens per Sec:    21202, Lr: 0.000300
2025-05-27 20:11:44,810 - INFO - joeynmt.training - Epoch   9, Step:    64700, Batch Loss:     0.843649, Batch Acc: 0.732641, Tokens per Sec:    24381, Lr: 0.000300
2025-05-27 20:11:48,127 - INFO - joeynmt.training - Epoch   9, Step:    64800, Batch Loss:     0.920851, Batch Acc: 0.731160, Tokens per Sec:    23505, Lr: 0.000300
2025-05-27 20:11:51,444 - INFO - joeynmt.training - Epoch   9, Step:    64900, Batch Loss:     0.983616, Batch Acc: 0.735219, Tokens per Sec:    24443, Lr: 0.000300
2025-05-27 20:11:54,778 - INFO - joeynmt.training - Epoch   9, Step:    65000, Batch Loss:     0.952441, Batch Acc: 0.730865, Tokens per Sec:    23914, Lr: 0.000300
2025-05-27 20:11:54,778 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:11:54,778 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 70.04it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 89.23it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 101.93it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 101.20it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 107.51it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 114.57it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 106.11it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 115.88it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:22, 34.60it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:19, 39.21it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 48.14it/s]Predicting...:  20%|██        | 185/923 [00:02<00:10, 70.11it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 79.95it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 73.11it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 73.40it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 80.24it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 50.67it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 48.81it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.58it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 50.62it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 54.97it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 58.17it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 58.58it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 67.29it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.83it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 87.69it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 89.42it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 80.21it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 87.45it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 84.99it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 89.70it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 74.27it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 73.20it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.03it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.57it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 76.40it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 60.73it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 43.38it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 38.04it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 35.76it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 44.20it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 33.32it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:10, 31.50it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 31.86it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 41.01it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 41.36it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 39.00it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:10, 25.79it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:11, 22.75it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:11, 23.51it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:08, 28.02it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 25.15it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 28.85it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:09, 23.90it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 31.04it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 32.23it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:04, 40.12it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 49.42it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 37.70it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:05, 28.49it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 37.50it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:03, 43.27it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 53.90it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 62.63it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 64.54it/s]Predicting...:  90%|█████████ | 835/923 [00:16<00:01, 45.23it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 58.33it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 55.17it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 66.66it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 74.14it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 82.87it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 53.41it/s]
2025-05-27 20:12:12,074 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 17.2827[sec], evaluation: 0.0000[sec]
2025-05-27 20:12:12,075 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:12:12,706 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/61500.ckpt
2025-05-27 20:12:12,730 - INFO - joeynmt.training - Example #0
2025-05-27 20:12:12,732 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:12:12,732 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:12:12,732 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ ti per di<unk> @ mostr<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i che i po<unk> @ ver<unk> @ i , che i c<unk> @ av<unk> @ evano circa 3 milioni di anni , per circa 3 milioni di anni , per circa 3 milioni di anni , per circa 4<unk> @ 0 , per c<unk> @ ento è stato in<unk> @ tor<unk> @ no a 4<unk> @ 0 % del 4<unk> @ 0 % , per c<unk> @ ento .
2025-05-27 20:12:12,732 - INFO - joeynmt.training - Example #1
2025-05-27 20:12:12,733 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:12:12,733 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:12:12,733 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ a<unk> @ der non è il D<unk> @ ic<unk> @ des .
2025-05-27 20:12:12,733 - INFO - joeynmt.training - Example #2
2025-05-27 20:12:12,734 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:12:12,734 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:12:12,734 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ ura ar<unk> @ t<unk> @ t<unk> @ av<unk> @ olo il cu<unk> @ ore c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:12:12,734 - INFO - joeynmt.training - Example #3
2025-05-27 20:12:12,735 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:12:12,735 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:12:12,735 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di chi e sc<unk> @ en<unk> @ a e sp<unk> @ av<unk> @ ent<unk> @ ato .
2025-05-27 20:12:12,735 - INFO - joeynmt.training - Example #4
2025-05-27 20:12:12,736 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:12:12,736 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:12:12,736 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a è una sc<unk> @ or<unk> @ sa , è un di<unk> @ seg<unk> @ no di quello che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:12:16,076 - INFO - joeynmt.training - Epoch   9, Step:    65100, Batch Loss:     0.852091, Batch Acc: 0.733417, Tokens per Sec:    19981, Lr: 0.000300
2025-05-27 20:12:19,417 - INFO - joeynmt.training - Epoch   9, Step:    65200, Batch Loss:     0.895582, Batch Acc: 0.731275, Tokens per Sec:    23976, Lr: 0.000300
2025-05-27 20:12:22,744 - INFO - joeynmt.training - Epoch   9, Step:    65300, Batch Loss:     0.888161, Batch Acc: 0.729299, Tokens per Sec:    23118, Lr: 0.000300
2025-05-27 20:12:26,047 - INFO - joeynmt.training - Epoch   9, Step:    65400, Batch Loss:     0.860217, Batch Acc: 0.731670, Tokens per Sec:    23439, Lr: 0.000300
2025-05-27 20:12:29,383 - INFO - joeynmt.training - Epoch   9, Step:    65500, Batch Loss:     1.000361, Batch Acc: 0.727818, Tokens per Sec:    23944, Lr: 0.000300
2025-05-27 20:12:29,383 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:12:29,383 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 68.00it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 84.36it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 94.60it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 96.57it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 98.46it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 108.46it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 110.35it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 120.75it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 51.21it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 52.66it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 51.19it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 73.94it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 80.27it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 75.15it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 77.28it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:07, 84.53it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:09, 68.40it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 62.53it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 59.16it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 60.20it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 63.75it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 68.14it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 61.31it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 69.35it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 82.31it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 91.28it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 93.40it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:08, 57.75it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 69.87it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 73.47it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 82.02it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 73.94it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 75.54it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 61.57it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 69.03it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 78.60it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 58.05it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 50.30it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 46.39it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 42.48it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 51.10it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.92it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 38.56it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 39.42it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 47.85it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 47.13it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 45.22it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 40.33it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.09it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 31.28it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 35.54it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 30.48it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 32.18it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 26.88it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 34.27it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.27it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 42.22it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 52.26it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 37.92it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 40.51it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 54.49it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 54.22it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:02, 61.44it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 70.80it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.21it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 50.43it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 61.67it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 65.37it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 81.68it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 89.95it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 101.58it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 111.60it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.48it/s] 
2025-05-27 20:12:44,657 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.2610[sec], evaluation: 0.0000[sec]
2025-05-27 20:12:45,154 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/64500.ckpt
2025-05-27 20:12:45,178 - INFO - joeynmt.training - Example #0
2025-05-27 20:12:45,179 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:12:45,179 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:12:45,179 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno sc<unk> @ or<unk> @ so per ri<unk> @ dur<unk> @ re la c<unk> @ aus<unk> @ a di un c<unk> @ entr<unk> @ o di g<unk> @ hi<unk> @ ac<unk> @ cio che gli e<unk> @ qu<unk> @ i<unk> @ li<unk> @ bri<unk> @ o per tre mili<unk> @ one di di anni , il 4<unk> @ 0 , per c<unk> @ ento è stato il 4<unk> @ 0 % del 4<unk> @ 0 % , per il 4<unk> @ 0 % .
2025-05-27 20:12:45,179 - INFO - joeynmt.training - Example #1
2025-05-27 20:12:45,180 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:12:45,180 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:12:45,181 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:12:45,181 - INFO - joeynmt.training - Example #2
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la c<unk> @ atti<unk> @ va di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - Example #3
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e s<unk> @ con<unk> @ f<unk> @ it<unk> @ ta .
2025-05-27 20:12:45,182 - INFO - joeynmt.training - Example #4
2025-05-27 20:12:45,183 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:12:45,183 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:12:45,183 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a che vi è acc<unk> @ a<unk> @ du<unk> @ to , è una c<unk> @ en<unk> @ a di ci<unk> @ b<unk> @ o che negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:12:48,504 - INFO - joeynmt.training - Epoch   9, Step:    65600, Batch Loss:     0.844443, Batch Acc: 0.729972, Tokens per Sec:    20336, Lr: 0.000300
2025-05-27 20:12:51,842 - INFO - joeynmt.training - Epoch   9, Step:    65700, Batch Loss:     0.985376, Batch Acc: 0.728889, Tokens per Sec:    24285, Lr: 0.000300
2025-05-27 20:12:55,151 - INFO - joeynmt.training - Epoch   9, Step:    65800, Batch Loss:     0.887936, Batch Acc: 0.731812, Tokens per Sec:    23936, Lr: 0.000300
2025-05-27 20:12:58,465 - INFO - joeynmt.training - Epoch   9, Step:    65900, Batch Loss:     1.016670, Batch Acc: 0.730447, Tokens per Sec:    24110, Lr: 0.000300
2025-05-27 20:13:01,809 - INFO - joeynmt.training - Epoch   9, Step:    66000, Batch Loss:     0.938673, Batch Acc: 0.728055, Tokens per Sec:    24186, Lr: 0.000300
2025-05-27 20:13:01,809 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:13:01,810 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 67.65it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 89.96it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 102.17it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 102.57it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 103.47it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 106.94it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 109.49it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 122.48it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.01it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:14, 53.26it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 51.56it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 74.86it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 85.74it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 76.41it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 76.63it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 80.84it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 57.73it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 56.12it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 51.99it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 54.99it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 58.51it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 66.23it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 64.23it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 71.45it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 82.73it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 87.20it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 90.76it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:06, 80.85it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 94.84it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 92.63it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 94.33it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 82.84it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 89.12it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 65.03it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 73.23it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 63.13it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 52.06it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 47.19it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 41.22it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 48.90it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 37.60it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 36.63it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.36it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 44.38it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:07, 41.55it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 41.75it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 39.61it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 30.88it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 31.02it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 33.89it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.99it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 31.01it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 28.30it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 36.65it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.72it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 44.43it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 54.11it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 39.21it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 41.65it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 51.67it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 55.83it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 64.08it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 71.77it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.65it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 50.24it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 65.19it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 62.57it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 76.91it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 81.50it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 93.84it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.47it/s]
2025-05-27 20:13:17,086 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.2632[sec], evaluation: 0.0000[sec]
2025-05-27 20:13:17,439 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/64000.ckpt
2025-05-27 20:13:17,465 - INFO - joeynmt.training - Example #0
2025-05-27 20:13:17,467 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:13:17,467 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:13:17,467 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due f<unk> @ att<unk> @ or<unk> @ no a questo punto , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per la str<unk> @ utt<unk> @ ura , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di persone che aveva fatto per tre milioni di persone , il 4<unk> @ 0 % di tre milioni di persone , il 4<unk> @ 0 % , il 4<unk> @ 0 % .
2025-05-27 20:13:17,467 - INFO - joeynmt.training - Example #1
2025-05-27 20:13:17,468 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:13:17,468 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:13:17,468 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ ent<unk> @ ale .
2025-05-27 20:13:17,468 - INFO - joeynmt.training - Example #2
2025-05-27 20:13:17,469 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:13:17,469 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:13:17,469 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ li<unk> @ mat<unk> @ ica è il g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:13:17,469 - INFO - joeynmt.training - Example #3
2025-05-27 20:13:17,470 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:13:17,470 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:13:17,470 - INFO - joeynmt.training - 	Hypothesis: Si può essere in est<unk> @ ate e s<unk> @ par<unk> @ ito in est<unk> @ ate e sp<unk> @ av<unk> @ ent<unk> @ a .
2025-05-27 20:13:17,470 - INFO - joeynmt.training - Example #4
2025-05-27 20:13:17,471 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:13:17,471 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:13:17,471 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o che vi è un di<unk> @ seg<unk> @ no di una c<unk> @ en<unk> @ a di di<unk> @ seg<unk> @ ni .
2025-05-27 20:13:20,849 - INFO - joeynmt.training - Epoch   9, Step:    66100, Batch Loss:     0.953296, Batch Acc: 0.729474, Tokens per Sec:    21317, Lr: 0.000300
2025-05-27 20:13:24,186 - INFO - joeynmt.training - Epoch   9, Step:    66200, Batch Loss:     0.835214, Batch Acc: 0.732816, Tokens per Sec:    23570, Lr: 0.000300
2025-05-27 20:13:27,533 - INFO - joeynmt.training - Epoch   9, Step:    66300, Batch Loss:     0.867090, Batch Acc: 0.731933, Tokens per Sec:    23798, Lr: 0.000300
2025-05-27 20:13:30,846 - INFO - joeynmt.training - Epoch   9, Step:    66400, Batch Loss:     0.900891, Batch Acc: 0.728543, Tokens per Sec:    23331, Lr: 0.000300
2025-05-27 20:13:34,173 - INFO - joeynmt.training - Epoch   9, Step:    66500, Batch Loss:     0.893106, Batch Acc: 0.730057, Tokens per Sec:    23199, Lr: 0.000300
2025-05-27 20:13:34,173 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:13:34,173 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 69.16it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 82.32it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 95.02it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 96.15it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 98.95it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 113.45it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 112.49it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 125.80it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:14, 52.91it/s] Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.15it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 84.87it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 93.28it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 79.78it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 72.37it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 58.87it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 56.89it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 53.34it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 58.07it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.24it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.44it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 62.69it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 68.71it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 80.49it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 85.45it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 91.56it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:08, 57.43it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 71.17it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 75.37it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 81.00it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 69.64it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 78.20it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.60it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 73.85it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 59.24it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 47.31it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 40.39it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 39.11it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 46.38it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 36.50it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 36.20it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 36.36it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 44.71it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 42.70it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 40.69it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 38.82it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 32.56it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 30.56it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.35it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.56it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 32.32it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:09, 25.01it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 32.97it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 34.13it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 40.20it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 49.37it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.05it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 38.82it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 48.43it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 51.76it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 64.33it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 75.34it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 75.20it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 62.21it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 55.88it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 66.64it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 70.10it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 82.52it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.47it/s]
2025-05-27 20:13:49,972 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.98, ppl:   2.66, acc:   0.72, generation: 15.7858[sec], evaluation: 0.0000[sec]
2025-05-27 20:13:49,985 - INFO - joeynmt.training - Example #0
2025-05-27 20:13:49,986 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:13:49,987 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:13:49,987 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose , ho mostr<unk> @ ato queste due cose per f<unk> @ ar vedere che i g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio , che i g<unk> @ hi<unk> @ ac<unk> @ cio per tre milioni di persone , e i di<unk> @ sp<unk> @ on<unk> @ i<unk> @ bili , il 4<unk> @ 0 % , aveva av<unk> @ uto 4<unk> @ 8 St<unk> @ ati Un<unk> @ iti , il 4<unk> @ 0 % .
2025-05-27 20:13:49,987 - INFO - joeynmt.training - Example #1
2025-05-27 20:13:49,988 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:13:49,988 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:13:49,988 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è molto for<unk> @ te , la di<unk> @ st<unk> @ anza di questo problema , perché non è la di<unk> @ st<unk> @ anza di questo problema , perché non si mostr<unk> @ a il ci<unk> @ b<unk> @ o del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:13:49,988 - INFO - joeynmt.training - Example #2
2025-05-27 20:13:49,989 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:13:49,989 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:13:49,989 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la lin<unk> @ ea c<unk> @ aus<unk> @ a della c<unk> @ li<unk> @ mat<unk> @ ica della nostra c<unk> @ li<unk> @ mat<unk> @ ica glob<unk> @ ale .
2025-05-27 20:13:49,989 - INFO - joeynmt.training - Example #3
2025-05-27 20:13:49,990 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:13:49,990 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:13:49,990 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si sp<unk> @ ost<unk> @ a in in<unk> @ ver<unk> @ no .
2025-05-27 20:13:49,990 - INFO - joeynmt.training - Example #4
2025-05-27 20:13:49,991 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:13:49,991 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:13:49,991 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @ ò che vi mostr<unk> @ er<unk> @ ò , è una ser<unk> @ ie di tr<unk> @ att<unk> @ amento di una ser<unk> @ ie di fr<unk> @ on<unk> @ te a qu<unk> @ ale è succ<unk> @ esso .
2025-05-27 20:13:53,353 - INFO - joeynmt.training - Epoch   9, Step:    66600, Batch Loss:     0.942054, Batch Acc: 0.726150, Tokens per Sec:    22993, Lr: 0.000300
2025-05-27 20:13:56,703 - INFO - joeynmt.training - Epoch   9, Step:    66700, Batch Loss:     0.926220, Batch Acc: 0.730332, Tokens per Sec:    23638, Lr: 0.000300
2025-05-27 20:14:00,077 - INFO - joeynmt.training - Epoch   9, Step:    66800, Batch Loss:     0.975681, Batch Acc: 0.730656, Tokens per Sec:    24396, Lr: 0.000300
2025-05-27 20:14:03,404 - INFO - joeynmt.training - Epoch   9, Step:    66900, Batch Loss:     0.839983, Batch Acc: 0.733124, Tokens per Sec:    23957, Lr: 0.000300
2025-05-27 20:14:06,740 - INFO - joeynmt.training - Epoch   9, Step:    67000, Batch Loss:     0.957166, Batch Acc: 0.724728, Tokens per Sec:    23611, Lr: 0.000300
2025-05-27 20:14:06,740 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:14:06,740 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 81.36it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 89.12it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 102.12it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 100.52it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 102.56it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 111.20it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 105.55it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 110.88it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 51.12it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:14, 54.58it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 52.44it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 74.79it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 83.46it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 71.15it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 72.15it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 77.47it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 58.55it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.34it/s]Predicting...:  30%|███       | 277/923 [00:03<00:12, 51.71it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 49.75it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 55.08it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 52.39it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 55.70it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 57.43it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 63.58it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 77.11it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 85.03it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 87.19it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 77.93it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 88.67it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 68.32it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:06, 74.59it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 68.68it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:07, 58.20it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:08, 50.39it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:07, 55.13it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 65.64it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:07, 54.50it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 45.65it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 39.99it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 39.56it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 46.98it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 32.12it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:11, 28.72it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:10, 30.46it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 39.35it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 37.29it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 36.28it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:08, 33.59it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:10, 25.66it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 26.28it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:08, 28.65it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 26.65it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 29.41it/s]Predicting...:  75%|███████▌  | 696/923 [00:14<00:15, 14.84it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:10, 20.98it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:08, 23.64it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:06, 30.17it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 38.22it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:05, 31.61it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 33.97it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 42.98it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 47.50it/s]Predicting...:  87%|████████▋ | 800/923 [00:16<00:02, 55.34it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 63.30it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 62.74it/s]Predicting...:  90%|█████████ | 835/923 [00:16<00:01, 45.26it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 57.35it/s]Predicting...:  93%|█████████▎| 862/923 [00:17<00:01, 59.02it/s]Predicting...:  95%|█████████▌| 878/923 [00:17<00:00, 72.54it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 75.87it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 86.39it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 52.37it/s]
2025-05-27 20:14:24,378 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.65, acc:   0.72, generation: 17.6239[sec], evaluation: 0.0000[sec]
2025-05-27 20:14:24,383 - INFO - joeynmt.training - Example #0
2025-05-27 20:14:24,383 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:14:24,383 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:14:24,383 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose che hanno mostr<unk> @ ato questi due cas<unk> @ i di c<unk> @ av<unk> @ i per di<unk> @ mostr<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i che hanno fatto per tre t<unk> @ as<unk> @ se di 4<unk> @ 0 % di qu<unk> @ elli che av<unk> @ evano 4<unk> @ 0 % , 4<unk> @ 0 % , il 4<unk> @ 0 % di cui è stato il 4<unk> @ 0 % .
2025-05-27 20:14:24,383 - INFO - joeynmt.training - Example #1
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o , perché non è il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - Example #2
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il punto , la c<unk> @ atti<unk> @ va del g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico , il cu<unk> @ ore del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico c<unk> @ li<unk> @ mat<unk> @ ico .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - Example #3
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - 	Hypothesis: Si può cres<unk> @ c<unk> @ ere in in<unk> @ ver<unk> @ no e in<unk> @ ver<unk> @ no .
2025-05-27 20:14:24,384 - INFO - joeynmt.training - Example #4
2025-05-27 20:14:24,385 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:14:24,385 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:14:24,385 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @ ò che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a di sc<unk> @ or<unk> @ so di 2<unk> @ 5 anni .
2025-05-27 20:14:27,753 - INFO - joeynmt.training - Epoch   9, Step:    67100, Batch Loss:     0.806152, Batch Acc: 0.731652, Tokens per Sec:    23722, Lr: 0.000300
2025-05-27 20:14:31,099 - INFO - joeynmt.training - Epoch   9, Step:    67200, Batch Loss:     0.989279, Batch Acc: 0.728875, Tokens per Sec:    23931, Lr: 0.000300
2025-05-27 20:14:34,431 - INFO - joeynmt.training - Epoch   9, Step:    67300, Batch Loss:     0.924313, Batch Acc: 0.731349, Tokens per Sec:    23682, Lr: 0.000300
2025-05-27 20:14:37,745 - INFO - joeynmt.training - Epoch   9, Step:    67400, Batch Loss:     0.864258, Batch Acc: 0.729423, Tokens per Sec:    23107, Lr: 0.000300
2025-05-27 20:14:41,093 - INFO - joeynmt.training - Epoch   9, Step:    67500, Batch Loss:     0.869777, Batch Acc: 0.729168, Tokens per Sec:    24532, Lr: 0.000300
2025-05-27 20:14:41,093 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:14:41,093 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 75.89it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 87.88it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 99.00it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 94.65it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 104.68it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 109.49it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 109.28it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 119.67it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 50.73it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:14, 53.67it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 63.23it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 91.11it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 98.54it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 73.81it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 66.83it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 76.25it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 56.16it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 55.05it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 49.54it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.70it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 55.64it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 59.76it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:11, 52.33it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 49.97it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 58.57it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 72.34it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 79.32it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 78.13it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:08, 58.48it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 70.83it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:07, 59.74it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:06, 68.20it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 64.58it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 67.63it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 72.85it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 80.40it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 63.07it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 48.38it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 41.45it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 35.84it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:08, 41.75it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 31.03it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:11, 29.52it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 32.25it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 40.58it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 39.99it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 36.16it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 35.58it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:08, 30.47it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 30.42it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 33.62it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 26.95it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 29.73it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:08, 26.75it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 34.92it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:05, 35.45it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 43.11it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 50.36it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 35.91it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 39.58it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 47.20it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 51.79it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 60.43it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 71.98it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 74.21it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 57.68it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 58.91it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 72.31it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 79.49it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 88.83it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.27it/s]
2025-05-27 20:14:57,510 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 16.4029[sec], evaluation: 0.0000[sec]
2025-05-27 20:14:57,510 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:14:58,014 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/66000.ckpt
2025-05-27 20:14:58,033 - INFO - joeynmt.training - Example #0
2025-05-27 20:14:58,034 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:14:58,035 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:14:58,035 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose che hanno mostr<unk> @ ato queste due cose , per cui i g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i po<unk> @ ver<unk> @ i po<unk> @ ver<unk> @ i , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , il 4<unk> @ 0 , per c<unk> @ ento di tre milioni di anni , il 4<unk> @ 0 , per c<unk> @ ento del 4<unk> @ 0 % .
2025-05-27 20:14:58,035 - INFO - joeynmt.training - Example #1
2025-05-27 20:14:58,036 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:14:58,036 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:14:58,036 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio , perché non è il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:14:58,036 - INFO - joeynmt.training - Example #2
2025-05-27 20:14:58,037 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:14:58,037 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:14:58,037 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il cu<unk> @ ore po<unk> @ ver<unk> @ tà po<unk> @ ver<unk> @ i po<unk> @ ver<unk> @ i po<unk> @ ver<unk> @ i del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:14:58,037 - INFO - joeynmt.training - Example #3
2025-05-27 20:14:58,038 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:14:58,038 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:14:58,038 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un in<unk> @ ver<unk> @ no e nel v<unk> @ ento e nel v<unk> @ ento .
2025-05-27 20:14:58,038 - INFO - joeynmt.training - Example #4
2025-05-27 20:14:58,039 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:14:58,039 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:14:58,039 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma cosa che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ en<unk> @ a di ri<unk> @ chi<unk> @ est<unk> @ a , che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:15:01,422 - INFO - joeynmt.training - Epoch   9, Step:    67600, Batch Loss:     0.980151, Batch Acc: 0.731523, Tokens per Sec:    20953, Lr: 0.000300
2025-05-27 20:15:04,734 - INFO - joeynmt.training - Epoch   9, Step:    67700, Batch Loss:     0.828859, Batch Acc: 0.732079, Tokens per Sec:    23445, Lr: 0.000300
2025-05-27 20:15:08,061 - INFO - joeynmt.training - Epoch   9, Step:    67800, Batch Loss:     0.884305, Batch Acc: 0.731860, Tokens per Sec:    23343, Lr: 0.000300
2025-05-27 20:15:11,387 - INFO - joeynmt.training - Epoch   9, Step:    67900, Batch Loss:     0.955600, Batch Acc: 0.730176, Tokens per Sec:    23288, Lr: 0.000300
2025-05-27 20:15:14,704 - INFO - joeynmt.training - Epoch   9, Step:    68000, Batch Loss:     0.991202, Batch Acc: 0.725738, Tokens per Sec:    24037, Lr: 0.000300
2025-05-27 20:15:14,705 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:15:14,705 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 61.08it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 77.07it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 81.68it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:10, 85.72it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 86.45it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 86.86it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:10, 76.66it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:12, 63.56it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.43it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.28it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 91.24it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:11, 58.90it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:13, 51.09it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:11, 58.32it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:13, 47.57it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:13, 47.34it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 47.08it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 46.67it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.42it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:10, 55.57it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 58.68it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 64.89it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 52.59it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 64.82it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 84.50it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 91.48it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 86.96it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 77.31it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 87.18it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 67.33it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 73.24it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 67.23it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 71.56it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 55.36it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 59.34it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 70.38it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 56.74it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 45.38it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 40.29it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 36.72it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 44.94it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 38.54it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.47it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 33.83it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 43.12it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 45.95it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 44.60it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:06, 42.41it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:07, 34.02it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 32.90it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 38.17it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 30.08it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 30.86it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 26.97it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 34.45it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:05, 35.53it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 43.89it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 55.52it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:03, 44.41it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:03, 42.79it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 53.48it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 57.74it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 68.11it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 75.82it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 77.21it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 61.85it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 56.95it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 67.73it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 70.71it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 80.31it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.93it/s]
2025-05-27 20:15:30,931 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.02, ppl:   2.76, acc:   0.71, generation: 16.2126[sec], evaluation: 0.0000[sec]
2025-05-27 20:15:30,936 - INFO - joeynmt.training - Example #0
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due di<unk> @ ta , per in<unk> @ contr<unk> @ are le due di<unk> @ ta , per con<unk> @ si<unk> @ der<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che hanno fatto per circa tre milioni di tre milioni di anni , il ci<unk> @ b<unk> @ o , per tre milioni di anni , il 4<unk> @ 0 , per c<unk> @ ento , il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:15:30,937 - INFO - joeynmt.training - Example #1
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:15:30,937 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la res<unk> @ ist<unk> @ enza di questo problema spe<unk> @ ci<unk> @ ale , perché non mostr<unk> @ a il fatto che non mostr<unk> @ a il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - Example #2
2025-05-27 20:15:30,938 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , è il cu<unk> @ ore po<unk> @ vere è il cu<unk> @ ore po<unk> @ vere il cu<unk> @ ore c<unk> @ atti<unk> @ vo del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:15:30,938 - INFO - joeynmt.training - Example #3
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Hypothesis: Si trtr<unk> @ at<unk> @ ta di un v<unk> @ ento e nel v<unk> @ ento e si sp<unk> @ ost<unk> @ a nel sen<unk> @ so di .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - Example #4
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:15:30,939 - INFO - joeynmt.training - 	Hypothesis: Il prosprosprosprosprospros<unk> @ si<unk> @ mo di<unk> @ mostr<unk> @ ato che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:15:34,282 - INFO - joeynmt.training - Epoch   9, Step:    68100, Batch Loss:     1.068740, Batch Acc: 0.729075, Tokens per Sec:    23187, Lr: 0.000300
2025-05-27 20:15:37,619 - INFO - joeynmt.training - Epoch   9, Step:    68200, Batch Loss:     0.943880, Batch Acc: 0.728827, Tokens per Sec:    23854, Lr: 0.000300
2025-05-27 20:15:40,927 - INFO - joeynmt.training - Epoch   9, Step:    68300, Batch Loss:     0.933599, Batch Acc: 0.731898, Tokens per Sec:    23495, Lr: 0.000300
2025-05-27 20:15:44,273 - INFO - joeynmt.training - Epoch   9, Step:    68400, Batch Loss:     0.940603, Batch Acc: 0.726211, Tokens per Sec:    24052, Lr: 0.000300
2025-05-27 20:15:47,578 - INFO - joeynmt.training - Epoch   9, Step:    68500, Batch Loss:     0.927231, Batch Acc: 0.729388, Tokens per Sec:    23287, Lr: 0.000300
2025-05-27 20:15:47,578 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:15:47,578 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 73.48it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 83.69it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 89.36it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 103.24it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 81.94it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:08, 95.35it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 68.73it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 85.89it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:17, 44.31it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 47.76it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.04it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.10it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 86.28it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 73.08it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:13, 51.89it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:11, 59.54it/s]Predicting...:  28%|██▊       | 258/923 [00:04<00:13, 48.47it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:14, 44.37it/s]Predicting...:  30%|███       | 277/923 [00:04<00:13, 46.39it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 45.67it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.62it/s]Predicting...:  34%|███▍      | 314/923 [00:05<00:10, 58.63it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 61.55it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 62.79it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 72.20it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 89.42it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 94.98it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:05, 92.38it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:07, 66.36it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 78.55it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:07, 64.09it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:06, 70.78it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:06, 65.64it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:06, 68.80it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:07, 55.91it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 59.86it/s]Predicting...:  58%|█████▊    | 531/923 [00:08<00:05, 69.87it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:06, 59.84it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 48.36it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:10, 36.24it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:10, 34.83it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 44.24it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 33.56it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:12, 25.87it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:11, 27.90it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:08, 36.37it/s]Predicting...:  68%|██████▊   | 630/923 [00:11<00:07, 37.00it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 36.00it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:08, 34.12it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:09, 28.88it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:09, 26.73it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:08, 31.39it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:08, 28.01it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:09, 25.83it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:10, 22.54it/s]Predicting...:  77%|███████▋  | 708/923 [00:14<00:07, 30.52it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:07, 28.86it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:05, 35.92it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:04, 40.02it/s]Predicting...:  81%|████████  | 749/923 [00:15<00:05, 31.55it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 33.55it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 44.32it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 47.80it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 58.94it/s]Predicting...:  88%|████████▊ | 815/923 [00:16<00:01, 67.05it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 69.07it/s]Predicting...:  90%|█████████ | 835/923 [00:16<00:01, 53.13it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 67.76it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:00, 66.17it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 80.87it/s]Predicting...:  97%|█████████▋| 892/923 [00:17<00:00, 86.75it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 89.05it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 53.07it/s]
2025-05-27 20:16:04,985 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 17.3937[sec], evaluation: 0.0000[sec]
2025-05-27 20:16:04,986 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:16:05,467 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/65500.ckpt
2025-05-27 20:16:05,492 - INFO - joeynmt.training - Example #0
2025-05-27 20:16:05,493 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:16:05,493 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:16:05,493 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due s<unk> @ ac<unk> @ chi per c<unk> @ aus<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ato , che gli e<unk> @ ic<unk> @ e<unk> @ ani , per tre milioni di anni , che ha fatto per il 4<unk> @ 8 stati di tre milioni di anni , il 4<unk> @ 8 stati di tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:16:05,493 - INFO - joeynmt.training - Example #1
2025-05-27 20:16:05,494 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:16:05,494 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:16:05,494 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la m<unk> @ em<unk> @ or<unk> @ ia di questo problema spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:16:05,494 - INFO - joeynmt.training - Example #2
2025-05-27 20:16:05,495 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:16:05,495 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:16:05,495 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la cosa ar<unk> @ t<unk> @ t<unk> @ ica è il cu<unk> @ ore ar<unk> @ t<unk> @ ico della nostra c<unk> @ li<unk> @ one .
2025-05-27 20:16:05,496 - INFO - joeynmt.training - Example #3
2025-05-27 20:16:05,496 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:16:05,496 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:16:05,496 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e cres<unk> @ c<unk> @ ere in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:16:05,496 - INFO - joeynmt.training - Example #4
2025-05-27 20:16:05,497 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:16:05,497 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:16:05,497 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a è una c<unk> @ ic<unk> @ l<unk> @ et<unk> @ ta di quello che vi mostr<unk> @ a cosa acc<unk> @ ade negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:16:08,836 - INFO - joeynmt.training - Epoch   9, Step:    68600, Batch Loss:     0.891236, Batch Acc: 0.728643, Tokens per Sec:    20377, Lr: 0.000300
2025-05-27 20:16:12,152 - INFO - joeynmt.training - Epoch   9, Step:    68700, Batch Loss:     0.864435, Batch Acc: 0.729300, Tokens per Sec:    23072, Lr: 0.000300
2025-05-27 20:16:15,474 - INFO - joeynmt.training - Epoch   9, Step:    68800, Batch Loss:     1.087281, Batch Acc: 0.729270, Tokens per Sec:    23557, Lr: 0.000300
2025-05-27 20:16:18,824 - INFO - joeynmt.training - Epoch   9, Step:    68900, Batch Loss:     0.950204, Batch Acc: 0.727381, Tokens per Sec:    24044, Lr: 0.000300
2025-05-27 20:16:22,141 - INFO - joeynmt.training - Epoch   9, Step:    69000, Batch Loss:     0.928588, Batch Acc: 0.726555, Tokens per Sec:    22992, Lr: 0.000300
2025-05-27 20:16:22,141 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:16:22,141 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 71.89it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 93.65it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:13, 64.21it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:11, 76.30it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 87.27it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:10, 76.55it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:11, 71.47it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:18, 42.14it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 47.16it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 57.10it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 80.55it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.47it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:08, 82.35it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 75.31it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 80.30it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:11, 54.95it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 52.18it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.38it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 51.40it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 55.36it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:10, 58.38it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:09, 65.02it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:13, 43.21it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 53.95it/s]Predicting...:  41%|████      | 379/923 [00:06<00:07, 69.46it/s]Predicting...:  43%|████▎     | 393/923 [00:06<00:06, 78.82it/s]Predicting...:  44%|████▍     | 408/923 [00:06<00:06, 79.46it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:07, 66.49it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:06, 76.68it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 80.39it/s]Predicting...:  51%|█████     | 469/923 [00:07<00:05, 89.56it/s]Predicting...:  52%|█████▏    | 480/923 [00:07<00:05, 77.12it/s]Predicting...:  54%|█████▎    | 494/923 [00:07<00:05, 82.12it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 63.45it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.05it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 80.42it/s]Predicting...:  59%|█████▊    | 540/923 [00:08<00:08, 42.89it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:09, 37.61it/s]Predicting...:  60%|██████    | 556/923 [00:09<00:09, 36.91it/s]Predicting...:  62%|██████▏   | 568/923 [00:09<00:09, 36.04it/s]Predicting...:  63%|██████▎   | 580/923 [00:09<00:07, 44.02it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:10, 31.70it/s]Predicting...:  65%|██████▍   | 596/923 [00:10<00:10, 32.50it/s]Predicting...:  66%|██████▌   | 605/923 [00:10<00:09, 32.43it/s]Predicting...:  67%|██████▋   | 618/923 [00:10<00:07, 41.29it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 42.65it/s]Predicting...:  69%|██████▉   | 639/923 [00:11<00:07, 39.59it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:07, 35.18it/s]Predicting...:  71%|███████   | 653/923 [00:12<00:10, 24.75it/s]Predicting...:  72%|███████▏  | 661/923 [00:12<00:10, 24.53it/s]Predicting...:  73%|███████▎  | 671/923 [00:12<00:08, 28.27it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 24.81it/s]Predicting...:  74%|███████▍  | 687/923 [00:13<00:08, 27.53it/s]Predicting...:  75%|███████▌  | 696/923 [00:13<00:10, 22.30it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:07, 30.59it/s]Predicting...:  78%|███████▊  | 717/923 [00:14<00:06, 30.09it/s]Predicting...:  79%|███████▉  | 729/923 [00:14<00:05, 37.96it/s]Predicting...:  80%|████████  | 742/923 [00:14<00:03, 48.25it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:05, 34.24it/s]Predicting...:  82%|████████▏ | 759/923 [00:15<00:04, 34.76it/s]Predicting...:  84%|████████▍ | 774/923 [00:15<00:03, 46.96it/s]Predicting...:  85%|████████▌ | 786/923 [00:15<00:02, 53.19it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:01, 64.62it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 76.44it/s]Predicting...:  90%|████████▉ | 827/923 [00:16<00:01, 72.86it/s]Predicting...:  92%|█████████▏| 850/923 [00:16<00:01, 62.46it/s]Predicting...:  93%|█████████▎| 862/923 [00:16<00:01, 59.53it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 71.03it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 75.55it/s]Predicting...:  98%|█████████▊| 908/923 [00:17<00:00, 76.90it/s]Predicting...: 100%|██████████| 923/923 [00:17<00:00, 53.45it/s]
2025-05-27 20:16:39,425 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.63, acc:   0.72, generation: 17.2698[sec], evaluation: 0.0000[sec]
2025-05-27 20:16:39,786 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/62500.ckpt
2025-05-27 20:16:39,807 - INFO - joeynmt.training - Example #0
2025-05-27 20:16:39,809 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:16:39,809 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:16:39,809 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose , per f<unk> @ ir<unk> @ m<unk> @ enti per c<unk> @ aus<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i qu<unk> @ elli che hanno fatto per tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % dei m<unk> @ oti<unk> @ vi per il 4<unk> @ 0 % del 4<unk> @ 0 % dei sol<unk> @ di , 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:16:39,809 - INFO - joeynmt.training - Example #1
2025-05-27 20:16:39,810 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:16:39,810 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:16:39,810 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ anza di questo part<unk> @ icol<unk> @ are spe<unk> @ ci<unk> @ f<unk> @ ico , perché non è il D<unk> @ ic<unk> @ e non lo mostr<unk> @ a il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:16:39,810 - INFO - joeynmt.training - Example #2
2025-05-27 20:16:39,811 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:16:39,811 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:16:39,811 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la c<unk> @ atti<unk> @ va del nostro s<unk> @ ito è il cu<unk> @ ore del nostro cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:16:39,811 - INFO - joeynmt.training - Example #3
2025-05-27 20:16:39,812 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:16:39,812 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:16:39,812 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ or<unk> @ r<unk> @ endo in in<unk> @ ver<unk> @ no e si in<unk> @ ver<unk> @ no .
2025-05-27 20:16:39,812 - INFO - joeynmt.training - Example #4
2025-05-27 20:16:39,812 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:16:39,813 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:16:39,813 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a , è una di<unk> @ segn<unk> @ ata di sc<unk> @ or<unk> @ r<unk> @ ere , e &apos; una sc<unk> @ or<unk> @ sa di 2<unk> @ 5 anni .
2025-05-27 20:16:43,174 - INFO - joeynmt.training - Epoch   9, Step:    69100, Batch Loss:     0.851346, Batch Acc: 0.727469, Tokens per Sec:    21414, Lr: 0.000300
2025-05-27 20:16:46,476 - INFO - joeynmt.training - Epoch   9, Step:    69200, Batch Loss:     0.949154, Batch Acc: 0.729226, Tokens per Sec:    24249, Lr: 0.000300
2025-05-27 20:16:49,791 - INFO - joeynmt.training - Epoch   9, Step:    69300, Batch Loss:     0.914277, Batch Acc: 0.725233, Tokens per Sec:    24249, Lr: 0.000300
2025-05-27 20:16:53,104 - INFO - joeynmt.training - Epoch   9, Step:    69400, Batch Loss:     0.977736, Batch Acc: 0.727470, Tokens per Sec:    23879, Lr: 0.000300
2025-05-27 20:16:56,436 - INFO - joeynmt.training - Epoch   9, Step:    69500, Batch Loss:     0.965108, Batch Acc: 0.726428, Tokens per Sec:    24306, Lr: 0.000300
2025-05-27 20:16:56,436 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:16:56,436 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 69.83it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 82.63it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 91.07it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 100.41it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 104.03it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 120.96it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 129.22it/s]Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 60.28it/s] Predicting...:  17%|█▋        | 160/923 [00:01<00:11, 67.32it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 90.90it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 98.19it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 88.04it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:08, 78.06it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 60.53it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 57.23it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 56.66it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 64.51it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 67.78it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 72.60it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 66.12it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:13, 44.30it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 51.72it/s]Predicting...:  41%|████      | 379/923 [00:05<00:08, 65.75it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:07, 73.61it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 78.42it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 88.84it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 100.68it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 102.77it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 107.63it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 79.53it/s] Predicting...:  56%|█████▌    | 517/923 [00:06<00:06, 62.40it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 68.59it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 61.36it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 51.04it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 49.67it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 46.08it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 53.80it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 40.81it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 40.03it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 41.45it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 49.11it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 47.80it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 43.22it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 40.83it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 35.93it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 34.97it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.90it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:10, 23.17it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:08, 26.28it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:09, 25.20it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 33.74it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 33.77it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 41.90it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 52.27it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 39.16it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:05, 29.60it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 40.12it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:03, 44.03it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 52.04it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 61.62it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 65.58it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 47.68it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 58.65it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 57.02it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 72.19it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 76.79it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 86.51it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.16it/s]
2025-05-27 20:17:12,048 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 15.6029[sec], evaluation: 0.0000[sec]
2025-05-27 20:17:12,048 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:17:12,534 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/63000.ckpt
2025-05-27 20:17:12,553 - INFO - joeynmt.training - Example #0
2025-05-27 20:17:12,555 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:17:12,555 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:17:12,555 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due p<unk> @ op<unk> @ ol<unk> @ i per ri<unk> @ dur<unk> @ re le g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico che i g<unk> @ hi<unk> @ ac<unk> @ cio per i qu<unk> @ elli che hanno av<unk> @ uto tre milioni di anni , il 4<unk> @ 0 , il 4<unk> @ 0 % del 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:17:12,555 - INFO - joeynmt.training - Example #1
2025-05-27 20:17:12,556 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:17:12,556 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:17:12,556 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la di<unk> @ st<unk> @ azione di questo part<unk> @ icol<unk> @ are probl<unk> @ emi spe<unk> @ ci<unk> @ ali spe<unk> @ ci<unk> @ f<unk> @ ici che non mostr<unk> @ a il D<unk> @ ic<unk> @ e<unk> @ da .
2025-05-27 20:17:12,556 - INFO - joeynmt.training - Example #2
2025-05-27 20:17:12,557 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:17:12,557 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:17:12,557 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ t<unk> @ amente , la lin<unk> @ ea ar<unk> @ t<unk> @ ico è la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio del cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:17:12,557 - INFO - joeynmt.training - Example #3
2025-05-27 20:17:12,558 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:17:12,558 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:17:12,558 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si in<unk> @ ver<unk> @ no .
2025-05-27 20:17:12,558 - INFO - joeynmt.training - Example #4
2025-05-27 20:17:12,559 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:17:12,559 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:17:12,559 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o che vi mostr<unk> @ o è una sc<unk> @ al<unk> @ a che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:17:15,909 - INFO - joeynmt.training - Epoch   9, Step:    69600, Batch Loss:     0.966279, Batch Acc: 0.732492, Tokens per Sec:    20330, Lr: 0.000300
2025-05-27 20:17:19,234 - INFO - joeynmt.training - Epoch   9, Step:    69700, Batch Loss:     0.962873, Batch Acc: 0.729508, Tokens per Sec:    23346, Lr: 0.000300
2025-05-27 20:17:22,582 - INFO - joeynmt.training - Epoch   9, Step:    69800, Batch Loss:     0.978434, Batch Acc: 0.729300, Tokens per Sec:    24284, Lr: 0.000300
2025-05-27 20:17:25,918 - INFO - joeynmt.training - Epoch   9, Step:    69900, Batch Loss:     0.983676, Batch Acc: 0.725484, Tokens per Sec:    23870, Lr: 0.000300
2025-05-27 20:17:29,248 - INFO - joeynmt.training - Epoch   9, Step:    70000, Batch Loss:     0.949489, Batch Acc: 0.730432, Tokens per Sec:    23867, Lr: 0.000300
2025-05-27 20:17:29,248 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:17:29,248 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 77.09it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 88.27it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 103.04it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 111.18it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 102.99it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 84.18it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:08, 96.21it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:15, 49.43it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 53.26it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.84it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 80.69it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 90.72it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.46it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 76.72it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:09, 73.49it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:09, 66.71it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 62.21it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 53.48it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 59.40it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 59.65it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 64.51it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 62.87it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 58.64it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 69.52it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 83.20it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 93.53it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 97.30it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 107.22it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 115.58it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 80.85it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:05, 88.45it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 79.70it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 83.17it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 72.48it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 75.05it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 60.03it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 53.29it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 59.34it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:06, 49.56it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:07, 46.28it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 46.19it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 54.23it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 53.77it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 49.22it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:05, 46.81it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 33.79it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 33.71it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 37.01it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 33.44it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 37.08it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:06, 37.24it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:04, 44.58it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:04, 43.40it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:04, 48.01it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:03, 59.95it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:03, 43.60it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 42.40it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 56.00it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 66.58it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 74.92it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 85.57it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 85.86it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:01, 71.63it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 67.14it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 81.68it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 89.70it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 101.46it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 65.77it/s] 
2025-05-27 20:17:43,295 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 14.0339[sec], evaluation: 0.0000[sec]
2025-05-27 20:17:43,296 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:17:43,801 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/65000.ckpt
2025-05-27 20:17:43,825 - INFO - joeynmt.training - Example #0
2025-05-27 20:17:43,827 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:17:43,827 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:17:43,827 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due cose , per fare per fare per con<unk> @ si<unk> @ der<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ai , per i con<unk> @ si<unk> @ der<unk> @ are i 4<unk> @ 8 milioni di volte , che ha av<unk> @ uto il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:17:43,827 - INFO - joeynmt.training - Example #1
2025-05-27 20:17:43,828 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:17:43,828 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:17:43,828 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ ra di tutto questo spe<unk> @ ci<unk> @ f<unk> @ ico , perché non è l&apos; idea di questo part<unk> @ icol<unk> @ are spe<unk> @ ci<unk> @ ale .
2025-05-27 20:17:43,828 - INFO - joeynmt.training - Example #2
2025-05-27 20:17:43,829 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:17:43,829 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:17:43,829 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la lin<unk> @ ea po<unk> @ ver<unk> @ a , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il cu<unk> @ ore c<unk> @ li<unk> @ m<unk> @ as<unk> @ e del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico .
2025-05-27 20:17:43,829 - INFO - joeynmt.training - Example #3
2025-05-27 20:17:43,830 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:17:43,830 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:17:43,830 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in in<unk> @ ver<unk> @ no e si tr<unk> @ at<unk> @ ta .
2025-05-27 20:17:43,830 - INFO - joeynmt.training - Example #4
2025-05-27 20:17:43,831 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:17:43,831 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:17:43,831 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma volta che vi mostr<unk> @ o è una c<unk> @ ura di una ser<unk> @ ie di sc<unk> @ or<unk> @ so , che vi mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:17:47,209 - INFO - joeynmt.training - Epoch   9, Step:    70100, Batch Loss:     0.883890, Batch Acc: 0.730245, Tokens per Sec:    20585, Lr: 0.000300
2025-05-27 20:17:50,543 - INFO - joeynmt.training - Epoch   9, Step:    70200, Batch Loss:     0.906340, Batch Acc: 0.726153, Tokens per Sec:    23662, Lr: 0.000300
2025-05-27 20:17:53,857 - INFO - joeynmt.training - Epoch   9, Step:    70300, Batch Loss:     1.011071, Batch Acc: 0.726810, Tokens per Sec:    23944, Lr: 0.000300
2025-05-27 20:17:57,187 - INFO - joeynmt.training - Epoch   9, Step:    70400, Batch Loss:     0.953250, Batch Acc: 0.730103, Tokens per Sec:    24047, Lr: 0.000300
2025-05-27 20:18:00,497 - INFO - joeynmt.training - Epoch   9, Step:    70500, Batch Loss:     0.940968, Batch Acc: 0.729158, Tokens per Sec:    23641, Lr: 0.000300
2025-05-27 20:18:00,497 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:18:00,497 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 70.69it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 85.22it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 91.92it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 95.00it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 103.97it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 111.99it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 73.25it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 88.97it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:25, 30.73it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:21, 36.02it/s]Predicting...:  20%|██        | 185/923 [00:02<00:11, 64.66it/s]Predicting...:  22%|██▏       | 201/923 [00:03<00:09, 73.78it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 73.96it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 65.92it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 74.70it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:09, 65.73it/s]Predicting...:  30%|███       | 277/923 [00:04<00:10, 64.31it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:10, 60.15it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 67.03it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 72.56it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 73.80it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 67.17it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 76.76it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 103.54it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 105.86it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 114.14it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:03, 126.18it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:03, 128.96it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:03, 111.37it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:03, 108.97it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 93.57it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 86.19it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:05, 67.42it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:05, 61.21it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 65.99it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:06, 50.74it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:06, 50.31it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 59.25it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:04, 59.75it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:04, 57.01it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 42.32it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:07, 36.74it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:07, 36.23it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 40.56it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:06, 36.57it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:05, 39.35it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:07, 30.43it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:05, 40.09it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 41.19it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 50.74it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 63.85it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 45.40it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 55.29it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 59.98it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 67.37it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 80.78it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 83.09it/s]Predicting...:  92%|█████████▏| 850/923 [00:13<00:00, 77.02it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 72.21it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 92.65it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 116.12it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 67.89it/s] 
2025-05-27 20:18:14,102 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.61, acc:   0.72, generation: 13.5960[sec], evaluation: 0.0000[sec]
2025-05-27 20:18:14,102 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:18:14,588 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/67500.ckpt
2025-05-27 20:18:14,611 - INFO - joeynmt.training - Example #0
2025-05-27 20:18:14,612 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:18:14,612 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:18:14,612 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ mostr<unk> @ a per ri<unk> @ dur<unk> @ re la g<unk> @ hi<unk> @ ac<unk> @ cio che , i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che aveva av<unk> @ uto 4<unk> @ 8 ore di tre milioni di anni , che aveva 4<unk> @ 8 ore di 4<unk> @ 8 ore , 4<unk> @ 8 ore di 4<unk> @ 8 ore .
2025-05-27 20:18:14,612 - INFO - joeynmt.training - Example #1
2025-05-27 20:18:14,613 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:18:14,613 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:18:14,613 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza che non è abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:18:14,613 - INFO - joeynmt.training - Example #2
2025-05-27 20:18:14,614 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:18:14,614 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:18:14,614 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la cosa più po<unk> @ ver<unk> @ a è il g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:18:14,614 - INFO - joeynmt.training - Example #3
2025-05-27 20:18:14,615 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:18:14,615 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:18:14,615 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ì in in<unk> @ ver<unk> @ no e si cres<unk> @ ci<unk> @ u<unk> @ te nel v<unk> @ ento .
2025-05-27 20:18:14,615 - INFO - joeynmt.training - Example #4
2025-05-27 20:18:14,615 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:18:14,616 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:18:14,616 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a è una c<unk> @ ura di di<unk> @ seg<unk> @ na è una c<unk> @ ura di di<unk> @ seg<unk> @ na che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:18:17,854 - INFO - joeynmt.training - Epoch   9, Step:    70600, Batch Loss:     0.824759, Batch Acc: 0.728348, Tokens per Sec:    20832, Lr: 0.000300
2025-05-27 20:18:21,184 - INFO - joeynmt.training - Epoch   9, Step:    70700, Batch Loss:     0.892371, Batch Acc: 0.727699, Tokens per Sec:    23593, Lr: 0.000300
2025-05-27 20:18:24,492 - INFO - joeynmt.training - Epoch   9, Step:    70800, Batch Loss:     0.966860, Batch Acc: 0.727346, Tokens per Sec:    23731, Lr: 0.000300
2025-05-27 20:18:27,798 - INFO - joeynmt.training - Epoch   9, Step:    70900, Batch Loss:     0.927842, Batch Acc: 0.731212, Tokens per Sec:    23246, Lr: 0.000300
2025-05-27 20:18:29,588 - INFO - joeynmt.training - Epoch   9: total training loss 7297.46
2025-05-27 20:18:29,588 - INFO - joeynmt.training - EPOCH 10
2025-05-27 20:18:31,104 - INFO - joeynmt.training - Epoch  10, Step:    71000, Batch Loss:     0.973666, Batch Acc: 0.732212, Tokens per Sec:    22836, Lr: 0.000300
2025-05-27 20:18:31,105 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:18:31,105 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 71.53it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 87.83it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 89.88it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 93.19it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 94.79it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 110.60it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 100.69it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:10, 77.13it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 64.44it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 67.44it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 90.31it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 94.48it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 73.52it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:09, 75.27it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 76.49it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:10, 62.25it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 56.74it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 55.41it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 48.38it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 53.97it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.55it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.11it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:10, 57.06it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 50.21it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 61.22it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 78.79it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 83.67it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 82.61it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:07, 70.03it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:07, 67.38it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 75.23it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 83.37it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 75.11it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 83.41it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 65.32it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 71.05it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 56.22it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 48.86it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 43.44it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.43it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.66it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 37.68it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.47it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 35.31it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 43.58it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 43.69it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 41.27it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:08, 30.84it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.06it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 29.95it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 32.67it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 27.77it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 30.55it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:09, 24.03it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 30.95it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 33.34it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 41.19it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 51.57it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 41.58it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 43.65it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 57.24it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 58.47it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 69.07it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 81.79it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 76.87it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 63.87it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 59.28it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 72.86it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 80.69it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 93.90it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.66it/s]
2025-05-27 20:18:46,855 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 15.7367[sec], evaluation: 0.0000[sec]
2025-05-27 20:18:47,286 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/69000.ckpt
2025-05-27 20:18:47,308 - INFO - joeynmt.training - Example #0
2025-05-27 20:18:47,309 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:18:47,309 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:18:47,309 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato questi due di<unk> @ rit<unk> @ ti per ri<unk> @ dur<unk> @ re i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per il 4<unk> @ 8 stati , per c<unk> @ op<unk> @ p<unk> @ ure , per tre milioni di anni .
2025-05-27 20:18:47,309 - INFO - joeynmt.training - Example #1
2025-05-27 20:18:47,310 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:18:47,310 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:18:47,310 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ anza , ma non è il D<unk> @ ic<unk> @ e non è il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio , non è il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ da .
2025-05-27 20:18:47,310 - INFO - joeynmt.training - Example #2
2025-05-27 20:18:47,311 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:18:47,311 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:18:47,311 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio , il sistema di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale .
2025-05-27 20:18:47,311 - INFO - joeynmt.training - Example #3
2025-05-27 20:18:47,312 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:18:47,312 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:18:47,312 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , nel v<unk> @ ento e si s<unk> @ v<unk> @ eg<unk> @ li<unk> @ ano .
2025-05-27 20:18:47,312 - INFO - joeynmt.training - Example #4
2025-05-27 20:18:47,313 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:18:47,313 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:18:47,313 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a è una st<unk> @ anza di di<unk> @ seg<unk> @ ni è una st<unk> @ anza di di<unk> @ seg<unk> @ ni , che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:18:50,516 - INFO - joeynmt.training - Epoch  10, Step:    71100, Batch Loss:     0.916095, Batch Acc: 0.738323, Tokens per Sec:    21542, Lr: 0.000300
2025-05-27 20:18:53,709 - INFO - joeynmt.training - Epoch  10, Step:    71200, Batch Loss:     0.877577, Batch Acc: 0.737826, Tokens per Sec:    24659, Lr: 0.000300
2025-05-27 20:18:56,872 - INFO - joeynmt.training - Epoch  10, Step:    71300, Batch Loss:     0.848791, Batch Acc: 0.737042, Tokens per Sec:    24720, Lr: 0.000300
2025-05-27 20:19:00,075 - INFO - joeynmt.training - Epoch  10, Step:    71400, Batch Loss:     0.906458, Batch Acc: 0.736351, Tokens per Sec:    24995, Lr: 0.000300
2025-05-27 20:19:03,262 - INFO - joeynmt.training - Epoch  10, Step:    71500, Batch Loss:     0.957808, Batch Acc: 0.741761, Tokens per Sec:    25563, Lr: 0.000300
2025-05-27 20:19:03,262 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:19:03,262 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 81.29it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 95.15it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:07, 112.43it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 115.59it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 82.60it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:08, 95.76it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:11, 71.80it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:12, 64.41it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 59.03it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 87.62it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 93.85it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 88.12it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 80.81it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 86.43it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:09, 66.32it/s]Predicting...:  30%|███       | 277/923 [00:03<00:09, 65.22it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 61.54it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:09, 68.04it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 66.41it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:07, 76.05it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:06, 83.95it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:06, 92.24it/s]Predicting...:  41%|████      | 379/923 [00:04<00:04, 109.38it/s]Predicting...:  43%|████▎     | 393/923 [00:04<00:04, 108.48it/s]Predicting...:  44%|████▍     | 408/923 [00:04<00:04, 110.33it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 97.98it/s] Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 106.01it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 106.39it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 112.40it/s]Predicting...:  54%|█████▎    | 494/923 [00:05<00:04, 100.75it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:04, 83.41it/s] Predicting...:  59%|█████▊    | 540/923 [00:06<00:04, 80.76it/s]Predicting...:  60%|██████    | 556/923 [00:06<00:06, 58.08it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:06, 53.31it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:05, 58.43it/s]Predicting...:  64%|██████▎   | 587/923 [00:07<00:07, 47.53it/s]Predicting...:  65%|██████▍   | 596/923 [00:07<00:07, 45.97it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:07, 42.85it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:05, 53.60it/s]Predicting...:  68%|██████▊   | 630/923 [00:08<00:05, 53.24it/s]Predicting...:  69%|██████▉   | 639/923 [00:08<00:05, 49.67it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:07, 39.33it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:08, 33.03it/s]Predicting...:  72%|███████▏  | 661/923 [00:09<00:08, 31.49it/s]Predicting...:  73%|███████▎  | 671/923 [00:09<00:06, 37.54it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 33.44it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:06, 37.90it/s]Predicting...:  75%|███████▌  | 696/923 [00:10<00:07, 29.41it/s]Predicting...:  77%|███████▋  | 708/923 [00:10<00:05, 40.42it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 39.27it/s]Predicting...:  79%|███████▉  | 729/923 [00:11<00:03, 49.99it/s]Predicting...:  80%|████████  | 742/923 [00:11<00:02, 62.16it/s]Predicting...:  82%|████████▏ | 759/923 [00:11<00:03, 48.36it/s]Predicting...:  84%|████████▍ | 774/923 [00:11<00:02, 60.03it/s]Predicting...:  85%|████████▌ | 786/923 [00:12<00:02, 61.27it/s]Predicting...:  87%|████████▋ | 800/923 [00:12<00:01, 71.33it/s]Predicting...:  88%|████████▊ | 815/923 [00:12<00:01, 83.09it/s]Predicting...:  90%|████████▉ | 827/923 [00:12<00:01, 87.90it/s]Predicting...:  92%|█████████▏| 850/923 [00:12<00:01, 71.09it/s]Predicting...:  93%|█████████▎| 862/923 [00:13<00:00, 67.43it/s]Predicting...:  95%|█████████▌| 878/923 [00:13<00:00, 81.21it/s]Predicting...:  97%|█████████▋| 892/923 [00:13<00:00, 84.50it/s]Predicting...:  98%|█████████▊| 908/923 [00:13<00:00, 96.91it/s]Predicting...: 100%|██████████| 923/923 [00:13<00:00, 68.45it/s]
2025-05-27 20:19:16,757 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 13.4857[sec], evaluation: 0.0000[sec]
2025-05-27 20:19:17,067 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/71000.ckpt
2025-05-27 20:19:17,084 - INFO - joeynmt.training - Example #0
2025-05-27 20:19:17,085 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:19:17,085 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:19:17,085 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due p<unk> @ ezz<unk> @ i di p<unk> @ ezz<unk> @ i di g<unk> @ hi<unk> @ ac<unk> @ cio , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i 4<unk> @ 8 stati , che aveva tre milioni di anni , il 4<unk> @ 8 stati di bas<unk> @ e di circa 4<unk> @ 8 stati , 4<unk> @ 8 stati , il 4<unk> @ 0 % del 4<unk> @ 0 % .
2025-05-27 20:19:17,085 - INFO - joeynmt.training - Example #1
2025-05-27 20:19:17,086 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:19:17,086 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:19:17,086 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la cre<unk> @ azione di questo problema spe<unk> @ ci<unk> @ ale , non c&apos; è il D<unk> @ ic<unk> @ a<unk> @ cia .
2025-05-27 20:19:17,086 - INFO - joeynmt.training - Example #2
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , il cu<unk> @ ore è il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema glob<unk> @ ale .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - Example #3
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - 	Hypothesis: Si cres<unk> @ c<unk> @ eva in v<unk> @ ento e si s<unk> @ v<unk> @ eg<unk> @ li<unk> @ ava .
2025-05-27 20:19:17,087 - INFO - joeynmt.training - Example #4
2025-05-27 20:19:17,088 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:19:17,088 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:19:17,088 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ azione che vi mostr<unk> @ er<unk> @ ò , una st<unk> @ azione di de<unk> @ fin<unk> @ i<unk> @ zione di quello che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:19:20,360 - INFO - joeynmt.training - Epoch  10, Step:    71600, Batch Loss:     0.956945, Batch Acc: 0.733958, Tokens per Sec:    21864, Lr: 0.000300
2025-05-27 20:19:23,619 - INFO - joeynmt.training - Epoch  10, Step:    71700, Batch Loss:     0.965264, Batch Acc: 0.737450, Tokens per Sec:    24143, Lr: 0.000300
2025-05-27 20:19:26,921 - INFO - joeynmt.training - Epoch  10, Step:    71800, Batch Loss:     0.793962, Batch Acc: 0.737250, Tokens per Sec:    24064, Lr: 0.000300
2025-05-27 20:19:30,246 - INFO - joeynmt.training - Epoch  10, Step:    71900, Batch Loss:     0.866184, Batch Acc: 0.740242, Tokens per Sec:    24034, Lr: 0.000300
2025-05-27 20:19:33,589 - INFO - joeynmt.training - Epoch  10, Step:    72000, Batch Loss:     0.839245, Batch Acc: 0.738287, Tokens per Sec:    24086, Lr: 0.000300
2025-05-27 20:19:33,589 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:19:33,589 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 76.19it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 93.52it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 98.60it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 104.82it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 78.59it/s] Predicting...:  10%|▉         | 88/923 [00:00<00:08, 94.69it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 97.86it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 112.07it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:18, 43.80it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 49.45it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 54.68it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 80.17it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.29it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 78.03it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 78.07it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 83.92it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 60.75it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 54.60it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 52.63it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 58.94it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 63.76it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 68.68it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:10, 53.99it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 60.11it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 74.80it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 81.13it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 84.86it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 86.69it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 93.30it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 91.30it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 95.10it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.77it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 80.89it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 63.90it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.08it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 82.83it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 52.94it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 49.76it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 43.60it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.51it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 37.11it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 35.31it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.98it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 45.12it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.06it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 42.21it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:09, 28.58it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 25.20it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:10, 25.17it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 30.08it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:09, 25.27it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:08, 28.46it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:10, 22.08it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:07, 29.30it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:07, 28.97it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 35.08it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:04, 43.93it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:05, 34.16it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 37.86it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:02, 49.79it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 53.29it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 64.82it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 76.85it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 79.19it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 60.84it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 59.38it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 73.25it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 82.32it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 94.07it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 57.47it/s]
2025-05-27 20:19:49,665 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 16.0619[sec], evaluation: 0.0000[sec]
2025-05-27 20:19:49,670 - INFO - joeynmt.training - Example #0
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ta per f<unk> @ ar s<unk> @ ì che il g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ d<unk> @ enti di tre milioni di persone che hanno av<unk> @ uto 4<unk> @ 8 ore di tre milioni di persone che aveva 4<unk> @ 8 % di tre milioni di persone , il 4<unk> @ 8 ore .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - Example #1
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ ar<unk> @ mente part<unk> @ icol<unk> @ ari , perché non è il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:19:49,671 - INFO - joeynmt.training - Example #2
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio del cu<unk> @ ore c<unk> @ atti<unk> @ vo del cu<unk> @ ore glob<unk> @ ale .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - Example #3
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ ap<unk> @ ete , in est<unk> @ ate e si sp<unk> @ ost<unk> @ a nel sen<unk> @ so di est<unk> @ ate .
2025-05-27 20:19:49,672 - INFO - joeynmt.training - Example #4
2025-05-27 20:19:49,673 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:19:49,673 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:19:49,673 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a cosa che vi mostr<unk> @ er<unk> @ ò è una c<unk> @ ura di di<unk> @ seg<unk> @ na che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:19:53,013 - INFO - joeynmt.training - Epoch  10, Step:    72100, Batch Loss:     1.044492, Batch Acc: 0.732716, Tokens per Sec:    23376, Lr: 0.000300
2025-05-27 20:19:56,344 - INFO - joeynmt.training - Epoch  10, Step:    72200, Batch Loss:     0.860607, Batch Acc: 0.743710, Tokens per Sec:    23532, Lr: 0.000300
2025-05-27 20:19:59,660 - INFO - joeynmt.training - Epoch  10, Step:    72300, Batch Loss:     0.816292, Batch Acc: 0.734097, Tokens per Sec:    23468, Lr: 0.000300
2025-05-27 20:20:02,995 - INFO - joeynmt.training - Epoch  10, Step:    72400, Batch Loss:     0.866279, Batch Acc: 0.735663, Tokens per Sec:    23675, Lr: 0.000300
2025-05-27 20:20:06,332 - INFO - joeynmt.training - Epoch  10, Step:    72500, Batch Loss:     0.885982, Batch Acc: 0.732871, Tokens per Sec:    23640, Lr: 0.000300
2025-05-27 20:20:06,332 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:20:06,332 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 79.75it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 94.76it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 100.54it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 91.91it/s] Predicting...:   8%|▊         | 72/923 [00:00<00:10, 78.54it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 95.14it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:08, 99.78it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 105.32it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.67it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 53.25it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 59.86it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 83.82it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 93.51it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 83.30it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 80.99it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 82.44it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 59.75it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 56.99it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 56.14it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 59.24it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 63.43it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 64.32it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 62.19it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:13, 42.80it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:10, 53.59it/s]Predicting...:  41%|████      | 379/923 [00:05<00:07, 70.15it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 78.02it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 83.71it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:07, 69.65it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 83.52it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 80.89it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 87.42it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 74.86it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 74.89it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 63.87it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.40it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 78.05it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 65.45it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 52.37it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:08, 42.95it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.55it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 49.33it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 34.93it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.00it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 35.02it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 43.52it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 44.91it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 42.42it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:09, 28.08it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:10, 25.01it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:09, 27.29it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 32.93it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.36it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 33.19it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:07, 28.82it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 36.98it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.26it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 41.25it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 50.53it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 42.49it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 45.85it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 60.61it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 63.26it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 73.91it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 80.89it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 81.66it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 65.15it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 60.91it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 73.35it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 78.67it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 78.01it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.86it/s]
2025-05-27 20:20:22,027 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.97, ppl:   2.64, acc:   0.72, generation: 15.6808[sec], evaluation: 0.0000[sec]
2025-05-27 20:20:22,036 - INFO - joeynmt.training - Example #0
2025-05-27 20:20:22,037 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:20:22,037 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:20:22,037 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due cas<unk> @ i per fare queste due cose che sono st<unk> @ ate di<unk> @ mostr<unk> @ ate che i g<unk> @ ett<unk> @ ori po<unk> @ ver<unk> @ i , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per la c<unk> @ aus<unk> @ a di tre milioni di anni , il 4<unk> @ 8 milioni di anni , aveva av<unk> @ uto 4<unk> @ 8 stati , per c<unk> @ aus<unk> @ a .
2025-05-27 20:20:22,037 - INFO - joeynmt.training - Example #1
2025-05-27 20:20:22,037 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la cre<unk> @ azione di questo part<unk> @ icol<unk> @ are probl<unk> @ emi spe<unk> @ ci<unk> @ ali , perché non ci mostr<unk> @ a il t<unk> @ ic<unk> @ ca del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - Example #2
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ t<unk> @ amente , la cosa più po<unk> @ ver<unk> @ a c<unk> @ aus<unk> @ a di g<unk> @ hi<unk> @ ac<unk> @ cio della nostra c<unk> @ atti<unk> @ va del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ a glob<unk> @ ale .
2025-05-27 20:20:22,038 - INFO - joeynmt.training - Example #3
2025-05-27 20:20:22,039 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:20:22,039 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:20:22,039 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ c<unk> @ ri<unk> @ v<unk> @ ano in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:20:22,039 - INFO - joeynmt.training - Example #4
2025-05-27 20:20:22,040 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:20:22,040 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:20:22,040 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ de che vi mostr<unk> @ er<unk> @ ò cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:20:25,201 - INFO - joeynmt.training - Epoch  10, Step:    72600, Batch Loss:     0.929835, Batch Acc: 0.729023, Tokens per Sec:    24402, Lr: 0.000300
2025-05-27 20:20:28,372 - INFO - joeynmt.training - Epoch  10, Step:    72700, Batch Loss:     0.887092, Batch Acc: 0.736869, Tokens per Sec:    25017, Lr: 0.000300
2025-05-27 20:20:31,545 - INFO - joeynmt.training - Epoch  10, Step:    72800, Batch Loss:     0.956872, Batch Acc: 0.737863, Tokens per Sec:    24952, Lr: 0.000300
2025-05-27 20:20:34,728 - INFO - joeynmt.training - Epoch  10, Step:    72900, Batch Loss:     0.821947, Batch Acc: 0.739159, Tokens per Sec:    25140, Lr: 0.000300
2025-05-27 20:20:37,895 - INFO - joeynmt.training - Epoch  10, Step:    73000, Batch Loss:     0.956521, Batch Acc: 0.735475, Tokens per Sec:    25076, Lr: 0.000300
2025-05-27 20:20:37,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:20:37,895 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 79.72it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 89.77it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 98.84it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 102.61it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 113.57it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 125.54it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 123.86it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:13, 60.34it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 53.65it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 62.01it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 84.36it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 92.57it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 86.18it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 79.58it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:07, 85.82it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 62.14it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 59.56it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 56.60it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 62.73it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 67.20it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 67.28it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:08, 72.90it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 62.86it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 72.61it/s]Predicting...:  41%|████      | 379/923 [00:04<00:05, 94.22it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 100.98it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:04, 104.47it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 99.52it/s] Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 109.55it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 105.15it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 111.18it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 96.97it/s] Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 73.17it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 81.21it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 57.48it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 48.64it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 54.21it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 39.76it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:08, 39.51it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:07, 42.62it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 44.09it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:07, 39.43it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:08, 33.09it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:09, 28.81it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 29.94it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 33.70it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:08, 29.70it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.11it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:14, 15.90it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:09, 22.27it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:08, 24.12it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:06, 30.48it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:04, 39.11it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:05, 33.27it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 35.97it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 42.38it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 47.45it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 59.19it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 68.81it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.02it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 58.88it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 58.60it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 72.43it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 80.48it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 92.83it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.53it/s]
2025-05-27 20:20:53,680 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 15.7714[sec], evaluation: 0.0000[sec]
2025-05-27 20:20:53,692 - INFO - joeynmt.training - Example #0
2025-05-27 20:20:53,693 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:20:53,693 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:20:53,693 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so sc<unk> @ or<unk> @ so , per ri<unk> @ fer<unk> @ ir<unk> @ mi , che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per con<unk> @ si<unk> @ der<unk> @ are che le b<unk> @ arri<unk> @ ere del 4<unk> @ 8 milioni di anni , che aveva fatto per il 4<unk> @ 0 % .
2025-05-27 20:20:53,693 - INFO - joeynmt.training - Example #1
2025-05-27 20:20:53,694 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:20:53,694 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:20:53,694 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ ha<unk> @ i un problema spe<unk> @ ci<unk> @ f<unk> @ ico , perché non è il D<unk> @ ic<unk> @ e<unk> @ ano il d<unk> @ ato di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:20:53,694 - INFO - joeynmt.training - Example #2
2025-05-27 20:20:53,695 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:20:53,695 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:20:53,695 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la cosa ar<unk> @ t<unk> @ ica è la p<unk> @ eg<unk> @ gi<unk> @ ore del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico glob<unk> @ ale .
2025-05-27 20:20:53,695 - INFO - joeynmt.training - Example #3
2025-05-27 20:20:53,696 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:20:53,696 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:20:53,696 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e in<unk> @ ver<unk> @ no .
2025-05-27 20:20:53,696 - INFO - joeynmt.training - Example #4
2025-05-27 20:20:53,697 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:20:53,697 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:20:53,697 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ p che vi mostr<unk> @ er<unk> @ ò cosa è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:20:56,878 - INFO - joeynmt.training - Epoch  10, Step:    73100, Batch Loss:     0.950769, Batch Acc: 0.737087, Tokens per Sec:    24451, Lr: 0.000300
2025-05-27 20:21:00,034 - INFO - joeynmt.training - Epoch  10, Step:    73200, Batch Loss:     0.963544, Batch Acc: 0.736988, Tokens per Sec:    25051, Lr: 0.000300
2025-05-27 20:21:03,186 - INFO - joeynmt.training - Epoch  10, Step:    73300, Batch Loss:     0.796974, Batch Acc: 0.733416, Tokens per Sec:    25032, Lr: 0.000300
2025-05-27 20:21:06,353 - INFO - joeynmt.training - Epoch  10, Step:    73400, Batch Loss:     0.924487, Batch Acc: 0.731193, Tokens per Sec:    25535, Lr: 0.000300
2025-05-27 20:21:09,516 - INFO - joeynmt.training - Epoch  10, Step:    73500, Batch Loss:     0.872640, Batch Acc: 0.735069, Tokens per Sec:    24797, Lr: 0.000300
2025-05-27 20:21:09,517 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:21:09,517 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 83.15it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 95.89it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 107.72it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 110.90it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 104.66it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 117.56it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 104.16it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:11, 67.76it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:12, 62.42it/s]Predicting...:  17%|█▋        | 160/923 [00:01<00:10, 70.74it/s]Predicting...:  20%|██        | 185/923 [00:02<00:07, 93.86it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 97.50it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 86.98it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:07, 87.03it/s]Predicting...:  27%|██▋       | 249/923 [00:02<00:07, 90.32it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 61.08it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 58.64it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 56.61it/s]Predicting...:  33%|███▎      | 302/923 [00:03<00:10, 60.62it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.67it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.72it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:10, 57.87it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:10, 54.56it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:08, 65.84it/s]Predicting...:  41%|████      | 379/923 [00:04<00:06, 83.08it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 90.89it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 94.26it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 103.26it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 113.75it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 105.00it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 107.58it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 92.91it/s] Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 75.18it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 81.76it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 56.99it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 51.49it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 45.39it/s]Predicting...:  63%|██████▎   | 580/923 [00:07<00:06, 51.46it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.91it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 39.41it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:08, 38.57it/s]Predicting...:  67%|██████▋   | 618/923 [00:08<00:06, 47.33it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.89it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 45.09it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:06, 40.17it/s]Predicting...:  71%|███████   | 653/923 [00:09<00:08, 32.59it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 32.22it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 35.39it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:08, 30.58it/s]Predicting...:  74%|███████▍  | 687/923 [00:10<00:07, 33.48it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 26.74it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:06, 35.09it/s]Predicting...:  78%|███████▊  | 717/923 [00:11<00:05, 34.61it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 41.57it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 49.44it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:05, 33.68it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:04, 35.22it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 46.90it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 53.79it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 63.30it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 71.69it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 72.08it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 53.11it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 66.30it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.32it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 77.22it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 86.52it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 98.26it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 62.36it/s]
2025-05-27 20:21:24,332 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 14.8022[sec], evaluation: 0.0000[sec]
2025-05-27 20:21:24,762 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/68500.ckpt
2025-05-27 20:21:24,780 - INFO - joeynmt.training - Example #0
2025-05-27 20:21:24,782 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:21:24,782 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:21:24,782 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due due di<unk> @ mostr<unk> @ ano che i g<unk> @ over<unk> @ ni per ri<unk> @ dur<unk> @ re il g<unk> @ hi<unk> @ ac<unk> @ cio po<unk> @ ver<unk> @ i , che il g<unk> @ hi<unk> @ ac<unk> @ cio di tre milioni di anni , il 4<unk> @ 8 milioni di anni , il 4<unk> @ 8 , il 4<unk> @ 8 % del 4<unk> @ 8 % .
2025-05-27 20:21:24,782 - INFO - joeynmt.training - Example #1
2025-05-27 20:21:24,783 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:21:24,783 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:21:24,783 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te , la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ co di questo problema .
2025-05-27 20:21:24,783 - INFO - joeynmt.training - Example #2
2025-05-27 20:21:24,784 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:21:24,784 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:21:24,784 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , il s<unk> @ ito di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico c<unk> @ atti<unk> @ vo .
2025-05-27 20:21:24,784 - INFO - joeynmt.training - Example #3
2025-05-27 20:21:24,785 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:21:24,785 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:21:24,785 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e in<unk> @ ver<unk> @ no .
2025-05-27 20:21:24,785 - INFO - joeynmt.training - Example #4
2025-05-27 20:21:24,786 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:21:24,786 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:21:24,786 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a è un di<unk> @ seg<unk> @ no di quello che succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:21:27,969 - INFO - joeynmt.training - Epoch  10, Step:    73600, Batch Loss:     0.946310, Batch Acc: 0.737582, Tokens per Sec:    21713, Lr: 0.000300
2025-05-27 20:21:31,195 - INFO - joeynmt.training - Epoch  10, Step:    73700, Batch Loss:     0.985453, Batch Acc: 0.736713, Tokens per Sec:    24467, Lr: 0.000300
2025-05-27 20:21:34,548 - INFO - joeynmt.training - Epoch  10, Step:    73800, Batch Loss:     0.831221, Batch Acc: 0.736418, Tokens per Sec:    23894, Lr: 0.000300
2025-05-27 20:21:37,869 - INFO - joeynmt.training - Epoch  10, Step:    73900, Batch Loss:     0.908190, Batch Acc: 0.736467, Tokens per Sec:    23786, Lr: 0.000300
2025-05-27 20:21:41,324 - INFO - joeynmt.training - Epoch  10, Step:    74000, Batch Loss:     0.912961, Batch Acc: 0.731679, Tokens per Sec:    22428, Lr: 0.000300
2025-05-27 20:21:41,324 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:21:41,324 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 83.05it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 95.75it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 108.23it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 115.94it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:07, 110.95it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:06, 119.97it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 115.23it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:09, 88.82it/s] Predicting...:  15%|█▍        | 134/923 [00:01<00:18, 42.04it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:16, 46.42it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.45it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 81.04it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 89.01it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 79.93it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 71.83it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 78.10it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 57.60it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 59.20it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 54.11it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 57.52it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.99it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:11, 53.79it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 51.61it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 50.16it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 59.50it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 78.49it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 83.94it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 86.57it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 85.37it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 91.60it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 88.28it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 92.00it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 84.91it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 83.94it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 68.30it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 72.76it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 83.33it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 65.00it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 53.35it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 50.55it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 45.60it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 53.14it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 40.05it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.94it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 38.16it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 48.22it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 48.83it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 46.33it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 43.77it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.93it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 31.82it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 38.82it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 32.03it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.62it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 27.52it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 37.00it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.05it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 42.94it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 52.20it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 40.79it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 42.88it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 55.73it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 61.26it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 71.31it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 82.23it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 84.66it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 65.63it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 65.10it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 79.24it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 85.27it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 95.38it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 61.93it/s]
2025-05-27 20:21:56,242 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.61, acc:   0.72, generation: 14.9048[sec], evaluation: 0.0000[sec]
2025-05-27 20:21:56,565 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/69500.ckpt
2025-05-27 20:21:56,587 - INFO - joeynmt.training - Example #0
2025-05-27 20:21:56,588 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:21:56,588 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:21:56,588 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ mostr<unk> @ azioni per ri<unk> @ vel<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , che gli al<unk> @ im<unk> @ ent<unk> @ ari , che hanno fatto per 4<unk> @ 8 ore , 4<unk> @ 8 ore , 4<unk> @ 8 ore , 4<unk> @ 8 ore di 4<unk> @ 8 stati , per c<unk> @ ento .
2025-05-27 20:21:56,588 - INFO - joeynmt.training - Example #1
2025-05-27 20:21:56,589 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:21:56,589 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:21:56,589 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema , perché non è il D<unk> @ ic<unk> @ e<unk> @ o , perché non è il D<unk> @ ic<unk> @ e<unk> @ e<unk> @ o .
2025-05-27 20:21:56,589 - INFO - joeynmt.training - Example #2
2025-05-27 20:21:56,590 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:21:56,590 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:21:56,590 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , il s<unk> @ ac<unk> @ co di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale .
2025-05-27 20:21:56,590 - INFO - joeynmt.training - Example #3
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Hypothesis: Si può ri<unk> @ m<unk> @ pi<unk> @ re e in<unk> @ ver<unk> @ no .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - Example #4
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:21:56,591 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a cosa succ<unk> @ ede negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:21:59,806 - INFO - joeynmt.training - Epoch  10, Step:    74100, Batch Loss:     1.059531, Batch Acc: 0.731668, Tokens per Sec:    22029, Lr: 0.000300
2025-05-27 20:22:03,125 - INFO - joeynmt.training - Epoch  10, Step:    74200, Batch Loss:     1.105442, Batch Acc: 0.732392, Tokens per Sec:    23933, Lr: 0.000300
2025-05-27 20:22:06,446 - INFO - joeynmt.training - Epoch  10, Step:    74300, Batch Loss:     0.900091, Batch Acc: 0.733088, Tokens per Sec:    23716, Lr: 0.000300
2025-05-27 20:22:09,741 - INFO - joeynmt.training - Epoch  10, Step:    74400, Batch Loss:     0.909979, Batch Acc: 0.735851, Tokens per Sec:    23270, Lr: 0.000300
2025-05-27 20:22:13,081 - INFO - joeynmt.training - Epoch  10, Step:    74500, Batch Loss:     0.903672, Batch Acc: 0.734331, Tokens per Sec:    24209, Lr: 0.000300
2025-05-27 20:22:13,081 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:22:13,081 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 74.80it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 86.84it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 90.70it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 90.32it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 95.89it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:10, 79.75it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:13, 59.46it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:15, 49.87it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:13, 56.64it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 74.60it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 81.24it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 77.25it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:08, 78.91it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 83.54it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 57.84it/s]Predicting...:  30%|███       | 277/923 [00:04<00:10, 59.20it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 56.76it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 58.54it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 62.27it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 65.05it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:08, 67.34it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 70.57it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 87.91it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 93.01it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 94.92it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:04, 101.24it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:04, 104.79it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 77.31it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:05, 86.16it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 80.38it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 79.64it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 68.54it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 65.48it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 77.58it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 68.30it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 54.81it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 51.37it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 48.35it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:05, 57.61it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 41.03it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 39.03it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 40.58it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 48.35it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 51.06it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:05, 49.42it/s]Predicting...:  70%|███████   | 647/923 [00:09<00:05, 47.17it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:07, 36.81it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:07, 34.85it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:06, 39.87it/s]Predicting...:  73%|███████▎  | 678/923 [00:10<00:07, 33.53it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 35.92it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:07, 28.76it/s]Predicting...:  77%|███████▋  | 708/923 [00:11<00:05, 36.67it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 36.05it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 45.36it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 56.11it/s]Predicting...:  81%|████████  | 749/923 [00:12<00:04, 40.30it/s]Predicting...:  82%|████████▏ | 759/923 [00:12<00:03, 41.77it/s]Predicting...:  84%|████████▍ | 774/923 [00:12<00:02, 55.06it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 57.75it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 66.49it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 60.74it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 66.64it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 49.19it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 59.20it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 57.89it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 72.58it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 80.64it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 89.05it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 61.77it/s]
2025-05-27 20:22:28,037 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 14.9432[sec], evaluation: 0.0000[sec]
2025-05-27 20:22:28,384 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/73500.ckpt
2025-05-27 20:22:28,407 - INFO - joeynmt.training - Example #0
2025-05-27 20:22:28,409 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:22:28,409 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:22:28,409 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ men<unk> @ si<unk> @ oni per ri<unk> @ dur<unk> @ re il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per tre milioni di anni , il 4<unk> @ 8 milioni di anni , il 4<unk> @ 8 per il 4<unk> @ 8 milioni di anni .
2025-05-27 20:22:28,409 - INFO - joeynmt.training - Example #1
2025-05-27 20:22:28,410 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:22:28,410 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:22:28,410 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la mor<unk> @ al<unk> @ ità di questo problema , perché non è il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ ent<unk> @ ale , non è il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:22:28,410 - INFO - joeynmt.training - Example #2
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la c<unk> @ atti<unk> @ va è la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ic<unk> @ cio glob<unk> @ ale .
2025-05-27 20:22:28,411 - INFO - joeynmt.training - Example #3
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:22:28,411 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:22:28,412 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di un p<unk> @ ezz<unk> @ o e vi<unk> @ sta .
2025-05-27 20:22:28,412 - INFO - joeynmt.training - Example #4
2025-05-27 20:22:28,412 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:22:28,412 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:22:28,412 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ a che vi è succ<unk> @ esso , è una sc<unk> @ at<unk> @ ola di di<unk> @ seg<unk> @ na è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:22:31,638 - INFO - joeynmt.training - Epoch  10, Step:    74600, Batch Loss:     0.879014, Batch Acc: 0.733933, Tokens per Sec:    21920, Lr: 0.000300
2025-05-27 20:22:34,941 - INFO - joeynmt.training - Epoch  10, Step:    74700, Batch Loss:     0.912327, Batch Acc: 0.730641, Tokens per Sec:    22984, Lr: 0.000300
2025-05-27 20:22:38,245 - INFO - joeynmt.training - Epoch  10, Step:    74800, Batch Loss:     0.882666, Batch Acc: 0.734364, Tokens per Sec:    23875, Lr: 0.000300
2025-05-27 20:22:41,567 - INFO - joeynmt.training - Epoch  10, Step:    74900, Batch Loss:     0.843552, Batch Acc: 0.734258, Tokens per Sec:    23779, Lr: 0.000300
2025-05-27 20:22:44,899 - INFO - joeynmt.training - Epoch  10, Step:    75000, Batch Loss:     0.828934, Batch Acc: 0.735196, Tokens per Sec:    24370, Lr: 0.000300
2025-05-27 20:22:44,900 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:22:44,900 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:10, 83.53it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 89.96it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 92.32it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 92.91it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 89.41it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 102.47it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:07, 113.57it/s]Predicting...:  15%|█▍        | 134/923 [00:02<00:20, 37.72it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:18, 42.72it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:14, 52.58it/s]Predicting...:  20%|██        | 185/923 [00:02<00:09, 75.77it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 83.81it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 75.15it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 69.40it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 74.10it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 56.76it/s]Predicting...:  29%|██▉       | 267/923 [00:04<00:12, 52.51it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 51.23it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 46.64it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 51.53it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 56.94it/s]Predicting...:  35%|███▌      | 327/923 [00:05<00:09, 64.22it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 61.67it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 73.34it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 101.11it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 98.85it/s] Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 99.10it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 106.41it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 102.70it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 100.73it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 92.06it/s] Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 91.92it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.30it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 79.95it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 56.78it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:07, 52.11it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 47.12it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 55.05it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 37.18it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:12, 27.23it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:10, 29.87it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:08, 37.86it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:07, 40.22it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:07, 37.64it/s]Predicting...:  70%|███████   | 647/923 [00:11<00:10, 26.12it/s]Predicting...:  71%|███████   | 653/923 [00:11<00:12, 22.48it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:10, 24.17it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 30.02it/s]Predicting...:  73%|███████▎  | 678/923 [00:12<00:09, 26.66it/s]Predicting...:  74%|███████▍  | 687/923 [00:12<00:07, 30.35it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:09, 24.06it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:06, 31.18it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:06, 32.68it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 42.96it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 55.24it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:05, 32.79it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 42.26it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 47.96it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 55.35it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 65.52it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 70.07it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 58.91it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 57.22it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 68.85it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 76.29it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 79.88it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 55.98it/s]
2025-05-27 20:23:01,401 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.96, ppl:   2.62, acc:   0.72, generation: 16.4878[sec], evaluation: 0.0000[sec]
2025-05-27 20:23:01,406 - INFO - joeynmt.training - Example #0
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so , ho mostr<unk> @ ato queste due di<unk> @ ta per ri<unk> @ guar<unk> @ do a la di<unk> @ st<unk> @ anza per ri<unk> @ guar<unk> @ do a il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio che ha av<unk> @ uto il 4<unk> @ 8 milioni di persone , i sol<unk> @ i 4<unk> @ 8 ore , il 4<unk> @ 8 ore ha av<unk> @ uto il 4<unk> @ 0 % .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - Example #1
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:23:01,407 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ qu<unk> @ in<unk> @ amento , la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are , perché non è il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - Example #2
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la c<unk> @ aus<unk> @ a della c<unk> @ aus<unk> @ a della c<unk> @ aus<unk> @ a glob<unk> @ ale del nostro sistema c<unk> @ li<unk> @ m<unk> @ as<unk> @ si<unk> @ mo glob<unk> @ ale .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - Example #3
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:23:01,408 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:23:01,409 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di una v<unk> @ ar<unk> @ i<unk> @ azione e sp<unk> @ or<unk> @ ca .
2025-05-27 20:23:01,409 - INFO - joeynmt.training - Example #4
2025-05-27 20:23:01,409 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:23:01,409 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:23:01,409 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ de che vi mostr<unk> @ o è una di<unk> @ seg<unk> @ na che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:23:04,732 - INFO - joeynmt.training - Epoch  10, Step:    75100, Batch Loss:     0.964849, Batch Acc: 0.733259, Tokens per Sec:    23257, Lr: 0.000210
2025-05-27 20:23:08,039 - INFO - joeynmt.training - Epoch  10, Step:    75200, Batch Loss:     0.842434, Batch Acc: 0.736203, Tokens per Sec:    23222, Lr: 0.000210
2025-05-27 20:23:11,353 - INFO - joeynmt.training - Epoch  10, Step:    75300, Batch Loss:     0.976141, Batch Acc: 0.738136, Tokens per Sec:    24022, Lr: 0.000210
2025-05-27 20:23:14,647 - INFO - joeynmt.training - Epoch  10, Step:    75400, Batch Loss:     0.868657, Batch Acc: 0.738468, Tokens per Sec:    23429, Lr: 0.000210
2025-05-27 20:23:17,988 - INFO - joeynmt.training - Epoch  10, Step:    75500, Batch Loss:     0.897708, Batch Acc: 0.736889, Tokens per Sec:    23775, Lr: 0.000210
2025-05-27 20:23:17,989 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:23:17,989 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 65.03it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 106.44it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 106.03it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 100.97it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 114.73it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:07, 109.62it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 123.68it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:19, 40.72it/s] Predicting...:  17%|█▋        | 160/923 [00:02<00:15, 48.40it/s]Predicting...:  20%|██        | 185/923 [00:02<00:11, 64.81it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:09, 74.43it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:09, 73.52it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 76.39it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 83.55it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 54.49it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 53.49it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.29it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 58.72it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 62.98it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 63.76it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 63.36it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:07, 72.41it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 83.96it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 93.65it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 98.72it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 88.21it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 92.66it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 89.61it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 95.41it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 83.34it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 81.31it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 65.57it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 69.58it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 80.62it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 66.96it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 54.62it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:08, 45.08it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 40.04it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 50.40it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 35.91it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 34.45it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.42it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 42.59it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.22it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 43.12it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:07, 39.06it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 30.94it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:08, 29.97it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 35.25it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:09, 26.95it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 30.26it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:14, 15.22it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:10, 21.34it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:08, 23.69it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:06, 30.95it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:04, 40.69it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:04, 35.04it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:04, 36.02it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 46.78it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 53.86it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 65.29it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 73.29it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 75.55it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 65.57it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 63.73it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 78.38it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 80.43it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 93.02it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 57.22it/s]
2025-05-27 20:23:34,134 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.95, ppl:   2.58, acc:   0.72, generation: 16.1317[sec], evaluation: 0.0000[sec]
2025-05-27 20:23:34,134 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:23:34,604 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/71500.ckpt
2025-05-27 20:23:34,629 - INFO - joeynmt.training - Example #0
2025-05-27 20:23:34,631 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:23:34,631 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:23:34,631 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due s<unk> @ ott<unk> @ om<unk> @ ar<unk> @ ini per ri<unk> @ fer<unk> @ ir<unk> @ ci che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ano per i ris<unk> @ ult<unk> @ ati ar<unk> @ t<unk> @ ici che av<unk> @ evano fatto per i 4<unk> @ 8 stati , per la qu<unk> @ ale è stato s<unk> @ otto i 4<unk> @ 8 stati , per il 4<unk> @ 0 % .
2025-05-27 20:23:34,631 - INFO - joeynmt.training - Example #1
2025-05-27 20:23:34,632 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:23:34,632 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:23:34,632 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la sost<unk> @ itu<unk> @ zione di questo part<unk> @ icol<unk> @ are probl<unk> @ emi , perché non è il D<unk> @ ic<unk> @ co del g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:23:34,632 - INFO - joeynmt.training - Example #2
2025-05-27 20:23:34,633 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:23:34,633 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:23:34,633 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so è la c<unk> @ atti<unk> @ va è la c<unk> @ atti<unk> @ va del nostro s<unk> @ ett<unk> @ ore c<unk> @ atti<unk> @ vo del nostro c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico glob<unk> @ ale .
2025-05-27 20:23:34,633 - INFO - joeynmt.training - Example #3
2025-05-27 20:23:34,634 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:23:34,634 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:23:34,634 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ it<unk> @ are e sp<unk> @ or<unk> @ ca nel sen<unk> @ so .
2025-05-27 20:23:34,634 - INFO - joeynmt.training - Example #4
2025-05-27 20:23:34,635 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:23:34,635 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:23:34,635 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ de che vi mostr<unk> @ er<unk> @ ò è una ri<unk> @ pres<unk> @ a di una di<unk> @ seg<unk> @ na che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:23:37,970 - INFO - joeynmt.training - Epoch  10, Step:    75600, Batch Loss:     0.874659, Batch Acc: 0.739633, Tokens per Sec:    20313, Lr: 0.000210
2025-05-27 20:23:41,290 - INFO - joeynmt.training - Epoch  10, Step:    75700, Batch Loss:     0.915896, Batch Acc: 0.738826, Tokens per Sec:    23996, Lr: 0.000210
2025-05-27 20:23:44,634 - INFO - joeynmt.training - Epoch  10, Step:    75800, Batch Loss:     0.881192, Batch Acc: 0.741301, Tokens per Sec:    24449, Lr: 0.000210
2025-05-27 20:23:47,934 - INFO - joeynmt.training - Epoch  10, Step:    75900, Batch Loss:     0.978765, Batch Acc: 0.737452, Tokens per Sec:    23705, Lr: 0.000210
2025-05-27 20:23:51,247 - INFO - joeynmt.training - Epoch  10, Step:    76000, Batch Loss:     0.975055, Batch Acc: 0.735602, Tokens per Sec:    23823, Lr: 0.000210
2025-05-27 20:23:51,248 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:23:51,248 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:13, 69.79it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 86.28it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 93.49it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 99.67it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 87.93it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:08, 103.80it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 104.64it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 117.14it/s]Predicting...:  15%|█▍        | 134/923 [00:01<00:16, 48.54it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 52.90it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 63.68it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 91.64it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 95.39it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 81.74it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:09, 69.23it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 78.87it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 61.19it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 59.16it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:11, 57.57it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 65.97it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:08, 70.27it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 69.04it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 63.79it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 72.90it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 87.17it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 93.90it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 96.10it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:06, 81.83it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 94.69it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 100.22it/s]Predicting...:  51%|█████     | 469/923 [00:05<00:04, 95.50it/s] Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 88.23it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 86.82it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 69.86it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:05, 77.72it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:05, 64.61it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 58.57it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:06, 52.92it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:07, 45.57it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 48.40it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 35.49it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:09, 35.59it/s]Predicting...:  66%|██████▌   | 605/923 [00:08<00:09, 35.32it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 46.08it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 47.66it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 41.62it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:10, 27.57it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 24.94it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:09, 26.61it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 32.48it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 30.20it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 33.51it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 26.96it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:05, 35.97it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 37.57it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 47.65it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 59.77it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 44.12it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 53.44it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 57.52it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 65.42it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 75.89it/s]Predicting...:  90%|████████▉ | 827/923 [00:13<00:01, 73.45it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 60.40it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:01, 57.61it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 70.38it/s]Predicting...:  97%|█████████▋| 892/923 [00:14<00:00, 79.34it/s]Predicting...:  98%|█████████▊| 908/923 [00:14<00:00, 88.83it/s]Predicting...: 100%|██████████| 923/923 [00:14<00:00, 61.65it/s]
2025-05-27 20:24:06,228 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.57, acc:   0.73, generation: 14.9714[sec], evaluation: 0.0000[sec]
2025-05-27 20:24:06,228 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:24:06,709 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/70000.ckpt
2025-05-27 20:24:06,734 - INFO - joeynmt.training - Example #0
2025-05-27 20:24:06,735 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:24:06,736 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:24:06,736 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so anno , questi due di<unk> @ f<unk> @ en<unk> @ om<unk> @ en<unk> @ i per ri<unk> @ vel<unk> @ are che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i cui i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ono per i 4<unk> @ 8 milioni di anni , per il 4<unk> @ 8 milioni di anni , per il 4<unk> @ 0 per c<unk> @ ento è sp<unk> @ av<unk> @ ent<unk> @ ato il 4<unk> @ 0 per c<unk> @ ento .
2025-05-27 20:24:06,736 - INFO - joeynmt.training - Example #1
2025-05-27 20:24:06,737 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:24:06,737 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:24:06,737 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza la di<unk> @ st<unk> @ ha<unk> @ i un problema di questo part<unk> @ icol<unk> @ are spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ or<unk> @ i<unk> @ ent<unk> @ ale .
2025-05-27 20:24:06,737 - INFO - joeynmt.training - Example #2
2025-05-27 20:24:06,738 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:24:06,738 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:24:06,738 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , la s<unk> @ om<unk> @ ig<unk> @ lia è il g<unk> @ hi<unk> @ ac<unk> @ cio del nostro c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:24:06,738 - INFO - joeynmt.training - Example #3
2025-05-27 20:24:06,739 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:24:06,739 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:24:06,739 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di in<unk> @ ver<unk> @ no e si in<unk> @ ver<unk> @ no nel est<unk> @ ate .
2025-05-27 20:24:06,739 - INFO - joeynmt.training - Example #4
2025-05-27 20:24:06,740 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:24:06,740 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:24:06,740 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o è una cer<unk> @ ta di<unk> @ mostr<unk> @ azione di cosa acc<unk> @ a<unk> @ du<unk> @ to in 2<unk> @ 5 anni .
2025-05-27 20:24:10,080 - INFO - joeynmt.training - Epoch  10, Step:    76100, Batch Loss:     0.798196, Batch Acc: 0.741112, Tokens per Sec:    21055, Lr: 0.000210
2025-05-27 20:24:13,401 - INFO - joeynmt.training - Epoch  10, Step:    76200, Batch Loss:     1.055248, Batch Acc: 0.735542, Tokens per Sec:    24391, Lr: 0.000210
2025-05-27 20:24:16,694 - INFO - joeynmt.training - Epoch  10, Step:    76300, Batch Loss:     0.860439, Batch Acc: 0.739012, Tokens per Sec:    24135, Lr: 0.000210
2025-05-27 20:24:19,995 - INFO - joeynmt.training - Epoch  10, Step:    76400, Batch Loss:     0.973831, Batch Acc: 0.735579, Tokens per Sec:    24079, Lr: 0.000210
2025-05-27 20:24:23,318 - INFO - joeynmt.training - Epoch  10, Step:    76500, Batch Loss:     0.921327, Batch Acc: 0.737537, Tokens per Sec:    24341, Lr: 0.000210
2025-05-27 20:24:23,318 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:24:23,318 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:14, 62.85it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 79.18it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 82.70it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:09, 87.34it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 93.84it/s]Predicting...:  10%|▉         | 88/923 [00:00<00:07, 106.06it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 106.08it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:10, 73.60it/s] Predicting...:  16%|█▌        | 146/923 [00:01<00:13, 59.48it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 66.07it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 87.35it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:08, 86.82it/s]Predicting...:  24%|██▍       | 224/923 [00:03<00:11, 58.96it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:11, 57.75it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:10, 64.50it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:12, 52.77it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 52.92it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 52.48it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:12, 50.83it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:12, 51.30it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:11, 54.55it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 58.18it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:09, 59.09it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 63.59it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.03it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 89.42it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 89.00it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:06, 80.75it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:05, 91.27it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:05, 88.39it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 89.84it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 79.24it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 74.31it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 64.65it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:05, 70.74it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:04, 79.63it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:07, 52.41it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:08, 43.57it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 40.61it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:08, 39.89it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 47.89it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:08, 38.83it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:08, 36.99it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 34.02it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:07, 42.99it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 46.52it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 46.33it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 40.82it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 32.95it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:07, 34.59it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:06, 40.33it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:07, 32.75it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:06, 34.68it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:10, 22.17it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:07, 29.52it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 32.33it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:04, 40.71it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 50.50it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 38.19it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 39.59it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 47.70it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 53.27it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 61.75it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 69.17it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 70.05it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 52.46it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 66.11it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 64.58it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 80.13it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 85.54it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 96.24it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.54it/s]
2025-05-27 20:24:39,100 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.56, acc:   0.73, generation: 15.7686[sec], evaluation: 0.0000[sec]
2025-05-27 20:24:39,101 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:24:39,620 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/74500.ckpt
2025-05-27 20:24:39,645 - INFO - joeynmt.training - Example #0
2025-05-27 20:24:39,646 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:24:39,646 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:24:39,646 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due di<unk> @ mostr<unk> @ a che i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ato per i con<unk> @ si<unk> @ der<unk> @ are i g<unk> @ hi<unk> @ ac<unk> @ ci<unk> @ ati , che gli es<unk> @ c<unk> @ lu<unk> @ si<unk> @ oni di tre milioni di persone che hanno av<unk> @ uto il 4<unk> @ 0 % dei di<unk> @ st<unk> @ ati , per s<unk> @ ott<unk> @ ol<unk> @ in<unk> @ e<unk> @ are , il 4<unk> @ 0 % .
2025-05-27 20:24:39,647 - INFO - joeynmt.training - Example #1
2025-05-27 20:24:39,647 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:24:39,648 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:24:39,648 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo problema spe<unk> @ ci<unk> @ ale , perché non si mostr<unk> @ a il D<unk> @ ic<unk> @ or<unk> @ io .
2025-05-27 20:24:39,648 - INFO - joeynmt.training - Example #2
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la cu<unk> @ ore è il cu<unk> @ ore di g<unk> @ hi<unk> @ ac<unk> @ cio del nostro sistema c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - Example #3
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ ento e si sta sp<unk> @ or<unk> @ g<unk> @ ett<unk> @ ando in est<unk> @ ate .
2025-05-27 20:24:39,649 - INFO - joeynmt.training - Example #4
2025-05-27 20:24:39,650 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:24:39,650 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:24:39,650 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma s<unk> @ li<unk> @ de che vi mostr<unk> @ er<unk> @ ò è una di<unk> @ vis<unk> @ a di quello che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:24:42,970 - INFO - joeynmt.training - Epoch  10, Step:    76600, Batch Loss:     0.787117, Batch Acc: 0.743147, Tokens per Sec:    20537, Lr: 0.000210
2025-05-27 20:24:46,280 - INFO - joeynmt.training - Epoch  10, Step:    76700, Batch Loss:     1.033736, Batch Acc: 0.736549, Tokens per Sec:    23850, Lr: 0.000210
2025-05-27 20:24:49,602 - INFO - joeynmt.training - Epoch  10, Step:    76800, Batch Loss:     0.861462, Batch Acc: 0.741751, Tokens per Sec:    23849, Lr: 0.000210
2025-05-27 20:24:52,884 - INFO - joeynmt.training - Epoch  10, Step:    76900, Batch Loss:     0.916741, Batch Acc: 0.740548, Tokens per Sec:    24085, Lr: 0.000210
2025-05-27 20:24:56,186 - INFO - joeynmt.training - Epoch  10, Step:    77000, Batch Loss:     0.838196, Batch Acc: 0.737836, Tokens per Sec:    23612, Lr: 0.000210
2025-05-27 20:24:56,187 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:24:56,187 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 70.23it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:10, 82.08it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:10, 86.01it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 97.59it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:10, 83.93it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 103.18it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:11, 70.66it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 58.41it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 67.30it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 91.98it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 100.56it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:08, 79.97it/s] Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 74.16it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 59.50it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 57.01it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 54.22it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:10, 58.90it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 60.65it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 60.29it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 62.01it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:08, 69.30it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 81.76it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 91.19it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 88.82it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:06, 77.52it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 89.99it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 94.80it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 96.06it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 95.93it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 76.81it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 84.81it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:06, 61.82it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:07, 49.63it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 55.43it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 40.21it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:07, 39.75it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 47.14it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 46.88it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 43.27it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:09, 29.68it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 25.00it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:09, 26.81it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:08, 31.31it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 28.48it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 30.79it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:14, 15.28it/s]Predicting...:  77%|███████▋  | 708/923 [00:13<00:10, 21.12it/s]Predicting...:  78%|███████▊  | 717/923 [00:13<00:08, 23.40it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:06, 30.19it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:04, 39.34it/s]Predicting...:  81%|████████  | 749/923 [00:14<00:06, 27.69it/s]Predicting...:  82%|████████▏ | 759/923 [00:14<00:05, 31.24it/s]Predicting...:  84%|████████▍ | 774/923 [00:14<00:03, 43.04it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 47.21it/s]Predicting...:  87%|████████▋ | 800/923 [00:15<00:02, 53.92it/s]Predicting...:  88%|████████▊ | 815/923 [00:15<00:01, 62.48it/s]Predicting...:  90%|████████▉ | 827/923 [00:15<00:01, 65.28it/s]Predicting...:  90%|█████████ | 835/923 [00:15<00:01, 52.02it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 64.37it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 60.83it/s]Predicting...:  95%|█████████▌| 878/923 [00:16<00:00, 77.49it/s]Predicting...:  97%|█████████▋| 892/923 [00:16<00:00, 89.79it/s]Predicting...:  98%|█████████▊| 908/923 [00:16<00:00, 94.39it/s]Predicting...: 100%|██████████| 923/923 [00:16<00:00, 56.20it/s]
2025-05-27 20:25:12,624 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.56, acc:   0.73, generation: 16.4241[sec], evaluation: 0.0000[sec]
2025-05-27 20:25:12,625 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:25:13,143 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/74000.ckpt
2025-05-27 20:25:13,176 - INFO - joeynmt.training - Example #0
2025-05-27 20:25:13,178 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:25:13,178 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:25:13,178 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ta per ri<unk> @ vel<unk> @ are i due di<unk> @ ta per con<unk> @ si<unk> @ der<unk> @ are che l&apos; or<unk> @ t<unk> @ ico ar<unk> @ t<unk> @ ico che ha av<unk> @ uto per tre milioni di anni , che aveva av<unk> @ uto 4<unk> @ 8 % , per tre milioni di anni , che aveva 4<unk> @ 8 % , per c<unk> @ ento è stato il 4<unk> @ 0 % dei con<unk> @ si<unk> @ der<unk> @ ati .
2025-05-27 20:25:13,178 - INFO - joeynmt.training - Example #1
2025-05-27 20:25:13,179 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:25:13,179 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:25:13,179 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ st<unk> @ izi<unk> @ a di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio , perché non è il D<unk> @ ic<unk> @ e<unk> @ ano .
2025-05-27 20:25:13,179 - INFO - joeynmt.training - Example #2
2025-05-27 20:25:13,180 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:25:13,180 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:25:13,180 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , in un cer<unk> @ to sen<unk> @ so è il cu<unk> @ ore di g<unk> @ hi<unk> @ ac<unk> @ cio glob<unk> @ ale .
2025-05-27 20:25:13,180 - INFO - joeynmt.training - Example #3
2025-05-27 20:25:13,181 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:25:13,181 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:25:13,181 - INFO - joeynmt.training - 	Hypothesis: Si tr<unk> @ at<unk> @ ta di v<unk> @ est<unk> @ iti e in<unk> @ ver<unk> @ no .
2025-05-27 20:25:13,181 - INFO - joeynmt.training - Example #4
2025-05-27 20:25:13,182 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:25:13,182 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:25:13,182 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ o è una c<unk> @ ic<unk> @ at<unk> @ ric<unk> @ e che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:25:16,508 - INFO - joeynmt.training - Epoch  10, Step:    77100, Batch Loss:     0.860328, Batch Acc: 0.739088, Tokens per Sec:    20763, Lr: 0.000210
2025-05-27 20:25:19,809 - INFO - joeynmt.training - Epoch  10, Step:    77200, Batch Loss:     0.817546, Batch Acc: 0.738014, Tokens per Sec:    23693, Lr: 0.000210
2025-05-27 20:25:23,107 - INFO - joeynmt.training - Epoch  10, Step:    77300, Batch Loss:     0.978915, Batch Acc: 0.736929, Tokens per Sec:    24117, Lr: 0.000210
2025-05-27 20:25:26,436 - INFO - joeynmt.training - Epoch  10, Step:    77400, Batch Loss:     0.889588, Batch Acc: 0.738249, Tokens per Sec:    24295, Lr: 0.000210
2025-05-27 20:25:29,717 - INFO - joeynmt.training - Epoch  10, Step:    77500, Batch Loss:     1.023718, Batch Acc: 0.738344, Tokens per Sec:    23634, Lr: 0.000210
2025-05-27 20:25:29,717 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:25:29,718 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 73.01it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:09, 91.72it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 95.20it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 106.75it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 102.37it/s]Predicting...:  11%|█▏        | 104/923 [00:00<00:06, 118.70it/s]Predicting...:  13%|█▎        | 121/923 [00:01<00:06, 129.53it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:14, 52.60it/s] Predicting...:  17%|█▋        | 160/923 [00:02<00:12, 60.71it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 90.82it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 87.79it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 77.07it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:10, 64.37it/s]Predicting...:  30%|███       | 277/923 [00:03<00:10, 63.67it/s]Predicting...:  31%|███▏      | 289/923 [00:03<00:10, 59.18it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:09, 62.38it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 64.90it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:09, 65.30it/s]Predicting...:  37%|███▋      | 337/923 [00:04<00:09, 63.99it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:09, 61.91it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 73.01it/s]Predicting...:  41%|████      | 379/923 [00:05<00:05, 90.99it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 92.73it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 92.60it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:06, 82.38it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 92.92it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:06, 69.86it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:05, 78.43it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:06, 71.67it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 73.44it/s]Predicting...:  54%|█████▍    | 503/923 [00:06<00:06, 62.33it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:06, 67.26it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 78.01it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 62.59it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 51.14it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:09, 40.61it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 36.54it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 45.33it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:09, 33.66it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 35.23it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 37.05it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 48.84it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:05, 50.56it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 44.77it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:09, 27.97it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:10, 25.36it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:09, 27.11it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 31.99it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 28.61it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 30.50it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:10, 22.31it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:07, 30.23it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:06, 31.68it/s]Predicting...:  79%|███████▉  | 729/923 [00:13<00:05, 38.76it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 47.15it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 36.87it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 38.73it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 49.30it/s]Predicting...:  85%|████████▌ | 786/923 [00:14<00:02, 56.45it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:02, 59.46it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 67.37it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 68.58it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 50.40it/s]Predicting...:  92%|█████████▏| 850/923 [00:15<00:01, 64.47it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:01, 57.91it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 74.02it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 80.30it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 94.24it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 58.64it/s]
2025-05-27 20:25:45,471 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.55, acc:   0.73, generation: 15.7404[sec], evaluation: 0.0000[sec]
2025-05-27 20:25:45,472 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:25:45,956 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/70500.ckpt
2025-05-27 20:25:46,001 - INFO - joeynmt.training - Example #0
2025-05-27 20:25:46,002 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:25:46,002 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:25:46,002 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato queste due di<unk> @ ta per di<unk> @ mostr<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico che l&apos; or<unk> @ ig<unk> @ ine ar<unk> @ t<unk> @ ico per le persone che hanno av<unk> @ uto il 4<unk> @ 0 gra<unk> @ di di .
2025-05-27 20:25:46,003 - INFO - joeynmt.training - Example #1
2025-05-27 20:25:46,003 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:25:46,004 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:25:46,004 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abb<unk> @ ast<unk> @ anza for<unk> @ te la giu<unk> @ sta , perché non è il D<unk> @ ic<unk> @ i<unk> @ p<unk> @ are il D<unk> @ ic<unk> @ e<unk> @ o .
2025-05-27 20:25:46,004 - INFO - joeynmt.training - Example #2
2025-05-27 20:25:46,005 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:25:46,005 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:25:46,005 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il cu<unk> @ ore è il cu<unk> @ ore ar<unk> @ t<unk> @ ico è il cu<unk> @ ore del nostro sistema c<unk> @ li<unk> @ ma glob<unk> @ ale .
2025-05-27 20:25:46,005 - INFO - joeynmt.training - Example #3
2025-05-27 20:25:46,005 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:25:46,006 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:25:46,006 - INFO - joeynmt.training - 	Hypothesis: Si cres<unk> @ c<unk> @ eva in in<unk> @ ver<unk> @ no e sp<unk> @ or<unk> @ g<unk> @ ere in est<unk> @ ate .
2025-05-27 20:25:46,006 - INFO - joeynmt.training - Example #4
2025-05-27 20:25:46,006 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:25:46,007 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:25:46,007 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @ ò è succ<unk> @ esso una cosa che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:25:49,311 - INFO - joeynmt.training - Epoch  10, Step:    77600, Batch Loss:     0.876878, Batch Acc: 0.739204, Tokens per Sec:    20182, Lr: 0.000210
2025-05-27 20:25:52,629 - INFO - joeynmt.training - Epoch  10, Step:    77700, Batch Loss:     0.927674, Batch Acc: 0.740964, Tokens per Sec:    23521, Lr: 0.000210
2025-05-27 20:25:55,958 - INFO - joeynmt.training - Epoch  10, Step:    77800, Batch Loss:     0.963026, Batch Acc: 0.738703, Tokens per Sec:    24012, Lr: 0.000210
2025-05-27 20:25:59,274 - INFO - joeynmt.training - Epoch  10, Step:    77900, Batch Loss:     0.930163, Batch Acc: 0.734404, Tokens per Sec:    23748, Lr: 0.000210
2025-05-27 20:26:02,580 - INFO - joeynmt.training - Epoch  10, Step:    78000, Batch Loss:     0.943340, Batch Acc: 0.736774, Tokens per Sec:    24020, Lr: 0.000210
2025-05-27 20:26:02,581 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:26:02,581 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:12, 74.27it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:11, 80.30it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:09, 88.82it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:08, 98.64it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:09, 89.62it/s]Predicting...:  11%|█▏        | 104/923 [00:01<00:07, 110.35it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:11, 71.69it/s] Predicting...:  16%|█▌        | 146/923 [00:02<00:12, 59.85it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 66.93it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 88.54it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 95.09it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:07, 88.64it/s]Predicting...:  25%|██▌       | 235/923 [00:02<00:08, 79.49it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:08, 76.82it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 60.05it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:11, 57.10it/s]Predicting...:  30%|███       | 277/923 [00:03<00:11, 56.36it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:11, 53.94it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 56.06it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:09, 61.47it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:08, 66.45it/s]Predicting...:  38%|███▊      | 347/923 [00:04<00:08, 65.62it/s]Predicting...:  39%|███▉      | 361/923 [00:04<00:07, 71.27it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:05, 93.67it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:06, 82.89it/s]Predicting...:  46%|████▌     | 424/923 [00:05<00:05, 84.53it/s]Predicting...:  48%|████▊     | 441/923 [00:05<00:05, 91.99it/s]Predicting...:  49%|████▉     | 455/923 [00:05<00:04, 94.39it/s]Predicting...:  51%|█████     | 469/923 [00:06<00:04, 97.98it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:04, 89.13it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:04, 88.98it/s]Predicting...:  56%|█████▌    | 517/923 [00:06<00:05, 73.60it/s]Predicting...:  58%|█████▊    | 531/923 [00:06<00:04, 80.13it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 63.41it/s]Predicting...:  59%|█████▉    | 548/923 [00:07<00:07, 53.13it/s]Predicting...:  60%|██████    | 556/923 [00:07<00:07, 47.77it/s]Predicting...:  62%|██████▏   | 568/923 [00:07<00:08, 43.14it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:06, 53.02it/s]Predicting...:  64%|██████▎   | 587/923 [00:08<00:08, 39.88it/s]Predicting...:  65%|██████▍   | 596/923 [00:08<00:08, 36.74it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:09, 35.27it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 44.67it/s]Predicting...:  68%|██████▊   | 630/923 [00:09<00:06, 43.85it/s]Predicting...:  69%|██████▉   | 639/923 [00:09<00:06, 43.43it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:08, 33.99it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:09, 28.28it/s]Predicting...:  72%|███████▏  | 661/923 [00:10<00:09, 28.32it/s]Predicting...:  73%|███████▎  | 671/923 [00:10<00:07, 32.93it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 27.82it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 29.77it/s]Predicting...:  75%|███████▌  | 696/923 [00:11<00:08, 26.76it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 34.32it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 35.34it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 42.61it/s]Predicting...:  80%|████████  | 742/923 [00:12<00:03, 51.56it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 37.43it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:04, 38.86it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:03, 49.58it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 53.07it/s]Predicting...:  87%|████████▋ | 800/923 [00:13<00:01, 63.40it/s]Predicting...:  88%|████████▊ | 815/923 [00:13<00:01, 72.33it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.21it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 53.90it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 65.40it/s]Predicting...:  93%|█████████▎| 862/923 [00:14<00:00, 63.70it/s]Predicting...:  95%|█████████▌| 878/923 [00:14<00:00, 78.40it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 81.60it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 93.55it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 60.66it/s]
2025-05-27 20:26:17,811 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.94, ppl:   2.55, acc:   0.73, generation: 15.2163[sec], evaluation: 0.0000[sec]
2025-05-27 20:26:18,148 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/75500.ckpt
2025-05-27 20:26:18,166 - INFO - joeynmt.training - Example #0
2025-05-27 20:26:18,168 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:26:18,168 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:26:18,168 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due di<unk> @ ti per fare queste due di<unk> @ ta per di<unk> @ mostr<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio di g<unk> @ hi<unk> @ ac<unk> @ cio , che l&apos; ho av<unk> @ uto 4<unk> @ 0 milioni di persone che aveva fatto per tre milioni di due milioni di persone , che aveva 4<unk> @ 0 % , il 4<unk> @ 0 % di c<unk> @ ento .
2025-05-27 20:26:18,168 - INFO - joeynmt.training - Example #1
2025-05-27 20:26:18,169 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:26:18,169 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:26:18,169 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza for<unk> @ te la ter<unk> @ n<unk> @ ità di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di questo part<unk> @ icol<unk> @ are probl<unk> @ emi di g<unk> @ hi<unk> @ ac<unk> @ cio .
2025-05-27 20:26:18,169 - INFO - joeynmt.training - Example #2
2025-05-27 20:26:18,170 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:26:18,170 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:26:18,170 - INFO - joeynmt.training - 	Hypothesis: In cer<unk> @ to , il sen<unk> @ so è il sistema di g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico , il cu<unk> @ ore c<unk> @ atti<unk> @ vo del nostro sistema c<unk> @ li<unk> @ m<unk> @ ass<unk> @ ico glob<unk> @ ale .
2025-05-27 20:26:18,170 - INFO - joeynmt.training - Example #3
2025-05-27 20:26:18,171 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:26:18,171 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:26:18,171 - INFO - joeynmt.training - 	Hypothesis: Si può cres<unk> @ c<unk> @ ere in est<unk> @ ate e in<unk> @ ver<unk> @ no .
2025-05-27 20:26:18,171 - INFO - joeynmt.training - Example #4
2025-05-27 20:26:18,171 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:26:18,172 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:26:18,172 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ mostr<unk> @ er<unk> @ ò è una di<unk> @ seg<unk> @ na di di<unk> @ seg<unk> @ na che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:26:21,474 - INFO - joeynmt.training - Epoch  10, Step:    78100, Batch Loss:     0.969628, Batch Acc: 0.736553, Tokens per Sec:    22033, Lr: 0.000210
2025-05-27 20:26:24,799 - INFO - joeynmt.training - Epoch  10, Step:    78200, Batch Loss:     0.910857, Batch Acc: 0.739438, Tokens per Sec:    24211, Lr: 0.000210
2025-05-27 20:26:28,055 - INFO - joeynmt.training - Epoch  10, Step:    78300, Batch Loss:     0.842467, Batch Acc: 0.740211, Tokens per Sec:    24720, Lr: 0.000210
2025-05-27 20:26:31,234 - INFO - joeynmt.training - Epoch  10, Step:    78400, Batch Loss:     0.938072, Batch Acc: 0.738290, Tokens per Sec:    24681, Lr: 0.000210
2025-05-27 20:26:34,524 - INFO - joeynmt.training - Epoch  10, Step:    78500, Batch Loss:     0.902632, Batch Acc: 0.736565, Tokens per Sec:    23764, Lr: 0.000210
2025-05-27 20:26:34,524 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:26:34,524 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   1%|▏         | 13/923 [00:00<00:11, 76.72it/s]Predicting...:   3%|▎         | 27/923 [00:00<00:08, 101.67it/s]Predicting...:   5%|▍         | 42/923 [00:00<00:08, 108.05it/s]Predicting...:   6%|▌         | 56/923 [00:00<00:07, 109.74it/s]Predicting...:   8%|▊         | 72/923 [00:00<00:08, 94.85it/s] Predicting...:  11%|█▏        | 104/923 [00:01<00:09, 82.01it/s]Predicting...:  14%|█▍        | 127/923 [00:01<00:12, 62.57it/s]Predicting...:  16%|█▌        | 146/923 [00:02<00:13, 56.75it/s]Predicting...:  17%|█▋        | 160/923 [00:02<00:11, 63.94it/s]Predicting...:  20%|██        | 185/923 [00:02<00:08, 85.31it/s]Predicting...:  22%|██▏       | 201/923 [00:02<00:07, 92.99it/s]Predicting...:  24%|██▍       | 224/923 [00:02<00:09, 76.62it/s]Predicting...:  25%|██▌       | 235/923 [00:03<00:10, 64.38it/s]Predicting...:  27%|██▋       | 249/923 [00:03<00:09, 70.49it/s]Predicting...:  28%|██▊       | 258/923 [00:03<00:11, 56.30it/s]Predicting...:  29%|██▉       | 267/923 [00:03<00:12, 53.98it/s]Predicting...:  30%|███       | 277/923 [00:04<00:12, 51.91it/s]Predicting...:  31%|███▏      | 289/923 [00:04<00:13, 47.29it/s]Predicting...:  33%|███▎      | 302/923 [00:04<00:11, 52.04it/s]Predicting...:  34%|███▍      | 314/923 [00:04<00:10, 55.52it/s]Predicting...:  35%|███▌      | 327/923 [00:04<00:10, 56.83it/s]Predicting...:  37%|███▋      | 337/923 [00:05<00:11, 52.32it/s]Predicting...:  38%|███▊      | 347/923 [00:05<00:11, 49.77it/s]Predicting...:  39%|███▉      | 361/923 [00:05<00:09, 60.05it/s]Predicting...:  41%|████      | 379/923 [00:05<00:06, 77.84it/s]Predicting...:  43%|████▎     | 393/923 [00:05<00:06, 85.16it/s]Predicting...:  44%|████▍     | 408/923 [00:05<00:05, 87.31it/s]Predicting...:  46%|████▌     | 424/923 [00:06<00:05, 96.72it/s]Predicting...:  48%|████▊     | 441/923 [00:06<00:04, 103.09it/s]Predicting...:  49%|████▉     | 455/923 [00:06<00:04, 98.55it/s] Predicting...:  51%|█████     | 469/923 [00:06<00:04, 99.31it/s]Predicting...:  52%|█████▏    | 480/923 [00:06<00:05, 85.46it/s]Predicting...:  54%|█████▎    | 494/923 [00:06<00:05, 78.96it/s]Predicting...:  54%|█████▍    | 503/923 [00:07<00:06, 62.16it/s]Predicting...:  56%|█████▌    | 517/923 [00:07<00:06, 66.06it/s]Predicting...:  58%|█████▊    | 531/923 [00:07<00:05, 72.07it/s]Predicting...:  59%|█████▊    | 540/923 [00:07<00:06, 58.19it/s]Predicting...:  59%|█████▉    | 548/923 [00:08<00:07, 47.81it/s]Predicting...:  60%|██████    | 556/923 [00:08<00:09, 40.54it/s]Predicting...:  62%|██████▏   | 568/923 [00:08<00:09, 38.62it/s]Predicting...:  63%|██████▎   | 580/923 [00:08<00:07, 46.55it/s]Predicting...:  64%|██████▎   | 587/923 [00:09<00:09, 37.29it/s]Predicting...:  65%|██████▍   | 596/923 [00:09<00:09, 35.57it/s]Predicting...:  66%|██████▌   | 605/923 [00:09<00:08, 38.86it/s]Predicting...:  67%|██████▋   | 618/923 [00:09<00:06, 49.70it/s]Predicting...:  68%|██████▊   | 630/923 [00:10<00:06, 48.57it/s]Predicting...:  69%|██████▉   | 639/923 [00:10<00:06, 43.84it/s]Predicting...:  70%|███████   | 647/923 [00:10<00:06, 40.11it/s]Predicting...:  71%|███████   | 653/923 [00:10<00:08, 31.51it/s]Predicting...:  72%|███████▏  | 661/923 [00:11<00:08, 29.69it/s]Predicting...:  73%|███████▎  | 671/923 [00:11<00:07, 33.77it/s]Predicting...:  73%|███████▎  | 678/923 [00:11<00:08, 29.17it/s]Predicting...:  74%|███████▍  | 687/923 [00:11<00:07, 31.89it/s]Predicting...:  75%|███████▌  | 696/923 [00:12<00:08, 28.34it/s]Predicting...:  77%|███████▋  | 708/923 [00:12<00:06, 35.52it/s]Predicting...:  78%|███████▊  | 717/923 [00:12<00:05, 34.53it/s]Predicting...:  79%|███████▉  | 729/923 [00:12<00:04, 41.99it/s]Predicting...:  80%|████████  | 742/923 [00:13<00:03, 50.88it/s]Predicting...:  81%|████████  | 749/923 [00:13<00:04, 41.54it/s]Predicting...:  82%|████████▏ | 759/923 [00:13<00:03, 43.03it/s]Predicting...:  84%|████████▍ | 774/923 [00:13<00:02, 54.00it/s]Predicting...:  85%|████████▌ | 786/923 [00:13<00:02, 59.21it/s]Predicting...:  87%|████████▋ | 800/923 [00:14<00:01, 66.94it/s]Predicting...:  88%|████████▊ | 815/923 [00:14<00:01, 77.17it/s]Predicting...:  90%|████████▉ | 827/923 [00:14<00:01, 72.74it/s]Predicting...:  90%|█████████ | 835/923 [00:14<00:01, 53.32it/s]Predicting...:  92%|█████████▏| 850/923 [00:14<00:01, 64.10it/s]Predicting...:  93%|█████████▎| 862/923 [00:15<00:00, 61.65it/s]Predicting...:  95%|█████████▌| 878/923 [00:15<00:00, 76.83it/s]Predicting...:  97%|█████████▋| 892/923 [00:15<00:00, 85.86it/s]Predicting...:  98%|█████████▊| 908/923 [00:15<00:00, 94.01it/s]Predicting...: 100%|██████████| 923/923 [00:15<00:00, 59.26it/s]
2025-05-27 20:26:50,114 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   0.93, ppl:   2.54, acc:   0.73, generation: 15.5761[sec], evaluation: 0.0000[sec]
2025-05-27 20:26:50,115 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-27 20:26:50,630 - INFO - joeynmt.helpers - delete models/bpe_2k_de_it/76000.ckpt
2025-05-27 20:26:50,654 - INFO - joeynmt.training - Example #0
2025-05-27 20:26:50,655 - INFO - joeynmt.training - 	Source:     L@@ etz@@ t@@ es Jahr habe ich diese bei@@ den F@@ ol@@ ien ge@@ zei@@ gt , um zu ver@@ an@@ sch@@ au@@ lichen , dass die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e , die für ann@@ ä@@ her@@ n@@ d drei Milli@@ onen Jahre die Gr@@ ö@@ s@@ se der unter@@ en 4@@ 8 St@@ a@@ aten hatte , um 4@@ 0 Proz@@ ent gesch@@ r@@ um@@ p@@ ft ist .
2025-05-27 20:26:50,655 - INFO - joeynmt.training - 	Reference:  L&apos; anno sc@@ or@@ so ho mostr@@ ato queste di@@ apos@@ iti@@ ve per di@@ mostr@@ are che la cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica , che per qu@@ asi tre milioni di anni ha av@@ uto le di@@ men@@ si@@ oni dei 4@@ 8 St@@ ati Un@@ iti cont@@ in@@ ent@@ ali , si è ri@@ str@@ et@@ ta del 4@@ 0 % .
2025-05-27 20:26:50,655 - INFO - joeynmt.training - 	Hypothesis: L&apos; anno sc<unk> @ or<unk> @ so ho mostr<unk> @ ato questi due di<unk> @ ti per di<unk> @ mostr<unk> @ are che il g<unk> @ hi<unk> @ ac<unk> @ cio ar<unk> @ t<unk> @ ico che gli ar<unk> @ t<unk> @ t<unk> @ av<unk> @ olo per tre milioni di anni , che aveva tre milioni di anni , per il 4<unk> @ 0 per c<unk> @ ento di tre milioni di anni , il 4<unk> @ 0 per c<unk> @ ento .
2025-05-27 20:26:50,655 - INFO - joeynmt.training - Example #1
2025-05-27 20:26:50,656 - INFO - joeynmt.training - 	Source:     Aber dies dr@@ üc@@ kt nicht star@@ k gen@@ u@@ g die Er@@ n@@ st@@ ha@@ f@@ tig@@ keit dieses spe@@ zi@@ ellen Probl@@ em@@ s aus , da es nicht die D@@ ic@@ ke des E@@ is@@ es zei@@ gt .
2025-05-27 20:26:50,656 - INFO - joeynmt.training - 	Reference:  T@@ utt@@ a@@ via questo s@@ ott@@ ov@@ al@@ ut@@ a la gr@@ av@@ ità del problema perché non mostr@@ a lo sp@@ ess@@ ore del g@@ hi@@ ac@@ cio .
2025-05-27 20:26:50,656 - INFO - joeynmt.training - 	Hypothesis: Ma non è abb<unk> @ ast<unk> @ anza in<unk> @ tel<unk> @ li<unk> @ gente di questo spe<unk> @ ci<unk> @ ale spe<unk> @ ci<unk> @ ale , perché non è il D<unk> @ ic<unk> @ e<unk> @ an<unk> @ o .
2025-05-27 20:26:50,657 - INFO - joeynmt.training - Example #2
2025-05-27 20:26:50,657 - INFO - joeynmt.training - 	Source:     In ge@@ wis@@ s@@ em S@@ in@@ ne ist die ar@@ kt@@ ische E@@ is@@ k@@ app@@ e das schl@@ ag@@ ende Her@@ z unser@@ es glob@@ alen K@@ li@@ m@@ as@@ yst@@ em@@ s .
2025-05-27 20:26:50,657 - INFO - joeynmt.training - 	Reference:  La cal@@ ot@@ ta gl@@ a@@ ci@@ ale ar@@ t@@ ica è , in un cer@@ to sen@@ so , il cu@@ ore p@@ ul@@ s@@ ante del sistema c@@ li@@ mat@@ ico glob@@ ale .
2025-05-27 20:26:50,657 - INFO - joeynmt.training - 	Hypothesis: In un cer<unk> @ to sen<unk> @ so , la f<unk> @ att<unk> @ or<unk> @ ia ar<unk> @ t<unk> @ ica è la c<unk> @ atti<unk> @ va del nostro sistema c<unk> @ li<unk> @ mat<unk> @ ico glob<unk> @ ale .
2025-05-27 20:26:50,658 - INFO - joeynmt.training - Example #3
2025-05-27 20:26:50,658 - INFO - joeynmt.training - 	Source:     Sie w@@ äch@@ st im W@@ in@@ ter und sch@@ r@@ um@@ p@@ ft im S@@ om@@ mer .
2025-05-27 20:26:50,658 - INFO - joeynmt.training - 	Reference:  Si es@@ p@@ an@@ de d&apos; in@@ ver@@ no e si rit@@ ir@@ a d&apos; est@@ ate .
2025-05-27 20:26:50,658 - INFO - joeynmt.training - 	Hypothesis: S<unk> @ al<unk> @ a s<unk> @ v<unk> @ eg<unk> @ li<unk> @ are nel v<unk> @ ento e sp<unk> @ or<unk> @ ti<unk> @ vo .
2025-05-27 20:26:50,658 - INFO - joeynmt.training - Example #4
2025-05-27 20:26:50,659 - INFO - joeynmt.training - 	Source:     Die näch@@ ste F@@ ol@@ ie , die ich Ihnen zei@@ ge , ist eine Z@@ ei@@ tra@@ ff@@ er@@ auf@@ nah@@ me was in den letz@@ ten 2@@ 5 Jahren passiert ist .
2025-05-27 20:26:50,659 - INFO - joeynmt.training - 	Reference:  La pros@@ si@@ ma di@@ apos@@ iti@@ va sar@@ à una rap@@ i@@ da car@@ r@@ ell@@ ata su@@ gli av@@ ven@@ im@@ enti degli ulti@@ mi 2@@ 5 anni .
2025-05-27 20:26:50,659 - INFO - joeynmt.training - 	Hypothesis: La pros<unk> @ si<unk> @ ma di<unk> @ apos<unk> @ iti<unk> @ va che vi mostr<unk> @ o è una di<unk> @ seg<unk> @ na di di<unk> @ seg<unk> @ na che è succ<unk> @ esso negli ulti<unk> @ mi 2<unk> @ 5 anni .
2025-05-27 20:26:54,002 - INFO - joeynmt.training - Epoch  10, Step:    78600, Batch Loss:     0.870978, Batch Acc: 0.738446, Tokens per Sec:    20338, Lr: 0.000210
2025-05-27 20:26:57,363 - INFO - joeynmt.training - Epoch  10, Step:    78700, Batch Loss:     0.962496, Batch Acc: 0.740699, Tokens per Sec:    23842, Lr: 0.000210
2025-05-27 20:27:00,701 - INFO - joeynmt.training - Epoch  10, Step:    78800, Batch Loss:     0.971170, Batch Acc: 0.741172, Tokens per Sec:    23694, Lr: 0.000210
2025-05-27 20:27:02,515 - INFO - joeynmt.training - Epoch  10: total training loss 7099.63
2025-05-27 20:27:02,515 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-27 20:27:02,515 - INFO - joeynmt.training - Best validation result (greedy) at step    78500:   2.54 ppl.
2025-05-27 20:27:02,535 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-27 20:27:02,579 - INFO - joeynmt.model - Enc-dec model built.
2025-05-27 20:27:02,664 - INFO - joeynmt.helpers - Load model from /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/78500.ckpt.
2025-05-27 20:27:02,680 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2000),
	loss_function=None)
2025-05-27 20:27:02,689 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-27 20:27:02,689 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:27:02,689 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/923 [00:00<?, ?it/s]Predicting...:   7%|▋         | 64/923 [00:01<00:16, 51.59it/s]Predicting...:  14%|█▍        | 128/923 [00:04<00:26, 29.58it/s]Predicting...:  21%|██        | 192/923 [00:05<00:21, 34.80it/s]Predicting...:  28%|██▊       | 256/923 [00:06<00:17, 37.80it/s]Predicting...:  35%|███▍      | 320/923 [00:08<00:15, 38.05it/s]Predicting...:  42%|████▏     | 384/923 [00:10<00:13, 40.10it/s]Predicting...:  49%|████▊     | 448/923 [00:11<00:11, 42.61it/s]Predicting...:  55%|█████▌    | 512/923 [00:13<00:10, 40.70it/s]Predicting...:  62%|██████▏   | 576/923 [00:14<00:08, 38.83it/s]Predicting...:  69%|██████▉   | 640/923 [00:17<00:08, 34.25it/s]Predicting...:  76%|███████▋  | 704/923 [00:20<00:07, 28.31it/s]Predicting...:  83%|████████▎ | 768/923 [00:22<00:05, 29.13it/s]Predicting...:  90%|█████████ | 832/923 [00:24<00:02, 32.00it/s]Predicting...:  97%|█████████▋| 896/923 [00:25<00:00, 36.98it/s]Predicting...: 100%|██████████| 923/923 [00:25<00:00, 39.84it/s]Predicting...: 100%|██████████| 923/923 [00:25<00:00, 36.17it/s]
2025-05-27 20:27:28,217 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 25.5199[sec], evaluation: 0.0000[sec]
2025-05-27 20:27:28,221 - INFO - joeynmt.prediction - Translations saved to: /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/00078500.hyps.dev.
2025-05-27 20:27:28,221 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-27 20:27:28,221 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-27 20:27:28,221 - INFO - joeynmt.prediction - Predicting 1567 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
Predicting...:   0%|          | 0/1567 [00:00<?, ?it/s]Predicting...:   4%|▍         | 64/1567 [00:01<00:26, 55.81it/s]Predicting...:   8%|▊         | 128/1567 [00:02<00:21, 65.61it/s]Predicting...:  12%|█▏        | 192/1567 [00:02<00:19, 70.21it/s]Predicting...:  16%|█▋        | 256/1567 [00:03<00:18, 71.77it/s]Predicting...:  20%|██        | 320/1567 [00:04<00:20, 62.20it/s]Predicting...:  25%|██▍       | 384/1567 [00:06<00:21, 55.54it/s]Predicting...:  29%|██▊       | 448/1567 [00:07<00:19, 56.04it/s]Predicting...:  33%|███▎      | 512/1567 [00:09<00:21, 49.84it/s]Predicting...:  37%|███▋      | 576/1567 [00:09<00:17, 55.32it/s]Predicting...:  41%|████      | 640/1567 [00:10<00:14, 65.17it/s]Predicting...:  45%|████▍     | 704/1567 [00:11<00:12, 67.66it/s]Predicting...:  49%|████▉     | 768/1567 [00:12<00:12, 64.34it/s]Predicting...:  53%|█████▎    | 832/1567 [00:14<00:14, 51.61it/s]Predicting...:  57%|█████▋    | 896/1567 [00:15<00:13, 50.62it/s]Predicting...:  61%|██████▏   | 960/1567 [00:16<00:12, 49.91it/s]Predicting...:  65%|██████▌   | 1024/1567 [00:18<00:10, 52.26it/s]Predicting...:  69%|██████▉   | 1088/1567 [00:19<00:09, 49.84it/s]Predicting...:  74%|███████▎  | 1152/1567 [00:20<00:08, 49.83it/s]Predicting...:  78%|███████▊  | 1216/1567 [00:21<00:06, 51.92it/s]Predicting...:  82%|████████▏ | 1280/1567 [00:23<00:05, 50.06it/s]Predicting...:  86%|████████▌ | 1344/1567 [00:24<00:04, 51.75it/s]Predicting...:  90%|████████▉ | 1408/1567 [00:25<00:03, 48.93it/s]Predicting...:  94%|█████████▍| 1472/1567 [00:27<00:02, 43.46it/s]Predicting...:  98%|█████████▊| 1536/1567 [00:29<00:00, 38.67it/s]Predicting...: 100%|██████████| 1567/1567 [00:30<00:00, 37.21it/s]Predicting...: 100%|██████████| 1567/1567 [00:30<00:00, 50.89it/s]
2025-05-27 20:27:59,024 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 30.7910[sec], evaluation: 0.0000[sec]
2025-05-27 20:27:59,030 - INFO - joeynmt.prediction - Translations saved to: /home/user/amsler/mt-exercise-4/models/bpe_2k_de_it/00078500.hyps.test.
